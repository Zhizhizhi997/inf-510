{"0": {"company": "Walmart eCommerce", "description": "Position Description\n\nData Scientist is responsible for analyzing large data sets to develop custom models and algorithms to drive business solutions. Data Scientists work on project teams in order to provide analytical support to projects for Walmart eCommerce. Data Scientists are responsible for building large data sets from multiple sources in order to build algorithms for predicting future data characteristics. Those algorithms will be tested, validated, and applied to large data sets. Data Scientists are responsible for training the algorithms so they can be applied to future data sets and provide the appropriate search results. Data Scientists are responsible for researching new trends in the industry and utilizing up-to-date technology\n\nMinimum Qualifications\n\n\u2022 Proficiency in machine learning algorithms such as multi-class classifications, decision trees, support vector machines and deep learning\n\u2022 Strong understanding of probability and statistical models (generative and descriptive models)\n\u2022 Ability to run experiments scientifically and analyze results\n\u2022 Ability to effectively communicate technical concepts and results to technical and business audiences in a comprehensive manner\n\u2022 Ability to collaborate effectively across multiple teams and stakeholders, including analytics teams, development teams, product management and operations\n\u2022 Understands and translates business and functional needs into data scientist problem statements\n\u2022 Build complex data sets from multiple data sources, both internally and externally.\n\u2022 Develop custom data models to drive innovative business solutions.\n\u2022 Write complex queries and extract data to build database architecture. Integrate data products into dashboards and user interfaces as needed, by collaborating with the engineering team\n\u2022 Sift and analyze data from multiple angles, looking for trends that highlight problems or opportunities\n\u2022 Use strong business acumen, as well as an ability to communicate findings and mine vast amounts of data for useful insights\n\u2022 Apply innovative and scientific/quantitative analytical approaches to draw conclusions and make recommendations to answer business objectives\n\nAdditional Preferred Qualifications\n\n\u2022 1-3 years experience in building ML based models\n\u2022 Strong CS fundamentals in algorithms, data structures, OOPS, functional programming.\n\u2022 Strong Experience with Big Data processing (Bigquery / Hive/ Hadoop/ HDFS/ Spark)\n\u2022 Productionize the developed Machine Learning solutions\n\u2022 Hands on Experience with GCP Cloud ( Dataflow, Dataproc, ML Engine, Datalabs, Kubeflows)\n\u2022 Strong background in ML algorithms for time series datasets.\n\u2022 Strong background in Statistics.\n\u2022 Familiarity with Deep Learning algorithms.\n\u2022 Strong knowledge and experience with Databases (Relational Maria/Mysql and NoSQL Cassandra/Hbase/Bigtable)\n\u2022 Expert knowledge and experience with Java/Scala/Python\n\u2022 String grasp of principles and approaches used in Data-driven systems, processes and algorithms\n\u2022 Scripting skills in at least one of the following: Shell, Perl, Python, Bash, or Ruby\n\u2022 Experience with Performance Engineering including testing, tuning and monitoring tools.\nEducation Requirements\n\u2022 Bachelor's degree in data science, applied mathematics, computer science or otherwise research-based field; Masters degree required.\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nData Scientist is responsible for analyzing large data sets to develop custom models and algorithms to drive business solutions. Data Scientists work on project teams in order to provide analytical support to projects for Walmart eCommerce. Data Scientists are responsible for building large data sets from multiple sources in order to build algorithms for predicting future data characteristics. Those algorithms will be tested, validated, and applied to large data sets. Data Scientists are responsible for training the algorithms so they can be applied to future data sets and provide the appropriate search results. Data Scientists are responsible for researching new trends in the industry and utilizing up-to-date technology\nApply Now: click Apply Now"}, "1": {"company": "Qualia Investments", "description": "Qualia Investments is a proprietary trading desk that leverages technology to enter volatile, underdeveloped markets. We believe that the influence of consumer buying patterns has created an \u2018Experience Economy\u2019 in certain retail markets, where assets are traded on a latitude of secondary exchanges. Trading assets reliant on outdated, retail-oriented infrastructure creates significant friction to market participants. However, it welcomes disruption through product innovation and market insight.\n\nThe software engineering team works closely with the rest of the firm, building tools, exploring trading ideas, and designing as well as maintaining the firm\u2019s software systems. We are a liquidity provider and a market accelerator, rapidly deploying products and insights to create new stakeholder opportunities. Our team works tirelessly to develop strategies that help us understand the black box of consumer behavior and the role experience plays in price-value theory.\n\nOur team is composed of traders and hackers working together to solve complex, abstract problems. Our office culture is unique and we embrace individuality and diversity of thought, encouraging our employees to take risks and expand expertise within a comfortable environment. We encourage those to apply who are passionate about self-learning and the non-traditional workplace.\nYou will:\nPolish our in-house trading dashboard into enterprise products that fit a variety of clients\u2019 needs\nDistill loose ideas into valuable data products\nIdentify and incorporate new data sources into our platform\nBuild and maintain ETL pipelines in Apache Airflow\nYou will need a background in:\nPython (2+ years software development experience)\nData modeling\nExposure to a task scheduler (Airflow, Luigi, etc)\nAbility to architect solutions in the cloud (preferably on AWS)\nDocker\nCI/CD\nNice to Haves:\nExperience with AWS lambda, or other FaaS platforms\nFamiliarity with React\nOur hiring is non-discriminatory to race, age, gender, background or experience. We embrace diversity of thought and intentionally hire from a wide array of backgrounds.\nBenefits & Culture\n100% coverage of health, vision and dental insurance\n401K employer match (3%)\nStock Options\nFrequent (optional) team events\nUnlimited PTO\nCommunal space with full scale-kitchen, lounge and quiet corners\nStart your job application: click Easy Apply"}, "2": {"company": "Avero", "description": "POSITION OVERVIEW\nAs a Data Science Modeler, you will be a key player in building out and deploying ML algorithms within the Avero Data Science team. You will have the opportunity to leverage Avero\u2019s robust historical/real time datasets and machine learning infrastructure to develop and tackle the complex business problems our customers face. You will work with ml-engineers, ml-ops engineers and product managers to develop and iterate on models that power Avero\u2019s intelligence suite of innovative solutions.\nWHAT YOU'LL DO\nActively develop Avero\u2019s machine learning features and analytical insights that enhance the hospitality experience provided by - Avero\u2019s customers\nRefine and enhance Avero\u2019s batch and real-time analytical algorithms, predictive models and machine intelligence\nBuild models for next generation accurate sales forecasting, inventory management, labor scheduling, fraud detection and benchmarking algorithms\nHave a passionate drive for the mission of Avero\nWHAT YOU'LL NEED\nMS/PhD in Statistics or Operations Research or a similar analytical field\nDeep understanding and knowledge of probability and statistics including statistical inference, hypothesis testing, maximum likelihood estimation, confidence intervals and A/B testing\nSolid expertise writing queries in SQL\nExperience building time series models and natural language processing algorithms\nGood programming experience building statistical algorithms with R and/or Python\nKeen ability to structure business problems in an analytical framework and explain solutions and results to general stake holders\nReady to dive into messy data and write reusable modules to extract features and build models\nAbility to handle multiple competing priorities in a fast-paced environment\nDeep understanding of how culture and team dynamics create exceptional teams\n3+ years\u2019 experience building statistical models required\nWHY YOU'LL LOVE WORKING AT AVERO\nHigh-growth company that is working to revolutionize hospitality\nOpportunity to work with, and drive, bleeding edge intelligence systems.\nCompetitive compensation, coupled with an emphasis on work/life balance.\nComprehensive benefits coverage (including medical, dental, and vision insurance), an FSA for tax free healthcare/dependent care expenses, 401k employer match, and 4 weeks of 100% paid parental leave.\nA fun, dynamic office, including an open floor plan, an intellectually curious and passionate team, and a fully-stocked kitchen.\nTuition reimbursement stipend, encouraging employees to pursue job-related degrees and coursework.\nEquity in the company \u2013 all employees have a stake in our growth.\nQuarterly cookoffs, Avero happy hours, and many more food-inspired events.\nAvero is proud to be an equal opportunity employer, dedicated to pursuing and hiring a diverse workforce."}, "3": {"company": "Jordan's Furniture", "description": "Organized, Detail Oriented, Multi-tasker, Self-Starter, and works well under pressure; these are some of the qualities we are looking for in our newest member of our growing ecommerce team! Here is a unique opportunity to join a proud and GROWING Berkshire Hathaway company that is well-known in the industry for its creative advertising and employee-focused culture. Reporting to the Director of eCommerce, the Web Analytics Manager is responsible for delivering the best-in-class web analytics aimed at understanding the customer journey and conversion trends, drive sales, as well as, proactively identify optimization opportunities to champion for execution. Partners with cross-functional stakeholders to assess actual vs. expected performance. Please note this job is located at our corporate offices: 450 Revolutionary Drive, East Taunton, MA.\n\nImproves the customer experience and drives sales by developing a deep understanding of our customer behavior on Jordans.com through detailed analytics\nTransforms business questions into actionable analysis that yields insights for improving the UX, optimizing marketing efforts, and driving incremental sales\nPartners in the management and strategy to drive forward a holistic A/B testing plan in effort to optimize the customer experience and provide more personalized content\nAssists in eCommerce investment decisions by evaluating and forecasting digital behavior\nScopes the impact of strategic initiatives as an input into eCommerce roadmap planning\nPro-actively identifies areas of opportunity through standard reporting or deep dive analysis\nBuilds and maintains dashboards, tools, and measurement systems to optimize key functions, including but not limited to traffic, UX, and conversion funnels\nStays current on trends and best practices in digital analytics and eCommerce\n\nThe qualified candidate must have:\nB.S. degree in Computer Science, Business, Statistics, or related discipline required\n5+ years of relevant experience required\nHigh level of business acumen. Retail/eCommerce industry knowledge required\nExperience with digital analytics, like Google or Adobe Analytics\nProficiency in SQL and knowledge of database models\nStrong proficiency in Microsoft Office\nAgile Excel skills (pivots, index match, offset, etc.) required\nExperience with programming languages (SQL/Python/VBA ) to facilitate automation a plus\nExcellent critical thinking, problem solving, and communication skills required\nAbility to adapt to changing trends of the business\nExcellent interpersonal and communication skills with the ability to collaborate, and influence others\nEffective relationship building skills\nHappy, healthy employees are our goal, and our benefits help J-Team members balance physical, financial, professional, social and emotional well-being. Visit our benefits page for more details.\nIf you're ready to make a difference in your career, we are interested in speaking with you!\nJordan\u2019s Furniture is an Equal Opportunity Employer\nTo apply to this job, click Apply Now"}, "4": {"company": "Runyon Saltzman", "description": "With direction, provides day-to-day support for agency digital marketing programs, either alone or as a member of a team. This includes collecting, maintaining, and analyzing data for digital marketing accounts, and providing recommendations based on insights gathered.\nESSENTIAL FUNCTIONS\nThe following reflects management\u2019s definition of essential functions for this job but does not restrict the tasks that may be assigned. Management may assign or reassign duties and responsibilities to this job at any time, including for reasonable accommodation purposes.\nCollect and analyze data from multiple studies using appropriate statistical methods (i.e. descriptive statistics, cross-tabulation, correlation), identifying trends and drawing conclusions taking into account secondary sources and industry knowledge\nSynthesize multi-study results, preparing detailed and accurate written reports (including data tables, charts, and graphics) with actionable insights for presentation to clients and media team\nExperience in digital marketing platforms including Google Ads, Google Analytics, Google Data Studio, Google Tag Manager and A/B Testing\nRecommend and oversee implementation of the most effective digital communications within client budgets for assigned agency clients\nConstantly explore new digital options, platforms and analyze for client benefit\nUpdate clients/agency with digital media trends and topics (integrate with other media\nBe visible in the community (ex: member of boards, events, nonprofits or associations)\nExcel at collaboration and communication with creative and client services\nAdvocate for new business opportunities; develop and utilize network of reps\nPlan, create, communicate and evaluate client digital marketing campaigns for successful outcomes\n\nKNOWLEDGE/SKILLS/ABILITIES\nExcellent written and verbal communication skills\nExpert knowledge of Microsoft Office Suite including Excel, PowerPoint, and Word\nExpert knowledge of Google marketing tools including Google Ads, Google Analytics, Google Data Studio and Google Tag Manager\nConvincing presentation skills\nAble to manage client expectations\nKnowledge of digital media planning process, digital media buying process and website project management\nStrong organizational, mathematical, problem solving and analytical skills\nAble to handle multiple projects and meet deadlines\nAble to engage effectively with diverse individuals at all levels\n\nQUALIFICATIONS\nFive plus years of related experience\nAdvanced knowledge of digital platforms\nEDUCATION\nBachelor's degree from four-year college or university or equivalent experience.\nWORKING CONDITIONS\nAble to lift and/or move 10 \u2013 25 pounds.\nEqual time spent sitting/standing, frequently required to walk.\n\nIf you are interested in this positon, please a apply at the following URL -\n\nhttps://www.paycomonline.net/v4/ats/web.php/jobs/ViewJobDetails?job=15516&clientkey=C67FC4335AD080F01C82CA9A44F5A930 or go to rs-e.com/jobs\nApply Now: click Easy Apply"}, "5": {"company": "Freed Maxick", "description": "Business Intelligence Analyst\n\n\nThe Business Intelligence Analyst will lead conversations with clients to define business requirements, have a hands-on role in developing Tableau dashboards to satisfy requirements, and training clients on effective use of dashboards. Additionally, this position will provide support for internal Business Intelligence Subject-Matter Experts (SMEs), whose role it is to engage clients proactively, and to identify and bring forward key observations derived from the aforementioned Business Intelligence (BI) solutions.\n\nDirect Responsibilities:\nAnalyze data, identify anomalies, and provide useable insight to internal and external clients.\nAddress external client data requests, including: project scope, consultation, conception, production, and end-user delivery.\nBuild custom data deliveries using Tableau Software.\nStay current with data analytics/business intelligence techniques and technologies.\nMaintain positive, professional business acumen and relationships with the company cross-functional teams and external customers.\nCollaborate with SMEs and clients on interpreting data and identifying opportunities evident in BI solution.\nRequirements:\nBS in Finance, Accounting, Economics, Statistics, Decision Sciences, Information Technology, Economics, Physics, Mathematics, or similar field\n3-5 years of professional business experience\n2 years\u2019 analytical experience (with exposure to BI tools)\nExperience utilizing Business Intelligence software, preferably Tableau Software\nWorking knowledge of MS SQL and Excel\nExperience working with both internal and external client data requests\nStrong communication skills\nPositive attitude and team oriented-mentality.\nSend cover letter, resume and requested salary range in confidence to career@freedmaxick.com\n\neoe\n\nSend cover letter, resume and salary requirements\nto career@freedmaxick.com.\nApply Online\n\nApply Now: click Easy Apply"}, "6": {"company": "Walmart eCommerce", "description": "Position Description\n\n\u2022 Understands and translates business and functional needs into data scientist problem statements\n\u2022 Build complex data sets from multiple data sources, both internally and externally.\n\u2022 Develop custom data models to drive innovative business solutions.\n\u2022 Write complex queries and extract data to build database architecture. Integrate data products into dashboards and user interfaces as needed, by collaborating with engineering team\n\u2022 Sift and analyze data from multiple angles, looking for trends that highlight problems or opportunities\n\u2022 Use strong business acumen, as well as an ability to communicate findings, and mine vast amounts of data for useful insights\n\u2022 Apply innovative and scientific/quantitative analytical approaches to draw conclusions and make recommendations to answer business objectives\\\\\u2022 Proficiency in machine learning algorithms such as multi-class classifications, decision trees, support vector machines, and deep learning\n\u2022 Strong understanding of probability and statistical models (generative and descriptive models)\n\u2022 Ability to run experiments scientifically and analyze results\n\u2022 Ability to effectively communicate technical concepts and results to technical and business audiences in a comprehensive manner\n\u2022 Ability to collaborate effectively across multiple teams and stakeholders, including analytics teams, development teams, product management and operations\n\nMinimum Qualifications\n\n\u2022 1-3 years experience in building ML based models\n\u2022 Strong CS fundamentals in algorithms, data structures, OOPS, functional programming.\n\u2022 Strong Experience with Big Data processing (Bigquery / Hive/ Hadoop/ HDFS/ Spark)\n\u2022 Productionize the developed Machine Learning solutions\n\u2022 Hands on Experience with GCP Cloud ( Dataflow, Dataproc, ML Engine, Datalabs, Kubeflows)\n\u2022 Strong background in ML algorithms for time series datasets.\n\u2022 Strong background in Statistics.\n\u2022 Familiarity with Deep Learning algorithms.\n\u2022 Strong knowledge and experience with Databases (Relational Maria/Mysql and NoSQL Cassandra/Hbase/Bigtable)\n\u2022 Expert knowledge and experience with Java/Scala/Python\n\u2022 String grasp of principles and approaches used in Data-driven systems, processes and algorithms\n\u2022 Scripting skills in at least one of the following: Shell, Perl, Python, Bash, or Ruby\n\u2022 Experience with Performance Engineering including testing, tuning and monitoring tools.\nEducation Requirements\n\u2022 Bachelor's degree in data science, applied mathematics, computer science or otherwise research-based field; Masters degree required.\n\nAdditional Preferred Qualifications\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\n\u2022 Understands and translates business and functional needs into data scientist problem statements\n\u2022 Build complex data sets from multiple data sources, both internally and externally.\n\u2022 Develop custom data models to drive innovative business solutions.\n\u2022 Write complex queries and extract data to build database architecture. Integrate data products into dashboards and user interfaces as needed, by collaborating with the engineering team\n\u2022 Sift and analyze data from multiple angles, looking for trends that highlight problems or opportunities\n\u2022 Use strong business acumen, as well as an ability to communicate findings and mine vast amounts of data for useful insights\n\u2022 Apply innovative and scientific/quantitative analytical approaches to draw conclusions and make recommendations to answer business objectives\\\\\u2022 Proficiency in machine learning algorithms such as multi-class classifications, decision trees, support vector machines, and deep learning\n\u2022 Strong understanding of probability and statistical models (generative and descriptive models)\n\u2022 Ability to run experiments scientifically and analyze results\n\u2022 Ability to effectively communicate technical concepts and results to technical and business audiences in a comprehensive manner\n\u2022 Ability to collaborate effectively across multiple teams and stakeholders, including analytics teams, development teams, product management and operations\nTo apply to this job, click Apply Now"}, "7": {"company": "Verizon", "description": "What you\u2019ll be doing...\n\nThe Consultant in Revenue Assurance is responsible for analysis, insights, observations and decision support for our business leaders in Finance, Marketing, & Network. As a senior level data analyst in Revenue Assurance, the consultant will perform complex data extraction and analysis, develop clear visualizations, and apply data models to deliver results-oriented insights to improve revenue, profitability and customer experience.\n\nThe tools used to perform these advanced analytics functions will vary depending on the nature of the request, but will likely include expert-level SQL (Teradata and/or Oracle) with the REVO Database and Cassandra/Hadoop experience a plus. Emerging data visualization technologies and experience in Tableau is also beneficial.\n\nThe Consultant will also be responsible to lead and manage enterprise level projects, identify risks, develop strategic relationships and design system controls. Candidates will have a strong background in project management and/or systems auditing.\n\nTechnical Leader:\nIndependently manage analytic projects of intermediate to advanced sophistication from design to resolution with minimal oversight.\nLeverage emerging technologies (Big Data) and advanced analytic techniques to create models that identify system risks and failures.\nDesign, develop and implement sophisticated solutions to ensure the ongoing integrity of our revenue streams and customer experience.\nDesign and develop standard and ad hoc reporting based on business requirement needs.\nDirect and coordinate ETL (Extract, Transform, Load), data analysis, and reporting with respect to business intelligence efforts.\nIdentify opportunities for revenue recovery and assist in implementation.\nUtilizing business knowledge, financial analysis skills and risk management techniques, champion efforts to effect changes within the business to ensure subscribers are billed correctly.\nPartner with cross-functional groups across the enterprise in Finance, Marketing, IT, Network and Supply Chain to assess impact and drive critical issue resolution.\nExercise sound judgment in developing methods and techniques that requires data analysis and interpretation.\nDirect the identification and use of appropriate analytical technologies.\nEnsure analytics are captured using dashboard using statistical means, Teradata, and ETL and critical issues are identified and resolved in a timely manner.\nProject Leader:\nLead cross-functional, enterprise level project efforts within Revenue Assurance. Assess risks and identify control processes, design user stories and drive to implementation.\nPartner with cross functional Finance organizations, IT, Marketing, and Product teams to identify issues and drive complex issues to resolution. This includes, but is not limited to:\nLead initiatives in the role of a Subject Matter Expert to resolve problems.\nArticulate and communicate to broad audience with focus on execution.\nDocument and communicate resolution action plans.\nWhat we\u2019re looking for...\n\nYou\u2019re analytical, organized, and detail oriented. A self-starter and quick learner who can work independently, but you\u2019re also great to have on a team. You communicate well with others. You\u2019re no stranger to a fast-paced environment and tight deadlines, and you adapt to changing priorities and juggle multiple projects with ease. You take a lot of pride in your work, and that\u2019s why people count on you to deliver.\n\nYou\u2019ll need to have:\nBachelor\u2019s degree or four or more years of work experience.\nFour or more years of relevant work experience.\nWillingness to work evenings and weekends.\nEven better if you have:\nA degree.\nDemonstrated technicalexperience in billing and accounting practices.\nAdvanced Tableau knowledge.\nDeepknowledge of both Oracle and Teradata, ideally holding a certification in one or more.\nExperience with cellular billing systems.\nLeadership experience with a heightened sense of diplomacy to accomplish significant projects and tasks.\nDemonstrated ability to understand stored data and create SQL statements to extract information.\nStrong desire to ensure accurate recording of company revenues.\nExperience managing multiple project deadline requirements.\nWhen you join Verizon...\n\nYou\u2019ll have the power to go beyond \u2013 doing the work that\u2019s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you\u2019ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we\u2019ll go far.\n\nEqual Employment Opportunity\n\nWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.\n\n]]>\nStart your job application: click Apply Now"}, "8": {"company": "Martin's Famous Pastry Shoppe", "description": "Scan Based Trading Data Analyst Intern\nCity\n\n\nChambersburg\n\nState/Territory\n\n\nPennsylvania\n\nWork Schedule\n\nM-F\n\nJob Brief\n\n\nJoin our team as a Scan Based Trading Data Analyst Intern for Summer of 2020!!\n\nCome join our Team as a Scan Based Trading Data Analyst Intern for Summer of 2020! We started with pastries handmade by Lois and Lloyd Martin produced inside of a garage and we have boomed into a multi-facility company where our many products are produced by machines and shipped domestically and internationally. Talk about a rich history and exciting future! As an employer of choice we offer physical, emotional, financial and professional benefits including 401K, disability insurance and paid holidays.\n\nAs an intern for Martin\u2019s, you would be assisting with all aspects of Scan Based Trading (SBT).\n\nEssential Duties and Responsibilities: (Other duties as assigned.)\nWorks with internal (i.e. sales, MIS, accounting teams) and external stakeholders to ensure smooth SBT rollouts.\nVerifies that all Point of Sale (POS) and SBT credit was properly given.\nAssists in identifying and resolving billing/pricing/shrink issues and resolve in a timely manner.\nRoutinely analyzes and identifies shrink and regularly reports variances at the product, store, route level\nAnalyzes historical sales SBT/POS data to look for inconsistencies and identify business risks\nUtilizes strong analytical skills to communicate discrepancies and suggest ways to resolve issues\nIdentifies and recommends SBT improvements\nReports on a periodic basis shrink settlements including exceptions and issues\nCompiles routine and ad hoc reports using various software tools\nAssists with coordinating SBT/POS communication of information between departments.\nDocuments and maintains written instructions for all SBT processes\nAssists billing, accounts receivable, internal controls team when needed\nReasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\n\nEducation and/or Experience:\nHigh School Diploma or GED;\nPursuing a degree in Accounting, Finance or related area helpful;\nWe are an Equal Opportunity Employer\nStart your job application: click Apply Now"}, "9": {"company": "Sandhills Global", "description": "The Business Intelligence Analyst is responsible for analyzing and reviewing data that is collected in our current and future products and services. Working with our Data Scientist team, the Business Intelligence Analyst would need to be able to take this data and apply to the markets our products are in for us to better serve our customers. This position will require a high degree of attention to detail along with ability to review calculations for quality assurance. The Business Intelligence Analyst must have good communication and organization skills, along with a working knowledge of day to day operations and priorities within their department and the company.\n\nTroubleshooting and problem solving issues, as well as working closely with managers and developers, to solve these problems, will be needed. Another responsibility could include creating internal reporting features to streamline information processing and sharing throughout the company. This position requires a high level of expertise with Microsoft Excel, and skills in SQL, Tableau, Microsoft Power BI, and/or R/Python are preferred. Assume other duties as assigned.\nTo apply to this job, click Easy Apply"}, "10": {"company": "Walmart eCommerce", "description": "Position Description\nA Data Scientist is responsible for analyzing large data sets to develop custom models and algorithms to drive business solutions. Data Scientists work on project teams in order to provide analytical support to projects (for example, email targeting, business optimization, consumer recommendations) for Walmart eCommerce. Data Scientists are responsible for building large data sets from multiple sources in order to build algorithms for predicting future data characteristics. Those algorithms will be tested, validated, and applied to large data sets. Data Scientists are responsible for training the algorithms so they can be applied to future data sets and provide the appropriate search results. Data Scientists are responsible for researching new trends in the industry and utilizing up-to-date technology (for example, HBase, MapReduce, LAPack, Gurobi) and analytical skills to support their assigned project.\nBuild complex data sets from multiple data sources, both internally and externally.\nBuild learning systems to analyze and filter continuous data flows and offline data analysis.\nCombine data features to determine search models.\nConduct advanced statistical analysis to determine trends and significant data relationships.\nDemonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans\nDevelop custom data models to drive innovative business solutions.\nDevelop models of current state in order to determine needed improvements.\nModels compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity\nProvides and supports the implementation of business solutions\nResearch new techniques and best practices within the industry.\nScale new algorithms to large data sets.\nTrain algorithms to apply models to new data sets.\nUtilize system tools including (MySQL, Hadoop, Weka, R, Matlab,ILog).\nValidate models and algorithmic techniques.\nWork with cross-functional partners across the business\nMinimum Qualifications\n\nModels compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity\nProvides and supports the implementation of business solutions\nResearch new techniques and best practices within the industry.\nScale new algorithms to large data sets.\nTrain algorithms to apply models to new data sets.\nUtilize system tools including (MySQL, Hadoop, Weka, R, Matlab,ILog).\nValidate models and algorithmic techniques.\nWork with cross-functional partners across the business</ul>\n\nAdditional Preferred Qualifications\n\nPlease add text\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nA Data Scientist is responsible for analyzing large data sets to develop custom models and algorithms to drive business solutions. Data Scientists work on project teams in order to provide analytical support to projects (for example, email targeting, business optimization, consumer recommendations) for Walmart eCommerce. Data Scientists are responsible for building large data sets from multiple sources in order to build algorithms for predicting future data characteristics. Those algorithms will be tested, validated, and applied to large data sets. Data Scientists are responsible for training the algorithms so they can be applied to future data sets and provide the appropriate search results. Data Scientists are responsible for researching new trends in the industry and utilizing up-to-date technology (for example, HBase, MapReduce, LAPack, Gurobi) and analytical skills to support their assigned project.\nBuild complex data sets from multiple data sources, both internally and externally.\nBuild learning systems to analyze and filter continuous data flows and offline data analysis.\nCombine data features to determine search models.\nConduct advanced statistical analysis to determine trends and significant data relationships.\nDemonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans\nDevelop custom data models to drive innovative business solutions.\nDevelop models of current state in order to determine needed improvements.\nModels compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity\nProvides and supports the implementation of business solutions\nResearch new techniques and best practices within the industry.\nScale new algorithms to large data sets.\nTrain algorithms to apply models to new data sets.\nUtilize system tools including (MySQL, Hadoop, Weka, R, Matlab,ILog).\nValidate models and algorithmic techniques.\nWork with cross-functional partners across the business</ul>\nStart your job application: click Apply Now"}, "11": {"company": "Walmart eCommerce", "description": "Position Description\n\nThis position is in the data science team under the Advertising Technology organization. The mission of the Advertising Technology organization is to advance Walmart eCommerce by driving higher value for our customers and vendor partners. Walmart is investing in building a world class advertising platform and the Ads team is responsible for defining and performance advertising products that drive discovery, sales and profits. The team operates an end to end advertising platform that includes a scalable ad service that serves hundreds of millions of impressions each day, sophisticated ad matching algorithms, real-time reports, self-service interface for end to end program management etc.\n\nWe are a highly motivated group of Big Data Geeks, Data Scientists and Applications Engineers, working in small agile group to solve sophisticated and high impact problems. We are building smart data systems that ingest, model and analyze massive flow of data from online and offline user activity. We use cutting edge machine learning, data mining and optimization algorithms on ad relevance, ranking and campaign optimization.\n\nJoin us if you want to be spending your time on:\nGathering and analyzing data, identifying modeling and optimization problems, devising solutions and building prototypes;\nFormulating machine learning/statistical approaches while paying attention to business metrics, designing features from the rich data available from many sources, training, evaluating, and deploying models;\nResearching and implementing methodologies to measure the impact of the technologies;\nInitiating and proposing unique and promising modeling projects, developing new and innovative algorithms and technologies, pursuing patents where appropriate;\nDeveloping high-performance algorithms for precision targeting, user engagement prediction, and ad relevance/ranking; testing and implementing these algorithms in scalable, product-ready code; interacting with other teams to define interfaces and understanding and resolving dependencies;\nStaying current on published data mining, machine learning and modeling techniques and competing technologies and sharing these findings with scientists and engineers in the organization;\nMaintaining world-class academic credentials through publications, presentations, external collaborations and service to the research community.\n\nMinimum Qualifications\n\nMasters or equivalent degree in a computational science with 4+ years of experience in Machine Learning/Statistics/Data Science;\nExperience with traditional as well as modern machine learning/statistical techniques, including Regression, Classification, Regularization, Ensemble Methods, and Neural Network;\nStrong implementation experience with high-level languages, such as Python, R, Perl, Ruby, Scala or similar scripting languages;\nFamiliarity with Linux/Unix/Shell environments;\nStrong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data;\nStrong written and oral communication skills.\n\nAdditional Preferred Qualifications\n\nPh.D. in a computational science with an emphasis in Machine Learning;\nExperience in online advertising, recommender system, ecommerce or relevant areas;\n2+ years of experience of writing production quality code;\nExperience with end-to-end modeling projects emerging from research efforts;\nExcellent academic or industrial track record of proposing, conducting and reporting results of original research, plus collaborative research with publications;\nKnowledge of data processing on Hadoop programming environments (e.g. Spark/Hive/Pig).\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nThis position is in the data science team under the Advertising Technology organization. The mission of the Advertising Technology organization is to advance Walmart eCommerce by driving higher value for our customers and vendor partners. Walmart is investing in building a world class advertising platform and the Ads team is responsible for defining and performance advertising products that drive discovery, sales and profits. The team operates an end to end advertising platform that includes a scalable ad service that serves hundreds of millions of impressions each day, sophisticated ad matching algorithms, real-time reports, self-service interface for end to end program management etc.\n\nWe are a highly motivated group of Big Data Geeks, Data Scientists and Applications Engineers, working in small agile group to solve sophisticated and high impact problems. We are building smart data systems that ingest, model and analyze massive flow of data from online and offline user activity. We use cutting edge machine learning, data mining and optimization algorithms on ad relevance, ranking and campaign optimization.\n\nJoin us if you want to be spending your time on:\nGathering and analyzing data, identifying modeling and optimization problems, devising solutions and building prototypes;\nFormulating machine learning/statistical approaches while paying attention to business metrics, designing features from the rich data available from many sources, training, evaluating, and deploying models;\nResearching and implementing methodologies to measure the impact of the technologies;\nInitiating and proposing unique and promising modeling projects, developing new and innovative algorithms and technologies, pursuing patents where appropriate;\nDeveloping high-performance algorithms for precision targeting, user engagement prediction, and ad relevance/ranking; testing and implementing these algorithms in scalable, product-ready code; interacting with other teams to define interfaces and understanding and resolving dependencies;\nStaying current on published data mining, machine learning and modeling techniques and competing technologies and sharing these findings with scientists and engineers in the organization;\nMaintaining world-class academic credentials through publications, presentations, external collaborations and service to the research community.\nApply Now: click Apply Now"}, "12": {"company": "IFG Companies", "description": "/ OBJECTIVE\n\nThis position will leverage data management and risk management skills to assist IFG Companies in the evaluation and management of property and liability exposures. The position will be responsible for developing building, validating, and maintaining catastrophe exposure data; evaluating the catastrophe risk profile of individual property accounts; assisting in the evaluation and development of portfolio catastrophe risk management reports and assisting when needed on other risk management activities. The position will work closely and will provide support to underwriters within IFG Companies\u2019 Property and Liability units.\n\nPOSITION RESPONSIBILITIES\nValidating the quality and integrity of property exposure data and performing pre-processing modeling activities; including data consistency checks. Identify and automate workflows so as to build a unified consistent data collection mart.\nWorking with IFG Companies\u2019 technology group to ensure data uniformity within the catastrophe risk modeling and rate making processes.\nSupporting requests from underwriters to assess, evaluate and price catastrophe risk through the use of catastrophe risk model results.\nSupporting the Actuarial unit in providing catastrophe risk reporting and effectively managing reinsurance programs.\nPerforming and Analyzing account and portfolio level catastrophe risk model runs.\nPlanning and organizing information with problem solving, decision making skills. Use of statistical models using R and Python is a plus.\nEffectively communicate catastrophe exposure and risk analysis with the ERM and Underwriting teams.\nAssist the ERM unit in performing operational risk review on people, processes, controls and systems.\nAssist in the implementation and monitoring of IFG Companies\u2019 risk limits.\nPerform other duties as required.\nKNOWLEDGE / SKILLS / ABILITIES\nAbility to demonstrate planning and organizational skills.\nStrong computer skills (Excel|Word|SQL) with demonstrated high accuracy output.\nExperience with Python or R is a plus.\nExcellent interpersonal and written/oral communication skills.\nExcellent attention to detail.\nEDUCATION / EXPERIENCE / CERTIFICATIONS\n4 year degree in statistics, mathematics, actuarial science, economics, risk management or finance from an accredited college or university.\n2-3 years\u2019 pf experience in Data Analytics or Risk Analysis is required.\nBackground in Insurance is a plus.\nPHYSICAL DEMANDS\nOccasional travel, up to 20%, is required.\nBENEFITS\nWe offer a competitive compensation and benefits package including medical, dental, vision, 401(k), flexible spending, short-term and long-term disability insurance, life insurance, long-term care, education assistance and paid time off, including paid parental leave and a birthday holiday.\nIFG Companies is an equal opportunity employer committed to a diverse workforce. M/F/D/V\nBack\nEmail\nApply Now\n\nApply Now: click Apply Now"}, "13": {"company": "Walmart eCommerce", "description": "Position Description\n\nAs part of the newly created Data Strategy and Enablement Team (DS&E), this role will be an enabler of our journey to be the worlds leading data-driven retailer. As part of this transformation, we are seeking an individual who will be responsible for establish robust data pipelines and services including both in house developed data enabling services and systems integrations across the DS&E team to ensure we our technical deliverables meet and exceed the quality expectations.\n\nWe are looking for a highly motivated, resourceful, team-oriented individual to drive the data engineering process. You are exceptionally talented Data engineer with an outstanding track record of working with very large data sets and building robust ETL pipelines for data acquisition for internal systems and external data sources. You will be modernizing and improving the data acquisition infrastructure from the ground up. You will be working with structured/unstructured Data sets, building large scale Data processing platforms, implementing world class data governance and operational controls, solving complex performance challenges.\n\nThe Data Engineer role will report up to the Lead Data Engineer/Senior Manager Data Engineering\n\nMinimum Qualifications\n\n- Play a pivotal design and hands on implementation role in improving the Data infrastructure in a project-oriented work environment.\nInfluence cross functional architecture in sprint planning\nGather and process raw data at scale from internal and external data sources and expose mechanisms for large scale parallel processing\nDesign, implement and manage a near real-time ingestion pipeline into a data warehouse and Hadoop data lake.\nProcess unstructured data into a form suitable for analysis and then empower state-of-the-art analysis for analysts, scientists, and APIs\nSolve complex SQL and Big Data Performance challenges.\nMitigate Risks in our data infrastructure by developing the best in class tools and processes.\nImplement controls, policies, processes and best practices in the Data Engineering space.\nEvangelize an extremely high standard of code quality, system reliability, and performance.\nHelp us improve our database deployment and change management process.\nProvide reliable and efficient Data services as part of the global data team.\nWork closely with the team on development best practices and standards.\nBe a mentor.\nWho you are:\nYou have prior experience with leading data engineering efforts across a variety of data systems\nYou have deep understanding of commercial data sources and understand database concepts and terminology\nYou have a demonstrated track record of handling multiple complex sourcing projects and delivering results in the data engineering area\nYou have strong SQL experience and the ability to work on multiple aspects of a data projects including ETL, tools integrations, data results and APIs.\nYou are a team player, with the courage to drive change through disruption while maintaining a respect for the team\nRequirements:\nVery Strong engineering skills. Should have an analytical approach and have good programming skills.\nProvide business insights, while leveraging internal tools and systems, databases and industry data\nMinimum of 5+ years experience. Experience in retail business will be a plus.\nExcellent written and verbal communication skills for varied audiences on engineering subject matter\nAbility to document requirements, data lineage, subject matter in both business and technical terminology.\nGuide and learn from other team members.\nDemonstrated ability to transform business requirements to code, specific analytical reports and tools\nThis role will involve coding, analytical modeling, root cause analysis, investigation, debugging, testing and collaboration with the business partners, product managers other engineering team\nExperience working with large data sets, experience working with distributed computing (MapReduce, Hadoop, Hive, Pig, Apache Spark, etc.) and platforms such as HDP, Cloudera etc.\nStrong Hadoop scripting skills to process petabytes of data\nExperience in Unix/Linux shell scripting or similar programming/scripting knowledge\nReal time data ingestion (Kafka)\nExperience in ETL/ processes with exposure to one or more tools such as Nifi, Talend, Informatica, SSIS etc.\n\nAdditional Preferred Qualifications\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nAs part of the newly created Data Strategy and Enablement Team (DS&E), this role will be an enabler of our journey to be the worlds leading data-driven retailer. As part of this transformation, we are seeking an individual who will be responsible for establish robust data pipelines and services including both in house developed data enabling services and systems integrations across the DS&E team to ensure we our technical deliverables meet and exceed the quality expectations.\nWe are looking for a highly motivated, resourceful, team-oriented individual to drive the data engineering process. You are exceptionally talented Data engineer with an outstanding track record of working with very large data sets and building robust ETL pipelines for data acquisition for internal systems and external data sources. You will be modernizing and improving the data acquisition infrastructure from the ground up. You will be working with structured/unstructured Data sets, building large scale Data processing platforms, implementing world class data governance and operational controls, solving complex performance challenges.\n\nThe Data Engineer role will report up to the Lead Data Engineer/Senior Manager Data Engineering.\nStart your job application: click Apply Now"}, "14": {"company": "DTN", "description": "DTN is a global leader providing insights and analytics to our customers who feed, protect, and fuel the world. The data science team at DTN currently has an opening for an individual with a passion for learning and solving challenging problems.\n\nThis role can be based out any one of the following DTN locations; Burnsville, MN, West Lafayette, IN, Omaha, NE, or Norman, OK.\n\nAs part of the team you will:\n\n\u2022Gain experience in all areas of data science\n\u2022Tackle a wide variety of problems in weather, agriculture, energy, and finance\n\u2022Explore our unique, proprietary datasets to find solutions to meaningful problems\n\u2022Work in a professional environment with passionate coworkers\n\nResponsibilities:\n\n\u2022Quick feasibility checks with go/no-go recommendations\n\u2022Data exploration to identify and advance insight solutions\n\u2022Data cleaning\n\u2022Model development to support production solutions\n\u2022Visualization generation\n\u2022Outcome presentation to senior leadership\n\u2022Model evaluations and recommendations\n\nRequirements:\n\n\u2022Machine Learning Experience (Supervised/Variety of Techniques)\n\u2022Python Programming Experience\n\u2022Experience with some of the common machine learning toolkits:\n\u2022Scikit-Learn, Numpy, Scipy, Pandas, Matplotlib, Tensorflow, Keras\n\u2022Mathematics/Probability/Statistics Understanding\n\u2022MS/PhD in math, CS, engineering, or related field\n\u20222+ years of relevant experience in a data science or machine learning role\n\u2022Evidence of past projects or experience may be considered in lieu of formal work experience\n\u2022Independent, Self-Directed\n\u2022Fast learner\n\u2022Good Communication Skills\n\u2022Experience building weather-driven models a plus\n\nWhy DTN?\n\nOUR VISION: To be the independent, trusted source of insights to our customers who feed, protect, and fuel the world.\n\nOUR MISSION: Empower our customers with intelligent and actionable insights that exceed their expectations and enable their success on a daily basis.\n\nOUR VALUES: Customer Delight, Education, Teamwork, Colleague Focus, Innovation, Integrity\n\nWe have great benefits at DTN \u2013 apply today to find out more!\n\nDTN is an Equal Opportunity Employer Minorities/Women/Veterans/Disabled\n\nApply Now: click Apply Now"}, "15": {"company": "Cengage", "description": ".\n\nDo you dare to reinvent the future of education?\n\n\nAt Cengage, we are harnessing the power of tech to build a future where all learners have the tools and confidence to achieve their goals. As a Cengage employee, you will blaze a new trail to transform the way people learn. Collaborating with the best of the best, you will feel challenged and inspired to do breakthrough work. With the support of our united team, there is no limit to what you can imagine, create and set in motion.\n\nAre we right for you?\n\n\nWe set the bar higher by bringing our unique talents and point of view to the table every day. We are curious and comfortable with change and are willing to take risks to transform education. Most importantly, with everything we do, we put learning first.\n\nWhat You'll Do Here:\n\n\nAs a Quantitative Researcher within the Higher Ed & Skills: Researcher Center of Excellence, you will design, lead and execute quantitative research projects in support of various product research initiatives. You will Recommend and employ statistical methodologies such as segmentation, multivariate analysis, discrete choice modeling, and experimental design while synthesizing analyses and presenting findings to management.\n\nSkills You Will Need Here:\nMaster's degree or other advanced degree with a strong background in business, market research, or behavioral sciences (e.g., Business Administration, Math/Stats, Psychology, Behavioral Economics/Decision Sciences, etc.)\nUp to 2 years as a researcher in a B2C environment and/or as a research vendor\nExperience with digital research tools (Qualtrics, online qualitative discussion boards/focus groups, etc.)\nExperience with statistical analysis tools (Excel, SPSS, R, Sawtooth, Quantitative Research)\nShown ability to conceive and execute quantitative analysis and deliver data minded insights in an extremely fast paced environment\nExperience applying quantitative market research techniques to a variety of product management issues\nAble to self-manage progress against achievements and deliverables with a high degree of accountability and personal urgency\nStrong bias for action\nStrong writing and verbal presentation skills enabling her/him to prepare and present information and recommendations to a diverse and often senior audience\nComfort with and eagerness to seek ambiguous problems\nHighly collaborative and will achieve results with and through others\nRecent academic experience in data science would be excellent.\nAbility to travel 25%\nApply Now: click Apply Now"}, "16": {"company": "Society Insurance", "description": "Primary Purpose\n\nEvaluates, collaboratively advances, and documents complex business process improvements that parallel overall company and departmental strategies related to data.Supports the development and understanding of business requirements for business intelligence, reporting and data analysis needs.\n\nEssential Functions and Responsibilities\n\n(Other duties may be assigned)\n\n\u00b7Assists Product Owner (PO) and business departments with eliciting user stories and acceptance criteria (for business intelligence, reporting and data analysis needs) in a manner that seeks to improve existing business processes.Places focus on the business value to be delivered.Assists PO with creation, prioritization, and maintenance of user stories.\n\n\u00b7Gather and document requirements from the business and technical users and translating those requirements into user stories that will result in efficient solutions to meet the customer\u2019s needs.\n\n\u00b7Produce high-quality output consistent with team and industry standards.\n\n\u00b7Possess substantial knowledge and familiarity with data warehousing, ETL concepts, wide range of reporting solutions within a relational and dimensional framework and have discernment skills to consult/select the most appropriate solution for use case.\n\n\u00b7Serve as a liaison with the business community around the usage of BI tools, visualization and reporting best practices.\n\n\u00b7Plans and accomplishes goals and responsibilities according to timelines provided by relying on substantial experience and judgement.\n\n\u00b7Reviews user stories and acceptance criteria to ensure full understanding of deliverables and identification of test requirements.\n\n\u00b7Defines, implements data testing systems.This includes planning, creating, evaluating and tracking testing results.\n\n\u00b7Troubleshoot issues with reports and data; works with business users, developers, architects to report, resolve defects and prevent further issues.\n\n\u00b7Solves problems with a wide degree of creativity and latitude.\n\nQualifications\n\n\nTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skills, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\n\nRequired:\nAssociate's Degree in computer science/business related discipline with a minimum of 4 years of work experience related to information systems and/or data analysis or2-year degree with a focus on information systems or business-related discipline and a minimum of six years\u2019 experience related to business analysis and/or business intelligence-related responsibilities.\nExperience gathering and writing detailed business requirements and/or user stories.\nA passion for delivering high-quality solutions/software and a drive to constantly improve and evolve processes.\nExperience working within a project-management environment.\nSolid command of written and verbal communication, and the ability to interpret the needs of the end user against the capabilities of available technology.\nExcellent analytical and problem-solving skills.\nProficient skills in BI reporting tools to create reports, dashboards and analytics.\nProficient level understanding of SQL.\nExperience with relational databases\nDemonstrated strong desire to learn new technical tools, techniques, and processes to support the data analytical needs of the enterprise.\nAn aptitude for Information Systems, Databases, BusinessIntelligence concepts, and a general understanding of a DataWarehouse structure.\nAbility to work well independently and as part of a team.\nPreferred:\nBachelor\u2019s degree in information systems or a business-related discipline.\nFive or more years of experience working as a Data Analyst or related position.\nAdvanced skills in BI reporting tools to create reports, dashboards and analytics.\nThree or more years of insurance industry experience.\nExperience working in an agile environment.\nExperience with Microsoft Azure DevOps, Azure Test Plans and Teams.\nMentoring and coaching experience in a technical environment.\nFamiliarity with insurance support applications, which may be supplied by internal or external vendors.\nContinued insurance and/or IT coursework.\nSupervisory Responsibilities\n\n\u00b7 None\n\nWorking Conditions and Environment\n\n\n\u00b7 Work is performed at the corporate location, which is an office setting, indoor and climate-controlled.\n\n\u00b7 Working hours may be altered to accommodate system upgrades\nor changes that are made.\n\nPhysical Demands\n\n\n\u00b7 Normal lifting (office work) occurs frequently.\n\n\u00b7 Requires near-sightedness (clarity of vision at 20 inches or less)\nfor extended periods of computer usage.\n\n\u00b7 Sitting for long periods of time.\n\nKey Competencies\nApproachability\nCreativity\nCustomer Focus\nListening\nWritten Communications\nTechnical Learning\nDecision Quality\nInterpersonal Savvy\nOrganizational Agility\nOrganizing\nPerspective\nProcess Management\nSociety Insurance is an Equal Opportunity Employer and is committed to providing employees with a work environment free of discrimination and harassment. All employment decisions at Society are based on business needs, job requirements and individual qualifications without regard to race, color, sex, sexual orientation, gender identity, religion, national origin, age, military or veteran status, disability, genetic information or any other consideration made unlawful by applicable federal, state or local laws.\n\nSociety Insurance is a drug-free workplace. Any candidate who receives an offer of employment from Society will be required to undergo a pre-employment drug test for controlled substances. All offers of employment are contingent upon successful completion of the pre-employment drug test, which is conducted in accordance with Society\u2019s substance abuse policy.\nApply Now: click Apply Now"}, "17": {"company": "Clinica Family Health", "description": "This job exists to: set up and maintain our EPM. This position will support Billing, Coding and Finance.\n\nESSENTIAL DUTIES AND RESPONSIBILITIES:\n\nGeneral Leadership\n\n\u2022 Collaborate with Finance, Accounting, Billing and Coding to ensure the system is set up and maintained in the best way to fit Clinica\u2019s needs.\n\n\u2022 Maximize System utility\n\n\u2022 Streamline and improve EPM workflows\n\n\u2022 Providing exceptional customer service to internal and external customers External Reporting& Compliance\n\n\u2022 Ensure system is set up to meet and comply with state and federal billing regulations.\n\n\u2022 Continuous Improvement Projects\n\n\u2022 Seeking opportunities to improve NextGen Software functions, Billing and Coding processes such as those to:\n\no Increase system efficiency\n\no Decrease manual workflows\n\no Increase reimbursement\n\no Increase accuracy (Quality)\n\n\u2022 Serves as Internal NextGen Support.\n\n\u2022 Troubleshoot and resolve issues with EPM. Refer calls beyond technical scope to EPM, E.H.R., EDR managing partners or vendors.\n\n\u2022 Encourages innovation and process improvement within the Finance team.\n\n\u2022 Complies with all guidelines established by the Centers for Medicare and Medicaid (CMS) and guidelines set forth by other regulatory agencies, where applicable. Participates in the development and implementation of insurance billing procedures.\n\n\u2022 Collaborates with the Billing and Coding teams to assure the system is set up and maintained in order to maximize revenue within corporate compliance.\n\n\u2022 Contributes to additional training projects and special projects as required\n\n\u2022 Prepares reports as needed and summarize information to verify accuracy as requested.\n\n\u2022 Participate in system upgrade for EPM\n\n\u2022 Maintain a positive attitude and fun work environment for fellow staff resulting in teamwork and productive collaboration with the site Operations and Clinical teams Operational Objectives\n\nOTHER DUTIES AND RESPONSIBILITIES\n\n\u2022 Maintain a safe work environment by remaining informed of and compliant with the clinic\u2019s safety policies, and in particular by application of safe practices in area of own responsibility.\n\n\u2022 Compliance:\n\no Knowledgeable of and compliant with all laws and regulations governing area of responsibility.\n\no Responsible for reporting any potentially non-compliant conduct.\n\no Cooperate fully with our Compliance Officer in upholding our Compliance Plan.\n\n\u2022 Serve as a resource in on-going support of staff using EPM. Assist in the evaluation and implementation of upgrades and assure a smooth transition to these new systems.\n\n\u2022 Train Finance staff in EPM, partner with other departments for training as needed.\n\n\u2022 Generate reports as needed to improve the revenue cycle and ACO Program performance.\n\n\u2022 Generate reporting for quality incentive opportunities.\n\n\u2022 Is part of the Finance team and partners with members of the team in strategic planning processes and implementation.\n\n\u2022 Serves as liaison for Billing, Coding, Clinical Services, Training EHR, ACO and IT, troubleshooting and resolving issues.\n\n\u2022 Participates on committees and in meetings as directed by their Manager.\n\n\u2022 Perform other duties and responsibilities, including billing, as required.\n\nSUPERVISION: No\n\nSCOPE OF AUTHORITY: Progress is reviewed quarterly and results are measured and formally evaluated annually.\n\nPOSITION QUALIFICATIONS:\n\nA. Education / Experience:\n\n\u2022 Associates degree in Computer science or equivalent training and job-related experience required.\n\n\u2022 3 years of medical billing and coding experience preferred.\n\n\u2022 Community Health Center experience preferred.\n\n\u2022 EPM Certification a plus.\n\n\u2022 Experience with NextGen EHR and EDR a plus.\n\nB. Knowledge, skills and abilities:\n\n\u2022 Office skills including typing, accounting, 10 key entry, and computer terminal usage required.\n\n\u2022 Ability to communicate to up line and down line staff in a professional and succinct manner.\n\n\u2022 Basic understanding of ICD-9, ICD-10 Medical Coding and Current Procedural Terminology (CPT), Current Dental Terminology (CDT), HCPCS, is required.\n\n\u2022 Basic knowledge of medical terminology, abbreviations, techniques; anatomy and physiology; major disease processes; pharmacology; and the metric system to perform daily functions.\n\n\u2022 Solid understanding of Medicaid, Medicare, Commercial insurances and other payers required.\n\n\u2022 Microsoft Office required.\n\n\u2022 Organizational, analytical, decision making, creative thinking, time management, problem solving and interpersonal skills.\nStart your job application: click Easy Apply"}, "18": {"company": "Walmart eCommerce", "description": "Position Description\n\nDemonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans\nDevelops analytical models to drive analytics insights\nLeads small and participates in large data analytics project teams\nModels compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity\nParticipates in the continuous improvement of data science and analytics\nPresents data insights and recommendations to key stakeholders\nProvides and supports the implementation of business solutions\n\nMinimum Qualifications\n\n3 + years of data science experience; MS or PhD degree\n\nAdditional Preferred Qualifications\n\n4 years experience with SQL and relational databases (for example, DB2, Oracle, SQL Server).\n4 years experience with statistical programming languages (for example, SAS, R).\nBachelor's degree in Statistics, Economics, Analytics, Mathematics and 7 years experience in an analytics related field.\nCertificate in business analytics, data mining, or statistical analysis.\nDoctoral degree in Statistics, Economics, Analytics, or Mathematics and 1 year experience in an analytics related field.\nMaster's degree in Statistics, Economics, Analytics, or Mathematics and 3 years experience in an analytics related field.\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nDemonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans\nDevelops analytical models to drive analytics insights\nLeads small and participates in large data analytics project teams\nModels compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity\nParticipates in the continuous improvement of data science and analytics\nPresents data insights and recommendations to key stakeholders\nProvides and supports the implementation of business solutions\nTo apply to this job, click Apply Now"}, "19": {"company": "zPREDICTA", "description": "JOB DESCRIPTION\n\nFounded with the mission to enable successful treatments for every patient, zPREDICTA has developed the organ-specific 3D cell culture technology replicating human tumor microenvironment permitting reliable identification of compounds with a high probability of success in the clinic. You will join a dynamic and agile team developing 3D tissue models to support anticancer drug development. You will be responsible for building a scientific team, directing internal R&D and external partner projects, and contributing to the growth of zPREDICTA brand.\n\nTo be successful, you have to be excited by the fast-paced environment of a start-up, be engaged while performing multiple roles, and possess a versatile set of technical skills. Along with a competitive compensation and benefits package and equity ownership we offer an opportunity to work side-by-side with the leadership team and advance into a senior leadership role in a highly collaborative environment at zPREDICTA.\n\nKEY RESPONSIBILITIES\nDesign, develop, and implement new organ-specific 3D tissue models for target discovery and efficacy and toxicity testing of anticancer agents\nBuild and grow a versatile scientific team responsible for R&D and partner projects\nSupport partner projects from study design through data analysis and report preparation\nEDUCATION\nPh.D. in Cell Biology, Immunology, or related life science discipline, AND\n1-5 years of industry experience; start-up experience is a plus\nREQUIRED EXPERIENCE\nScaffold-based 3D cell culture of primary human/mouse cells and cell lines\nExpertise in tumor microenvironment, specifically ECM and cellular heterogeneity\nAssay development\nFlow cytometry\nMicroscopy (brightfield, immunofluorescence, confocal, high content)\nSetting-up SOPs and developing protocols and procedures\nPREFERRED EXPERIENCE\nPDX models and culture of PDX tissue\nLab automation\nPERSONAL CHARACTERISTICS\nFocused, but capable of driving multiple projects\nCurious, creative, and independent thinker driven to solve problems\nUnafraid of working outside of the area of expertise and experimenting with new approaches\nRoll-up-your-sleeves and jump-in attitude\nAppreciate a fast-paced environment\nEnjoy teaching\nTO APPLY\nPlease send your resume to careers@zpredicta.com.\n\nCANDIDATE MUST HAVE APPROPRIATE WORK AUTHORIZATION TO WORK IN THE UNITED STATES.\n\nThis position does not offer relocation benefits.\n\nzPREDICTA is an equal opportunity employer.\nTo apply to this job, click Easy Apply"}, "20": {"company": "Amobee", "description": "Amobee is the worlds leading independent advertising platform that unifies all channelsincluding TV, programmatic and socialacross all formats and devices. We provide marketers with advanced cross-channel media planning powered by advanced analytics and proprietary data. Our platform and technology provide sophisticated video-advertising solutions for the convergence of linear TV, over the top, connected TV, and premium digital.\n\nAmobee has been named to Fortunes Top 10 Best Workplaces in Advertising and Marketing. Amobees platforms have been widely recognized amongst our industry winning numerous awards in technology innovation. We are a wholly owned subsidiary of Singtel, one of the largest telco companies in the world, reaching over 700 million mobile subscribers in 21 countries. Amobee operates across North America, Europe, Middle East, Asia and Australia. For more information, visit amobee.com or follow @amobee.\n\nPosition Overview:\n\nAs a Data Scientist you will be working with large data sets to perform analysis, define data transformations, and build models. You will collaborate with the team to design solutions that focus on buying, selling, forecasting, allocating, delivering, and reporting of advertising on the internet and TV. You will generate bleeding-edge solutions through the application of mathematics, optimization, and machine learning capabilities. The position provides great opportunities to communicate with the business directly, bridging the gap between technology and business. Qualified individuals will have a solid background in the fundamentals of data engineering, data science, computer science or statistics, with experience and comfort with data access and manipulation.\n\nResponsibilities:\nApply mathematics to optimize the acquisition and allocation of advertising inventory using information about the inventory, advertiser and the targeted consumer\nWork cross functionally to gather feedback and requirements from end users\nDesign innovative solutions and build prototypes for proof of concept\nDevelop, launch, and evolve new products\nBe a thought leader in identifying and vetting new data sources\nExecute research that results in ground-breaking papers and case studies that support the needs of the sales and marketing functions\nPerform ad-hoc analysis on campaign, publisher, or product performance\nRequirements:\nA masters or PhD degree in a quantitative discipline, such as Computer Science, Statistics , Mathematics, Industrial Engineering, Mechanical Engineering.\nStrong analytical and problem-solving skills with attention to detail\nAbility to work as part of a team in a fast-paced environment\nAbility to quantify and communicate the value of a new method or process to the business\nExperience with data engineering tools used to access, merge, transform and evaluate data sources\nExperience with statistical software (e.g., Python, R), SQL and data frameworks (e.g., Spark, Pig)\nExperience with Gurobi a plus\nExperience with modeling concepts, such as training/test paradigm, validation of models, and knowledge of modeling techniques (linear and logistic regression, decision trees, etc.)\nLocation: Baltimore, MD\n\nIn addition to our great environment, we offer a competitive base salary, employee development programs and other comprehensive benefits. Please send a cover letter along with your resume when applying to the position of interest located at Amobee.com. We are an Equal Opportunity Employer. No phone calls and no recruiting agencies, please.\nTo apply to this job, click Apply Now"}, "21": {"company": "Genscape", "description": "We have an outstanding opportunity for a Director of Data Intelligence. The role will offer the candidate the opportunity to lead our team of Data Scientists in employing advanced analytics in our production environment. The team utilizes Big Data techniques, Machine Learning and other AI methodologies, Predictive Analytics, and Business Intelligence to unleash industry leading insights for the Energy Markets.\n\nThe ideal candidate has the ability to see solutions in sprawling data sets and to rally a strong team of data scientists to deliver these solutions into products. They will understand the right approach for a given data problem using AI, ML, statistical or other techniques. The Director of DI will work closely with leaders across product technology and product groups to implement high-quality, data-driven decisions. They will ensure model and data accuracy and consistent reporting by designing and creating optimal processes and procedures for data scientists to follow. They will use advanced data modeling, predictive modeling and analytical techniques to generate business insights from a diverse set of data.\n\nResponsibilities :\nResponsible for the end-to-end development and deployment of a broad set of production models.\nProduct development from concepts to end user delivery.\nLead cross-functional projects using advanced data modeling, analysis and optimization techniques.\nBuild, develop, deploy and maintain data models, reporting systems, data automation systems, dashboards and performance metrics support that support key business decisions.\nRecruit, train, develop and supervise a collaborative team in an Agile environment.\nLeverage ML/statistical and software testing techniques to monitor and ensure accuracy of data and deliverables\nDevelop and implement quality controls and departmental standards to ensure quality standards, organizational expectations, and regulatory requirements.\nQualifications:\nKnowledge of data mining principles: predictive analytics, mapping, collecting data from multiple data systems on premises and cloud-based data sources.\nStrong database skills with SQL and NoSQL environments\nUnderstanding of and experience using analytical concepts and statistical modeling techniques to solve commercial data analysis\nStrong problem solving, quantitative and analytical abilities.\nStrong ability to plan and manage numerous processes, people and projects simultaneously.\nExcellent communication, collaboration and delegation skills.\nAt least 5 years of experience in a position in data science and analytics, at least 3 years of experience leading a team.\nTechnical Skills:\nStrong programming skills (Python, Scala, R), and query languages: SQL, CYPHER\nExperience with big data pipeline tools and environments: Hadoop, Kafka, Spark\nExperience with Data Science tools: Databricks, TensorFlow/Keras, Jupyter notebooks\nCloud environments: AWS and Azure\nCI/CD and DevOps tools and environments: git, github.com/gitlab.com, Jenkins, unit testing frameworks.\nC, C++, Java, NodeJS, or other programming languages a plus.\nTo apply to this job, click Apply Now"}, "22": {"company": "Zimmerman Advertising", "description": "Overview:\n\nBlazing a new trail, we are further developing our Insight Marketing team to include the data science discipline. We are looking for candidates who love learning, questioning the status quo, and finding data-backed ways to \"do-it better''. We need a self-starter to tackle algorithmic modeling, what-if analysis, attribution, and more. Your work will be on the front-edge of one of the most innovative Automotive advertisers (rated \"Genius\" by L2 think tank). As we continue to develop our big data team you will wear many hats and will be responsible for a fair amount of trail blazing. You will function as a combination of a data scientist, data engineer, and project manager. Together, you and your trusty Junior Data Analyst, will accomplish many things.\n\nPurpose:\n\nThe Data Scientist position requires a multidisciplinary approach to technology, business, and marketing applied together to unlock insights hidden within our marketing data. You'll use your talent for breaking down business challenges into data-driven problems that guide performance gains for one of the world's largest Automotive manufacturers. You will create predictive and prescriptive models by detecting and exploiting patterns in massive data sets. You will also create data visualizations and give presentations that will help key stakeholders in the decision making process.\n\nDesired Qualifications:\n\nWe need people that feel comfortable across the entire spectrum of data science, from collaborating across teams and brainstorming on the whiteboard, all the way to implementing and testing their models. If you are detail oriented and passionate about leveraging data, statistics, and improving client outcomes, this position is for you.\n\nResponsibilities:\nPerform exploratory data analysis\ngenerate and test working hypotheses in a cross-silo collaborative environment\nPrepare and analyze historical data and identify patterns\nDemonstrate expertise in deriving insights from structured, semi-structured, and unstructured datasets\nMust have developed and deployed data-backed solutions in the domain of marketing\nDesigning and implementing your own algorithms and data structures\n\n\nOther Qualifications:\nExperience manipulating big and noisy data sets (e.q. SQL, server log file)\nExperience working in big data framework (Hadoop, NoSQL, BigQuery, etc)\nExperience and knowledge of data storage, data management, and big data processing tools preferred\nStrong background in statistics\nExperience with scripting and rapid prototyping using python\nData mining experience (using python/pandas)\nExperience with Machine learning\nKnowledge of data visualization tools (tableau, datastudio, matplotlib)\nMicrosoft Office - Excel, PowerPoint, Word expert proficiency\nThe responsibilities are many, various, and not limited to those written in this document.\n\nRequired Skills\n\nRequired Experience\n\nJob Location\nFort Lauderdale, US-FL\nApply Now: click Apply Now"}, "23": {"company": "Verizon", "description": "What you\u2019ll be doing...\n\nThis is a key role within our Roaming Finance & Systems Programming team. Under minimal supervision and as an individual contributor, you will perform advanced data analysis and modeling. The majority of the functions performed will be to support the daily, monthly, and ad-hoc functions within the roaming financial organization.\nResearching issues to resolution, strategic project support, analytical assignments, and designs reporting.\nData analysis and modeling, including the design, development, implementation and validation.\nUtilizing enhanced BI visualization tools, such as Qlik or Tableau.\nWhat we\u2019re looking for...\n\nYou will need to have:\nBachelor\u2019s degree or four or more years of work experience.\nThree or more years of relevant work experience.\nExperience with Microsoft products, including Excel.\nData management, analysis and visualization skills.\nExperience in data mining; Teradata and using SQL queries to extract data for use in analysis and presentations.\nEven better if you have:\nBachelor\u2019s degree in business, marketing, information systems, analytics/business intelligence, engineering, mathematics, statistics, other relevant discipline or four or more years of relevant work experience.\nExperience in data mining using Microsoft SQL Server database environments with Structured Query Language (SQL).\nExperience investigating and solving complex technical problems and data discrepancies. and Microsoft SQL Server database environments with Structured Query Language (SQL).\nData management, analysis and visualization skills including knowledge of BI/BA platforms and visualization tools such as Qlik or Tableau.\nExperience using advanced SQL queries to extract data for use in analysis and presentations.\nKnowledge of cellular roaming and roaming data repositories.\nExperience with analytical and statistical interpretation of quantitative data.\nKnowledge of Python, R or other languages for scripting and more advanced analyses.\nExperience in database administration (DBA).\nExperience implementing change requests to existing databases and verifying structure and data integrity as well as manage SDLC change ticket process by coordination with reporting team and EDW DBA team.\nDesign, build, and maintain data models to support financial reporting analytics.\nExperience in process and requirements documentation.\nExcellent presentation, facilitation, and communication skills, both oral and written.\nAbility to communicate effectively to both technical and non-technical teams.\nStrong interpersonal, influencing, and organizational skills.\nAbility to work with various/complex stakeholder groups and functions, and various levels of management.\nWillingness to travel occasionally.\nWhen you join Verizon...\n\nYou\u2019ll have the power to go beyond \u2013 doing the work that\u2019s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you\u2019ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we\u2019ll go far.\n\nEqual Employment Opportunity\n\nWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.\n\n]]>\nStart your job application: click Apply Now"}, "24": {"company": "Elevate Credit", "description": "General Summary:\n\nThe position plays a critical role in the oversight of predictive analytics and robust modeling at Elevate. The Sr. Data Scientist, Model Governance provides effective challenge, review, oversight, guidance, and ongoing monitoring for all models used within our Account Origination (Fraud, Risk and Response) and Account Management functions.\n\nPrincipal Duties and Responsibilities:\nReview models and provide effective challenge and feedback to the developers to action change.\nManage a model review/validation program aligned to OCC 2011-12 / SR 11-7 guidelines.\nPerform model stability monitoring to ensure ongoing performance for business applications.\nDeliver model variable stability and performance reviews on determined cadence.\nWrite clear and detailed model documentation coordinating efforts with the model developers.\nWork with other members of the Governance team to ensure all documentation is saved in the official repository and meets internal Credit Policy standards for all new and existing models.\nUtilize advanced statistical software to validate linear/non-linear, parametric/non-parametric based predictive modeling/data mining analytic methodologies.\nCreation of associated decks for presentation to executive management.\nPresent findings and make recommendations to Model and Risk Governance teams.\nAct as liaison between partner banks / third party validators and Elevate.\nComplete all other projects as assigned.\nExperience and Education:\nMinimum M.S./M.A. in a highly quantitative field (Statistics, Economics, Mathematics, or other quantitatively-oriented degree) or experience in a process related Senior Analyst role in an analytical capacity.\nStrong quantitative /statistical modeling capabilities, including with 5+ years of experience in credit scoring and model development preferred.\n3+ years\u2019 experience in Risk Management or Model Governance functions including knowledge of OCC / FDIC regulations for model documentation.\n3+ years\u2019 experience within the consumer lending environment.\nStrong SAS, R, and SQL skills preferred, with ability to conduct extensive data research required. Candidates with experience with other software such as Python, SPSS, MATLAB may also be considered.\nDemonstrated experience working with large complex data sources.\nStrong PowerPoint presentation skills a plus.\nRequired Skills and Abilities:\nAbility to work in fast-paced environment with ever-changing demands.\nAbility to manage multiple projects at one time, possibly including overseeing others projects.\nStrong communication skills. Must be able to clearly communicate in speech and writing with Risk Management peers, Marketing, Operations, Collections, Finance, C-level Executives, CEO, and BOD.\nApply Now: click Apply Now"}, "25": {"company": "Walmart eCommerce", "description": "Position Description\n\nA Staff Data Scientist is responsible for analyzing large data sets to develop multiple custom models and algorithms to drive innovative business solutions. Staff Data Scientists work on large project teams in order to provide analytical support and guidance to an assigned area on for large projects (for example, email targeting, business optimization, consumer recommendations) within Walmart eCommerce. Staff Data Scientists are responsible for building large data sets from multiple sources in order to build algorithms for predicting future data characteristics. Those algorithms will be tested, validated, and applied to large data sets. Staff Data Scientists are responsible for training the algorithms so they can be applied to future data sets and provide the appropriate search results. Staff Data Scientists are responsible for researching new trends in the industry and utilizing up-to-date technology (for example, HBase, MapReduce, LAPack, Gurobi) and analytical skills to support their assigned project.\n\nMinimum Qualifications\n\nExperience with deep learning techniques like CNN, RNN, LSTM, etc.\nUnderstanding of Deep Reinforcement Learning\nBuild complex data sets from multiple data sources, both internally and externally.\nBuild learning systems to analyze and filter continuous data flows and offline data analysis.\nPhD in computer science or similar field with 3+ years of experience\n\u2022 Highly proficient in Python or Java\n\u2022 Extremely hands-on in building Machine Learning products\n\u2022 Experience in building data products and crunching terabytes of data\n\u2022 A good portfolio of machine learning projects with a significant impact on the bottom line\n\u2022 Experience in working as a tech lead\n\u2022 Blog posts, papers or conference talks showing your involvement in the community\n\nAdditional Preferred Qualifications\n\n\u2022 Familiarity with Deep Learning\n\u2022 Contributions to open-source ML projects\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nA Staff Data Scientist is responsible for analyzing large data sets to develop multiple custom models and algorithms to drive innovative business solutions. Staff Data Scientists work on large project teams in order to provide analytical support and guidance to an assigned area on for large projects (for example, email targeting, business optimization, consumer recommendations) within Walmart eCommerce. Staff Data Scientists are responsible for building large data sets from multiple sources in order to build algorithms for predicting future data characteristics. Those algorithms will be tested, validated, and applied to large data sets. Staff Data Scientists are responsible for training the algorithms so they can be applied to future data sets and provide the appropriate search results. Staff Data Scientists are responsible for researching new trends in the industry and utilizing up-to-date technology (for example, HBase, MapReduce, LAPack, Gurobi) and analytical skills to support their assigned project.\nTo apply to this job, click Apply Now"}, "26": {"company": "Battelle", "description": "We are currently seeking a Sr. Subsurface Machine Learning Scientist.This position located in Pittsburgh, PA.\n\nBattelle is guided by a founding mission. We invest our knowledge, talents and resources, helping our customers achieve their most important goals. We apply scientific rigor and creativity, succeeding where others may fail, and we invest in our communities, making the world better for generations to come. All of us share a common purpose: to solve the greatest challenges of today and tomorrow.\n\nOur 22,000 employees work at the forefront of scientific innovation to tackle critical challenges in security, human health, manufacturing, energy and environmental management. Battelle\u2019s work is grounded in the belief that science, technology and a passion for excellence can make industries more competitive and the world a better place.\nJOB SUMMARY\nThe Senior Research will support the National Energy Technology Laboratory\u2019s Science-Informed Machine Learning for Subsurface Applications (SMART) Initiative. This Senior Research will contribute to the research effort by working closely with other researchers. In addition, this position will use their experience in scientific problem-solving techniques, incorporating quick learning, teamwork and critical thinking related to sub-surface systems to lead these projects. This position will support the collaborative nature of the initiative through coordination of several partners including universities and other DOE National Laboratories as well contribute to the overall strategy and direction of the initiative. This position will work closely with program management, NETL researchers and senior fellows to ensure successful outcomes from the large, multi-disciplinary initiative.\n\nWe are currently seeking Senior Subsurface Machine Learning Scientist located in Pittsburgh, PA.\nMAJOR RESPONSIBILITIES\nExhibit a high degree of ingenuity, creativity and resourcefulness in the application of advanced technologies, principles, theories and concepts.\nActively engage in outstanding research in an area of specialization.\nAct as a high-level technical resource to improve the quality of all projects in that area.\nProvide high-level strategic and/or technical advice to senior management.\nAssist line management in evaluating the technical performance of other staff.\nEnhance Battelle\u2019s reputation in the area of specialization by publishing and presenting results of R&D activities.\nTHE FOLLOWING IS REQUIRED\nPh.D. in engineering, science or related degree.\nExperienced with applying machine learning and artificial intelligence for subsurface data sets.\nExperienced in complex multi-discipline problem solving techniques that require learning of new skills and techniques.\nAble to operate and excel in a multi-disciplinary environment comprised of engineers and scientists of varied backgrounds and skill levels.\nBuilds relationships with internal and external clients who have varying backgrounds.\nProven Scientific writing capabilities in a collaborative environment.\nCreates and delivers oral and poster presentations of results.\nTHE FOLLOWING IS DESIRED\nExperience working with DOE National Laboratories and/or universities.\nLEGAL DISCLAIMER\nThe above statements are intended to describe the nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, activities and skills required of staff members. No statement herein is intended to imply any authorities to commit Battelle unless special written permission is granted by Battelle\u2019s Legal Department.\n\nBENEFITS\n\nBattelle\u2019s competitive benefits program includes comprehensive medical and dental care, matching 401K, paid time off, flexible spending accounts, disability coverage, and other benefits that help provide financial protection for you and your family.\n\nBattelle provides employment and opportunities for advancement, compensation, training, and growth according to individual merit, without regard to race, color, religion, sex (including pregnancy), national origin, sexual orientation, gender identity, marital status, age, genetic information, disability, veteran-status, or any other characteristic protected under applicable Federal, state, or local law. Our goal is for each staff member to have the opportunity to grow to the limits of their abilities and to achieve personal and organizational objectives. We will support positive programs for equal treatment of all staff and full utilization of all qualified employees at all levels within Battelle.\n\nFor more information about our other openings, please visit www.battelle.org/careers\nApply Now: click Apply Now"}, "27": {"company": "S&P GLOBAL MARKET INTELLIGENCE", "description": "Data Scientist Job Description\n\nThe Senior Data Scientist will be a part of the S&P Global Market Intelligence (SPGMI) Data Science team.\n\nThe Role:\n\n\u2022 Discover insights and identify opportunities through the use of statistics, algorithms, data mining and visualization techniques\n\u2022 Build and evaluate models, make predictions, gather results, and communicate findings to stakeholders\n\u2022 Evaluate the big picture and solve problems rather than looking at metrics alone\n\u2022 Use advanced business knowledge and advanced machine learning techniques to acquire, combine & transform multiple dataset to solve a business use case\n\u2022 Collaborate with engineering and product teams to create and build strategic models that drive product improvements while maintaining cost efficiency\n\u2022 Build and maintain re-usable machine learning and model validation procedures for the rest of the team to use\n\nExperience and qualifications:\n\n\u2022 Bachelors Degree in Mathematics, Statistics, Computer Science, Engineering, Operations Research or related fields preferred (Masters degree an advantage)\n\n\u2022 5+ years practical experience with statistical analysis and creating complex models, preferably in the financial services sector\n\n\u2022 Excellent analytical and problem solving skills\n\n\u2022 Advanced experience in at least one data analysis/data transformation package (R, Python, Alteryx)\n\n\u2022 Exposure to one or more data discovery, data visualization tools\n\n\u2022 5+ years of hypothesis testing, web analytics and python scripting\n\n\u2022 Experience with Machine Learning and Natural Language Processing\n\n\u2022 Ability to remain focused and to think logically in a fast-paced environment\n\n(NICE TO HAVE)\n\n* experience with nlp\n\n* exposure to reinforcement learning\n\n* exposure to information retrieval (search)\nTo apply to this job, click Apply Now"}, "28": {"company": "Liberty Mutual Insurance", "description": "Data Analyst/Sr Data Analyst\n\nAt Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as an Agile team within a Fortune 100 company, we are on the front edge of an IT transformation for how people work and deliver solutions.\nThis is a range posting. The actual internal level/grade for this role will depend on the candidate's overall experience and skill level.\n\nGRM Information Management is actively searching for a highly productive member of a distributed, dynamic agile team to serve as a technical expert in analysis, design, coding, and testing innovative data warehouse reporting solutions and analytics. This position will support Customer, Prospect, Marketing & Digital within Business Data Solutions Engineering.\n\nParticipates in the analysis and development of logical data base designs, data models and relational data base definitions across multiple computing environments. Assists in data management deliverables such as business need analysis, data source identification and analysis and data modeling techniques. Participates in the analysis and resolution of issues related to information flow and content with data stakeholders. Develops technical expertise in data modeling directions, methodologies, techniques and tools to ensure development of logical and relational data base designs which meet the needs of the business customers\nResponsibilities:\nParticipates in the evaluation of business requirements.\nTransforms client requests into data deliverables to include data models, data mappings and data transformation rules.\nContributes to the development of project plans for data deliverables. Depicts moderately complex to complex ideas, issues and data designs to varied audiences.\nContributes to the development of project plans and supports development team throughout project lifecycle including during test phase; researches test issues and data content and assists with moderately complex problem resolution.\nParticipates in the creation and implementation of new standards and procedures.\nInvestigates components of new tools and techniques.\nPerforms related duties as assigned or requested.\n\n\nQualifications:\nBachelor's Degree in a technical or business discipline or equivalent technical expertise. Generally, a minimum of 3 years related experience.\nGeneral knowledge in the following areas; IT concepts, strategies and methodologies, IT architectures and data standards, and general knowledge of a business function(s) and of business operations. Extensive knowledge of data design and tools required. Proficiency in SQL and DBMS languages and tools; knowledgeable in new and emerging technologies. Good negotiation and communication skills.\n\n\nBenefits:\n\nWe value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits\nOverview:\nAt Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.\nWe're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.\nTo apply to this job, click Apply Now"}, "29": {"company": "Intalere", "description": "Apply\n\nDescription\n\nAs a member of the Digital Solutions and Data and Analytics IT team, this person will be responsible for developing reports, dashboards, and self-service data analysis solutions to internal users as well as our customers, using a variety of technologies.\n\nThis role demands a strong technical/design skillset for presenting data in a clear, insightful, user-focused way, as well as broader capabilities relating to understanding existing and in-development data models/schemas and the business context they represent.\n\nThe visualization specialist will not just implement reports and dashboards via tools like Tableau and SQL Server Reporting Services (SSRS); they will also be responsible for designing them, utilizing technical best practices as well as their analytical skills to obtain a full understanding of underlying data and functional needs/requirements.\n\nResponsibilities\n\nDesign and develop new reports and dashboards in Tableau and SSRS.\n\nDetermine the appropriate tooling for development (Tableau, SSRS, Excel extracts, etc) based on your understanding of requirements and constraints as well as the team\u2019s best practices/patterns.\n\nDevelop necessary SQL (and other) queries for data ingestion to Tableau from SQL Server data marts/databases.\n\nDevelop SQL queries for ad hoc reporting and data analysis needs.\n\nUnderstand the context and constraints of how ETL (SSIS) processes are executed to populate relevant datastores (you need not be experienced with SSIS/ETL; however, a high-level understanding is necessary to inform your designs/decision making.)\n\nLead requirements analysis efforts relating to implementing new reports, dashboards and other visualizations, as well as periodic or ad hoc data extracts, via direct communication with technical and non-technical stakeholders.\n\nMaintain extensive existing set of SSRS reports:\nTroubleshoot SSRS reports when there are failures (evaluate cause, determine and test solution, implement solution) and provide communication to stakeholders during \u201coutage\u201d as well as document the situation after it is resolved to support retrospectives/knowledge sharing.\nIteratively enhance SSRS reports and queries for performance improvement.\nAdjust reports when underlying data schemas change.\nContribute to team knowledge sharing/training efforts.\n\nDevelop a strong understanding of Intalere and customer data models/context.\n\nProvide subject matter expertise (technical and business context) input and feedback to data/BI teams and development scrum teams as needed.\n\nIdentify, communicate, and mitigate BI/analytics risks, including invalid data, invalid data calculations, formulas or derived insights, and misrepresentation of or otherwise confusing visual representations of data.\n\nRequirements\n\nTechnical\n\n1+ years of experience designing data visualizations (components, reports, dashboards)\n\n2+ years of experience implementing data visualizations (components, reports, dashboards)\n\nExperience with debugging, performance profiling and optimization of data visualization components, reports, and dashboards\n\nDemonstrated analytical capabilities paired with a strong initiative to find ways to improve the analysis and communication of complex data\n\nSpecific experience with Tableau\nCandidates with extensive experience in other BI/reporting/analytics toolsets may be considered if they have a commitment to learning Tableau and a demonstrated ability to ramp up to proficiency rather quickly (2 months) in a primarily self-directed way\nPreference will be given to candidates with prior Tableau experience\nSpecific experience with Microsoft SQL Server Reporting Services (SSRS) and SQL Server toolset\nCandidates with extensive experience in other BI/reporting/analytics toolsets may be considered if they have a commitment to learning SSRS and a demonstrated ability to ramp up to proficiency rather quickly (2 months) in a primarily self-directed way\nPreference will be given to candidates with prior SSRS experience\nCapable of designing complex and performant SQL queries\n\nDemonstrated ability to quickly learn/understand and discuss data models\n\nProfessional\n\nExcellent interpersonal and organizational acumen with regard to collaborating with both internal team members and external business stakeholders\n\nInternally motivated, able to work proficiently both independently and in a team environment\n\nStrong written and verbal communication skills with staff and leadership at all levels of seniority and technical experience\n\nBachelor\u2019s Degree or higher (Computer Science, Engineering, Human Computer Interaction/Design, or similar/relevant field)\n\nMotivated to \u201cstay current\u201d with technical change/commit to professional development to learn relevant new skills/tools/methodologies\n\nDesired Additional Competencies:\n\nExperience with relational database design, SQL DDL, performance tuning relating to indexes, etc.\n\nExperience with non-relational \u201cnoSQL\u201d data sources\n\nExperience with ETL processes and tools\n\nHealthcare industry experience not required but a significant plus (supply chain, provider, payer, medical device, life-science, pharmacy, etc.)\n\nExperience with other data/BI tools, especially within the Microsoft ecosystem (SQL Server Analysis Services (SSAS), Power BI, Power Query, DAX, R)\n\nStart your job application: click Apply Now"}, "30": {"company": "Walmart eCommerce", "description": "Position Description\n\nDemonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans\nDevelops analytical models to drive analytics insights\nLeads small and participates in large data analytics project teams\nModels compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity\nParticipates in the continuous improvement of data science and analytics\nPresents data insights and recommendations to key stakeholders\nProvides and supports the implementation of business solutions\n\nMinimum Qualifications\n\n3 + years of data science experience; MS or PhD degree\n\nAdditional Preferred Qualifications\n\n4 years experience with SQL and relational databases (for example, DB2, Oracle, SQL Server).\n4 years experience with statistical programming languages (for example, SAS, R).\nBachelor's degree in Statistics, Economics, Analytics, Mathematics and 7 years experience in an analytics related field.\nCertificate in business analytics, data mining, or statistical analysis.\nDoctoral degree in Statistics, Economics, Analytics, or Mathematics and 1 year experience in an analytics related field.\nMaster's degree in Statistics, Economics, Analytics, or Mathematics and 3 years experience in an analytics related field.\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nDemonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans\nDevelops analytical models to drive analytics insights\nLeads small and participates in large data analytics project teams\nModels compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity\nParticipates in the continuous improvement of data science and analytics\nPresents data insights and recommendations to key stakeholders\nProvides and supports the implementation of business solutions\nStart your job application: click Apply Now"}, "31": {"company": "Walmart eCommerce", "description": "Position Description\n\n\u2022 Understands and translates business and functional needs into data scientist problem statements\n\u2022 Build complex data sets from multiple data sources, both internally and externally.\n\u2022 Develop custom data models to drive innovative business solutions.\n\u2022 Write complex queries and extract data to build database architecture. Integrate data products into dashboards and user interfaces as needed, by collaborating with engineering team\n\u2022 Sift and analyze data from multiple angles, looking for trends that highlight problems or opportunities\n\u2022 Use strong business acumen, as well as an ability to communicate findings, and mine vast amounts of data for useful insights\n\u2022 Apply innovative and scientific/quantitative analytical approaches to draw conclusions and make recommendations to answer business objectives\\\\\u2022 Proficiency in machine learning algorithms such as multi-class classifications, decision trees, support vector machines, and deep learning\n\u2022 Strong understanding of probability and statistical models (generative and descriptive models)\n\u2022 Ability to run experiments scientifically and analyze results\n\u2022 Ability to effectively communicate technical concepts and results to technical and business audiences in a comprehensive manner\n\u2022 Ability to collaborate effectively across multiple teams and stakeholders, including analytics teams, development teams, product management and operations\n\nMinimum Qualifications\n\n\u2022 1-3 years experience in building ML based models\n\u2022 Strong CS fundamentals in algorithms, data structures, OOPS, functional programming.\n\u2022 Strong Experience with Big Data processing (Bigquery / Hive/ Hadoop/ HDFS/ Spark)\n\u2022 Productionize the developed Machine Learning solutions\n\u2022 Hands on Experience with GCP Cloud ( Dataflow, Dataproc, ML Engine, Datalabs, Kubeflows)\n\u2022 Strong background in ML algorithms for time series datasets.\n\u2022 Strong background in Statistics.\n\u2022 Familiarity with Deep Learning algorithms.\n\u2022 Strong knowledge and experience with Databases (Relational Maria/Mysql and NoSQL Cassandra/Hbase/Bigtable)\n\u2022 Expert knowledge and experience with Java/Scala/Python\n\u2022 String grasp of principles and approaches used in Data-driven systems, processes and algorithms\n\u2022 Scripting skills in at least one of the following: Shell, Perl, Python, Bash, or Ruby\n\u2022 Experience with Performance Engineering including testing, tuning and monitoring tools.\nEducation Requirements\n\u2022 Bachelor's degree in data science, applied mathematics, computer science or otherwise research-based field; Masters degree required.\n\nAdditional Preferred Qualifications\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\n\u2022 Understands and translates business and functional needs into data scientist problem statements\n\u2022 Build complex data sets from multiple data sources, both internally and externally.\n\u2022 Develop custom data models to drive innovative business solutions.\n\u2022 Write complex queries and extract data to build database architecture. Integrate data products into dashboards and user interfaces as needed, by collaborating with the engineering team\n\u2022 Sift and analyze data from multiple angles, looking for trends that highlight problems or opportunities\n\u2022 Use strong business acumen, as well as an ability to communicate findings and mine vast amounts of data for useful insights\n\u2022 Apply innovative and scientific/quantitative analytical approaches to draw conclusions and make recommendations to answer business objectives\\\\\u2022 Proficiency in machine learning algorithms such as multi-class classifications, decision trees, support vector machines, and deep learning\n\u2022 Strong understanding of probability and statistical models (generative and descriptive models)\n\u2022 Ability to run experiments scientifically and analyze results\n\u2022 Ability to effectively communicate technical concepts and results to technical and business audiences in a comprehensive manner\n\u2022 Ability to collaborate effectively across multiple teams and stakeholders, including analytics teams, development teams, product management and operations\nStart your job application: click Apply Now"}, "32": {"company": "Presbyterian Healthcare Services", "description": "Overview\n\n\nJob Description Type of Opportunity: Full Time FTE: 1.000000 Exempt: Yes Work Schedule: Days\n\nSummary:Develop innovative & sophisticated analytics models in concert with other Directors within the Analytics Organization (AO) and in partnership with IT to support analytics/reporting needs of business leaders & fellow colleagues for the real time business decision making. Support optimization and enhancement of existing analytical models utilized by the PHS across the AO. Support development and testing of analytical prototypes and contribute to analytical solutions best practices. Develop the communication strategies and transitioning of solutions to other teams within the AO. Responsible for guiding, mentoring and supporting fellow junior scientist and other analytical talent across the AO.\n\nResponsibilities\n\n\nResponsibilities:*Provide support in creating/coding, designing and testing pilot data-driven predictive/descriptive analytical models for PHS.to solve business problems leveraging the latest and most appropriate technologies in statistical modeling and machine learning*Ability to work in a diverse team setting across the AO to develop, refine and scale data management and analytics procedures, systems, workflows, best practices and other issues.*Assist in risk identification and mitigation planning and communicate to analytical senior leadership of any issues/escalations & risks*Support management of multi-tasking, achieving milestones, deadlines, and maintaining customer relationships*Support and assist healthcare reporting/analytics system implementations throughout the project life-cycle, performing workflow analysis, testing, training, go-live, system upgrades and issues management in partnership with IT *Ability and experience to deal with very granular data available through various data storage platform (e.g., Hadoop) and summarize, interpret and translate the findings to the leadership promoting data-driven strategic decision making*Design and test structured data and algorithms to support clinical, operational and financial data analysis using advanced data-driven analytical methods from statistics, data mining, econometrics, and operations research*Design models for investigations of various acute/chronic clinical and/or operational and/or financial areas, including hypotheses generation and creating an analysis plan with appropriate primary and secondary data required, and evaluate results of the analysis and interpret conclusions, taking into consideration bias/data limitations as well as performing any specialized analysis required*Create and test optimization algorithms, forecasting and predictive models for patient level outcomes, utilization management, and overall medical services*Support design, build and test of population scoring, stratification and segmentation based on predicted risk of adverse utilization/clinical and financial outcomes*Synthesize findings and conclusions including efficacy of existing programs as well as incremental impact of new care inventions and interventions; design and institute appropriate metrics to assess progress vs. projected impact.*Routinize advanced analytical and reporting methods and techniques for broader use of the AO community*Work with large and complex datasets to derive and validate predictive models across clinical, operational and financial areas*Collaborate and partner with management, project managers, and IT to identify cases that can benefit from predictive analytics and other advanced statistical techniques*Visualize, interpret, report, and communicate data findings creatively in a various formats and audiences*Support advanced analytical and data mining efforts which could include but not limited to clustering, segmentation, logistic and multivariate regression, decision/CART trees, neural networks, time-series analysis, sentiment analysis, topic modeling, random forests, and Bayesian analysis *Support collaboration with other analytics stakeholder to define, gather requirements and build a pilot prototype BI tools*Provide support in designing and development of reusable analytical assets (data structures, code, solutions); test and improvise improvements to existing assets; and conduct evaluation of the suitability and value of potential new assets*Assist in developing training material and provide hands-on mentoring to analytical talent on the appropriate use and interpretation of new analytical models, integration of these models into existing business analyses as well as assure, maintain and improve efficiency and quality; validate work product of peers across the AO*Assist with the preparation of documents/publications and presentation materials describing analytic methods, observations and findings in the AO area *Contribute towards and assist Informaticists leadership in developing a year-end value story to demonstrate value of the team and their contribution to progress towards the AOs and PHSs goals.\n\nQualifications\n\n\nOther information:Bachelors degree in an econometrics, physics, biostatistics, computer science, applied mathematics, engineering or any other quantitative related subject area. A Masters or a Ph.D. is highly preferred. Four or more years of related business intelligence, statistical/mathematical, predictive modeling along with the business strategy experience required. Understanding of natural language processing, machine learning, conceptual modelling and hypothesis testing as well as relational database management systems (Oracle, Teradata, SQL Server, DB2 etc.) Knowledge of healthcare industry and healthcare information standards such as HL7, LOINC, FHIR, ICD 9/10 and CPT codes, industry standard groupers (e.g., ETGs, DRGs, DCGs, etc.) as well as of the health care delivery system processes. Experience in big data technologies such as Hadoop, Spark, Kafka, Storm, R, Python, SQL, no-SQL databases, database analytics and graph databases is a PLUS. Adept in using BI tools (e.g., Business Objects/BO, Cognos), data visualizations tools (e.g., Tableau), statistical software such as SAS and general health service research and reporting/analytics. Working knowledge of extract transform and loading (ETL), data cleaning, data normalization/mapping and business process management (BPM) is expected. Experience in mathematical modeling skills including but not limited to classification, regression, survival analysis, recommender systems, experimentation systems (A/B testing), hypothesis testing and supporting development of mathematical algorithms.\n\nPreferred Qualifications:\nEvidence based care work\nClinical analytics background\nExperience with Epic\nStatistical analysis background\nExperience with SAS, R, Python, Tableau\nBenefits\n\n\nBenefits Benefits are effective day-one (for .45 FTE and above) and include:\nCompetitive salaries\nFull medical, dental and vision insurance\nFlexible spending accounts (FSAs)\nFree wellness programs\nPaid time off (PTO)\nRetirement plans, including matching employer contributions\nContinuing education and career development opportunities\nLife insurance and short/long term disability programs\nAbout Us Presbyterian Healthcare Services is a locally owned, not-for-profit healthcare system of nine hospitals, a statewide health plan and a growing multi-specialty medical group. Founded in New Mexico in 1908, it is the state's largest private employer with approximately 11,000 employees.\n\nPresbyterian's story is really the story of the remarkable people who have chosen to work here. Starting with Reverend Cooper who began our journey in 1908, the hard work of thousands of physicians, employees, board members, and other volunteers brought Presbyterian from a tiny tuberculosis sanatorium to a statewide healthcare system, serving more than 700,000 New Mexicans. We are part of New Mexico's history - and committed to its future. That is why we will continue to work just as hard and care just as deeply to serve New Mexico for years to come. About New Mexico New Mexico's unique blend of Spanish, Mexican and Native American influences contribute to a culturally rich lifestyle. Add in Albuquerque's International Balloon Fiesta, Los Alamos' nuclear scientists, Roswell's visitors from outer space, and Santa Fe's artists, and you get an eclectic mix of people, places and experiences that make this state great. Cities in New Mexico are continually ranked among the nation's best places to work and live by Forbes magazine, Kiplinger's Personal Finance, and other corporate and government relocation managers like Worldwide ERC. New Mexico offers endless recreational opportunities to explore, and enjoy an active lifestyle. Venture off the beaten path, challenge your body in the elements, or open yourself up to the expansive sky. From hiking, golfing and biking to skiing, snowboarding and boating, it's all available among our beautiful wonders of the west. AA/EOE/VET/DISABLED. PHS is a drug-free and tobacco-free employer with smoke free campuses.\n\nAD123\n\n#CB\nApply Now: click Apply Now"}, "33": {"company": "Master Electronics", "description": "Master Electronics has an exciting career opportunity for aData Scientist that will report to the Vice President of Data Science in Phoenix, AZ. The position involves modeling complex business problems, uncovering insights, and identifying growth opportunities using data science, machine learning, artificial intelligence, data mining, visualization, and statistical analysis. Candidates will collaborate with cross functional teams and external partners to discover and model operational efficiencies that will enable Master Electronics to better serve its customers.\n\nCandidates should be able to effectively answer a wide variety of high business impact questions, while presenting key data science and quantitative insights in a concise and effective manner to a variety of audiences. The candidate must have a high degree of creativity and independence, using a variety of data science algorithms, integrating a wide number of structured and non-structure data sources, with significant Python software development skills, to model and simulate effective solutions to challenging business issues.\n\nHow you will spend your time:\nEffectively partner with teams to build prediction models to forecast sales, product demand and performance\nBuild or select the correct algorithms to model customer behavior, purchases, and recommendation systems\nUse predictive analytics, machine learning, and artificial intelligence to solve complex business problems\nUse descriptive analytics to create reports, dashboards, and pivots to quantify historical performance\nIndependently solve analytical problems, effectively communicating results to non-technical audiences\nWe\u2019re excited if you have:\nUndergraduate degree from an accredited university in data science, supply chain management, computer science, mathematics/physics, machine learning, operations research, applied to business decision making\n3+ years professional experience in modeling and statistical analysis of large (3+ terabytes) data sets\n3+ years of experience working using AWS SageMaker, Microsoft SQL Server and Microsoft Power BI\nTrack record working in large (3+ terabytes) scale databases, data marts, and data warehouses\nProven Python 3 experience developing data science models using Machine Learning and AI\n\nWe would prefer you have:\nGraduate degree from an accredited university in data science, supply chain management, computer science, mathematics/physics, machine learning, operations research, applied to business decision making\nTrack record leading and delivering on the design and execution of data science projects\nExperience in several of the following areas: statistics, machine learning, recommendation systems, and AI\nDeep Python 3 and SQL scripting skills; Functional knowledge of AWS platforms such as S3, Glue, Sagemaker\nAdvanced skills in Python, Machine Learning, AI, Statistical Modeling, SQL, Data Warehouses, and Hadoop\nExtensive Python experience using Sci-Kit, TensorFlow, Matplotlib, Numpy, Pandas, Seaborn, Beautiful Soup\nWhy Master Electronics:\n\nAs a customer focused and driven organization, we offer attractive, competitive compensation with an increase after the 1st and 2nd year of employment in the distribution center and benefits including, medical, dental, life, paid time off, 401k match and an EAP program as well as an opportunity to grow with the company.\n\nMaster Electronics has a fast-paced and entrepreneurial environment, which requires a professional, flexible self-starter attitude.\n\nHeadquartered in Phoenix, AZ, Master Electronics is a leading global authorized distributor of electronic components. For more than half a century, our family-owned company has remained focused on strong relationships, responsive service and added value. This is howMaster Electronics has grown to serve hundreds of thousands of customers in partnership with hundreds of world-class suppliers.\n\nMaster Electronics, a leading global authorized distributor of electronic components, is committed to providing equal employment opportunities for all applicants and employees. The Company does not unlawfully discriminate on the basis of race, color, creed, pregnancy, religion, sex, national origin, age, disability, veteran, marital, or any other protected status. The Company also makes reasonable accommodations for disabled employees. Finally,Master Electronics prohibits the harassment of any individual based on their protected status. This policy applies to all areas of employment, including recruitment, hiring, training, promotion, compensation, benefits, transfer, and social and recreational programs.\nTo apply to this job, click Apply Now"}, "34": {"company": "Crossix Solutions", "description": "Crossix is seeking intellectually curious, resourceful, and collaborative Data Scientists with experience in quantitative research methods and statistical sampling to join our Advanced Analytics team. This is an excellent opportunity to help us build the technology and data science products that power our business and be at the forefront of innovation in the healthcare technology space.\n\nThe team is guided by its core values as it works to solve the most challenging problems in healthcare data and analytics:\nSingular Focus\nSpeed\nHumility\nOwnership\nChallenge\nWhat You'll Do\nLeverage quantitative research experience to design and build nationally representative datasets\nCollaborate closely with a team of data scientists, product managers, and executives to discover and deliver product offerings from prototype to massive scale\nRapidly build prototype product solutions, communicate findings, and iterate\nExplore and find meaning in high volumes of data to evaluate data quality and extract actionable insights that will help drive business decisions; execute data querying, data cleansing, and experiment design\nDraw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solved\nMaster core parts of the Crossix technology platform. Technologies include Spark, SQL, Python, R, AWS, and proprietary data mining software\nWork with engineering and development teams to improve and implement features in Crossix's platform\nWhat You've Done\nGraduate level degree in statistics, social sciences, or other quantitative discipline with at least 2 years of work experience\nExpertise in quantitative and survey research methods, sampling, designing representative panels\nAdvanced knowledge and professional experience in statistical modeling and data mining\nStrong problem-solving skills\nStrong hands-on coding skills in statistical modeling programing languages such as R and Python\nAdvanced SQL skills; expertise in best practices and tools for interacting with large data sets\nExperience with AWS for data-warehousing and processing is a plus\nExcellent written and verbal communication skills\nWho You Are\nHave a desire and preference for working in a fast-paced, entrepreneurial environment\nEnjoy having clear ownership of a goal even if the path to get there is not entirely clear\nHave a curiosity to figure out new problems\nAre humble and truly think about the success of the group before your own contribution\nAre comfortable challenging existing norms, thinking and teammates, always doing so respectfully\nAbout the Team \u2013 Crossix is the market leader in delivering hard-to-come-by insights that enable healthcare marketers to plan, measure, and optimize their marketing campaigns with confidence. Using our own proprietary technology and network of health and non-health data, our analyses pinpoint the tactics, programs, and channels that improve performance and boost sales, enabling better healthcare communications. And we do it all while protecting consumer privacy.\n\nLeadership \u2013 With decades of combined experience and an unrivaled track record of healthcare innovation, our leadership team sets the standard for us. Their knowledge and expertise continually challenge us and the industry \u2013 through their work, their speaking engagements at conferences and their thought leadership published in the top industry publications.\n\nCulture \u2013 We know that our employees set us apart. Along with competitive salaries and benefits, we invest in creating compelling opportunities for professional development and career growth. We also believe that diversity is essential to building an environment where everyone can feel they belong. We're continuously building an inclusive company where everyone feels welcome and heard. Come join our rapidly growing team!\n\nWe are an equal opportunity employer and welcome all qualified applicants regardless of race, color, religion, sex, gender identity, sexual orientation, marital status, ancestry, national origin, age, disability, genetic information, or veteran status.\nApply Now: click Apply Now"}, "35": {"company": "The Church of Jesus Christ of Latter-day Saints", "description": "Purposes\n\nThis is a contract, remote position that works with multiple departments throughout the organization to take their data and transform it into information that will allow them to make better decisions. The data engineer is responsible for gathering requirements, design, creation and support of the data warehouse.\n\nThis individual works with divine guidance to provide or support technology that furthers the mission of the Church and reflects the eternal impact of the gospel.\n\nResponsibilities\nPossess and utilize comprehensive knowledge, specific to the data field, to complete significant assignments\nMaintain a strong understanding of the supported business processes\nGather and document requirements for the data warehouse\nDesign dimensional Star Schema data models\nCreate and support all ETL jobs pulling data from various source systems and loading data into the data warehouse\nCreate semantic layer to support end-user self-service\nBuild complex reports using SQL Server Reporting Services (SSRS)\nCreate complex dashboards using Microsoft Power BI or Tableau\nForecast, analyze data and trends, and create reports that highlight areas in need of performance improvement\nInteract with customers as a technical resource to troubleshoot problems with the delivered BI solutions\nMaintain production documentation\nQualifications\n\nEducation:\nBachelor's degree in related field or equivalent professional experience. Master\u2019s degree preferred.\nWork Experience:\n8+ years of data warehouse experience\n3+ years of industrial grade experience in data science, including machine learning and NLP\nExperience evaluating industrial grade experience in data science, including machine learning and NLP\nProven track record of completing multiple data science projects end to end, from idea generation to implementation in production systems (warehouse, or applications)\nExtensive professional experience in data analysis and report design/development\nProfessional experience in presentation/interface creation\nDemonstrated Skills and Abilities:\nExceptional communicator; both written and verbal\nOutstanding troubleshooter\nProven ability to resolve complex problems under pressure\nComprehensive knowledge of engineering best practices\nStrong operational understanding and discipline\nAbility to resolve security issues and requests and implement improvements\nExpert dimensional data modeling skills\nAbility to quickly learn new tools and technology\nAdvanced problem solving, analytical, and diagnostic skills\nExcellent documentation, presentation, and communication skills\nHighly skilled in developing ETL code, can manage the ingestion and cleansing of large sets of structured and unstructured data\nStrong knowledge of the algorithms used for regressions, clustering, classification, forecasting, and constructing graphs\nThis job operates in a professional office environment\nTo successfully perform the essential functions of the job there may be physical requirements which need to be met such as sitting for long periods of time and using computer monitors/equipment\nWorthiness Qualification\n\nMust be a member of The Church of Jesus Christ of Latter-day Saints and currently temple worthy.\n\nPosting Notice/More Info.\n\nPlease Note: All positions are subject to close without notice.\n\nFind out more about the many benefits of Church Employment at http://careers.churchofjesuschrist.org.\n\n]]>\nApply Now: click Apply Now"}, "36": {"company": "Juniper Networks", "description": "\"About the Position:\nThe position of the IT Data Analyst is responsible for developing and implementing data analyses, data collection systems, and reporting capabilities to enhance and ensure the Juniper IT department is executing at the greatest efficiency and effectiveness. This position should be highly skilled in all aspects of data analytics, including data acquisition, processing, generation, and visualization. This individual will be accountable for the generation of key performance indicators and measures and advise on data and process improvements for greater organizational and vendor accountability and transparency.\n\nPosition Objectives:\nDevelop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.\nIdentify trends and opportunities for growth through analysis of complex data sets.\nEvaluate organizational methods and provide source-to-target mappings and information-model specification documents for data sets.\nCreate best practice reports based on data mining, analysis, and visualization.\nEvaluate internal systems for efficiency, problems, and inaccuracies, developing and maintaining protocols for handling, processing, and cleaning data.\nWork directly with management and stakeholders to gather requirements, provide status updates, and build relationships.\nResponsibilities:\nWork closely with service owners, service integration managers, and process owners to understand and maintain focus on their analytical needs, including identifying critical metrics and KPIs, and deliver actionable insights to relevant decision makers.\nProactively analyze data to answer key questions from stakeholders with a focus on what drives business performance, investigating and communicating areas for improvement in efficiency and productivity.\nCreate and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources.\nDefine and implement data acquisition and integration logic, selecting the most appropriate combination of methods and tools within the Juniper defined technology stack to ensure optimal scalability and performance of the solution.\nDevelop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make the data evaluation process more flexible and/or scalable across data sets.\nIdentify, analyze, and interpret trends or patterns across complex data sets and processes.\nLocate and define process improvement opportunities and work with process owners and stakeholders to implement such opportunities.\nSkills and Qualifications:\nBachelors degree in Mathematics, Computer Science, Economics, or Statistics\n3+ years of experience as a data analyst or business analyst\nLean Six Sigma knowledge and experience. Green Belt or higher preferred\nExcellent analytic skills, including data mining, evaluation, analysis, and visualization\nStrong technical writing experience in relevant areas, including queries, reports, and presentations\nTechnical expertise regarding data models, database design development, data mining and segmentation techniques\nStrong working knowledge of SQL, Excel, Power Pivot, Power BI, DAX, Tableau\nAbility to program in newer and emerging languages such as R and Python desired\nGood working knowledge and experience in ITIL frameworks and processes\nGood knowledge, experience, and understanding of ServiceNow tool and data structure\n\nABOUT JUNIPER NETWORKS\n\nJuniper Networks is in the business of network innovation. From devices to data centers, from consumers to cloud providers, Juniper Networks delivers the software, silicon and systems that transform the experience and economics of networking. Our products and technology run the world's largest and most demanding networks today, enabling service providers, enterprises, and governments to create value and accelerate business success. Everyday our 9,000+ colleagues come together across 46 countries to realize our company vision - Connect Everything, Empower Everyone. We are innovating in ways that empower our customers, our partners and ultimately, everyone, in a connected world. These customers include the top 130 global service providers, 96 of the Fortune 100 and hundreds of public sector organizations.\n\n\nWHERE WILL YOU DO YOUR BEST WORK?\n\nWherever you are in the world, whether it's downtown Sunnyvale or London, Westford or Bangalore, Juniper is a place that was founded on disruptive thinking - where colleague innovation is not only valued, but expected. We believe that the great task of delivering a new network for the next decade is delivered through the creativity and commitment of our people. The Juniper Way is the commitment to all our colleagues that the culture and company inspire their best work-their life's work. At Juniper we believe this is more than a job - it's an opportunity to help change the world...\n\n\nELIGIBILITY TO WORK AND E-VERIFY\n\nIn compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.\n\nJuniper Networks participates in the E-Verify program. E-Verify is an Internet-based system operated by the Department of Homeland Security (DHS) in partnership with the Social Security Administration (SSA) that allows participating employers to electronically verify the employment eligibility of new hires and the validity of their Social Security Numbers.\n\n_ Information for applicants about E-Verify / E-Verify Informacin en espaol: This Company Participates in E-Verify / Este Empleador Participa en E-Verify\n_ Immigrant and Employee Rights Section (IER) - The Right to Work / El Derecho a Trabajar\n\nE-Verify is a registered trademark of the U.S. Department of Homeland Security.\n\nJuniper is an Equal Opportunity workplace and Affirmative Action employer. We do not discriminate in employment decisions on the basis of race, color, religion, gender (including pregnancy), national origin, political affiliation, sexual orientation, gender identity or expression, marital status, disability, genetic information, age, veteran status, or any other applicable legally protected characteristic. All employment decisions are made on the basis of individual qualifications, merit, and business need.\"\nTo apply to this job, click Apply Now"}, "37": {"company": "Walmart eCommerce", "description": "Position Description\n\nAs the Walmart Voice Commerce team we are building completely new capabilities to allow our customers to shop by seamlessly interacting with their connected devices using spoken language. This team is part of the Growth organization and will build new voice experiences both in-house and in collaboration with strategic partners. Voice as a medium for shopping is still in its infancy and as part of this team you will get to work on industry leading solutions and be at the forefront of this emerging platform. You will get to part of defining how customers shop in everyday lives.\n\nMinimum Qualifications\nPh. D. in computer science or similar field or MS with 3+ years of related experience\nDeep knowledge of machine learning, information retrieval, data mining, statistics, NLP or related field.\nGood functional coding skills in C++, Java, Scala in addition to good knowledge of one of the scripting languages such as Python or Perl.\nExperience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark etc.)\nSuperior ability to analyze and interpret the results of product experiments.\nProven experience working with statistical languages such as R.\nStrong communication skills both written and verbal\nAdditional Preferred Qualifications\nKnowledge of Spark, Scikit-learn, Problem solving, Willing to learn new technologies.\nSelf-starter, Quick learner, Keen observer, eye for detail and someone who relishes challenges\nStrong research and publication record\n#LI-SN1\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nAs the Walmart Voice Commerce team we are building completely new capabilities to allow our customers to shop by seamlessly interacting with their connected devices using spoken language. This team is part of the Growth organization and will build new voice experiences both in-house and in collaboration with strategic partners. Voice as a medium for shopping is still in its infancy and as part of this team you will get to work on industry leading solutions and be at the forefront of this emerging platform. You will get to part of defining how customers shop in everyday lives.\nTo apply to this job, click Apply Now"}, "38": {"company": "Walmart eCommerce", "description": "Position Description\n\nThis position is part of the Growth organization in @WalmartLabs. The mission of the Growth organization is to advance Walmart eCommerce by driving higher value for our customers and vendor partners. We are seeking talented and self-driven individuals to join the Walmart Ads team. The Ads team owns the platform that enhances user experience while improving monetization on Walmart.com, by displaying highly optimized targeted product advertisements to our customers. The team operates an end to end advertising platform that includes a scalable ad service that serves hundred of millions of impressions each day, sophisticated ad matching algorithms, real-time reports, self service interface for end to end program management etc.\n\nWe are a highly motivated group of Big Data Geeks, Data Scientists and Applications Engineers, working in small agile group to solve sophisticated and high impact problems. We are building smart data systems that ingest, model and analyze massive flow of data from online and offline user activity. We use cutting edge machine learning, data mining and optimization algorithms underneath it all to analyze all this data on top of Spark/Hadoop/Druid.\n\nMinimum Qualifications\n\n*Manager's Ideal Candidate Must-Haves\n\u2022Deliver highly scalable and reliable production ready code\n\u2022Design, develop, and operate code across multiple productions systems\n\u2022Work with Spark / Hadoop and large-scale Analytics systems that are capable of ingesting, managing, storing and analyzing hundreds of terabytes of data\n\u2022Be excited about making an immediate impact on a global scale\n\nAdditional Preferred Qualifications\n\n\u2022 Good verbal and written communication skills.\n\nCompany Summary\n\nWalmart Global eCommerce is comprised of Walmart.com, VUDU, SamsClub.com, and our technical powerhouse @WalmartLabs. Here, innovators incubate next gen e-commerce solutions in real-time. We integrate online, physical, and mobile shopping experiences for billions of customers around the globe. How do we do it? We continuously build and invest in new technology including open source tools and big data innovations. Data scientists, front and back-end engineers, product managers, and web and UX/UI teams collaborate alongside e-commerce experts to envision, prototype, and bring revolutionary ideas to life in a dynamic, flexible and fun work culture.\n\nPosition Summary\n\nThis software development position will be responsible for design, implementation and unit testing of VUDUs content delivery and server architecture. This position will be primarily responsible for the companys core server applications and advertising technology.\nStart your job application: click Apply Now"}, "39": {"company": "LSQ", "description": "Job Title: Data Scientist (Risk)\n\nLocation: Orlando, Florida\n\nManager: Head of Data Science\n\nAbout LSQ\n\nLSQ is a technology-driven provider of accounts receivable financing to companies who need working capital but may not be able to obtain sufficient financing from their bank. Our focus is to help businesses release the liquidity tied up in their accounts receivable. With financing from LSQ, a business can purchase more inventory, fill more orders, and take advantage of new growth opportunities. Our technology and data driven approach to providing working capital, along with our accounts receivable management services, allows our clients to driving business success.\n\nJob Overview\n\nLSQ is searching for a Data Scientist (Risk) to join our growing team of analytics experts. The hire will be responsible for building data driven tools to automate and scale risk decisions decision points include, fraud detection, commercial credit analysis, and invoice payment behavior. The ideal candidate is an experienced researcher and data wrangler who enjoys applying complex theories to solve real world business problems. The Data Scientist will need to collaborate effectively with both technical (engineers, data experts) and non-technical (business users) colleagues to bring the data to life.\n\nResponsibilities of Data Scientist (Risk)\nWe have 20+ years of real-world commercial data weve observed businesses and their interactions with other businesses across market cycles, industries, and catastrophic events. Build risk tools that optimize for velocity and scale.\nBuild risk tools that optimize science & art you will work with risk experts who have been in the trenches (and learned from losses). Augment human decisions with machine.\nLay the foundation for scale. A data science framework for optimal data acquisition, model training and deployment. Dont take short-cuts. Bring quantitative and statistical rigor to your body of work.\nLead by example. You are joining a data team at ground-level. Building and inserting a data team, into a 20+ year old company (organism) will be hard, but rewarding.\nQualifications for Risk Data Scientist\nCuriosity, Grit, and Humility\n5+ years of experience of hands-on data science role\nPrevious experience of building commercial finance risk tools should be beneficial, but not required\nBachelor or Masters degree in Data Science, Operations Research, Computer Science, Industrial Engineering, Statistics, or another quantitative field\nA toolkit of modern data science techniques\nExperience with any data science tools/packages: Python, R, SAS, XGBoost, TensorFlow, NLTK\nExperience with any big data tools: Hadoop, Spark, Kafka, Data Bricks\nExperience with any reporting tools: Tableau Server, Power BI, SSRS, Excel\nExperience with any AWS cloud services: EC2, EMR, RDS, Redshift, Aurora, S3\nExperience with any Stream-processing systems: Storm, Spark-Streaming\nPosition Type and Expected Hours of Work:\n\nThis is a full-time position. Days and hours of work are Monday through Friday, 8:00 a.m. to 5 p.m. Occasional evening and weekend work may be required as job duties demand.\n\nPhysical Demands:\n\nWhile performing the duties of this job, the employee is regularly required to sit and use hands to finger, handle, or feel. The employee is frequently required to reach with hands and arms and talk or hear. The employee is occasionally required to stand; walk and stoop, kneel, crouch.\n\nTravel:\n\nThere will be minimal travel required for this position.\n\nLSQ is an Equal Opportunity Employer that does not discriminate on the basis of actual or perceived, race, religion, color, sex (including pregnancy and gender identity), sexual orientation, parental status, national origin, age, disability, family medical history or genetic information, political affiliation, military service, any other non-merit based factor or any other characteristic protected by applicable federal, state or local laws. Our leadership team is dedicated to this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, employee activities and general treatment during employment. If youd like more information about your EEO rights as an applicant under the law, please click here http://www1.eeoc.gov/employers/poster.cfm\nStart your job application: click Easy Apply"}, "40": {"company": "Walmart eCommerce", "description": "Position Description\nA Staff Data Scientist is responsible for analyzing large data sets to develop multiple custom models and algorithms to drive innovative business solutions. Staff Data Scientists work on large project teams in order to provide analytical support and guidance to an assigned area on for large projects (for example, email targeting, business optimization, consumer recommendations) within Walmart eCommerce. Staff Data Scientists are responsible for building large data sets from multiple sources in order to build algorithms for predicting future data characteristics. Those algorithms will be tested, validated, and applied to large data sets. Staff Data Scientists are responsible for training the algorithms so they can be applied to future data sets and provide the appropriate search results. Staff Data Scientists are responsible for researching new trends in the industry and utilizing up-to-date technology (for example, HBase, MapReduce, LAPack, Gurobi) and analytical skills to support their assigned project. Staff Data Scientists are the subject matter experts for statistical analysis and modeling for their project team.\nBuild complex data sets from multiple data sources, both internally and externally.\nBuild learning systems to analyze and filter continuous data flows and offline data analysis.\nCollaborate with cross-functional partners across the business.\nCollaborate with project teams to implement data modeling solutions.\nCombine data features to determine search models.\nConduct advanced statistical analysis to determine trends and significant data relationships.\nDevelop models of current state in order to determine improvements needed.\nDevelop multiple custom data models to drive innovative business solutions.\nDrives the execution of multiple business plans and projects\nEnsures business needs are being met\nInterpret data to identify trends to go across future data sets.\nPromotes and supports company policies, procedures, mission, values, and standards of ethics and integrity\nProvides supervision and development opportunities for associates\nResearch new techniques and best practices within the industry.\nScale new algorithms to large data sets.\nTrain algorithms to apply models to new data sets.\nTranslate business needs into data requirements.\nUtilize system tools including (MySQL, Hadoop, Weka, R, Matlab,ILog).\nValidate models and algorithmic techniques.\nMinimum Qualifications\nBachelor of Science and 7 years' data science experience OR Master of Science and 5 years' data science experience.\nAdditional Preferred Qualifications\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\nA Staff Data Scientist is responsible for analyzing large data sets to develop multiple custom models and algorithms to drive innovative business solutions. Staff Data Scientists work on large project teams in order to provide analytical support and guidance to an assigned area on for large projects (for example, email targeting, business optimization, consumer recommendations) within Walmart eCommerce. Staff Data Scientists are responsible for building large data sets from multiple sources in order to build algorithms for predicting future data characteristics. Those algorithms will be tested, validated, and applied to large data sets. Staff Data Scientists are responsible for training the algorithms so they can be applied to future data sets and provide the appropriate search results. Staff Data Scientists are responsible for researching new trends in the industry and utilizing up-to-date technology (for example, HBase, MapReduce, LAPack, Gurobi) and analytical skills to support their assigned project. Staff Data Scientists are the subject matter experts for statistical analysis and modeling for their project team.\nBuild complex data sets from multiple data sources, both internally and externally.\nBuild learning systems to analyze and filter continuous data flows and offline data analysis.\nCollaborate with cross-functional partners across the business.\nCollaborate with project teams to implement data modeling solutions.\nCombine data features to determine search models.\nConduct advanced statistical analysis to determine trends and significant data relationships.\nDevelop models of current state in order to determine improvements needed.\nDevelop multiple custom data models to drive innovative business solutions.\nDrives the execution of multiple business plans and projects\nEnsures business needs are being met\nInterpret data to identify trends to go across future data sets.\nPromotes and supports company policies, procedures, mission, values, and standards of ethics and integrity\nProvides supervision and development opportunities for associates\nResearch new techniques and best practices within the industry.\nScale new algorithms to large data sets.\nTrain algorithms to apply models to new data sets.\nTranslate business needs into data requirements.\nUtilize system tools including (MySQL, Hadoop, Weka, R, Matlab,ILog).\nValidate models and algorithmic techniques.\nApply Now: click Apply Now"}, "41": {"company": "Liberty Mutual Insurance", "description": "At Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.\nWork with a team committed to excellence!\nHelp bring Information Management operations into the future!\nModel and promote a 'Data First' attitude\nWork with a modern tech stack\nGRM is currently working to create new systems with modern architectures and transition business lines policies to those systems. As part of the Global Retail Markets organization you will be part of a team that will serve the US region and facilitate world class experiences for our customers and agents. As part of our MDM team you will be modernizing and building out the systems that provide clean, standardized and mastered customer and agent data. We are well on our way to revolutionizing our customer's experience and need a strong developer to help us achieve our desired results.\nIn this role you will:\nWork with Scrum Masters, Product Owners, and peer developers to iteratively create solutions that meet business and technical requirements\nDevelop Master Data Management applications using Java, Spring, and Informatica MDM\nAnalyze technical system problems, and design and implement effective solutions\nHandle end-to-end development, including coding, testing, and debugging during each cycle\nCreate applications using Informatica's MDM software\nCreate and maintain technical documentation\nDevelop automated tests for multiple scopes (Unit, System, Integration, Regression)\nMentor new and junior developers\nQualifications:\nBachelor's or Master's degree in technical or business discipline or equivalent experience, technical degree preferred.\nGenerally, 5+ years of professional experience in software development with 3+ years of Java development experience\nExperience with Master Data Management and Informatica's MDM product preferred.\nExperience with WebLogic, Kafka, AWS/Cloud and Oracle desired.\nExtensive knowledge of IT concepts, strategies, methodologies.\nExperience working with agile methodologies (Scrum, Kanban, XP) and cross-functional teams (Product Owners, Scrum Masters, Developers, Test Engineers)\nVersed in diverse technologies and new technical architecture principles and concepts including extensive knowledge in layered systems architectures solutions and designs and shared software concepts.\nDemonstrates leadership and active pursuit of optimizing CI/CD process and tools, testing frameworks and practices\nMust be proactive, demonstrate initiative, and be a logical thinker.\nStrong collaboration, prioritization, and adaptability skills required.\nIdentify and recommend appropriate continuous improvement opportunities\n\n\nBenefits & Culture:\n\nIn GRM - Information Management, we embrace all of the values of our Fortune 100 company and push our practices and technology skill sets to the next level. In this organization, we are an agile set of teams dedicated to helping impact the lives of thousands of customers every day. We embrace a modern co-working style with exceptional work/life balance, ergonomic work areas, substantial benefits, and best-in-class amenities.\n\nLiberty Mutual is one of America's Best Employers for Diversity and one of the Best Employers for Women http://bit.ly/LibertyMutual-BestPlacesToWorkforWomen one of the Best Employers for New Grads http://bit.ly/LibertyMutual-BestPlacesforNewGrads and one of the Best Places to Work http://bit.ly/LibertyMutual-BestPlacestoWork . We offer excellent benefits for our employees including generous parental leave, retirement plans including 401k and pension, education reimbursement, commuter benefits, college savings plans, and much more.\n\nTo learn more about our benefit offerings and culture please visit:\nhttps://LMI.co/Benefits\nhttp://bit.ly/LibertyMutual-Culture\nEOE Statement:\n\n\nLiberty Mutual is an equal opportunity employer. We embrace an environment that is free from all discrimination in the workplace, in its business, or by its vendors. Liberty Mutual values diversity and the differences and similarities of our employees. We foster a diverse and inclusive work environment that leads to better ideas, stronger teams and more innovative products and services for our customers. Learn More:\nStart your job application: click Apply Now"}, "42": {"company": "Camino Financial", "description": "Camino Financial - Los Angeles, CA\n\nRequires Travel: Once in a while\n\nPeople Manager: NO\n\nMinimum Skills: AWS, Python, R Studio, GIT, SQL, BI tools, Ability to be a team player\n\nABOUT US:\n\nCamino Financial is an online lending platform extending credit to underbanked small businesses. The company uses a proprietary credit scoring system to assess the credit for businesses with limited or no credit history. We are looking for talented engineers to join our team and make a difference.\n\nWe have been featured on CNN Money, Forbes, Discovery Channel ESP, NBC News, Univision, Latin Post, American Banker.\n\nWe are extremely mission-driven and is here to make a difference in the US lending space and beyond.\n\nSUMMARY:\n\nThe Engineering team is looking for a self-motivated Data Engineer who can help with building out our data pipeline that powers our various BI tools, dashboards and data warehousing. You\u2019ll help to build a general, secure, scalable, fast, and high throughput data pipeline to process a decent amount of data on a daily basis.\n\nWe are very passionate about performance, correctness, and data quality. The team spends their time day to day developing new pipelines or features that make it seamless for data to be moved throughout our infrastructure.This includes choosing and working with cutting edge tools. You will If you enjoy working in a collaborative environment where everyone can have their say while still being able to set and hit deadlines, then this is the role for you.\n\n.\n\nWHAT YOU\u2019LL DO:\nCreate and maintain optimal data pipeline architecture, which performs Extract Transform Load (ETL) of our incoming data.\nAssemble large, complex data sets that meet functional / non-functional business requirements.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Python and AWS \u2018big data\u2019 technologies.\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\nKeep our data separated and secure across national boundaries through multiple data centers and AWS regions.\nCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\nWork with data scientists and analytics experts to strive for greater functionality in our data systems.\nREQUIREMENTS:\n2 Years or more of related experience\nStrong data engineering background\nStrong software development background\nModerate experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\nModerate knowledge of AWS cloud services: EC2, EMR, RDS, Redshift\nExperience with object-oriented/object function scripting languages: Python, Java, C++\nExperience building and optimizing AWS data pipelines, architectures and data sets\nWe are a fun startup with people from great schools like Columbia, UPenn, Harvard, Berkeley, USC, UCLA, UC Irvine, etc.\nWe cherish diversity\nWe are well funded\nWe have decent revenue and bank partnerships in place\nStrong coaching culture\nLearning opportunities on-site and at expos\nPet friendly office\nPaternity / maternity leave\nJob Location:\nLos Angeles, CA\nJob Type: Full-time\nWork authorization:\nUnited States (Required)\nAdditional Compensation:\nOther forms\nWork Location:\nOne location\nBenefits:\nHealth insurance\nPaid time off\nParental leave"}, "43": {"company": "Presbyterian Healthcare Services", "description": "Overview\n\n\nJob Description Type of Opportunity: Full Time FTE: 1.000000 Exempt: Yes Work Schedule: Days\n\nSummary:Support portfolio management of reporting/analytics solutions across the business units in the analytics organization. Identify business issues/problems, form hypotheses, plan and conduct interviews, whiteboard sessions & perform reporting/analysis to synthesize conclusions, transform them into recommendations and develop a solution. Lead and manage small cross functional team to implement, test and deploy the approved reporting/analytics solution in response to the business (clinical/operational/financial) needs. Identify reporting/analytics improvement opportunities and provide proactive, consultative strategic solutions. Responsible for mentoring junior analysts as well as coordinating various reporting/analytics initiatives with end business users. Support reporting/analytics projects prioritization and planning as well as cconduct due diligence concerning business implications of planned solutions.\n\nResponsibilities\n\n\nResponsibilities:Consultation and Communication:*Ability to collaborate and partner with management, project managers, and IT to develop, implement and manage reporting/analytics portfolio with the vision & goals of specific Hub/Spoke core teams*Effective communication skills across the organization and at different levels, strategic thinking and actions to influence key stakeholders and business decisions *Support day-to-day consultation to business users and participate and contribute cross-functional project teams*Work with business stakeholders to identify business needs and support creation of the use cases and user stories satisfying those needs Project Management and Execution:*Coordinate with other departments across the AO such as IM governance & EDW and support conceptualization and development of reporting/analytical methodologies, solutions and initiatives*Aid in the development of project plans and strategies as well as execute assigned project plans to deliver solutions in a timely manner*Support collaboration on roadmaps, dependencies, and execution plans across analytical units and with applicable teams in the organization *Manage the intake requests across the business units; track and monitor the work to ensure critical milestones are met, identify and report/escalate risks to management appropriately; manage stakeholder relations*Obtain data, direct/execute reporting/analysis, perform interpretations and conclusions, and prepare recommendations. *Assist in determining business needs by effectively conducting fact-finding interviews and leveraging various tools and analytical methods and then summarize findings in a coherent manner to develop and propose appropriate solution *Conduct research studies that include collecting data from various sources, analyzing, trending and presenting the findings and recommendations to management *Support translation of business requirements and unstructured business issues into data analytic problems*Perform overall program evaluations (i.e., planning-implementation-completion/analysis-reporting) and other assessments such as change management assessments, workflow optimization assessments, etc. Training and Guidance:*Manage and support teams to structure data and analysis to analyze issues and proactively identify improvement opportunities*Responsible for the work flow management of analysts and ensuring reliability, integrity, and timeliness of end products*Support coordination of training for analysts in core and expanded business departmentThought Leadership:*Support in development of presentations/publications/point-of-views with senior leadership within the AO *Contribute towards and assist senior leadership in developing a year-end value story to demonstrate value of the team and their contribution to progress towards the AOs and PHSs goals\n\nQualifications\n\n\nOther information:SKILLS: Bachelors degree in a quantitative, business, or healthcare related subject. A Masters degree is highly preferred. Four or more years of combined experience in business intelligence, reporting and analytics preferably in a healthcare setting. Demonstrated project management skills as well as the ability to efficiently work and manage teams and resources. Experience working on complex analytical projects with diverse teams and developing data driven and outcome based initiatives to improve business decision making and operational efficiencies. Knowledge of health plan and delivery system operations, health care informatics, and healthcare benefits and terminology (e.g., care management). Understanding of operations in the Health Care industry and a strong acumen of business processes, including operations, delivery models and revenue models. Understanding of program evaluation life cycle, predictive modeling, data mining, and clinical best practices preferred. Content knowledge related to program outcomes evaluation, BI tools (e.g., BO), data visualizations tools (e.g., Tableau), statistical software such as SAS and Modeling techniques, as well as general health service research and outcomes reporting/analytics. Working knowledge of healthcare industry and healthcare information standards such as HL7, LOINC, FHIR, ICD 9/10 and CPT codes, industry standard groupers (e.g., ETGs, DRGs, DCGs, etc.) as well as of health care delivery system processes. Excellent written and oral communications is a MUST.\n\nPreferred Qualifications:\nHealth Plan/Finance Experience\nStrong Communicator\nSAS/SQL Coding Experience\nMicrosoft Access experience preferred\nVBA(Visual Basic for Applications) experience is a plusNote: They will not be building new databases but one of our key customers is heavy utilizer of Access in order to best support them they need an understanding of how Access works and the challenges/pitfalls that exist with Access & VBA\nCompetencies and skills:Essential:* SKILL-Demonstrated ability to communicate effectively in person and via telephone with members, employer groups, brokers, physicians, and physician office staff using strong dialogue and customer service competencies. * SKILL-Written communication Nonessential:* Analytics skills* SKILL-Decision Making* SKILL-Project management methods and tools in support of managing Scope, Time, Cost, Quality, Communication, Risk, and Procurement Management;\n\nBenefits\n\n\nBenefits Benefits are effective day-one (for .45 FTE and above) and include:\nCompetitive salaries\nFull medical, dental and vision insurance\nFlexible spending accounts (FSAs)\nFree wellness programs\nPaid time off (PTO)\nRetirement plans, including matching employer contributions\nContinuing education and career development opportunities\nLife insurance and short/long term disability programs\nAbout Us Presbyterian Healthcare Services is a locally owned, not-for-profit healthcare system of nine hospitals, a statewide health plan and a growing multi-specialty medical group. Founded in New Mexico in 1908, it is the state's largest private employer with approximately 11,000 employees.\n\nPresbyterian's story is really the story of the remarkable people who have chosen to work here. Starting with Reverend Cooper who began our journey in 1908, the hard work of thousands of physicians, employees, board members, and other volunteers brought Presbyterian from a tiny tuberculosis sanatorium to a statewide healthcare system, serving more than 700,000 New Mexicans. We are part of New Mexico's history - and committed to its future. That is why we will continue to work just as hard and care just as deeply to serve New Mexico for years to come. About New Mexico New Mexico's unique blend of Spanish, Mexican and Native American influences contribute to a culturally rich lifestyle. Add in Albuquerque's International Balloon Fiesta, Los Alamos' nuclear scientists, Roswell's visitors from outer space, and Santa Fe's artists, and you get an eclectic mix of people, places and experiences that make this state great. Cities in New Mexico are continually ranked among the nation's best places to work and live by Forbes magazine, Kiplinger's Personal Finance, and other corporate and government relocation managers like Worldwide ERC. New Mexico offers endless recreational opportunities to explore, and enjoy an active lifestyle. Venture off the beaten path, challenge your body in the elements, or open yourself up to the expansive sky. From hiking, golfing and biking to skiing, snowboarding and boating, it's all available among our beautiful wonders of the west. AA/EOE/VET/DISABLED. PHS is a drug-free and tobacco-free employer with smoke free campuses.\n\nAD123\n\n#CB\nStart your job application: click Apply Now"}, "44": {"company": "Walmart eCommerce", "description": "Position Description\n\n\u2022 Play a pivotal design and hands on implementation role in improving the Data infrastructure in a project-oriented work environment.\n\u2022 Influence cross functional architecture in sprint planning\n\u2022 Gather and process raw data at scale - collect data across all business domains (our functional-first, event sourced, micro services backend) and expose mechanisms for large scale parallel processing\n\u2022 Design, implement and manage a near real-time ingestion pipeline into a data warehouse and Hadoop data lake.\n\u2022 Process unstructured data into a form suitable for analysis and then empower state-of-the-art analysis for analysts, scientists, and APIs\n\u2022 Build efficient new Data Models and refactor existing ones. Partner with business to build right data models and analytics capabilities.\n\u2022 Solve complex SQL and Big Data Performance challenges.\n\u2022 Mitigate Risks in our data infrastructure by developing the best in class tools and processes.\n\u2022 Implement controls, policies, processes and best practices in the Data Engineering space.\n\u2022 Evangelize an extremely high standard of code quality, system reliability, and performance.\n\u2022 Help us improve our database deployment and change management process.\n\u2022 Provide reliable and efficient Data services as part of the database team.\n\u2022 Work closely with the devs on development best practices and standards.\n\u2022 Be a mentor.\n\nMinimum Qualifications\n\n\u2022 Degree in Computer Science, Information Technology, Math or related technical field preferred.\n\u2022 Natural inclination for designing well thought out data solutions as well as solid hands-on implementation capability\n\u2022 4+ years experience in engineering data solutions using technologies including Spark (batch/streaming), Scala/Java (building data pipelines vs frameworks), Hadoop, Hive, HBase, Kafka, Spark, Oozie, Yarn.\n\u2022 Solid hands-on experience in building data pipelines, deploying and managing Big Data infrastructure, establishing deployment and operational excellence of Big Data clusters.\n\u2022 Experience in Relational databases, Data Warehousing, SQL, ETL and/or NOSQL databases will be sweet.\n\u2022 Proven experience in Building or improving large scale data infrastructure from the ground up. This could include building Data warehousing stores, Data Architecture, Data Integration, building highly performant data movement pipelines, building tools and automation to facilitate Data and operational governance, Data Lineage, Automation and Monitoring.\n\u2022 Proven Performance Tuning Accomplishments and Advanced tuning and trouble shooting skills in Large data environments on the Hadoop or RDBMS stack.\n\u2022 Advanced knowledge of internals of at least one RDBMS (MSSQL preferred) and best practices.\n\u2022 Data Ops experience including hands on skills in scripting language such as Python, Perl or Bash\n\u2022 Proven experience in trouble shooting, problem determination and rapid problem resolution\n\u2022 Experience and ability to work under high pressure in a complex technical environment.\n\nAdditional Preferred Qualifications\n\nCompany Summary\n\nThe Walmart eCommerce team is rapidly innovating to evolve and define the future state of shopping. As the worlds largest retailer, we are on a mission to help people save money and live better. With the help of some of the brightest minds in technology, merchandising, marketing, supply chain, talent and more, we are reimagining the intersection of digital and physical shopping to help achieve that mission.\n\nPosition Summary\n\nThe Data Platforms team at JET is looking for an exceptionally talented Data engineer with an outstanding track record reflecting achievements and skills in modernizing and improving the data infrastructure from the ground up. So, if you are passionate about working with very Large Data sets (structured/unstructured), building large scale Data processing platforms, implementing world class data governance and operational controls, solving complex performance challenges and building robust ETL pipelines then we would love to talk to you.\nJet Data Environment\nJets Event driven Ecommerce Microservices generate massive volume of data every second. Our Data Platform ingests and organizes this and other third party high speed, high volume data and enables strategic and operational decisions and reporting by Analysts and Data Scientist in every domain of Jet Ecommerce business.\nOur Data Platform supports Strategic and Operational Analytics and leverages Azure hosted Big Data clusters as well as a constellation of Big Microsoft SQL Server instances. Our platform leverages Spark, Hive, Kafka, Redis, Elastic Search, Cosmos DB and stores several petabytes of data.\nStart your job application: click Apply Now"}, "45": {"company": "Altitude Networks", "description": "Job Description\nAs a senior data engineer at Altitude Networks, you are in charge of transforming data into a format that can be easily accessed and analyzed. You develop and maintain data pipelines to read data from external APIs, format them in a way that is easy to analyze, and store them in data stores that are scalable, stable, and accessible by other services in the organization.\nMore: https://altitudenetworks.com/careers.html\n\nResponsibilities\n- Contribute to the core design of data architecture, data models and schemas, and implementation plan.\n- Design, build and maintain optimal data pipeline architecture for optimal extraction, transformation, and loading of data from a wide variety of data sources, including external APIs, data streams, and data stores.\n- Design, create and maintain the infrastructure for ingesting data into our data lake and data warehouse and providing frameworks and services for operating on that data.\n- Design, create and maintain the infrastructure for real-time streaming analytics, big data analytics, and machine learning analytics capabilities.\n- Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n- Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\n- Work with security to implement data privacy and data security requirements to ensure solutions stay compliant to security standards and frameworks.\n\nRequirements\n- Bachelor's degree in engineering\n- 5+ years of experience with python programming\n- 3+ years of experience with AWS data infrastructure, including RDS, DynamoDB, S3.\n- Proficient with relational (SQL) and non-relational (key-value data types) data modeling.\n- Proficient message queuing and stream processing including SQS and DynamoDB Streams.\n- Working familiarity with a variety of big data frameworks and tools, including AWS EMR, Redshift, Kinesis, Hadoop, Spark, HBase, Hive, Pig.\n- Experience with containerized (Docker, ECS) or serverless (Lambda) deployment.\n\nAbout Altitude\nAltitude Networks provides companies with the data security they need to safely use collaboration SaaS (GSuite, Box, Dropbox, Office365 etc) without the threat of data loss, theft or inadvertent sharing with unauthorized individuals. Altitude Networks is founded by Michael Coates, former CISO of Twitter and 15 year veteran in the information security space, and Amir Kavousian, Stanford PhD and former data scientist from CapitalOne ML fraud team. We are a BusinessInsider Top 30 CyberSecurity Startup in 2019, backed by prominent Silicon Valley Venture Capital. At Altitude Networks, we use a modern architecture that is designed to optimize development efficiency and velocity. We use a serverless architecture and advanced CI/CD tools that enable all team members to quickly develop, deploy, and maintain code in production in AWS cloud.\n\nAltitude Networks is proud to offer the following benefits:\nHealth, Dental, Vision, PTO, Parental Leave Policy, 401K, Commuter/Parking Benefits, Short/Long Term Disability, Friday Team Lunch, and One Medical Membership, Unlimited Coffee & Kambucha\nStart your job application: click Easy Apply"}, "46": {"company": "Decisive Analytics", "description": "Overview\n\n\nDecisive Analytics Corporation has an opening in Huntsville, Alabama, for a Radar Data Analyst to provide technical services in support of the Ronald Reagan Ballistic Missile Defense Test Site. Kwajalein Atoll is home to the Reagan Test Site (RTS), where some of the most sophisticated missile testing in the world is conducted by the US. RTS operates and maintains a technologically advanced suite of sensors including radars, optics and telemetry sites around the Atoll that are used to collect mission-critical test data on various missile systems being tested there. The successful applicant\u2019s primary job responsibilities will include flight test planning to ensure RTS customer objectives are met, as well as flight test sensor data analysis to assess the performance of both the missile system and the RTS sensor systems during the test.\n\nResponsibilities\nApply engineering principles and scientific investigative techniques to support planning, analysis, assessment, and reporting on flight tests.\nParticipate in meetings and test events, which may include overseas travel, and document complete and accurate observations noted in test events.\nPerform analysis of test events to support performance assessments of the system under test, and prepare briefings and reports summarizing analysis and assessments.\nWork autonomously as well as a member of a team of engineers and scientists to investigate complex system and or sensor behavior, and produce complete technical products.\nAssess complex systems through synthesis of analytical results and expert judgment, review technical documentation, conduct analytical studies and prepare technical reports on research findings.\nQualifications\n\n\nRequired:\nBachelor\u2019s degree in one of the following disciplines: engineering, mathematics, physical sciences, or computer science.\nExcellent written and oral communication skills and be proficient with office automation tools\nSoftware design & maintenance experience\nRadar Analysis\nSoftware Development\nHigh-level programming languages (MatLab, C, C++, Python)\nRadio Frequency (RF) signature modeling and analysis\nExperience with RF signature prediction codes (Xpatch, SAF, Periodic Method of Moments, ANSYS/HFSS, Cicero, etc.)\nBallistic missile intercept modeling using first-principle physics codes\nAerodynamic modeling of missiles and intercept debris\nFuel debris and intercept debris signature modeling\nDevelopment of finite element models\nModeling of BMDS radars\nAbility to obtain and maintain a DoD SECRET clearance.\nDesired:\n\nFamiliarity with:\nRTS sensors and command & control, including instrumentation class radars, optical sensors, telemetry sensors, communications and the command & control software.\nAF Global Strike flight testing and Missile Defense Agency (MDA) flight testing.\nExperience in one or more of the following areas: conducting complex analytical studies, developing or adapting analysis tools to suit needs, building reusable, well documented MATLAB utilities, assessing the suitability, effectiveness, survivability, and interoperability of complex military systems, evaluating threat intelligence information as it pertains to system performance.\nKeywords: Data science, MatLab, Python, C++, RF Modeling, Radar Analysis, Software Development\n\nEEO statement\n\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status or disability.VEVRAA Federal Contractor\nTo apply to this job, click Apply Now"}, "47": {"company": "WebPT", "description": "Are you a data expert that knows how to solve problems and answer complex questions using data? Do you geek out on analytics? Can you define the Job To Be Done? If so, we want to hear from you.\n\nAs a WebPT SQL Data Analyst you\u2019ll be responsible for working with BI Analyst to develop queries, views, of complexed clinical and financial data. You\u2019ll need excellent communication skills as you collaborate closely with customers, Product and our Reporting and Analytics engineering team to create custom reports that our customers love. In short, we\u2019re looking for a total data rockstar who not only possesses a high level analytics acumen, but also excels at working in a cross functional environment.\n\nAt WebPT, we hire the most talented people for our teams, and then give them the freedom to do their jobs. Here, we work hard, but we have lots of fun doing it. So, if you like a cool, collaborative, and challenging work environment, you\u2019ll fit right in. Throw business casual to the wind. We want casual-casual. Rock flip flops and jeans. We don\u2019t care as long as you do good work and have a great time.\n\nResponsibilities\nDevelop and maintenance of SQL queries and data views.\nCommunicate with designated customers to understand reporting needs that are outside of a standard reporting solution. Then, work to develop reports that solve our customer\u2019s reporting problems.\nCollaborate with the BI analyst and analytics team on the best approach to solving complex reporting needs that utilize multiple data sources and types.\nBuild and maintain comprehensive dashboards and metrics to enable real time business decisions\nHave a role in picking research and analysis processes, platforms, and tools that will scale with business growth\nDevelop business requirements for technical data initiatives needed to support reporting, testing, and analytics\nSkills and Qualifications\n\nAbilities and Knowledge\nDevelopment experience with SQL Server, Vertica, or Redshift.\nAttention to detail and the ability to adjust quickly to changing requirements, inconsistent data or any other anomalies that impact a deliverable.\nLearn the WebPT Analytics inside and out, backwards and forwards, up and down, you get the drift.\nBe an SQL master. This role requires that you work with data and SQL is part of that work.\nLove a good puzzle. You\u2019ll need to think critically, and analytically, on a daily basis especially when it comes to researching data and industry trends.\nBe organized, ahead of schedule, communicative, and accountable. In short, own your role entirely, while being open to criticism, suggestions, and new ideas.\nRock the mic like a vandal. Not just in karaoke, but in all forms of communication (i.e., talk well and write good stuff). You\u2019re working with our customers and internal team members that you need to effectively communicate with.\nBe a customer service superstar, both internally and externally. You will be a visible representative our WebPT and we take our brand seriously. Customers will depend on you and will look to you to help them solve their problems.\nKeep calm and carry the conversation on. Things can get pretty hectic around here, and you may need to navigate stressful situations with scheduling limitations and conflicts.\nBe able to juggle many complex projects, all with strict deadlines, simultaneously. Major props if you can actually juggle like a real circus performer.\nJive with our company culture. We\u2019re talkin\u2019 energy, integrity, positivity, a hunger for knowledge, and a passion for billing. Bring all that and a bag of chips. Seriously, we love chips.\nBe ready to fly by the seat of your pants. This role is ever evolving, just like WebPT. So, while you don\u2019t need to be Cirque du Soleil flexible, we may occasionally ask you to do a few cartwheels, or at least try some things outside of your wheelhouse.\nEducation and Experience\n\nRequired\nBachelor\u2019s degree\nFull report development life cycle experience using SQL Server, Vertica, or Redshift\n3+ years of SQL development experience within healthcare or related industry\nStrong oral and written communication skills\nBlend of data and business analysis skills\nPreferred\nPT/OT/SLP billing experience\nExperience developing within an Agile work environment\nUnderstanding of Machine Learning concepts\nUnderstanding of statistics\nAutomation experience\nAdditional Aspects of the Job\n\nWorking Conditions\n\nWebPT will make reasonable accommodations to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee will not be exposed to weather conditions, and the noise level is usually moderate.\n\nPhysical Requirements\n\nWebPT will make reasonable accommodations to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee may occasionally need to stand; walk; sit; use hands to finger, handle, or feel objects, tools or controls; reach with hands and arms; climb stairs; balance; stoop, kneel, crouch or crawl; talk or hear; or taste or smell. The employee must occasionally lift and/or move up to 25 pounds. This job requires specific vision abilities, including close vision, distance vision, color vision, peripheral vision, depth perception, and the ability to adjust focus.\n\nEEO Statement\n\nWebPT, Inc. provides equal opportunity for all applicants without regard to race, color, religion, sex (including pregnancy), national origin, ancestry, age, genetic information, marital status, sexual orientation, veteran status, or any other basis protected by state or federal law.\n\nRequirements\nSQL development experience within healthcare or related industry\nApply Now: click Apply Now"}, "48": {"company": "BOK Financial", "description": "Req ID: 52811\n\nAreas of Interest: Marketing\n\nBOK Financial (BOKF), Headquartered in Tulsa, Oklahoma, BOK Financial Corporation (NASDAQ: BOKF) is a top 25 U.S.-based financial services holding company with operations in ten states \u2013 Oklahoma, Texas, Arkansas, Arizona, Colorado, Kansas/Missouri, New Mexico, Nebraska and Wisconsin. The company began more than 100 years ago in Tulsa and has successfully diversified into a variety of industries, businesses and geographies. .\n\nThe Consumer Data Analyst II provides expertise and actionable guidance to management through the analysis of Consumer Division, market, and banking center operations data, as well as the impacts of industry, financial services, and regulatory trends. Provides information and detailed analysis to guide business decisions. Develops strong working relationships with internal Consumer departments and line of business partners to understand business issues, key performance indicators, strategies and plans.\n\nPRINCIPAL DUTIES AND RESPONSIBILITIES\nData Analysis & Trend Identification\n\u2022 In consultation with Consumer senior management, extracts and deciphers complex data, performs a broad range of analyses, and employs data visualization tools to illustrate emerging trends\n\u2022 Exercises sound judgment in researching problems, evaluating various solutions, and using data to inform decision making that impacts the Division\u2019s bottom line\n\u2022 Effectively partners with line of business leaders and managers to identify, address, and satisfy data and reporting needs for various LOB projects.\n\u2022 Provides actionable guidance by determining the meaning of complex data and formulating clear, concise, and compelling written/verbal conclusions or recommendations based on analyses.\nAnalytics and Reporting\n\u2022 Develops easily digestible monthly dashboards of KOIs/KPIs related to LOB strategic initiatives to inform key decision making by Division leadership\n\u2022 Ensures data quality and validation controls are in place to support accurate reporting and mitigate risk associated with inaccurate or incomplete data\n\u2022 Automates key performance metrics and key performance indicators presented in dashboards and other LOB reporting.\n\u2022 Provides analytics and commentary in support of business case development for LOB projects.\nDeveloping Self and Others\n\u2022 Researches relevant industry, financial services, and line of business issues to build upon knowledge base, identifying trends and sharing insights with team.\n\u2022 Anticipates and identifies issues inhibiting the attainment of assigned goals; develops and implements problem resolution.\n\u2022 Researches and maintains a continuing education curriculum related to analytic technology\nKNOWLEDGE, SKILLS and ABILITIES:\nStrong conceptual thinking, analytical, and problem solving skills, including the ability to analyze complex problems that include interrelationships and dependencies in order to identify common themes and solutions\nStrong aptitude to collect and analyze information and make appropriate recommendations\nSelf-motivated, disciplined, and task focused\nStrong time management and organizational skills to effectively handle projects in a fast-paced, high-volume, and deadline intensive environment\nHighly detail-oriented\nWell-developed written and oral communication skills to effectively represent self and the Division, as well as the ability to present complex information and issues in a clear concise manner\nWorking knowledge of Power BI Software.\nWorking knowledge of Microsoft Office.\nExperience with data aggregation and analysis with tools such as R, SAS, or Python.\nExperience with data visualization and report building/automation.\nGeneral knowledge of financial products and services\nThis level of knowledge is normally acquired by completion of a Bachelor\u2019s Degree in Mathematics, Economics, Computer Science, Information Management or Statistics and 1-2 years of relevant professional business experience and/or the pursuit of a Master\u2019s degree (e.g., MBA, MSF).\n\nBOK Financial is a stable and financially strong organization that provides excellent training and development to support building the long term careers of our employees. With passion, skill and partnership you can make an impact on the success of the bank, our customers and your own career!\n\nApply today and take the first step towards your next career opportunity!\n\nBOK Financial is an equal opportunity employer. We are committed to providing equal employment opportunities for training, compensation, transfer, promotion and other aspects of employment for all qualified applicants and employees without regard to sex, race, color, religion, national origin, age, disability, sexual orientation, genetic information or veteran status.\n\nAttention All Third Party Agencies, Headhunters, and Recruiters\nBOK Financial and its Subsidiaries will not accept candidate submission by unsolicited third parties through this site or any company email address. All unsolicited candidates presented to BOK Financial and its Subsidiaries will be considered the property of BOK Financial. BOK Financial and its Subsidiaries will not be responsible for any fees associated with unsolicited candidates, nor will a contractual relationship be formed by the submission. BOK Financial and its Subsidiaries are not obligated and will not under any circumstances pay any fees to said third parties submitting candidates in this manner. BOK Financial and its Subsidiaries only forms contracts with recruiters with whom we have an established business relationship and with whom we have in place a signed agreement. All contact with BOK Financial and its Subsidiaries from third parties must be through our Human Resources Department. Any contact made outside of the BOK Financial Human Resources Department by a third party will cancel any future business relationships between the third party and BOK Financial.\n\nPlease contact recruiting_coordinators@bokf.com with any questions.\nTo apply to this job, click Apply Now"}, "49": {"company": "Alector", "description": "At Alector, our mission is to develop therapies that empower the immune system to cure neurodegeneration. Our team is solely focused on developing cures for some of the most challenging diseases facing our society. We are supported in this mission by experienced and accomplished scientists and board members, leading healthcare investors and some of the most innovative pharma companies.\n\nUse your scientific skills to help us achieve our mission of saving lives by curing neurodegenerative diseases.As a Senior Analytical Scientist for the Biologics Manufacturing team, you will report to the Associate Director and work closely with other scientists in Upstream and Downstream process development. Alector is seeking a candidate with expertise in antibody therapeutics, especially in the fields of protein characterization and protein formulation. You will be the analytical lead for manufacturing, and responsible for designing and conducting experiments, optimizing throughput, maintaining detailed records, developing new analytical technologies, and generating standard operating procedures and reports. In this role, you will have the opportunity to work cross-functionally across multiple departments including discovery, pre-clinical, protein production and CMC. You will identify and provide support for ongoing programs and your work will be central to Alector\u2019s strategic goals. You will be influential in championing and developing Alector\u2019s culture.\n\nDuring your first year, your goals will include:\nExpand in-house analytical capabilities by developing and qualifying new assays for product characterization\nParticipate actively in decision-making process on cross-functional project teams by providing scientific input\nPerform upstream, downstream analytics in support of cell line development, protein characterization, and in-process and Drug Substance stability studies\nAdvance group capabilities and know-how by identifying and implementing novel technologies\nAuthor analytical Standard Operating Procedures and technical reports\nServe as analytical SME for the tech transfer of various methods and procedures to CMOs on multiple projects\nTrain cross-functional colleagues and junior personnel in analytical techniques and lead direct reports\nWe'd love to hear from you if:\nBS or MS with 5+ years industry experience or PhD with at least 2 years of postdoctoral or equivalent industry experience, with industry experience preferred (willing to consider more experience for the right candidate)\nPerform analytical assay development (troubleshoot and optimize assays) and author SOPs and reports\nPrior experience characterizing monoclonal antibodies, fusion proteins, and bispecific molecules\nExperience with the following analytical assays: SEC-HPLC, HIC-HPLC, IEX-HPLC, Protein A HPLC, reverse phase, iCIEF, CE-SDS, SDS-PAGE, glycoanalytics, DSC/DSF, etc.\nExperience performing and optimizing liquid and lyophilization drug formulations\nFamiliar with DoE experimental design and statistical interpretation of data using software suites (e.g. JMP, Stat-Ease)\nHands-on experience using Agilent HPLC/UPLC systems and CDS software\nExperience using Waters and/or Thermofisher HPLC/UPLC systems with Empower or Chromeleon software is a plus\nDemonstrated ability to independently run functional responsibilities\nManaging and mentoring junior personnel\nExcellent written and oral interpersonal skills\nAt Alector, we believe that high-performing teams include people from a wide variety of backgrounds and experiences who can challenge each other\u2019s assumptions with fresh perspectives and bring creative ideas to the table. We are committed to building an open, diverse, and inclusive environment for all employees. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, sexual orientation, age, marital status, veteran status, or disability status, or any other characteristics protected under applicable federal, state, or local laws.\nAlector is a phenomenal place to learn and experiment. If you excel in a dynamic environment where everyone is committed to finding a cure, where you\u2019ll drive growth, this is the role for you. There is no limit to how far you can go with us.\n\nBenefits\nWhile we\u2019ve focused on what to look forward to during the first year and beyond, Day One is great, too: committed and driven colleagues, a bold and important company goal, state-of-the-art brand-new brightly-lit offices in the heart of the biotech area, competitive compensation and benefits. But these matter only if you\u2019re excited to build and own something great, and tackle these challenges with us. Come join us.\nTo apply to this job, click Apply Now"}, "50": {"company": "Briq", "description": "<h>The Startup</h2>\n\nLocated in breathtaking downtown Santa Barbara, centered in the vibrant, up-and-coming Haley Corridor, Briq is altering the landscape for construction decision making. We are harnessing the power of data to build the industry's first construction data cloud. Leaders in automation, machine learning, and artificial intelligence, Briq is helping construction companies minimize risk and maximize success.\n\n<h>The Skinny</h2>\n\nBriq is ready for curious, charismatic, creative people to join the Engineering Team at one of the fastest-growing construction analytics companies.\n\nOur team of strategists, leaders, data scientists, and change-makers are revolutionizing the world by providing data tools that improve decision-making in one of the most predominant industries today. Our clients are among the largest builders in the world; responsible for creating the infrastructure you thrive on and designing the cities you live, work and play in. They are hungry for better, smarter data and we are hungry for your talents to help make it happen.\n\n<h>The Skill</h2>\n\nThe Briq Engineering team is looking for a Principal Data Scientist to fuel our accelerated growth. We are rapidly growing and ready for someone who harbors a passion for crafting and deploying top quality, high-performing, data, AI, and analytic systems to join the Briq family in evolving our platform and changing the world of construction.\n\nThe Principal Data Scientist will guide the engineering team in decision-making and best practices; ensuring a consistently high-quality product while:\nDriving engineering culture of excellence in partnership with product teams\nLeading technical direction on design, implementation, and deployment of data services and pipelines that satisfy the evolving needs of our customers\nCoordinating leadership contribution and buy-in to design planning process across Briq products and services\nEnsuring the use of data and AI is woven throughout the Briq enterprise\nEstablishing organizational best-practices scalable across teams and products resulting in consistent, high-quality, industry standard-setting analytics and AI systems\nBuilding internal and external relationships as a Briq evangelist and thought leader\n<h>The Standard</h2>\n\nTo be successful as a principal data scientist, you will have exceptional leadership, communication and project management skills with a deep understanding of software systems at multiple levels of abstraction and an intrinsic desire to develop the skills and talents of others. You take a keen interest in international trends in engineering and leadership and harbor an above average emotional intelligence. Moreover, your background likely looks a lot like this:\nFifteen (15) years of experience in artificial intelligence, machine learning, natural language processing or related areas in the context of web-based software development/software engineering, data warehousing, or other client/server applications,\nMaster's degree in Computer Science or a related field, PhD preferred,\nActively participated in a development team operating at large scale,\nTechnically led a team of data scientists and demonstrated mentoring skills within the group,\nExperience with a wide range of programming languages such as Python and Scala,\nExperience with relational and noSQL databases,\nExperience with real world applications of artificial intelligence and machine learning,\nProficiency with cloud computing providers such as Amazon Web Services, Google Cloud Services, or Microsoft Azure.\nThe Briq platform is used by construction leaders looking for meaning in their data. You'll join a highly collaborative and passionate engineering and product organization who are on a mission to help people see and understand data, dedicated to building a fantastic company and workplace, and are relentlessly focused on our customers and on building amazing products. Principal software engineers report directly to the CTO and work closely with the director of engineering to support all aspects of developing and operating our products.\n\nBriq is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. If you think you have what it takes to thrive here, we want you!"}, "51": {"company": "Comprehensive Healthcare", "description": "What are we looking for in a Data Analyst?\n\nAs a member of the Information Services department, the Data Analyst supports Comprehensive\u2019s technology and business initiatives by coordinating the collection, storage, and utilization of essential data. This position will work closely with leadership and other staff to determine data needs for specific projects or ad hoc requests, and then gather, interpret, and present the information to the team. The work of the Data Analyst will impact day-to-day clinic operations as well as business decisions, so a high degree of accuracy, thoroughness, and timeliness are essential. Previous experience performing data analytics in the healthcare field is required. This is an on-site, in-person position working out of our Yakima office and does not offer the option for remote work.\n\nData Analyst duties may include:\nintegrating data from internal & external sources and performing extract, transform, and load operations to data in various applications\nanalyzing data to identify and interpret patterns or trends in data sets\nperforming data audits to identify problem areas & implementing strategies to optimize data integrity and process improvements\nassisting with the design & implementation of database warehouse structure and developing standards for the design of data elements\nsupporting the implementation, testing, and validation of data & software systems\nassisting with ongoing data architecture processes & governance\nproviding Tier II technical support to employees\ndocumenting all work as required\nEducation/Experience: Bachelor's degree in computer science, information science, or a related field. Three years of related data analytics experience required, preferably in the healthcare field.\n\nOther Credentials Required: Driver's license, vehicle liability insurance\nApply Now: click Apply Now"}, "52": {"company": "Cadent", "description": "Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sourcescable, broadcast, and digital mediaour technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns.\n\nRight now we are looking for a highly motivated Data Scientist who will be responsible for the applying scientific methods to identify business optimization strategies, developing, evaluating and demonstrating prototypes of empirical software including but not limited to machine learning, signal processing and optimization based numerical methods.\n\nData Scientists collaborate directly with the Business Intelligence, Data Engineering and Development team members to productize research as reporting and business software. This is a critical mathematical engineering role whose work is leveraged by other engineers and by senior executives to define the future of Cadent.\n\nOur ideal player will:\nDesign, train and apply statistics, mathematical models, and machine learning techniques to create scalable solutions for predictive learning, forecasting and optimization\nWork with Software development team to deploy models as micro-services leveraged inside of business software products\nMonitor, maintain, and refine predictive models as necessary, including re-training\nWork with product team to align software goals with KPI's via empirical measure of effectiveness\nParticipate in the agile / scrum process\nFollow the CRISP-DM process to generate robust documentation associated with iterative work\nPresent results to technical and business stakeholders.\nCollaborate effectively with other members of the engineering research team and broader data services group including but not limited to Data Engineers, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence analysts\nOur ideal player will have:\nM.S. or higher in computer science, mathematics or related discipline with a focus on machine learning or the equivalent of 4 years of experience in machine learning, forecasting and\nPractical expertise building evaluating and deploying machine learning pipelines as with python, preferably with the scikit-learn ecosystem\nExperience with SQL, accessing and organizing data drawn from relational databases\nExperience in cloud computing ecosystems (preferably in AWS)\nPractical experience in deep learning architectures and frameworks is a plus\nProven background answering open ended research questions using data\nExperience with computational statistics and understanding of theoretical fundamentals of statistics\nStrong analytical and quantitative problem-solving ability.\nFundamental understanding of the mathematical workings of standard feature engineering and machine learning algorithms.\nDemonstrated communication skills including the ability switch between technical and business contexts.\nPreferably a background in software development\nExtra Credit if you have:\nMedia Experience\nAWS\nIf the leading edge of media technology is the place you want to be, please contact us today and let's start the conversation!\n\n/CADENT/ is an EOE M/F/D/V. We do not work with 3rd Party Staffing Agencies.\n\n]]>\nApply Now: click Apply Now"}, "53": {"company": "Quotient Technology Inc.", "description": "As a Data Analyst with Quotient, you will be responsible for quantifying deep understanding of consumer behavior patterns and motivations through analysis of consumer response to product and marketing strategies and tactics. The right candidate will utilize advanced data mining and statistical techniques to drive this empirical understanding and surface optimization and product enhancement insights and opportunities.\n\nYou will be a key member of the Analytics and Research team, and contribute to the analytics product lifecycle of strategy, design, development, test and delivery of data-driven algorithms and techniques to further optimize the product offerings. As a part of this team, you will collaborate on driving consumer focused solutions across personalized promotion, media and advertisement recommendations, targeting and insights.\n\nPosition Responsibilities:\nIdentify and assess key opportunity areas where data and science can enhance products\nDevelop detailed plans for achieving desired product goals, including impact assessment\nDevise, develop, test and deploy new data models\nEffectively engage and partner with other product teams, engineering, and sales to drive the implementation of your models and make an impact\nActively influence product roadmaps to drive higher monetization and optimization\nDrive the production of analytic capabilities in data management, modeling and algorithms\nBe an innovator with demonstrated ability to craft a data science vision, get people excited by ideas and get them quickly to market via existing or new products\nPosition Qualifications:\nBS in Computer Science, Statistics, Applied Mathematics, AI, or related areas from a top school\nPreferred MS in one of the above disciplines\nUp to 3 years\u2019 experience in applying data and science to improve products and services\nSolid and proven background in data mining, statistical analysis, segmentation and modeling\nAbility to grasp complex concepts and develop clear, concise, synthesized recommendations backed by data and analyses\nExperience in manipulating large data sets and analyzing them to identify actionable insights\nFluency in analytical tools such as R (preferred), SAS, etc.\nUnderstanding of programming languages like C/C++/Java and scripting languages like Perl/Python\nExperience in designing, executing and measuring A/B tests for optimization models\nExceptional collaborative, communication and presentation skills with the ability to work well across the organization driving overall shareholder value\nStrong initiative, high energy, hands-on and impeccable integrity\nStart your job application: click Apply Now"}, "54": {"company": "Kforce", "description": "RESPONSIBILITIES:\n\nKforce has a client in search of a Cloud Data Engineer (2 openings) in Salt Lake City, Utah (UT).\n\nSummary:\nAs a Cloud Data Engineer, you will guide the business on how to ingest, store, process, analyze, explore, and visualize data on the AWS Cloud Platform. You will work on data migrations and transformational projects, and with developers to design large-scale data processing systems, develop data pipelines optimized for scaling, and troubleshoot potential platform issues.\n\nTogether with the team you will support implementation of AWS Cloud products through: architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring and much more.\n\nThe cloud platform team looks to build out next-generation hybrid data platform by leveraging new technologies and techniques to maximize the value out of data assets and empower employees to innovate.\n\nThe Value You Deliver:\nIdentify and respond to data needs for business users to use the analytics environment\nWork with data architects to design and implement solutions to ingest, transform, connect, store and expose data to range of users\nIncorporate new data sources by building pipelines for automated and semi-automated data ingestion and data refresh\nREQUIREMENTS:\nBA/BS degree in Computer Science, database or related technical field, or equivalent practical experience\nExperience with data processing software (such as Hadoop, Spark, Pig, Hive) and with data processing algorithms (MapReduce, Flume)\nRelational databases including Oracle and Microsoft SQL Server\nExperience in writing software in one or more languages such as Java, C++, Python, Go and/or JavaScript\nColumnar data structures like Apache Parquet and columnar databases like Redshift Distributed SQL query engines like Presto DB and Athena\nAmazon Web Services including Redshift, S3, Kinesis, Glue, and DynamoDB\nExperience managing internal or client-facing projects to completion; Experience troubleshooting clients' technical issues; Experience working with engineering teams, sales, services, and customers\nExperience working with data warehouses, including data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools and environments\nExperience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and AWS Cloud Platform\nExperience working with big data, information retrieval, data mining or machine learning as well as experience in building multi-tier high availability applications with modern web technologies (such as NoSQL, MongoDB, SparkML, Tensorflow)\nKforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nTo apply to this job, click Apply Now"}, "55": {"company": "OODA Health", "description": "We are looking for an experienced manager and leader to lead our Data Science and Analytics teams, and to help us discover and extract information from data in claims, EHRs, and other healthcare-related data sets. The work will support information insights, discovery, and construction of predictive analytics and automation products.\n\nYour primary focus will be working closely with clients and internal stakeholders throughout the company to understand problems and shape investigations so as to create significant value, and then guiding and supporting a team to deliver that value.\nResponsibilities\nWork with the team and the company to find the highest value analyses and models\nProvide regular feedback and learning opportunities for our team to grow\nExtending company\u2019s data with third party sources of information when needed\nEnhancing data collection procedures to include information that is relevant for building analytic systems\nBuild long term strategies for proper management, accessibility, and utility of our data\nBuild tools and processes to facilitate rapid delivery of accurate, clear, and useful reports\nGuide product, engineering, and other teams to gather data well and to interpret and use analytics appropriately\nSkills and Qualifications\nExcellent understanding of learning algorithms and approaches to building models from data\nUnderstanding of the methods in machine learning such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\nExperience with common data science toolkits, such as R, H2O, Python libraries, Spark-ML, MatLab, etc.\nGreat communication skills\nExperience with data visualization tools, such as D3.js, GGplot, etc.\nProficiency in using query languages such as SQL, Hive, Pig and analytics platforms such as SLOR or Elastic Search\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\nExperience managing substantial code bases\nData-oriented personality\nFormal training in Computer Science, Engineering, or other relevant field\nFamiliarity with Healthcare datasets and business models a plus\nOODA Health is proud to be an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, gender identity, national origin, age, disability, genetics or any other basis forbidden under federal, state, or local law. OODA Health considers all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.\nTo apply to this job, click Apply Now"}, "56": {"company": "Enterprise", "description": "About the Role\n\nThe AI and Machine Learning Data Science Manager serves as a dedicated business partner responsible for developing advanced technical data science strategies and maximizing the implementation of analytical solutions for the business unit(s) to which they are dedicated. This role is embedded in both the business unit(s), leveraging a detailed, current working knowledge of unit operations, strategic goals and deep technical acumen, and the Center of Excellence for Data Science (CEDA), leading a team of analytics professionals to design, execute, and implement analytical solutions to support and grow the business unit(s) being served.\n\nThe ideal candidate for this role will possess:\nStrong business acumen to bridge the gap between the business and technology/analytics\nSkilled in data visualization, statistical analysis, process automation, and design thinking\nAdvanced Technical Platform experience and expertise\nWith the ability to demonstrate this to peers and executives, this role will manage a small team of Data Scientists, and help develop the strategy for their team going forward.\n\nCompany Overview\nEnterprise Holdings is the largest car rental provider in the world as measured by revenue and fleet. The company and its affiliate Enterprise Fleet Management which combined offer a total transportation solution that includes extensive car rental and car-sharing services, truck rental, corporate fleet management and retail car sales accounted for $24.1 billion in revenue and operated 2 million vehicles throughout the world in 2018. Enterprise Holdings annual revenues also place it near the top of the global travel industry, exceeding all other rental car companies, many airlines, and most cruise lines, hotels, tour operators and online travel agencies. Enterprise Holdings regional subsidiaries and Enterprise Fleet Management currently employ more than 100,000 people worldwide.\n\nThrough its integrated global network of independent regional subsidiaries and franchises, Enterprise Holdings operates the Enterprise Rent-A-Car, National Car Rental and Alamo Rent A Car brands at more than 10,000 fully staffed neighborhood and airport locations. The Enterprise Holdings global network operates in more than 90 countries and territories, including North America, Central America, South America, the Caribbean and Europe, as well as parts of Asia-Pacific and the Middle East. Today, the companys three brands serve more than 95 percent of the worldwide car rental market.\n\nThis position is located at our Corporate Headquarters in Clayton, MO\n\nResponsibilities:\nProvide senior level technical expertise to help drive the execution of data science projects; Serve as a data science business partner providing direct support and connection between CEDA data scientists, strategic analysts and assigned operational business unit(s) to drive the application of and generate opportunities for data science into business processes\nDevelop and leverage a detailed understanding of assigned business unit(s) strategic needs to develop a data science/analytics strategy to meet those needs, leading and coordinating project teams in the design, development and delivery of analytics solutions to support and grow the business\nUse design thinking and knowledge of data science and machine learning to challenge the business and define use cases, develop roadmaps for rapid, iterative execution of potential solutions, and work with management to prioritize investment\nLead a team of data scientists and/or strategic analysts dedicated to applying advanced analytical methods for assigned business unit(s); Apply deep technical expertise to provide guidance to team regarding methodology, project approach and appropriate tools; Provide continuous education on the business context and application of data science solutions to the team\nChallenge and influence the business on ways to use data science to more accurately value proposed changes and new ideas\nTranslate and communicate efforts underway, progress, results, and solutions to business unit leadership and Center of Excellence for Data Science leadership\nLead innovation using latest advances in data science across machine learning, operations research and mathematical optimization; Develop and deploy new methodologies globally to accelerate business and product development efforts\nMonitor and measure the effectiveness of the implemented solutions and feed learnings back into the development process to further improve outcomes\nIdentify and coordinate with Center of Excellence for Data Science innovation/R&D resources, both internal or external to leverage best in class supplemental data, tools, and methodologies to support business unit to accelerate progress; Assess and select vendors, in areas such as auto machine learning and operations research platforms, to enhance the capabilities of the data science team\nAdditional Responsibilities\nSeek to improve job performance through self-assessment, skill development, training and goal setting\nMaintain a regular and reliable level of attendance and punctuality\nPerform miscellaneous job-related duties as assigned\nEqual Opportunity Employer/Disability/Veterans\n\nQualifications:\n\nMinimum:\nPhD in Mathematics, Statistics, Operations Research, Physics, Engineering, Economics, Computer Science or a related quantitative field required OR\nMaster's Degree in Business, Economics, Mathematics, Statistics, Psychology or other quantitative field with 5+ years experience working with the business to influence strategy and decision making by applying data science and analytics\nMust be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future\n3+ years experience working with the business to influence strategy and decision making by applying data science and analytics\n3+ years experience as a practitioner in data science\nExperience designing and building data analytics strategies as well as designing analytics projects and leading the work of others\nStrong business acumen to bridge the gap between the business and technology/analytics\nSkilled in data visualization, statistical analysis, process automation, and design thinking\nAdvanced level of Technical Platform experience and expertise\nCompetency Based:\nForward-Thinking\nLeading and Inspiring People\nManaging and Developing People\nBuilding Relationships\nPlanning and Organizing\nDecision Making\nPersuading and Influencing\nResilience\nApply Now: click Apply Now"}, "57": {"company": "CHG Healthcare", "description": "Healthcare\u2019s helping hand.\nCHG shook things up in 1979 by inventing the locum tenens staffing model. We connect doctors with patients who need their care. As the largest physician staffing firm in America, our providers treat millions of patients each year.\nOur industry is growing and demand is high. This means you\u2019ll have plenty of opportunities to grow and develop in your career. Keeping healthcare healthy can be as fun as it is rewarding.\nMarketing Analytics Analyst will lead the execution of strategic marketing analytics initiatives, from idea to successful implementation. They will leverage a variety of analytics and marketing performance sources, and champion the design, development and implementation of an end-to-end performance measurement process across Marketing. Partner with functional teams (Digital, Strategy, Channels, Campaign) to measure and analyze the scale and effectiveness of marketing contributions.\nThe ideal candidate will have a blend of marketing and analytic ability. S/he must be able to process and interpret vast amounts of data and compile the data into insightful reports that support the organizational needs. S/he will monitor, report and project the performance of our marketing efforts and inform on trends and variances against expectations. This individual should be a driven, self-starter capable of identifying business needs and suggesting solutions and improvements.\nThis role is also responsible for leading the translation/simplification of complex data into impactful business actions. This role will work with executive and management teams to directly influence business development, customer relationship management and marketing programs. In addition, they will directly influence the tools, techniques and internal processes that are utilized to advance the internal analytic capabilities.\nYour role:\nBuild a program to measure and monitor customer acquisition cost, lifetime value and ROI.\nDevelop expertise in conversion funnel and metrics used to measure success and opportunities.\nAnalyze channel spend and effectiveness to support investment decisions.\nCommunicate marketing analytics insights through compelling storytelling to drive action and decision-making.\nLeverage analytical proficiency to contribute to marketing performance reporting and analysis at an aggregate and campaign level.\nAct as a champion for a data-driven culture, evangelizing best practices with internal stakeholders across functional areas.\nAbility to measure the impact of marketing as a whole or drill into specific campaign successes.\nWork closely with the sales, finance and marketing teams, particularly leadership, to ensure the best use of budget and deliver an effective marketing analytics strategy to meet the business objectives.\nYour qualifications:\nStrong project manager with experience working with cross functional teams to deliver results\nSolid understanding of digital marketing and can manage and report on marketing campaign tracking, including sources across multiple channels\nStrong analytical skills and data-driven thinking; up to date with the latest trends and best practices in online & offline marketing and measurement.\nExperience using Salesforce, Tableau and MS Office\nStrong verbal and written communication skills with the ability to communicate methods and results to a non-technical audience\nProven track record to prioritize day-to-day and long-term strategic projects\nStrong ability to influence, collaborate and partner with teams and leaders across the organization\nLead marketing attribution modeling/ROI measurement\nAnalyze existing marketing programs for performance, profitability and revenue opportunity, and recommend improvements.\nEducation & Years of Experience:\n6+ years of marketing, analytics, or statistics experience\n5+ years related experience in B2B marketing and/or Sales, Marketing or Financial analysis\nIn return, we offer:\nCompetitive pay\nHealthcare coverage with corporate wellness program\nFree on-site health center and health coaching for employees and dependents\n401(k) company match\nTuition reimbursement\n14 days of PTO your first year and paid holidays\nHall of fame development programs as recognized by Training Magazine\nOn-site cafeteria and game room\nClick here to learn more about our company and culture.\nHow to Get Started\nTo have your resume reviewed by Talent Acquisition, click \u201cApply\u201d at the top of the screen.\nWe are an Affirmative Action/Equal Opportunity Employer\nVeterans/Disabled\nWe are an at-will employer\nApply Now: click Apply Now"}, "58": {"company": "Corbins Electric", "description": "At Corbins Electric, we believe people are first! Our teammates, our partners, and our customers can expect that we genuinely care to serve them and look out for their best interests. Our culture is built on the cornerstone of our Core Values \u2013 Passion, Relationships, Innovation, Development and Excellence! They set our expectation of each and every employee and are integrated in everything we do. As one of the largest electrical contractors in the Southwest and an industry leader in virtual construction, fabrication, electrical construction, and electrical service, we continually look for people who share in our Core Values to better themselves and contribute to our mission of changing the construction industry as empowered thought leaders.\nAs the Data Analyst/Programmer you will be providing cutting edge analysis of financial and construction data. You will work with key stakeholders to interpret and present the data in a meaningful way to help drive business decisions. You will get the opportunity to drive entire process from start to finish: inception to finished product.\n\n\nTo apply to this job, click Apply Now"}, "59": {"company": "Cognite", "description": "#data-scientist #data-viz #data-engineer #data-ops #data-products\n\nWhile you cruise through life in a digital bliss, the industrial world is stuck in a swamp of legacy applications running on some windows server in some basement. Forget about scaling and operationalizing machine learning models, even getting an overview of your data is close to impossible.\n\nAt Cognite, we liberate data from their legacy cages, use machine learning to figure out how data from different sources fit together, design company-wide data models, build high-performing and scalable storage and streaming solutions, help industry deploy analytics at scale across all their assets, and use gaming technology to visualize it all.\n\nWe have proven Cognite Data Fusion and technologies and in 2019 are looking to scale across Power, Oil and gas and other sensor rich industries. Working as a part of Cognite\u2019s cross-functional customer facing teams, you will have a unique opportunity to build and deploy solutions (not just demos and slides) that augment to improve operations.\n\nWe believe in open culture, open source, and open data (see #dataliberationfront) but why the open application? At Cognite we live the idea that data science is a team sport. Our teams need to be as diverse as the problems we solve, covering\nModel development\nDesign thinking\nData engineering\nDevOps\nData visualization\nIndustrial domain expertise\nFront end development\nSomething we have not yet learned!\nFor this role, we\u2019re looking for various levels of experience. Candidates should possess 2+ years of experience (including masters, PHD, and relevant work experience). You will be evaluated for technical competency (github), drive (self training / projects) and customer empathy (project experience). Offers will be competitive and commensurate with experience and competency.\n\nWant to know more? You should! Check out our website and then write to us and tell us what you\u2019ll bring to our cross-functional customer facing teams and why you\u2019re excited to help guide our customers through industrial digitalization.\n\nRequirements\n30-50% travel. We don\u2019t build solutions in isolation. We sit with the subject matter experts day to day and build solutions together.\nHumility and integrity\nTeam-oriented\nRole to be based in Houston or Austin, TX\nBenefits\n\nWe are an exciting fusion of the technological and the industrial, fast growth and sustainable innovation.\nCompetitive salary and benefits (including 401K plans, health insurance, and more)\nOpportunity to work with great people on projects that create real impact\nOpportunity to be part of- and participate in global projects\nMinimal bureaucracy and overhead, with focus on agility and speed\nRegular internal or external tech-talks\nAll the tools you need to be productive\nOpen and friendly company culture\nEmphasis on individual health, with competitive health insurances\nFlat structure with direct access to decision-makers\nHigh level of autonomy and ability to influence decisions\nNew, attractive offices\nStart your job application: click Easy Apply"}, "60": {"company": "Stratagem Group", "description": "Machine Learning Engineer\nColorado Springs, COApply Now\nAre you interested in supporting the ever-changing technology needs of the U.S. Government by providing services that support defense initiatives? Come look at Stratagem, where we help the U.S. Government solve some of the most difficult and fun problems in the world.\n\nStratagem is hiring motivated, creative, and technically-minded individuals with a passion and skill for building the state-of-the-art in emerging technologies. We understand that candidates may not be able to check the boxes for all desired qualifications, but what is most important to us at Stratagem is that candidates have exceptional problem-solving skills, creative out-of-the-box thinking, and comfort with quickly learning, evaluating, and deploying new technologies. Successful employees are self-starters, excellent communicators and positive individuals with a passion for delivering uncompromising quality products.\n\n** TS - SSBI Required **\n\nThis is a Software Engineer position in Valley Forge, PA, and we are not hiring your average Java Joe\u2019s. We are looking for the Macchiato with a double shot. You will be given substantial feature ownership, and we'll expect you to contribute product ideas as well as code. Your ideas will help shape the future of Stratagem.\n\nResponsibilities & Skills\nOur ideal candidate is a programming expert with a passion for machine learning. We need someone with prior experience designing and implementing modern machine-learning and computer-vision concepts and algorithms, and who stays up to date on all best-practice standards.\nAs a software engineer, your responsibilities include:\nInvestigating and solving exciting and difficult challenges in image recognition, classification, content analysis, and deep learning\nIntegrating with a diverse team to deliver in an agile-like manner\nDeveloping new algorithms\nContributing to building aspects of a web-accessible system\nPrototyping ideas/concepts to prove a solution quickly\nYour core skills/experience include:\nExpertise in one of the following: Java, Python, C++, etc.\nProficiency with containerization - Docker preferred\nProficiency with cloud Infrastructure - AWS or C2S preferred\nProficiency with PostgreSQL \u2013 or similar GIS database concepts\nExperience with Hadoop, Spark, etc.\nExperience developing and implementing Image Classification and Content Analysis\nExperience with neural networks, K-means, etc.\nExperience working with deep learning frameworks, such as Caffe, TensorFlow and Theano\n3-15 years\u2019 experience\nYou are the proud owner of a TS/SCI SSBI clearance\nBonus points if you have experience in any of the following:\nDevOps experience\nIn-depth understanding of modern best-practices, such as Kaggle competition winners\nComfortable with statistics and data science concepts\nMission Management\nSIGINT experience\nAbout you\nYou are an exceptional problem solver, a quick learner, and a creative out-of-the-box thinker who values team work. You are comfortable with the pace and ever-changing requirements of a small development company while maintaining a healthy work life balance.\n\nWho is Stratagem\nStratagem is a small and fast-growing technology company built around the idea that we can make a lasting impact for our customers and employees. We believe in a culture of innovation, fun, empowerment, and family. We want you to learn new skills so you can become more fulfilled in both your personal and professional life.\n\nAt Stratagem, our goal is to make our company the last company you work for!\nStart your job application: click Apply Now"}, "61": {"company": "Liberty Mutual Insurance", "description": "Data Engineer / Senior Data Engineer\n\nAt Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as an Agile team within a Fortune 100 company, we are on the front edge of an IT transformation for how people work and deliver solutions.\n\nGRM Information Management is actively searching for a highly productive member of a distributed, dynamic agile team to serve as a technical expert in analysis, design, coding, and testing innovative data warehouse reporting solutions and analytics. This position will support Customer, Prospect, Marketing & Digital within Business Data Solutions Engineering. This is a range posting; the hiring manager is open to a Senior Data Engineer / Data Engineer.\n\nJob Summary:\n\nAs a Senior Data Engineer / Data Engineer, you will work collaboratively on a geographically diverse agile team to develop and enhance complex systems and/or software from user stories and technical/architectural specifications. You will analyze complex technical system problems and create innovative solutions that exceed customer expectations.\n\nThis is a fast-paced environment providing rapid delivery for our business partners. You will be working in a highly collaborative environment that values speed and quality, with a strong desire to drive change and foster a positive work environment as we continue our agile transformation journey. You will have the opportunity to help lead this change with us as we grow this culture, mindset and capability.\n\nIn this role you will:\nWork in a dynamic and exciting agile environment with Scrum Masters, Product Owners, and team members to develop creative data-driven solutions with our ETL pipeline that meet business and technical initiatives\nImprove speed to market by focusing on current Finance data needs as well as building out the long-term strategic data solutions using SQL, Unix, Informatica and AWS, as well as other modern data technologies\nDemonstrate open minded and collaborative approach to creating innovative technical solutions\nAnalyze data and technical system problems to design and implement effective, flexible solutions\nHandle end-to-end development, including coding, testing, and debugging during each cycle\nDevelop automated tests for multiple scopes (Unit, System, Integration, Regression)\nMentor new and junior developers\nIdentify and recommend appropriate continuous improvement opportunities\nQualifications:\nBachelor's or Master's degree in technical or business discipline or equivalent experience, technical degree preferred\nGenerally, 3 - 5 years of professional experience\nExperience developing back end, database/warehouse technology solutions\nKnowledge of a variety of data platforms including DB2, Teradata, (Cloud based DB a plus)\nExperience with Unix, Informatica, SQL, and AWS (such as S3, Aurora, Athena)\nExtensive knowledge of IT concepts, strategies, methodologies.\nExperience working with agile methodologies (Scrum, Kanban, XP) and cross-functional teams (Product Owners, Scrum Masters, Developers, Test Engineers)\nVersed in diverse technologies and new technical architecture principles and concepts\nDemonstrates leadership and active pursuit of optimizing CI/CD process and tools, testing frameworks and practices\nMust be proactive, demonstrate initiative, and be a logical thinker\nMust be team oriented with strong collaboration, prioritization, and adaptability skills required\nAdditional Qualifications:\nJava, Ruby, NoSQL, Python development experience\nUnderstanding of Cloud / Hybrid data architecture concepts\nUnderstanding of insurance industry and products\nExcited by trying new technology and learning new tools\nBenefits & Culture:\n\nIn GRM, we embrace all of the values of our Fortune 100 company and push our practices and technology skill sets to the next level. In this organization, we are an agile set of teams dedicated to helping impact the lives of thousands of customers every day. We embrace a modern co-working style with exceptional work/life balance, ergonomic work areas, substantial benefits, and best-in-class amenities.\n\nLiberty Mutual is one of America's Best Employers for Diversity and one of the Best Employers for Women http://bit.ly/LibertyMutual-BestPlacesToWorkforWomen one of the Best Employers for New Grads http://bit.ly/LibertyMutual-BestPlacesforNewGrads and one of the Best Places to Work http://bit.ly/LibertyMutual-BestPlacestoWork . We offer excellent benefits for our employees including generous parental leave, retirement plans including 401k and pension, education reimbursement, commuter benefits, college savings plans, and much more.\n\nTo learn more about our benefit offerings and culture please visit:\nhttps://LMI.co/Benefits\nhttp://bit.ly/LibertyMutual-Culture\nEOE Statement:\n\n\nLiberty Mutual is an equal opportunity employer. We embrace an environment that is free from all discrimination in the workplace, in its business, or by its vendors. Liberty Mutual values diversity and the differences and similarities of our employees. We foster a diverse and inclusive work environment that leads to better ideas, stronger teams and more innovative products and services for our customers. Learn More:\nApply Now: click Apply Now"}, "62": {"company": "Zimmerman Advertising", "description": "Overview:\n\nBlazing a new trail, we are further developing our Insight Marketing team to include the data science discipline. We are looking for candidates who love learning, questioning the status quo, and finding data-backed ways to \"do-it better''. We need a self-starter to tackle algorithmic modeling, what-if analysis, attribution, and more. Your work will be on the front-edge of one of the most innovative Automotive advertisers (rated \"Genius\" by L2 think tank). As we continue to develop our big data team you will wear many hats and will be responsible for a fair amount of trail blazing. You will function as a combination of a data scientist, data engineer, and project manager. Together, you and your trusty Junior Data Analyst, will accomplish many things.\n\nPurpose:\n\nThe Data Scientist position requires a multidisciplinary approach to technology, business, and marketing applied together to unlock insights hidden within our marketing data. You'll use your talent for breaking down business challenges into data-driven problems that guide performance gains for one of the world's largest Automotive manufacturers. You will create predictive and prescriptive models by detecting and exploiting patterns in massive data sets. You will also create data visualizations and give presentations that will help key stakeholders in the decision making process.\n\nDesired Qualifications:\n\nWe need people that feel comfortable across the entire spectrum of data science, from collaborating across teams and brainstorming on the whiteboard, all the way to implementing and testing their models. If you are detail oriented and passionate about leveraging data, statistics, and improving client outcomes, this position is for you.\n\nResponsibilities:\nPerform exploratory data analysis\ngenerate and test working hypotheses in a cross-silo collaborative environment\nPrepare and analyze historical data and identify patterns\nDemonstrate expertise in deriving insights from structured, semi-structured, and unstructured datasets\nMust have developed and deployed data-backed solutions in the domain of marketing\nDesigning and implementing your own algorithms and data structures\n\n\nOther Qualifications:\nExperience manipulating big and noisy data sets (e.q. SQL, server log file)\nExperience working in big data framework (Hadoop, NoSQL, BigQuery, etc)\nExperience and knowledge of data storage, data management, and big data processing tools preferred\nStrong background in statistics\nExperience with scripting and rapid prototyping using python\nData mining experience (using python/pandas)\nExperience with Machine learning\nKnowledge of data visualization tools (tableau, datastudio, matplotlib)\nMicrosoft Office - Excel, PowerPoint, Word expert proficiency\nThe responsibilities are many, various, and not limited to those written in this document.\n\nRequired Skills\n\nRequired Experience\n\nJob Location\nFort Lauderdale, US-FL\nTo apply to this job, click Apply Now"}, "63": {"company": "Amobee", "description": "Amobee is the worlds leading independent advertising platform that unifies all channelsincluding TV, programmatic and socialacross all formats and devices. We provide marketers with advanced cross-channel media planning powered by advanced analytics and proprietary data. Our platform and technology provide sophisticated video-advertising solutions for the convergence of linear TV, over the top, connected TV, and premium digital.\n\nAmobee has been named to Fortunes Top 10 Best Workplaces in Advertising and Marketing. Amobees platforms have been widely recognized amongst our industry winning numerous awards in technology innovation. We are a wholly owned subsidiary of Singtel, one of the largest telco companies in the world, reaching over 700 million mobile subscribers in 21 countries. Amobee operates across North America, Europe, Middle East, Asia and Australia. For more information, visit amobee.com or follow @amobee.\n\nPosition Overview:\n\nAs a Data Scientist you will be working with large data sets to perform analysis, define data transformations, and build models. You will collaborate with the team to design solutions that focus on buying, selling, forecasting, allocating, delivering, and reporting of advertising on the internet and TV. You will generate bleeding-edge solutions through the application of mathematics, optimization, and machine learning capabilities. The position provides great opportunities to communicate with the business directly, bridging the gap between technology and business. Qualified individuals will have a solid background in the fundamentals of data engineering, data science, computer science or statistics, with experience and comfort with data access and manipulation.\n\nResponsibilities:\nApply mathematics to optimize the acquisition and allocation of advertising inventory using information about the inventory, advertiser and the targeted consumer\nWork cross functionally to gather feedback and requirements from end users\nDesign innovative solutions and build prototypes for proof of concept\nDevelop, launch, and evolve new products\nBe a thought leader in identifying and vetting new data sources\nExecute research that results in ground-breaking papers and case studies that support the needs of the sales and marketing functions\nPerform ad-hoc analysis on campaign, publisher, or product performance\nRequirements:\nA masters or PhD degree in a quantitative discipline, such as Computer Science, Statistics , Mathematics, Industrial Engineering, Mechanical Engineering.\nStrong analytical and problem-solving skills with attention to detail\nAbility to work as part of a team in a fast-paced environment\nAbility to quantify and communicate the value of a new method or process to the business\nExperience with data engineering tools used to access, merge, transform and evaluate data sources\nExperience with statistical software (e.g., Python, R), SQL and data frameworks (e.g., Spark, Pig)\nExperience with Gurobi a plus\nExperience with modeling concepts, such as training/test paradigm, validation of models, and knowledge of modeling techniques (linear and logistic regression, decision trees, etc.)\nLocation: Baltimore, MD\n\nIn addition to our great environment, we offer a competitive base salary, employee development programs and other comprehensive benefits. Please send a cover letter along with your resume when applying to the position of interest located at Amobee.com. We are an Equal Opportunity Employer. No phone calls and no recruiting agencies, please.\nTo apply to this job, click Apply Now"}, "64": {"company": "Zions Bancorporation", "description": "Senior Data Scientist\n(\nJob Number:\n\n\n046663\n)\n\n\nDescription\n\n\n\nZions Bancorporation is currently looking for an experienced Data Scientist to join our Enterprise Data Science team. This role focuses on delivering insight from data that is actionable and will drive revenue growth, cost reduction, and meet new regulatory requirements. The team works on strategic projects with tactical components that aim to drive all business decisions to be data driven.\n\nThe Data Scientist will be responsible for end-to-end analytic projects including:\nThe understanding of business and data needs\nDiscovering, cleaning, and transforming data as needed\nDesigning and building analytical models\nPrototyping\nPerforming statistical analyses\nProviding diagnostic, descriptive, prescriptive, and predictive analytics\nDetermine opportunities and needs around the use of machine and deep learning for help in prescriptive and predictive analytics, automation, and model training\n\n\nQualifications\n\n\nBachelor's Degree in Computer Science, Engineering, Statistics or other related area of study\nMasters or PhD in Computer Science, Engineering, Statistics or other related area of study is preferred\n8+ years' experience preferred\nStrong quantitative background with applied statistics skills, such as distributions, statistical testing, regression, etc.\nFamiliarity with predictive modeling, machine learning, and data mining techniques and algorithms\nSoftware skills\nExperience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable\nData visualization tools, such as GGplot, Tableau, D3.js\nScripting language experience, such as Java, Perl, PHP, or Python\nProficiency with SQL\nHadoop/Hive/Pig/Spark is a plus\nETL workflows and scheduling is a plus\nStrong analytical, organizational, and problem solving skills\nStrong interpersonal, presentation, and communication skills, both verbal and written along with an understanding of how to present results such that they are meaningful across multiple levels of management\nAbility to function in a consultative role and lead a team or project\nAbility to effectively teach and train fellow team members on models, processes or tools\nAbility to collaborate and coordinate with multiple teams and team members\nMust be able to meet deadlines and work with little or no supervision\nExperience in banking or financial services preferred\nExperience working with formal project management methodologies or a project management certification preferred\n\nWork Locations\n\n\nUtah-Salt Lake City-UT - Zions Bancorporation - HDQTRS\n\nBusiness Operations\n\nSep 16, 2019\nApply Now: click Apply Now"}, "65": {"company": "ManTech", "description": "Secure our Nation, Ignite your Future\n\nJob Summary\n\nEach day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings requires the application of big data solutions to promote efficient trade and travel. Through the use of effective big data technologies and solutions, CBP ensures that the movement of people, capital, and products is legal, safe, and secure.\n\nAs a Data Analyst on our team, you will use your unique technical skills to aid in the ongoing assessment of our systems, further driving developments and capabilities. You will facilitate data-driven decision making in response to national security threats. You will support the development of predictive models via the identification of behaviors and attributes that inform illicit activities, provide on-demand analysis to support emergent operational needs, and develop performance dashboards and artifacts to inform resource allocation, justify requirements, and support statutory reporting mandates. You will transforming large volumes of raw data, both structured and unstructured forms, into mission-focused insights that enhance understanding of mission performance, workload, and/or behavioral trends (i.e., strategic, tactical, and operational insights). Analysts may be called upon to support a diverse array of initiatives involving complex queries in support of network analysis, entity resolution, threat research, visualization, and impact assessments.\n\nDuties and Responsibilities\nObtain, join, scrub, explore, model, and interpret large datasets\nTransform and manipulate large datasets to suit the desired analysis\nCreate and present clear oral and written reports on the findings\nBecome an expert on name and entity matching\nRequired Qualifications\n3+ years of experience working with SQL\nExperience performing data analysis and interpreting results\nExperience using Java, R, or python, Matlab, SQL for data analysis\nConceptual understanding of and/or prior experiences related to data profiling, fuzzy matching, entity resolution, and signal detection theory (specifically with respect to SD theory: designing and improving upon systems that monitor, minimize, and balance false positive and false negative outcomes)\nBS Degree in a related technical fields (Computer Science, Math, Statistics, etc.)\nClearance: Active Top Secret\nDesired Qualifications\nExperience working in field of entity resolution, analytics, data mining or name matching.\nKnowledge or experience with data wrangling, cleansing, and analytics\nFinancial background is a plus\nExperience working with Customs or ICE travel-related data.\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS clearance is required as well as CBP suitability.\n\nMust be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) Background Investigation.\n\n#LI-FA1\n\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\n\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.\nStart your job application: click Apply Now"}, "66": {"company": "Software Engineering Institute", "description": "Position Summary:\n\nMachine Learning researchers at the SEI help our government and industry clients solve their problems using ML technology. In this role, you will work with our customers to identify areas where advanced statistical techniques can help tackle problems, plan and develop prototype solutions, and build out final products. You'll get a chance to work with elite cybersecurity professionals and university faculty to build new technologies that will influence national cybersecurity strategy for decades to come. You will co-author research proposals, execute studies, and present findings to DoD sponsors and at academic conferences.\n\nOur team works on a wide range of projects. Some of our current work includes developing metrics and experimental designs for large-scale cybersecurity research programs, researching human-in-the-loop machine learning, and building classifiers to identify security vulnerabilities in code. We have access to a wide variety of cyber-related data, including malware samples, netflow data, cybersecurity training runs and tests, incident tickets, and more. If you are a computer science or statistics expert with an interest in cybersecurity, we want to hear from you!\n\nRequirements:\nBS in machine learning, cybersecurity, statistics, or related discipline with eight (8) years of experience or equivalent combination of training or experience; or MS in machine learning, cybersecurity, statistics, or related discipline with five (5) years of experience; or PhD in machine learning, cybersecurity, statistics, or related discipline with two (2) years of experience.\nWillingness to travel to various locations to support the SEI\u2019s overall mission. This includes within the SEI and CMU community, sponsor sites, conferences, and offsite meetings on occasion.\nYou will be subject to a background check and will need to obtain and maintain a Department of Defense security clearance.\nKnowledge, Skills and Abilities:\nDeep understanding of statistical modeling techniques\nComfortable working in the Unix command line\nThrives in a multi-disciplinary environment\nSuperb communication skills\nExpertise implementing machine learning techniques (e.g., K-means, SVM, neural networks)\nFamiliar with at least one mathematical/statistical programming package (e.g., python numpy/scipy/pandas, R, MATLAB, etc.)\nStrong software engineering skills\nYou should have Cybersecurity or privacy experience\nExperience supporting test and evaluation for large-scale government research programs is a plus\nDesired Experience:\nExperience with specific methods and/or evidence that you can learn.\nMore Information\n\nPlease visit \u201cWhy Carnegie Mellon\u201d to learn more about becoming part of an institution inspiring innovations that change the world.\n\nA listing of employee benefits is available at: www.cmu.edu/jobs/benefits-at-a-glance/.\n\nCarnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.\n\n#seijob\nTo apply to this job, click Apply Now"}, "67": {"company": "Liberty Mutual Insurance", "description": "Senior Data Engineer\n\nAt Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as an Agile team within a Fortune 100 company, we are on the front edge of an IT transformation for how people work and deliver solutions.\n\nGRM Information Management is actively searching for a highly productive member of a distributed, dynamic agile team to serve as a technical expert in analysis, design, coding, and testing innovative data warehouse reporting solutions and analytics. This position will support Agency and Strategic Partnerships within Business Data Solutions Engineering.\nJob Summary:\n\nSenior Data Engineer, you will work collaboratively on a geographically diverse agile team to develop and enhance complex systems and/or software from user stories and technical/architectural specifications. You will analyze complex technical system problems and create innovative solutions that exceed customer expectations.\n\nThis is a fast-paced environment providing rapid delivery for our business partners. You will be working in a highly collaborative environment that values speed and quality, with a strong desire to drive change and foster a positive work environment as we continue our agile transformation journey. You will have the opportunity to help lead this change with us as we grow this culture, mindset and capability.\nIn this role you will:\nWork in a dynamic and exciting agile environment with Scrum Masters, Product Owners, and team members to develop creative data-driven solutions with our ETL pipeline that meet business and technical initiatives\nImprove speed to market by focusing on current Agency & Strategic Partners data needs as well as building out the long-term strategic data solutions using AWS, SQL, Unix, Informatica, as well as other modern data technologies\nDesign and develop programs and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science\nDemonstrate open minded and collaborative approach to creating innovative technical solutions\nAnalyze data and technical system problems to design and implement effective, flexible solutions\nHandle end-to-end development, including coding, testing, and debugging during each cycle\nDevelop automated tests for multiple scopes (Unit, System, Integration, Regression)\nMentor new and junior developers\nIdentify and recommend appropriate continuous improvement opportunities\n\nQualifications:\nBachelor's or Master's degree in technical or business discipline or equivalent experience, technical degree preferred\nGenerally, 5+ years of professional experience\nExperience developing back end, data warehouse technology solutions\nKnowledge of a variety of data platforms including Teradata, DB2 (Cloud based DB a plus)\nExperience with AWS (such as S3, Snowflake, Athena, snapLogic), Unix, Informatica & SQL\nExtensive knowledge of IT concepts, strategies, methodologies.\nExperience working with agile methodologies (Scrum, Kanban, XP) and cross-functional teams (Product Owners, Scrum Masters, Developers, Test Engineers)\nVersed in diverse technologies and new technical architecture principles and concepts\nDemonstrates leadership and active pursuit of optimizing CI/CD process and tools, testing frameworks and practices\nMust be proactive, demonstrate initiative, and be a logical thinker\nMust be team oriented with strong collaboration, prioritization, and adaptability skills required\nAdditional Qualifications:\n\nJava, Ruby, NoSQL, Python development experience\nUnderstanding of Cloud / Hybrid data architecture concepts\nUnderstanding of insurance industry and products\nExcited by trying new technology and learning new tools\nBenefits & Culture:\n\nIn GRM, we embrace all of the values of our Fortune 100 company and push our practices and technology skill sets to the next level. In this organization, we are an agile set of teams dedicated to helping impact the lives of thousands of customers every day. We embrace a modern co-working style with exceptional work/life balance, ergonomic work areas, substantial benefits, and best-in-class amenities.\n\nLiberty Mutual is one of America's Best Employers for Diversity and one of the Best Employers for Women http://bit.ly/LibertyMutual-BestPlacesToWorkforWomen one of the Best Employers for New Grads http://bit.ly/LibertyMutual-BestPlacesforNewGrads and one of the Best Places to Work http://bit.ly/LibertyMutual-BestPlacestoWork . We offer excellent benefits for our employees including generous parental leave, retirement plans including 401k and pension, education reimbursement, commuter benefits, college savings plans, and much more.\n\nTo learn more about our benefit offerings and culture please visit:\nhttps://LMI.co/Benefits\nhttp://bit.ly/LibertyMutual-Culture\nEOE Statement:\n\n\nLiberty Mutual is an equal opportunity employer. We embrace an environment that is free from all discrimination in the workplace, in its business, or by its vendors. Liberty Mutual values diversity and the differences and similarities of our employees. We foster a diverse and inclusive work environment that leads to better ideas, stronger teams and more innovative products and services for our customers. Learn More:\nOverview:\n\nAt Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.\n\nWe're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.\nTo apply to this job, click Apply Now"}, "68": {"company": "BombBomb", "description": "Who we are...\n\nConnecting people in a more meaningful way is not just what BombBomb's software delivers - it's what drives our teams every day. Through simple, personal video, we aim to Rehumanize communication. Our team is resourceful and intelligent. Competitive and collaborative. Fun-loving and tenacious. We're close-knit and love adding new talent to the mix. If you are seeking a dynamic workplace and new challenges, we want to hear from you!\n\nWho we're looking for\n\nA Data Engineer eager to learn and collaborate with those around them, who produces quality results with a low frequency of serious defects. The Engineer is attentive to the needs of the quality feedback loop, from report to resolution and has the ability to take ideas and requirements from concept to completion and engage those who are crucial to the project's success.\n\nWhat you will do\nDesign, construct and optimize systems to aggregate, transform and process large amounts of data from relational, columnar and other kinds of data stores.\nEmpower internal users with tools that allow them to service their own needs in collecting, querying and analyzing data.\nImprove our data systems' performance and reliability against steadily increasing loads and varieties of work.\nWork creatively to derive data from existing sets to enable new capabilities.\nEmploy machine learning tools to enable new product features and outcomes.\nHow you'll do it...\n\nEmbody BombBomb's core values: Relationships, Fun, Humility, Flexibility and Service.\nProactivity: Acts without being told what to do. Brings new ideas to the company.\nPersistence: Demonstrates tenacity and willingness to go the distance to get something done.\nAttention to Detail: Does not let important details slip through the cracks or derail a project.\nFollow-Through on Commitments: Lives up to verbal and written agreements.\nFlexible: Can bounce between projects day to to day.\nOur ideal candidate will be or have\n3+ years experience with various relational databases, tuning, ETL: Oracle, Postgres, MySQL, etc.\n3+ years experience with AWS data systems: S3, RDS, DynamoDB, Aurora, Redshift, etc.\nScripting and programming experience: Python, NodeJS, PHP, etc.\nTelemetry and monitoring experience: Splunk, Elasticsearch, etc.\nBombBomb Benefits Package Includes\nExcellent Medical, Dental and Vision Benefits for you and your family (2 PPO + HSA option)\n15 days paid time off\n9 paid holidays\n401k Plan with employer match\nWeekly company-catered lunch\nFun workplace: happy hour every Friday and company game room\nAnnual Education / Development for your career growth\nTo apply to this job, click Easy Apply"}, "69": {"company": "VividCortex", "description": "*Only candidates residing inside of the United States will be considered for this role*\n\nAbout VividCortex\nVividCortex provides deep database performance monitoring to drive speed, efficiency and savings. Our cloud-based SaaS platform offers full visibility into major open source databases \u2013 MySQL, PostgreSQL, Amazon Aurora, MongoDB, and Redis \u2013 at any scale without overhead. By giving entire engineering teams the ability to monitor database workload and query behavior, VividCortex empowers them to improve application speed, efficiency, and up-time.\n\nFounded in 2012, and headquartered in the Washington, DC metro area with remote teams in the US and abroad, our company\u2019s growth continues to accelerate (#673 Inc. 5000). Hundreds of industry leaders like DraftKings, Etsy, GitHub, SendGrid, Shopify, and Yelp rely on VividCortex.\n\nWe know our team is our greatest strength so we support our people with excellent benefits including 401k, professional development assistance, flexible paid leave (vacation, parental, sick, etc.), and a health/wellness benefit. We enjoy getting together and giving back to the community through volunteer services. We believe in offering every employee the tools and opportunity to impact the business in a positive way. We care about inclusiveness and working with people who help us learn and grow.\n\nAbout the Role\n\nVividCortex is looking for an experienced Data Engineer to architect and build our next-generation internal data platform for large scale data processing. You are at the intersection of data, engineering, and product, and run the strategy and tactics of how we store and process massive amounts of performance metrics and other data we measure from our customers' database servers.\n\nOur platform is written in Go and hosted on the AWS cloud. It uses Kafka, Redis, and MySQL for data storage and analysis. We are a DevOps organization building a 12-factor microservices application; we practice small, fast cycles of rapid improvement and full exposure to the entire infrastructure, but we don't take anything to extremes.\n\nThe position offers excellent benefits, a competitive base salary, and the opportunity for equity. Diversity is important to us, and we welcome and encourage applicants from all walks of life and all backgrounds.\n\nResponsibilities:\nWork with others to define, and propose for approval, a modern data platform design strategy and matching architecture and technology choices to support it, with the goals of providing a highly scalable, economical, observable, and operable data platform for storing and processing very large amounts of data within tight performance tolerances.\nPerform high-level strategy and hands-on infrastructure development for the VividCortex data platform, developing and deploying new data management services both in our existing data center infrastructure, and in AWS.\nCollaborate with engineering management to drive data systems design, deployment strategies, scalability, infrastructure efficiency, monitoring, and security.\nDiscover, define, document, and design scalable backend storage and robust data pipelines for different types of data streams.\nWrite code, tests, and deployment manifests and artifacts, using CircleCI, Git and GitHub, pull requests, issues, etc. Collaborate with other engineers on code review and approval.\nMeasure and improve the code and system performance and availability as it runs in production.\nSupport product management in prioritizing and coordinating work on changes to our data platform, and serve as a lead on user-focused technical requirements and analysis of the platform.\nHelp provide customer support, and you'll pitch in with other departments, such as Sales, as needed.\nRotate through on-call duty.\nUnderstand and enact our security posture and practices.\nContinually seek to understand and improve performance, reliability, resilience, scalability, and automation. Our goal is that systems should scale linearly with our customer growth, and the effort of maintaining the systems should scale sub-linearly.\nContribute to a culture of blameless learning, responsibility, and accountability.\nManage your workload, collaborating and working independently as needed, keeping management appropriately informed of progress and issues.\nPreferred Qualifications:\nExperience building systems for both structured and unstructured data.\nAWS infrastructure development experience.\nMastery of relational database technologies such as MySQL.\nYou are collaborative, self-motivated, and experienced in the general development, deployment, and operation of modern API-powered web applications using continuous delivery and Git in a Unix/Linux environment.\nExperience and knowledge programming in Golang or Java\nYou have experience resolving highly complex data infrastructure design and maintenance issues, with at least 4 years of data-focused design and development experience.\nYou are hungry for more accountability and ownership, and for your work to matter to users.\nYou\u2019re curious with a measured excitement about new technologies.\nSaaS multitenant application experience.\nAbility to understand and translate customer needs into leading-edge technology.\nExperience with Linux system administration and enterprise security.\nA Bachelor\u2019s degree in computer science, another engineering discipline, or equivalent experience.\nNote to Agencies and Recruiters: VividCortex does not engage with unsolicited contact from agencies or recruiters. Unsolicited resumes and leads are property of VividCortex and VividCortex explicitly denies that any information sent to VividCortex can be construed as consideration.\nStart your job application: click Easy Apply"}, "70": {"company": "Elanco", "description": "Interested in joining a cause-driven, customer focused company dedicated to positively impacting the health of animals, people and the planet? Search our job listings below.\n\nThe Principal Research Scientist is responsible for analytical control strategies and for leading a team in the development, qualification/validation, and use of analytical, bioanalytical and characterization methods in support of Elancos Food and Companion Animal Vaccine product development.\n\nFunctions, Duties, Tasks:\nDevelop all or portions of analytical control strategies.\nDevelopment and verification/qualification/validation of analytical methods to support in-process, release, characterization analysis, and stability testing of antigen ingredient and final vaccine.\nProvide support for discovery, toxicology, cell culture, fermentation, bioassay, purification, formulation, and manufacturing.\nDrive innovation for analytical methods, strategy and capabilities\nOversight for method transfers to development, QCL, or third party personnel.\nCoaching, training, and administration of performance management to personnel (primarily, but not limited to, direct reports).\nEnsure work and team activities are aligned with all relevant development quality, regulatory, HSE, GLP, and GMP requirements.\nMinimum Qualification (education, experience and/or training, required certifications):\nPh.D. in analytical, biophysical, biochemistry, molecular/cell biology, or related field; alternatively, skills commensurate with a PhD scientist.\nMinimum 8 years experience in relevant/applicable field.\nExperience with knowledge of one or more of the following, as appropriate: separation sciences, immunochemistry, biophysical/biochemical characterization, molecular biology, and bioanalytical sciences\nAdditional Preferences:\nExperience with assay development in the Animal Health industry is highly desired\nExperience with the drug development process, including knowledge of regulatory compliance issues.\nFundamental knowledge of cGMP/GLP/USDA compliance requirements.\nExperience with the supervision of direct reports.\nElanco is an EEO/Affirmative Action Employer and does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status\nStart your job application: click Apply Now"}, "71": {"company": "National Interstate", "description": "Overview\n\n\nNational Interstate is a member of Great American Insurance Group. As one of the leading commercial transportation insurers in the nation, we offer risk financing solutions in all 50 states tailored to meet the needs of a wide variety of transportation classes. Our offerings include traditional insurance and innovative alternative risk transfer (ART) programs, including more than a dozen group captive programs catering to niche wheels markets. We are proud to be a multiple Northcoast 99 winner and Cleveland Plain Dealer Top Workplace in Northeast Ohio. It is because of our talented and dedicated team that we are able to live out our company values of integrity, transparency, fairness, accountability, empowerment and collaboration with each transaction we make. If you are ready to join an engaging and driven team such as ours, we would love to hear from you!\n\nResponsibilities\nContributes to and / or accountable for product premium volume growth and profitability results within assigned product lines.\nAssists as primary product support contact for business units, agents, and other staff.\nAssist with interactions with relevant departments such as Claims, Underwriting, Sales/Marketing, and provides customer service support (i.e. agents, regulators and industry groups).\nMay participate in business unit, compliance, claims, agency, program reviews and audits (i.e. compliance audits, rate/pricing reviews, and agency reviews.\nSupports action plans and strategic direction for functional areas and maintain alignment with other product managers to ensure successful development of entire product line.\nSupports the review, approval, implementation, and communication of assigned filings and ensures compliance with statutory requirements.\nParticipates in developing product and rate revisions, underwriting guidelines, manuals, and procedures.\nGathers and analyzes data from various sources specific to product.\nAssists in monitoring product performance.\nProvides summary analysis and communicates to business units.\nParticipates in the development of new and revised insurance products, policies, and other required forms to ensure compliance with regulatory requirements and company guidelines.\nMonitors pertinent insurance publications to determine impact on line of business. This may include:\nIdentifying emerging coverage issues, state regulatory concerns and business unit needs.\nDeveloping action plans, implementing and communicating changes when appropriate.\nResolves and/or assists with researching, documenting, communicating moderately complex compliance related issues.\nProvides technical advice to lower level positions and other functional areas.\nPerforms other duties as assigned.\nQualifications\n\n\nEducation: Bachelor\u2019s Degree or equivalent experience.Field of Study: Business, Liberal Arts or a related disciplineExperience: 2 to 5 years of related underwriting, claims, or product experience. Progression toward certification in area of expertise preferred; appropriate certifications could include Associate in Underwriting (AU), Chartered Property Casualty Underwriter (CPCU), Certified Insurance Counselor (CIC), Program in General Insurance (INS), Associate of Risk Management (ARM), Certified Licensing Professional (CLP) or other applicable designations.\nTo apply to this job, click Apply Now"}, "72": {"company": "Enterprise Holdings", "description": "About the Role\n\nThe AI and Machine Learning Data Science Manager serves as a dedicated business partner responsible for developing advanced technical data science strategies and maximizing the implementation of analytical solutions for the business unit(s) to which they are dedicated. This role is embedded in both the business unit(s), leveraging a detailed, current working knowledge of unit operations, strategic goals and deep technical acumen, and the Center of Excellence for Data Science (CEDA), leading a team of analytics professionals to design, execute, and implement analytical solutions to support and grow the business unit(s) being served.\n\nThe ideal candidate for this role will possess:\nStrong business acumen to bridge the gap between the business and technology/analytics\nSkilled in data visualization, statistical analysis, process automation, and design thinking\nAdvanced Technical Platform experience and expertise\nWith the ability to demonstrate this to peers and executives, this role will manage a small team of Data Scientists, and help develop the strategy for their team going forward.\n\nCompany Overview\nEnterprise Holdings is the largest car rental provider in the world as measured by revenue and fleet. The company and its affiliate Enterprise Fleet Management which combined offer a total transportation solution that includes extensive car rental and car-sharing services, truck rental, corporate fleet management and retail car sales accounted for $24.1 billion in revenue and operated 2 million vehicles throughout the world in 2018. Enterprise Holdings annual revenues also place it near the top of the global travel industry, exceeding all other rental car companies, many airlines, and most cruise lines, hotels, tour operators and online travel agencies. Enterprise Holdings regional subsidiaries and Enterprise Fleet Management currently employ more than 100,000 people worldwide.\n\nThrough its integrated global network of independent regional subsidiaries and franchises, Enterprise Holdings operates the Enterprise Rent-A-Car, National Car Rental and Alamo Rent A Car brands at more than 10,000 fully staffed neighborhood and airport locations. The Enterprise Holdings global network operates in more than 90 countries and territories, including North America, Central America, South America, the Caribbean and Europe, as well as parts of Asia-Pacific and the Middle East. Today, the companys three brands serve more than 95 percent of the worldwide car rental market.\n\nThis position is located at our Corporate Headquarters in Clayton, MO\n\nResponsibilities:\nProvide senior level technical expertise to help drive the execution of data science projects; Serve as a data science business partner providing direct support and connection between CEDA data scientists, strategic analysts and assigned operational business unit(s) to drive the application of and generate opportunities for data science into business processes\nDevelop and leverage a detailed understanding of assigned business unit(s) strategic needs to develop a data science/analytics strategy to meet those needs, leading and coordinating project teams in the design, development and delivery of analytics solutions to support and grow the business\nUse design thinking and knowledge of data science and machine learning to challenge the business and define use cases, develop roadmaps for rapid, iterative execution of potential solutions, and work with management to prioritize investment\nLead a team of data scientists and/or strategic analysts dedicated to applying advanced analytical methods for assigned business unit(s); Apply deep technical expertise to provide guidance to team regarding methodology, project approach and appropriate tools; Provide continuous education on the business context and application of data science solutions to the team\nChallenge and influence the business on ways to use data science to more accurately value proposed changes and new ideas\nTranslate and communicate efforts underway, progress, results, and solutions to business unit leadership and Center of Excellence for Data Science leadership\nLead innovation using latest advances in data science across machine learning, operations research and mathematical optimization; Develop and deploy new methodologies globally to accelerate business and product development efforts\nMonitor and measure the effectiveness of the implemented solutions and feed learnings back into the development process to further improve outcomes\nIdentify and coordinate with Center of Excellence for Data Science innovation/R&D resources, both internal or external to leverage best in class supplemental data, tools, and methodologies to support business unit to accelerate progress; Assess and select vendors, in areas such as auto machine learning and operations research platforms, to enhance the capabilities of the data science team\nAdditional Responsibilities\nSeek to improve job performance through self-assessment, skill development, training and goal setting\nMaintain a regular and reliable level of attendance and punctuality\nPerform miscellaneous job-related duties as assigned\nEqual Opportunity Employer/Disability/Veterans\n\nQualifications:\n\nMinimum:\nPhD in Mathematics, Statistics, Operations Research, Physics, Engineering, Economics, Computer Science or a related quantitative field required OR\nMaster's Degree in Business, Economics, Mathematics, Statistics, Psychology or other quantitative field with 5+ years experience working with the business to influence strategy and decision making by applying data science and analytics\nMust be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future\n3+ years experience working with the business to influence strategy and decision making by applying data science and analytics\n3+ years experience as a practitioner in data science\nExperience designing and building data analytics strategies as well as designing analytics projects and leading the work of others\nStrong business acumen to bridge the gap between the business and technology/analytics\nSkilled in data visualization, statistical analysis, process automation, and design thinking\nAdvanced level of Technical Platform experience and expertise\nCompetency Based:\nForward-Thinking\nLeading and Inspiring People\nManaging and Developing People\nBuilding Relationships\nPlanning and Organizing\nDecision Making\nPersuading and Influencing\nResilience\nStart your job application: click Apply Now"}, "73": {"company": "Riverside Research Institute", "description": "Returning Candidate? Log back in to the Career Portal and click on 'Job Browsing/History' and find the job you're looking for.\n\n2019-132-INT: Data Scientist\n\nDirectorate Intelligence & Defense Solutions\nLocation Wright-Patterson AFB, OH\nRiverside Research\u2019s Intelligence and Defense Solutions (IDS) directorate is seeking a Data Scientist to support the National Air and Space Intelligence Center (NASIC) at Wright Patterson AFB, OH. Responsibilities will include prototyping applications and implementing processes to extract knowledge or insights from both structured and unstructured data. Candidates must be technically proficient and have real-word experience devising and implementing practical and sustainable solutions. You will be working with a team of Riverside Research, government, and contractor personnel supporting artificial intelligence/machine learning (AI/ML) projects. The work is in support of both US Air Force and Intelligence Community programs.\n\nAll Riverside Research opportunities require U.S. citizenship.\n\nJob Responsibilities:\n\u2022 Assess customer systems and processes for application of data science techniques and processes to support their needs\n\u2022 Assist with implementation of AI/ML initiatives through preparing, analyzing, and visualizing structured, semi-structured, and unstructured data\n\u2022 Develop and conduct algorithm quality trade studies, identifying best case uses and characterizing performance\n\u2022 Refine the verification and validation process for analytics\n\u2022 Enhance existing models to leverage analytic output for driving automated tasking\n\u2022 Develop scripts for running and testing algorithms and analytics using a variety of programs\n\u2022 Develop machine learning, data mining, statistical, and graph-based algorithms to analyze and make sense of data sets\n\u2022 Prototype/consider several algorithms and decide upon final model based on suitable performance metrics\n\u2022 Generate reports and visualizations that summarize data sets and provide data driven insights to customers\n\u2022 Other duties as assigned\n\nQualifications:\n\u2022 Bachelors degree in a technical domain plus 5 years of experience related to the job description above; an additional 4 years of experience (for a total of 9 years) related to the job duties listed above can be substituted in lieu of a Bachelors degree\n\u2022 Minimum of 5 years\u2019 experience in data science or related field\n\u2022 Demonstrated proficiency in data analysis, modeling, and visualization\n\u2022 Proficiency with programs used for data analytics such as R or Python\n\u2022 Strong communication, organizational, and analytical skills\n\u2022 Current Top Secret clearance with SCI adjudication\n\u2022 Self-motivated, independent, detail oriented, responsible team player\n\nDesired Qualifications:\n\u2022 Doctorate degree in applied statistics, applied mathematics, computer science or related technical field with specialization in data science\n\u2022 Agile software development experience/certifications\n\u2022 Technical project management and oversight experience\n\u2022 Experience working with or in support of Department of Defense (DoD) or intelligence community (IC) organizations\n\nRiverside Research strives to be one of America\u2019s premier providers of independent, trusted technical and scientific expertise. As we continue to add experienced, technically astute staff, we are looking for highly motivated, talented team members that can help our DoD and Intelligence Community (IC) customers continue delivery of world class programs. As a not-for-profit, technology-oriented Defense Company, we believe service to customers and support of our staff is our mission. Our goal is to serve as a destination company by providing an industry-leading, positive, and rewarding employee experience for all who join us. We aspire to be a valued partner to our customers and to earn their trust through our unwavering commitment to achieve timely, innovative, cost-effective and mission-focused solutions.\n\nAll positions at Riverside Research are subject to background investigations. Employment is contingent upon successful completion of a background investigation including criminal history and identity check.\n\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability, and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.\n\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans, and requires affirmative action by covered contractors and subcontractors to employ and advance in employment qualified protected veterans.\n\nApply Now\nApply Now: click Apply Now"}, "74": {"company": "Driscoll's", "description": "About the Opportunity\nThe Sr. Data Scientist, Molecular Biology will be responsible for applying the tools of mathematics, computer science, and high performance computing to accelerate traditional plant breeding. This role will work together with a small creative team to design and conduct research. Responsibilities include discovery and application work including algorithm development, deployment, and database development. This role will also plan and assure completion of complex projects involving cross-functional teams, and will stay current with the newest bioinformatics techniques that would aid Driscoll\u2019s in accomplishing our mission.\nResponsibilities\n\n\nResearch:\nWork with the molecular biology team to develop algorithms that assist in the analysis of genetic and genomic data.\nApply open-source and custom algorithms to genetic and genomic data sets to aid in discovery of marker-trait associations.\nDevelop database systems capable of primary data storage and export for secondary analysis with other tools.\nFacilitate interaction with Driscoll's IT to maintain/enhance molecular databases and to secure primary data integrity.\nCollaboration/Communication:\nEstablish collaborative relationships with other researchers in the field through attendance of conferences and symposia.\nOccasional travel to locations in the European Union will be required.\nGeneral:\nFollow Company policies and practices while representing Driscoll\u2019s in an ethical and business-like manner in all interactions with employees, governmental agencies, growers, customers, etc.\nOther duties as assigned.\nCandidate Profile\nMaster\u2019s degree in Mathematics or Computer Science with 5+ years of work experience.\nProficiency in Java, C++, and PostgreSQL.\nStrong knowledge of Linux and bash shell scripting.\nExperience with high performance computing environments in Linux.\nExperience with routine Linux systems administration.\nExperience with R and Python or another scripting language is a plus.\nKnowledge of genetics and genomics.\nExperience in the analysis of whole genome sequence data or genotyping by sequencing data is highly desired.\nExperience in bioinformatics.\nExperience planning complex projects involving cross-functional or interdisciplinary teams.\nIndividual must possess the ability to develop strong trust in all working relationships.\nDemonstrated ability to successfully work in a cross-functional team environment.\nExcellent communication skills, including written, verbal, and presentation.\nSome travel will be required.\nA California driver\u2019s license and the ability to be covered under company-sponsored vehicle insurance program are also required.\nPassport and the ability to travel internationally without restrictions is also required.\n</br>Driscoll's\nApply Now: click Apply Now"}, "75": {"company": "iSeatz", "description": "We have an exciting opportunity forYOU to joinUS, as ourData Science Leader.\n\nThis position will be based in New Orleans, Louisiana.\n\nReporting to the VP of Product and Design, you will be ourData Science SME, responsible for the collection, cleaning and munging of data to meet the company\u2019s purpose. Duties include creating experimental frameworks for product development and machine learning with the aim to lay a strong data foundation for robust analytics to be performed.\n\nWHAT WILL YOU DO?\n\nAs a Data Science Leader, you will :\nBe responsible for design and end-to-end execution of the iSeatz analytics strategy.\nLead an agile team of BI Analysts that owns all analytics / machine learning initiatives involving the customer, experience personalization, merchandising, customer segmentation, propensity to purchase, email engagement optimization and commercial customer experience optimization.\nLead the overhaul, including hands on development, of all marketing analytics including web tagging (Adobe Analytics - Omniture), data sourcing/modeling, descriptive analytics, and applied machine learning (ML) engagement.\nTeam with website optimization team and provides statistical analyses / guidance for hypothesis testing.\nTeam with the executive leadership team (c-suite) to consolidate organizational data, evaluate/scope third party data sources, and develop interactive KPI dashboards for the leadership reviews.\nUse statistics, data mining, machine learning, and deep learning techniques to deliver data-driven insights for our clients.\nWork with internal teams and clients to understand their challenges and create solutions, inform the business\u2019 strategic direction and identify opportunities\nBe a thought leader for your team on projects and about leading technologies\nStay on top of AI trends\nManage a team of strategic, tactical, operational and technical resources.\nProduce a range of data-driven visualizations (dashboards, reports, presentations) and provide insights on business performance and Key Performance Indicators (KPIs).\nTeam with Product Managers and Product Owners to understand requirements and develop processes/tools to monitor and analyze data (e.g. transaction, e-commerce, user experience, etc.) accuracy and business performance\nEnhance data (including 3rd party sources) acquisition to include information that is relevant for building analytic systems\nProcess, cleanse, and verify the integrity of data used for analysis\nWHAT YOU WILL BRING TO THE ROLE:\nData expertise with serious analytical and statistical skills.\nExperience in taking massive amounts of data and find the insights our clients need to help iSeatz do more.\nDegree in Computer Science, Statistics, Applied Math or related field\n5-7 years\u2019 practical experience with data processing, database programming and data analytics\nPersonnel and team management experience (e.g. interviewing, performance goals and feedback, etc.)\nExperience using statistical computer languages (e.g. R, Python, SQL, etc.) and tools (e.g. Adobe, DOMO, Salesforce, Simian, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams.\nWHY iSeatz IS A GREAT CHOICE FOR YOU:\n\niSeatz is a well-established, innovative and high growth company in New Orleans, providing one of the most powerful booking engines for ancillary travel products in the market to some of the world\u2019s most iconic brands. The award-winning iSeatz \u201cOneView\u201d platform meets brands\u2019 exact requirements for delivering a highly personalized and engaging commerce experience that drives conversions, customer satisfaction and advocacy.\nVoted one of New Orleans City Business Best Places to Work for eight of the last nine years Our company culture reflects the value of a strong and talented team, the importance of giving back, and the balance of having fun along the way\nEnergetic company where you will have the opportunity to stand out, shine and build your career\nHuge emphasis on supporting our team in order to allow for top notch contributions\nCompetitive salaries, a comprehensive suite of benefits and fun perks including a casual dress code, flexible working arrangements and a dog-friendly office\nIf you\u2019re looking for an excellent workplace where hard work and fun go hand in hand and respect for team members is our core value,iSeatz is the RIGHT place for you!\nApply Now: click Apply Now"}, "76": {"company": "NCSOFT", "description": "WHO WE ARE\n\nArenaNet is an iconic and world class member of the NCSOFT West family that builds online worlds infused with innovation, hand-crafted excellence, and creative passion. We're not the only ones who share this passion; gamers made Guild Wars 2 the fastest selling MMO in the West with more than 3 million copies sold in its first 9 months, and players and press have consistently called it one of the best games of all time.\n\nWe are seeking a talented and enthusiastic Senior Data Analyst to join our team! As a Senior Data Analyst, you'll be responsible for helping the studio navigate the vast oceans of data our games produce. We're looking for an experienced analyst with a burning curiosity about our players and our games, someone who can go deep to find answers and bring back actionable insights.\n\nRESPONSIBILITIES\nUse SQL, Tableau, and other tools to query gameplay and financial data\nConduct quantitative and statistical analyses on gameplay and financial data\nCreate and maintain accurate and comprehensible data visualizations and dashboards\nPrepare and present reports and analyses to design and production stakeholders\nConduct ad hoc data analysis based on current team needs and management priorities\nWork collaboratively with designers, producers, and engineers to understand business and design needs\nStay actively engaged in our games and develop a deep understanding of game mechanics including gameplay and economy\nQUALIFICATIONS\nBA or BS in statistics, business, analytics, data science, or related field \u2013 MS or PhD a plus\nA passion for games and the gaming industry\n5-7+ years hands-on experience as a data analyst or business analyst\nSQL, Excel and Tableau proficiency, including experience querying and visualizing large, complex data sets\nStrong quantitative skills, and experience utilizing scientific analytic methods, qualitative methods, and quantitative analysis techniques, as well as predictive modeling\nAbility to effectively communicate with people at various levels of business and technical expertise, including the ability to simplify difficult technical concepts\nDemonstrated history of turning raw data into actionable insights\nThis is a full time, on-site position at our studio in Bellevue, Washington. A casual, friendly work environment, comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.\n\nNCSOFT West is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\nNCSOFT West participates in E-Verify.\nTo apply to this job, click Easy Apply"}, "77": {"company": "Enterprise", "description": "About the Role\n\nThe Center of Excellence for Data and Analytics (CEDA) Senior Data Scientist leads initiatives using advanced analytics expertise to understand internal and external customers' strategic business objectives, relate those objectives to measurable indicators and focus on delivering analytic products and services to create new insights and strategies promoting continuous performance improvements for the company. The CEDA Senior Data Scientist acts as a resource and mentor for less experienced Data Scientists and applies expert analytics to create efficiencies and improve the decision making process for internal business units by developing and implementing advanced statistical and mathematical solutions.\n\nCompany Overview\nEnterprise Holdings is the largest car rental provider in the world as measured by revenue and fleet. The company and its affiliate Enterprise Fleet Management which combined offer a total transportation solution that includes extensive car rental and car-sharing services, truck rental, corporate fleet management and retail car sales accounted for $24.1 billion in revenue and operated 2 million vehicles throughout the world in 2018. Enterprise Holdings annual revenues also place it near the top of the global travel industry, exceeding all other rental car companies, many airlines, and most cruise lines, hotels, tour operators and online travel agencies. Enterprise Holdings regional subsidiaries and Enterprise Fleet Management currently employ more than 100,000 people worldwide.\n\nThrough its integrated global network of independent regional subsidiaries and franchises, Enterprise Holdings operates the Enterprise Rent-A-Car, National Car Rental and Alamo Rent A Car brands at more than 10,000 fully staffed neighborhood and airport locations. The Enterprise Holdings global network operates in more than 90 countries and territories, including North America, Central America, South America, the Caribbean and Europe, as well as parts of Asia-Pacific and the Middle East. Today, the companys three brands serve more than 95 percent of the worldwide car rental market.\n\nThis position is located at our Corporate Headquarters in Clayton, MO.\n\nResponsibilities:\nLead the design and delivery of end-to-end analytical solutions that address the business needs\nExtract, clean, and manipulate both structured and unstructured datasets\nPerform exploratory data analysis, generate hypotheses, and extract actionable insights\nDevelop statistical and/or mathematical models that are put in production\nDeliver detailed documentation including descriptions of efforts, results, insights and recommendations\nPresent findings and recommendations to other CEDA members and various levels of management\nPartner with the other CEDA teams to ensure solutions are delivered successfully\nProvide technical guidance and mentoring to other Data Scientists\nIdentify and offer strategies to link the team's analytical activities with business goals and objectives\nAdditional Responsibilities\nSeek to improve job performance through self-assessment, skill development, training and goal setting\nMaintain a regular and reliable level of attendance and punctuality\nPerform miscellaneous job-related duties as assigned\nEqual Opportunity Employer/Disability/Veterans\n\nQualifications:\n\nMinimum:\nMust have a Master's Degree or greater in Mathematics, Statistics, Operations Research, Physics, Engineering, Economics, Computer Science or a related quantitative field\nMust be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future\nMust have 4+ years experience data mining and developing statistical and/or mathematical models using R or CPLEX\nMust have 4+ years experience with SQL and/or Python programming or directly querying relational databases such as Teradata, SQL Server or Oracle\nCompetency Based:\nForward-Thinking\nResults-Oriented\nWorking With a Team\nProblem Solving\nCommunication\nStart your job application: click Apply Now"}, "78": {"company": "Precision Biosciences", "description": "Summary\n\nThe Analytical Scientist/Senior Scientist, CMC will be a key member of the CMC organization which aims to drive operational excellence for the successful development of Precision BioSciences Cell and Gene Therapy Products, including allogeneic CAR-T cells, AAV vectors, and Lipid Nanoparticle Encapsulated mRNA. The Analytical Scientist/Senior Scientist, CMC will be primarily responsible for: 1) supporting technology transfers to external vendors and within internal departments at Precision BioSciences and 2) managing outsourced analytical testing. Responsibilities include preparation of tech transfer and qualification protocols, management of tech transfer data, and review and approval of reports.\n\nEssential Duties and Responsibilities\n\nReasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position.This list contains the major duties and requirements of the job and is not all-inclusive. Incumbent(s) may be expected to perform role-related duties other than those contained in this document.\nAuthor/review/approve tech transfer and qualification protocols and reports\nSupport troubleshooting of analytical methods performed by external vendors\nManage analytical data generated by external vendors\nInterface with Quality, Regulatory, and CMC functions (Analytical Development, Formulation) to present ensure events and issues associated with analytical testing are communicated and escalated appropriately\nRemain current with regulatory and industry requirements relevant to the analytical method qualification and validation\nTake a lead role in quality events (OOS, OOT, laboratory investigations, CAPA, CC) as needed\nQualifications\n\nThe requirements listed below are representative of the knowledge, skill, and/or ability required to perform this job successfully.\n\nEducation/Experience:\nPhD in life sciences and 3+ years of industry experience or postdoc, or BS with 8+ years experience, or MS with 5+ years experience in pharmaceutical development with direct experience with analytical method qualification and validation. Preference will be given to individuals with experience with the development of biologics, cell therapies, or gene therapies.\nKnowledge of regulatory expectations (e.g. ICH guidelines, etc.) for biologic analytical method qualification and validation\nExperience in working with external vendors for analytical testing\nTravel Requirements\nThis position may require minimal travel\nPrecision BioSciences mission and vision is to translate the worlds most powerful genome editing technology into greatly needed products throughout the life sciences, by being the conduit through which the greatest genome engineering challenges are solved. Precisions wholly proprietary ARCUS genome editing platform enables the production of highly specific nucleases that can insert, remove, and modify DNA at essentially any location in a complex genome. Through our ARCUS platform, we are developing genome editing-based products to address critical needs in oncology, genetic disease, agriculture, and beyond. For additional information, please visit www.precisionbiosciences.com\n\nPrecision BioSciences provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Precision BioSciences complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\nApply Now: click Easy Apply"}, "79": {"company": "ManTech", "description": "Secure our Nation, Ignite your Future\n\nManTech is seeking a motivated, career, and customer-oriented Data Scientist to join our team in the Reston, VA area to provide unparalleled support to multiple federal agencies through the Continuous Diagnostics & Mitigation (CDM) Program. The CDM Program is a high-profile, high-visibility, cybersecurity modernization and risk management program where you can contribute innovative solutions and consult with many different federal agencies to enhance their Information Assurance (IA) programs and continuous monitoring capabilities.\n\nThe Data Scientist provides all the necessary technical expertise to architect, design, and model data for cyber security enterprise solutions into a Federal Agencys overarching enterprise.\n\nThis position ensures effective and efficient use of data within all architecture, engineering, and integration tasks with the agency assigned projects. The position is also responsible for providing thought leadership for our clients while providing technical oversight for solution deployment engagements. The position performs a critical role in understanding DHS strategic and programmatic needs, proposing effective solutions, and consistently providing high-level customer service. The position will interface regularly with Project Control, Customer Success and Agency Advocacy Managers, and PMO Manager, as well as our Strategy, Transition and Operations teams to assist in resolving issues, improving processes, and increasing productivity.\n\nResponsibilities:\nLead architecture and design data approaches and solutions for a large set of data across multiple COTS products.\nUnderstands and improves how data is modeled against the program Logical Data Model\nUnderstands and improves how data is sourced from COTS products and ingested with the data integration solution\nEnsures that enterprise architects are addressing all data requirements in their respective projects and solutions\nLead the technical engagements to assess client business and technical objectives, determine deliverables, evaluate risk and execute projects effectively.\nArchitects and designs enterprise-class security systems for a production environment\nAlign standards, frameworks and security with overall business and technology strategy\nIdentify and communicate current and emerging security threats\nConduct Design Workshops with multiple stakeholders\nIdentify security design gaps in existing and proposed architectures and recommend changes or enhancements\nWork with Service Design management to develop strategic plans for architecture, engineering, integration, and dashboard\nEnsure ManTech and DEFEND E policies and procedures are followed via audits and other inspection mechanisms.\nProvide reporting and feedback to senior management as required\nSupport the development and delivery of RFS proposals and/or Rough Orders Magnitude (ROMs) for initiatives as required\nAssist in rectifying issues and improving service in faltering/failing projects\nOther duties as assigned\nJob Requirements:\n10 years of enterprise data architecting & engineering experience\n10 years of experience leading and delivering business solutions that rely on data science, data warehousing, or Business Intelligence\n4 years of experience working with Security Authorization requirements, developing and enhancing the security risk posture, and analysis and reporting of IT security metrics.\nExperience implementing technical solutions in complex and heterogeneous environments, including the following:\nExperience developing, configuring, and delivering COTS data solutions in support of enterprise security solutions\nExperience leading integration planning activities of multiple U.S. Government Agencies\nExperience leading multi-organizational and matrixed technical resources and teams in accordance with approved integration plans and TO terms and conditions.\nStrong understanding of the core principles of data science and machine learning\nAbility to analyze, summarize and characterize large or small data sets with varying degrees of fidelity or quality; able to identify and explain any insights or patterns within them\nSolid experience applying one or more of the following analytical methods\nStrong understanding of and experience with advanced statistical theoretical knowledge\nSolid experience in exploratory data analysis and visualization\nExperience collaborating with Agencies to mature operational processes, reduce redundancies, and develop innovative solutions\nExperience understanding organizational needs, proposing solutions, and managing project execution efforts designed to deliver overall program benefits for Government Agencies\nExperience collaborating with US Government Agencies, state or local governments, or commercial entities to develop IT service program maturity in accordance with Federal IT mandates and best practices\nStrong experience in ensuring customer satisfaction, problem resolution, and risk management on several medium to large projects\nExperience in conducting assessments at an Enterprise by reviewing technical documentations, conducting interviews and workshops to identify gaps and developing a tailored solution is highly desired\nGeneral scripting experience\nExperience with Python\nExperience with BI and visualization tools\nMust be a US citizen\nBachelors degree in related field\nAble to obtain DHS Public Trust/ Suitability\nAble to obtain possess a TS security clearance and be SCI eligible.\nISC2 CISSP is preferred\nSecurity Clearance:\nUS Citizenship is required, due to the security requirements of our client. Individuals with dual citizenship may not be considered for this role.\nCandidates with active clearance will be given preference.\nPhysical Requirements:\nOffice work, typically sedentary with some movement around the office.\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\n\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.\nApply Now: click Apply Now"}, "80": {"company": "Extra Space", "description": "At Extra Space Storage, if it matters to you, it matters to us!\n\nIt is a really exciting time to be at Extra Space Storage! We got our start in 1977. Today we are a New York Stock Exchange-traded company leading the self-storage industry in more ways than one. But in order to maintain this lead, we need exceptionally motivated, capable, and driven people like you. We offer a fast-paced collaborative environment where each of us directly contributes to the company\u2019s success. Come join us and find out why Glassdoor recognized Extra Space Storage as one of the top 100 places to work in 2018!\n\nWe are currently seeking a BI Engineer at our corporate offices located in Salt Lake City, Utah. In this role, you will be an individual contributor on a team of Data Engineers, reporting to a Data Management Manager.\n\nIn this specific position, you\u2019ll work on developing new ETL process for our DWH and maintaining existing ETL processes in SSIS and SQL scripts. Additionally, you will be working on data integrations between systems.\n\nEssential Duties and Responsibilities:\nDevelop and Maintain ETL processes for DWH\nAbility and motivation to learn new technologies quickly with minimal support and guidance\nEffective communicator, positive attitude, a dedicated team player\nCollaborates with other BI engineers and managers, technical leads, and other departments to ensure successful delivery of BI projects\nSkills/Experience:\nStrong T-SQL programming\nMicrosoft BI tools a plus (SSIS, SSAS)\nQuery performance optimization is a plus\nExperience with Kimball modeling is a plus\nAzure Experience is a plus\nBachelor\u2019s degree in computer science or related field, or equivalent work experience\nEffective communicator, positive attitude, a dedicated team player\nWe pride ourselves on hiring top talent and provide the following benefits and more:\nWell defined career paths\nQualify for Medical, Dental, and Vision benefits on Day 1\nHealth Savings Account (HSA) or Flexible Spending (FSA)\nCompany paid Life, AD&D, and Short & Long Term Disability\n401K with company match after 90 days of service\nHoliday pay and paid time off\nExtensive Wellness Program and various Employee Discount Programs\nPersonal Health Advocate\nOnsite Fitness Center\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\nIf you are a current Extra Space employee, please apply through the \\\"Find Internal Career Openings\\\" in Workday.\nTo apply to this job, click Apply Now"}, "81": {"company": "Strategic Financial Solutions", "description": "Do you love numbers and finding the story in the numbers? Does the thought of tackling a complex data issue make you smile? Have you got a knack for solving problems? Do you want to help drive the results of a multi-million dollar business? If you have answered \"yes\" to these questions, the Data Scientist position at Strategic Financial Solutions may be the right fit for you.\nStrategic is looking for an experienced Data Scientist with statistical and machine learning experience to join our Data Science Team, which produces models for prescriptive and predictive analytics. The person in this role would be responsible for conducting data analysis and developing predictive models by leveraging data science and machine learning to solve various business use cases, including marketing intelligence, customer segmentation, and predictive models for operations.\nThis is a great opportunity for someone who wants to learn all aspects of business as he/she will support our product, sales, leadership and marketing teams with insights gained from analyzing company and external data.\nCandidates must have strong experience in a variety of data manipulation tools, data analysis/ mining methods to build and implement models and should be able to develop algorithms and simulation methods. A successful candidate will have the proven ability to drive business results with their data-based insights.\nResponsibilities\nResearch and develop statistical and machine learning methodologies to solve complicated business problems\nWork with stakeholders to identify opportunities by leveraging large data sets to drive business decisions. Collaborate with sales, marketing and senior executive teams for model development\nStrong communication skills and ability to clearly present ideas and technical findings to key decision makers\nQualifications\nKnowledge of statistical and machine learning techniques in regressions and classifications such as generalized linear models, classification trees, Random Forest, XGBoost, SVMs etc. Industry experience in such areas a definite plus.\nKnowledge of stochastic process in terms of transaction matrix and equilibrium distribution, etc.\nExperience in R, Python, and SQL, etc. and in variable selection and dimension reduction skills such as LASSO and PCA\nStrong problem-solving skills with an emphasis on financial risk management in sales and marketing predictive analytics\nUnsupervised learning experience such as k-means, hierarchical clustering, Bayesian network etc.\nExcellent written and verbal communication skills for coordinating across teams\nGraduate degree in Statistics, Data Science, Applied Math, Operations Research, Computer Science or other areas in STEM. Exceptional candidates with undergraduate degree will be also be seriously considered.\nAbout Strategic:\nStrategic Financial Solutions is a leading consumer finance company that specializes in helping people that have too much credit card debt. We were recently named the 21st Best Company to Work for in New York by Best Companies to Work For and have been certified as a Great Place to Work 4 times. Additional honors include being named, two times, as one of the 50 fastest growing companies in New York City and to the prestigious Inc. 500 list as one of the 500 fastest growing companies in the United States.\nApply Now: click Easy Apply"}, "82": {"company": "2nd Watch, Inc.", "description": "Who is 2nd Watch?\n\n2nd Watch is an AWS Premier Partner, a Microsoft Azure Gold Partner, and a recognized leader among Managed Service Providers (MSPs), providing professional and managed cloud services to enterprises. The company's subject matter experts and software-enabled services provide companies with tested, proven, and trusted solutions with a focus on five solution areas: Enterprise Cloud Migration, Security and Compliance, Cloud Native and DevOps, Optimization, and Managed Services. 2nd Watch is a new breed of partner which tailors solutions for enterprises, including design, deploy and managed cloud solutions. 2nd Watch has more than 400 enterprise workloads under its management and more than 200,000 instances in its managed public cloud. The venture-backed company is headquartered in Seattle, Washington. To learn more about 2nd Watch, visit www.2ndwatch.com or call 888-317-7920.\n\nWhy 2nd Watch?\n\n2nd Watch is in growth mode, and we are looking to build out our existing teams this year. From Managed Cloud Services to Cloud Consulting, Operations, Application Development, DevOps, Automation, Product Development, and everything in betweenwe are looking for superstars. Our teams are setting industry-level standards around cloud product management and delivery, and we are looking for like-minded, focused candidates to join us. We're building our team with talented and passionate Cloud Consultants who will have the opportunity to help shape and deliver on a broad use of the cloud's utility computing web resources.\n\nWhere you fit:\n\n2nd Watch has a unique company culture and working environment that live and breathe success and promote pushing the envelope every day in your respective role at the company. This is what drives our teams. Getting our attention takes creativity, ingenuity, a desire to improve each day, and a track record of caring about who you are affecting both positively and negatively while you are getting the right stuff done.\n\nWe are looking for a the most technically forward-thinking, Cloud-Passionate employees in the world and work daily to align our core values with those that we hire - Fearlessness, Tenacity, Humility, Customer Focus, Empowering One Another, Working Together, Winning as a Team, Honesty, Transparency, Having FUN these are all key elements to who we hire.\n\nPosition Title:\n\nOptimization Data Analyst\n\n2nd Watch has an opening for an Optimization Data Analyst (ODA) to join our team! Located in Liberty Lake, Washington the Optimization Data Analyst will be responsible for analyzing cloud based customer usage patterns for trends and variances which support overall optimization of customer spend. Additionally, the ODA will provide meaningful insights to internal business units in support of customer facing value propositions and developing internal efficiencies. The ODA will also assist in developing our Enterprise Data Lake (EDL)which supports actionable intelligence to internal business units and our customers.\n\nScope and Accountability\nWorks collaboratively as a member of the 2nd Watch team to manage data flows from a variety of systems into the EDL. Leverages data warehousing concepts to develop efficient processes to manage large amounts of data monthly.\nCollaborates with member of the Product Development team to design, build and optimize reporting solutions using cloud native technologies such as Redshift.\nCollaborates with the account managers to assist in providing cost optimization recommendations for clients as requested by account managers and as part of the Optimization Team.\nCollaborates with sales teams to provide analytics and business value cases for products related to cost optimization and future product features targeted at Cloud provider billing file consumption or utilization KPI's.\nCollaborates with cross functional stakeholders on monthly dashboards, reports, Financial and Margin analytics, including margin and profitability by client.\nDesired Skills and Experience\nAdvanced skills in data modeling, analytics and scenario management.\nAbility to work with customers to understand current and emerging needs and translate into product requirements.\nFamiliar with Cloud Technologies.\nExpertise in managing large data sets with the ability to provide actionable insights through analytics and business needs.\nAbility to translate complex analytics into consumable intelligence for varying level of end-users\nThe ideal candidate will possess:\nHoned analytical skills and highly developed communication skills\n5+ years experience in developing and presenting financial based recommendations such as ROI and maximizing constrained resources.\nDemonstrated ability in variance analysis\nAdvanced skills with Pivot Tables\nSkills in understanding and implementing data warehousing concepts\nOutstanding oral and written communication skills, problem solving and analytical skills\nDemonstrated ability to learn new and complex technologies so that concepts can be communicated at all levels of the organization\nExperience in data visualization tools such as Power BI strongly desired.\n3+ years in data modeling, data warehousing overall data management.\nBenefits and Perks:\n\nBeyond an amazing, collaborative work environment, great people and inspiring, innovative work, we have some great benefits and perks:\nCompetitive salaries and all employees are bonus eligible\n401(k) with company stock plans to all employees\n100% paid medical, dental and vision coverage for all employees and 90% paid for family, along with other wellness and disability plans\nNo limit / regulation on Paid Time Off We let you manage yourself.\nCatered lunches, fully stocked kitchens, focus on Philanthropy and giving back to the communities we support\nStart your job application: click Easy Apply"}, "83": {"company": "TransUnion", "description": "What We'll Bring:\n\nWhat We'll Bring:\n\nAt TransUnion, we have a welcoming and energetic environment that encourages collaboration and innovation \u2013 we\u2019re consistently exploring new technologies and tools to be agile. This environment gives our people the opportunity to hone current skills and build new capabilities, while discovering their genius.\n\nCome be a part of our team \u2013 you\u2019ll work with great people, pioneering products and cutting-edge technology\n\nWhat You'll Bring:\nYou come in with 1-2 years of academic or professional analytical or modeling experience with solid knowledge of statistical methods such as GLM and machine learning techniques such as random forest, GBM, XGBoost, etc.\nAdvanced proficiency with one or more statistical programming languages such as R, Python, or H2O\nIntellectual curiosity and experience writing intermediate or advanced SQL queries for data extraction\nAbility to clearly articulate ideas to both technical and non-technical audiences\nYour strong project management and time management skills including the ability to prioritize and contribute to multiple assignments simultaneously, setting clear goals, and managing customer expectations\nYou have an advanced degree in fields of quantitative discipline such as Statistics, Analytics, or any STEM field\nWhat we love to see:\nPrior Marketing Analytics experience\nStrong data visualization skills\nExperience working with large data sets and tools such as Hive, Pig, Apache Spark, etc.\nImpact You'll Make:\n\nImpact You'll Make:\nParticipate in insurance analytics tool development projects\nCollaborate with internal and external partners to develop advanced analytical solutions for insurance marketing and retention\nContribute to projects involving descriptive, predictive, and prescriptive analysis leveraging a variety of techniques\nLead small projects and/ or work streams as a part of larger projects\nExtract insights from large data sets using languages such as R, SAS, SQL, and Python\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.\n\nTransUnion's Internal Job Title:\n\nAnalyst, Data Science and Analytics\nStart your job application: click Apply Now"}, "84": {"company": "Affinity Solutions", "description": "Data Scientist\nAffinity Solutions / Marketing Cloud seeks smart, curious, technically savvy candidates to join our cutting-edge data science team. We hire the best and brightest and give them the opportunity to work on industry-leading technologies.\nThe data sciences team at AFS/Marketing Cloud build models, machine learning algorithms that power all our ad-tech/mar-tech products at scale, develop methodology and tools to precisely and effectively measure market campaign effects, and research in-house and public data sources for consumer spend behavior insights. In this role, you'll have the opportunity to come up with new ideas and solutions that will lead to improvement of our ability to target the right audience, derive insights and provide better measurement methodology for marketing campaigns. You'll access our core data asset and machine learning infrastructure to power your ideas.\nDuties and Responsibilities\n\u00b7 Support all clients model building needs, including maintaining and improving current modeling/scoring methodology and processes,\n\u00b7 Provide innovative solutions to customized modeling/scoring/targeting with appropriate ML/statistical tools,\n\u00b7 Provide analytical/statistical support such as marketing test design, projection, campaign measurement, market insights to clients and stakeholders.\n\u00b7 Mine large consumer datasets in the cloud environment to support ad hoc business and statistical analysis,\n\u00b7 Develop and Improve automation capabilities to enable customized delivery of the analytical products to clients,\n\u00b7 Communicate the methodologies and the results to the management, clients and none technical stakeholders.\nBasic Qualifications\n\u00b7 Advanced degree in Statistics/Mathematics/Computer Science/Economics or other fields that requires advanced training in data analytics.\n\u00b7 Being able to apply basic statistical/ML concepts and reasoning to address and solve business problems such as targeting, test design, KPI projection and performance measurement.\n\u00b7 Entrepreneurial, highly self-motivated, collaborative, keen attention to detail, willingness and capable learn quickly, and ability to effectively prioritize and execute tasks in a high pressure environment.\n\u00b7 Being flexible to accept different task assignments and able to work on a tight time schedule.\n\u00b7 Excellent command of one or more programming languages; preferably Python, SAS or R\n\u00b7 Familiar with one of the database technologies such as PostgreSQL, MySQL, can write basic SQL queries\n\u00b7 Great communication skills (verbal, written and presentation)\nPreferred Qualifications\n\u00b7 Experience or exposure to large consumer and/or demographic data sets.\n\u00b7 Familiarity with data manipulation and cleaning routines and techniques.\nStart your job application: click Easy Apply"}, "85": {"company": "Ascension - The Resource Group", "description": "We Are Hiring\n\nData Analyst - Office Operations - Full-Time, Days - Chicago, IL\n\nWhy Join Ascension?\n\nThe Resource Group is a business transformation services organization that specializes in non-payroll spend management. Through its User-Directed Integrated Solutions, The Resource Group transforms the resource and supply function delivering value through Operations and Logistics Optimization, Strategic Sourcing, and Change Management. Although it specializes in these areas, as its core, The Resource Group is rooted in the ideals of hospitality and believes that success is measured by the satisfaction of the customer. The Resource Group started as a Solution of Ascension, its success has allowed it to expand and serve various healthcare systems looking to decrease non-payroll expenses and increase operational efficiencies. Today, The Resource Group serves over 2,500 locations including over 165 acute care hospitals across 21 states and Washington D.C.\n\nThe Resource Group is part of Ascension, a faith-based healthcare organization dedicated to transformation through innovation across the continuum of care. As one of the leading non-profit and Catholic health systems in the U.S., Ascension is committed to delivering compassionate, personalized care to all, especially to those most in need. In FY2018, Ascension provided nearly $2 billion in care of persons living in poverty and other community benefit programs.\n\nWhat You Will Do\n\nAs an Associate with The Resource Group, you will have the opportunity to collect and analyze data from multiple sources for the development of reports and statistical information.\n\nResponsibilities:\nCompiles analytical and statistical reports as needed.\nFormulates, defines and recommends scope and format of reports.\nOversees provision of ad hoc management reports.\nReviews information for accuracy and reconciles data on a regular basis.\nProvides support and education to staff on how to access reports and interpret the data.\nIdentifies data trends and makes recommendations for quality improvement.\nWhat You Will Need\n\nEducation:\nBachelor's degree required.\nEqual Employment Opportunity\nAscension is an EEO/AA employer: M/F/Disabled/Vet. For further information regarding your EEO rights, click on the following link to the \u201cEEO is the Law\u201d poster:\nhttp://www1.eeoc.gov/employers/upload/eeoc_self_print_poster.pdf\u201d\nPlease note that Ascension will make an offer of employment only to individuals who have applied for a position using our official application. Be on alert for possible fraudulent offers of employment. Ascension will not solicit money or banking information from applicants.\n\nE-Verify Statement\n\nAscension participates in the Electronic Employment Verification Program. Please click the E-Verify link below for more information.\n\nE-Verify (link to E-verify site)\n\n]]>\nStart your job application: click Apply Now"}, "86": {"company": "Ecolab", "description": "With annual sales of $15 billion, Ecolab (ECL) is the global leader in water, hygiene and energy technologies and services that protect people and vital resources. Our 49,000 associates help make the world cleaner, safer and healthier by delivering critical insights and innovative solutions to help our customers achieve clean water, safe food, abundant energy and healthy environments at nearly three million customer locations in more than 170 countries.\n\nOur innovative products and services touch virtually every aspect of daily life and are used in hospitals, hotels, restaurants, schools, manufacturing plants, refineries and other locations throughout the world. Many of the worlds most recognizable brands rely on Ecolab to help ensure operational efficiencies, product integrity and brand reputation.\n\nWhen you come to work at Ecolab, you get to take on some of the worlds most meaningful challenges and have the opportunity to learn and grow, shape your career, make an impact and quickly see the importance of your work.\n\nFor more Ecolab news and information, visit www.ecolab.com. Follow us on Twitter @ecolab, Facebook at facebook.com/ecolab, LinkedIn at Ecolab or Instagram at Ecolab Inc.\n\nEcolabs Nalco Water division is seeking a business focused Data Scientist to unlock the value in data assets while creating new and unique offerings for customers in the industrial segment. In this role, you will work with the business innovation teams, marketing, sales and customers along with expertise from Ecolabs Center for Advanced Analytics, to help develop the data strategy and advanced analytics pipeline for the business.\n\nWhat you will do\nActively engage with internal business teams to understand industrial challenges and deliver robust, data driven solutions.\nWork alongside global counterparts to solve data-intensive problems using standard analytical frameworks and tools.\nBe encouraged and expected to innovate and be creative in your data analysis, problem solving and presentation of solutions.\nNetwork and collaborate with a broad range of internal business units to define and deliver joint solutions.\nWork alongside customers to leverage cutting edge technology (machine learning, streaming analytics and real big data) to creatively solve problems and disrupt existing business models.\nWhats in it for you\nA problem-solving mindset with the ability to understand business challenges and how to apply your analytics expertise to solve them.\nThe unique person who can present complex mathematical solutions in a simple manner that most will understand including customers.\nAn individual excited by innovation and new technology and eager to finds ways to employ these innovations in practice.\nA team mentality empowered by the ability to work with a diverse set of individuals.\nMinimum Qualifications\nA Bachelors degree in Data Science, Math, Statistics, Computer Science or related field with an emphasis on analytics.\n6+ Years professional experience in a data scientist/analyst role\nProficiency in your statistics/analytics/visualization tool of choice, but preferably in the Microsoft Azure Suite, including Azure ML Studio and PowerBI as well as Python and SQL.\nPreferred Qualifications\nExcellent communication, organizational transformation, and leadership skills\nDemonstrated excellence in Data Science, Business Analytics and Engineering\nOur Commitment to Diversity and Inclusion\n\nAt Ecolab, we believe the best teams are diverse and inclusive, and we are on a journey to create a workplace where every associate can grow and achieve their best. We are committed to fair and equal treatment of associates and applicants. We recruit, hire, promote, transfer and provide opportunities for advancement on the basis of individual qualifications and job performance. In all matters affecting employment, compensation, benefits, working conditions, and opportunities for advancement, we will not discriminate against any associate or applicant for employment because of race, religion, color, creed, national origin, citizenship status, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran.\n\nIn addition, we are committed to furthering the principles of Equal Employment Opportunity (EEO) through Affirmative Action (AA). Our goal is to fully utilize minority, female, disabled and covered veteran individuals at all levels of the workforce. Ecolab is a place where you can grow your career, own your future and impact what matters.\n\nWe will consider for employment all qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles Fair Chance Initiative for Hiring Ordinance and the San Francisco Fair Chance Ordinance.\nTo apply to this job, click Apply Now"}, "87": {"company": "ExtraHop Networks, Inc.", "description": "Would you like to be part of a company where the machine learning is at the core of its product offerings? Do you want to build (not analyze, support or A/B test) machine learning based product features from scratch? Are you interested in applying machine learning to a dataset that no other company in the world has? Can you innovate in a greenfield machine learning application environment that has rarely been researched in academia? Then come and join a collaborative team that builds solutions which provide deep performance insights, behavioral security analyses, and drives business analytics.\n\nAre you looking to make an impact? Do you love seeing your work implemented and hearing how your contributions have made a difference? ExtraHop offers an exciting, high energy, and versatile environment in which people are encouraged and supported to collaborate on industry-leading technology while they develop and enrich their individual growth. And we're doing it with creativity, intellectual curiosity, and a sense of humor (it's required here, seriously).\n\nThe ExtraHop platform is a novel approach to processing vast amounts of wire data in real-time. It provides unparalleled visibility into every transaction and behavior for every single entity within an enterprise network. This complete visibility allows our customers to proactively detect and remediate IT performance issues and cyber attacks in real time. As part of the data science team, you will be responsible for end-to-end delivery and operation of all machine learning capabilities across ExtraHop products.\n\nThe Role\nInnovate and build new attack detection and analytic capabilities using machine learning on the ExtraHop platform\nCollaborate with software engineers and own the end-to-end development of machine learning features and capabilities (from ideation to productionization)\nIdentify and engineer new features with our networking subject matter experts\nInspire and educate our user interaction designers to incorporate model results and analysis into user workflows\nLearn from threat researchers and become an expert in network attack scenarios and encode domain expertise into algorithms and models\nTypical successful candidates have;\nBachelor\u2019s, Master\u2019s or Phd degree or equivalent experience in computer science, engineering, mathematics/statistics or other quantitative fields\nFive or more years of professional experience and/or equivalent combination of education and experience\nProficient at programming in Python or other high level languages\nKnowledge of basic computer science data structures and algorithms\nA deep understanding of the theory behind machine learning models such as generalized linear models, classification, clustering, ensemble learning, time series analysis, graphical analysis, neural networks, etc.\nWillingness to learn complex topics in cyberattacks and network monitoring\nYou make the bonus round if you have:\nExperience in applying machine learning or statistical modeling to solve real world problems\nExperience in building end-to-end machine learning systems\nAn understanding of network protocols including IP, TCP, UDP, DNS, and HTTP\nKnowledge of building scalable and high-performance systems\nAn understanding of various product-development life cycles\nABOUT EXTRAHOP\n\nExtraHop is an enterprise cyber analytics and performance monitoring company helping the world\u2019s leading organizations understand and secure their entire environment from core to edge to cloud. Our breakthrough approach to analytics and machine learning helps our customers investigate threats, ensure the delivery of critical applications, and secure their investment in the cloud, resulting in 95% faster threat detection and reducing unplanned downtime by 86% while providing the best possible customer experience.\n\nExtraHop is recognized by leading organizations for both its innovation in the market and its commitment to building a world-class team. We\u2019ve been named to Wealthfront\u2019s Career-Launching Companies list for the last four years, and JMP Securities put ExtraHop on its 2018 Super 70 List as one of the most strategically positioned private companies in the cybersecurity industry. Credit Suisse recognized ExtraHop as a member of its inaugural Disruptive Technology Recognition Program, and SC Media named ExtraHop a 2019 Industry Innovator for enterprise network traffic analysis.\n\nWith well over $100 million in bookings in 2018, and 10x growth in security, the opportunity with ExtraHop has never been greater. Are you ready to rise above the noise?\n\nExtraHop is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, disability, military status, or national origin or any other characteristic protected under federal, state, or applicable local law.\n#LI-BKW\nApply Now: click Apply Now"}, "88": {"company": "Frontier Technology Inc.", "description": "FTI is currently looking for a full time Associate Data Scientist to support the Naval Safety Center in Norfolk VA. The Associate Data Scientist will be working with a diverse program team comprised of FTI team members as well as active duty and Government civilian employees to produce a series of predictive analytics models that will help diagnose and predict precursors to Naval mishaps.\n\nApply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to develop a series of predictive analytics models. Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data. Generate and test hypotheses and analyze and interpret the results of product experiments.\n\nEntry-level professional within field. Requires basic skill set and proficiency. Conducts work assignments as directed. Closely supervised with little latitude for independent judgment. Typically requires a bachelor's degree in Mathematics, Business Analytics, or Computer Science (or international equivalent) and 0-3 years of relevant experience.\nTo apply to this job, click Apply Now"}, "89": {"company": "iModules", "description": "Summary:\n\nThe Data Scientist is responsible for collaborating with and supporting our product, sales, leadership, and marketing teams with insights gained from analyzing data from multiple sources. The Data Scientist will build and deploy predictive modeling, using a variety of methods, algorithms, and technical tools. Additionally, the Data Scientist will use internal and institutional data to find opportunities for product and process optimization and test the effectiveness of different courses of action. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\nResponsibilities:\n\n\u00b7 Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes\n\n\u00b7 Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions\n\n\u00b7 Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies\n\n\u00b7 Assess the effectiveness and accuracy of new data sources and data gathering techniques.\n\n\u00b7 Develop custom data models and algorithms to apply to data sets\n\n\u00b7 Coordinate with different functional teams to implement models and monitor outcomes\n\n\u00b7 Develop processes and tools to monitor and analyze model performance and data accuracy\n\n\u00b7 Share and present findings effectively and creatively to internal teams and to our member campuses.\n\n\u00b7 Other duties as assigned\n\nEducation:\n\n\u00b7 BS/MS/PhD in in a STEM field with a deep understanding of mathematics, statistics, and computer science\n\nQualifications/Experience:\n\n\u00b7 Experience using statistical computer languages (e.g., R [required], Python) to clean, shape, and draw insights from large data sets\n\n\u00b7 Experience creating, deploying, and maintaining predictive models\n\n\u00b7 Experience using a variety of machine learning techniques (e.g., clustering, decision tree learning, artificial neural networks, random forest, etc.)\n\n\u00b7 Experience visualizing, reporting, and presenting data for stakeholders\n\n\u00b7 Experience leveraging the Microsoft Azure development stack for scaling solutions, preferred\n\n\u00b7 Completion of data science certificate or certification, preferred\n\n\u00b7 Experience querying relational databases using SQL, preferred\n\n\u00b7 Experience working in higher education, preferred\n\n\u00b7 Experience working with Big Data technologies, preferred\n\nSkills/Competencies:\n\n\u00b7 Curiosity\n\n\u00b7 Attention to detail\n\n\u00b7 Strong problem-solving skills\n\n\u00b7 Knowledge of statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications\n\n\u00b7 Ability to learn new techniques and tools as needed. A self-starter, always exploring ways to improve yourself and your work\n\n\u00b7 Ability to meet deadlines and detail oriented\n\n\u00b7 Ability to understand stakeholder needs and explain complex concepts\n\n\u00b7 Excellent written and verbal communication skills for coordinating across teams\n\nA commitment to Equal Opportunity Employer/Affirmative Action Employer\n\nWe are committed to creating and maintaining a workplace in which all of our employees have an opportunity to participate in and contribute to the success of the business.We are dedicated to providing every Campus Labs employee with the best possible employment experience regardless of their race, national origin, sex, sexual orientation, socioeconomic status, familial status, religion, age, disability, gender identity, gender expression, results of genetic testing/genetic information, service in the military, veteran status, or any other status protected by federal, state, or local laws.Diverse candidates are strongly encouraged to apply.We highly value the many identities, perspectives, and experiences of all of our employees.\nStart your job application: click Apply Now"}, "90": {"company": "Enterprise Holdings", "description": "About the Role\n\nThe Center of Excellence for Data and Analytics (CEDA) Senior Data Scientist leads initiatives using advanced analytics expertise to understand internal and external customers' strategic business objectives, relate those objectives to measurable indicators and focus on delivering analytic products and services to create new insights and strategies promoting continuous performance improvements for the company. The CEDA Senior Data Scientist acts as a resource and mentor for less experienced Data Scientists and applies expert analytics to create efficiencies and improve the decision making process for internal business units by developing and implementing advanced statistical and mathematical solutions.\n\nCompany Overview\nEnterprise Holdings is the largest car rental provider in the world as measured by revenue and fleet. The company and its affiliate Enterprise Fleet Management which combined offer a total transportation solution that includes extensive car rental and car-sharing services, truck rental, corporate fleet management and retail car sales accounted for $24.1 billion in revenue and operated 2 million vehicles throughout the world in 2018. Enterprise Holdings annual revenues also place it near the top of the global travel industry, exceeding all other rental car companies, many airlines, and most cruise lines, hotels, tour operators and online travel agencies. Enterprise Holdings regional subsidiaries and Enterprise Fleet Management currently employ more than 100,000 people worldwide.\n\nThrough its integrated global network of independent regional subsidiaries and franchises, Enterprise Holdings operates the Enterprise Rent-A-Car, National Car Rental and Alamo Rent A Car brands at more than 10,000 fully staffed neighborhood and airport locations. The Enterprise Holdings global network operates in more than 90 countries and territories, including North America, Central America, South America, the Caribbean and Europe, as well as parts of Asia-Pacific and the Middle East. Today, the companys three brands serve more than 95 percent of the worldwide car rental market.\n\nThis position is located at our Corporate Headquarters in Clayton, MO.\n\nResponsibilities:\nLead the design and delivery of end-to-end analytical solutions that address the business needs\nExtract, clean, and manipulate both structured and unstructured datasets\nPerform exploratory data analysis, generate hypotheses, and extract actionable insights\nDevelop statistical and/or mathematical models that are put in production\nDeliver detailed documentation including descriptions of efforts, results, insights and recommendations\nPresent findings and recommendations to other CEDA members and various levels of management\nPartner with the other CEDA teams to ensure solutions are delivered successfully\nProvide technical guidance and mentoring to other Data Scientists\nIdentify and offer strategies to link the team's analytical activities with business goals and objectives\nAdditional Responsibilities\nSeek to improve job performance through self-assessment, skill development, training and goal setting\nMaintain a regular and reliable level of attendance and punctuality\nPerform miscellaneous job-related duties as assigned\nEqual Opportunity Employer/Disability/Veterans\n\nQualifications:\n\nMinimum:\nMust have a Master's Degree or greater in Mathematics, Statistics, Operations Research, Physics, Engineering, Economics, Computer Science or a related quantitative field\nMust be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future\nMust have 4+ years experience data mining and developing statistical and/or mathematical models using R or CPLEX\nMust have 4+ years experience with SQL and/or Python programming or directly querying relational databases such as Teradata, SQL Server or Oracle\nCompetency Based:\nForward-Thinking\nResults-Oriented\nWorking With a Team\nProblem Solving\nCommunication\nApply Now: click Apply Now"}, "91": {"company": "h2o.ai", "description": "Company Overview\n\nH2O.ai is the open source leader in AI with a mission to democratize AI for everyone. H2O.ai is transforming the use of AI with software with its category-creating visionary open source machine learning platform, H2O. More than 18,000 companies use open-source H2O in mission-critical use cases for Finance, Insurance, Healthcare, Retail, Telco, Sales and Marketing. H2O Driverless AI uses \"AI to do AI\" in order to provide an easier, faster and cost-effective means of implementing data science. H2O.ai partners with leading technology companies such as NVIDIA, IBM, AWS, Intel, Microsoft Azure and Google Cloud Platform and is proud of its growing customer base which includes Capital One, Progressive Insurance, Comcast, Walgreens and MarketAxes. For more information and to learn more about how H2O.ai is driving an AI Transformation, visit www.h2o.ai.\n\nJob Summery:\nCan you learn demonstrations (demos) built with R and/or Python? If you think of a cool demo and it doesn't exist, will you raise your hand to get it built?\nCan you code proficiently in at least one language used by data scientists and/or data engineers, and does it excite you to learn more?\nAre you skilled at predictive modeling?\nDo you view communication skills just as important as technical ones? Can you listen to the needs of your peers and customers and adapt where need be? Can you write a technical proposal and explain it in simple terms?\nDo you have a competitive drive to be the best you can be?\nCan you finish what you start? Can you own assignments given to you?\nIf the answer is \"yes\" to these questions, you potentially could be an excellent fit to join the team of customer engineering makers at H2O.ai. We deliver world-class solution experiences for our customers and drive revenue for our organization. Some of the technical projects you will work on include: training advanced machine learning models at scale in distributed environments, influencing next generation data science tools and data products, and pioneering ideas and products in new areas, such as machine learning interpretability, automatic machine learning, model management, deployment pipelines, and GPU computing.\n\nQualifications and Skills:\n\nA great candidate for Customer Data Scientist/Sales Engineer should:\nKnow Python, R, Java, Scala, Spark.\nHave experience with Big Data including Hadoop, Spark, Kafka.\nHave a working knowledge of ML algorithms for Regression and Classification problems.\nUnderstanding of Supervised, Unsupervised, Deep learning techniques\nKnowledge of XGBoost, Linear regression, GBM, GLM, LightGBM, Random Forest and other common ML algorithms\nExperience using TensorFlow, Keras, Scikit libraries for performing ML .\nHave strong interpersonal, communication and presentation skills.\n2+ years' experience with performing customer facing activities as part of a pre-sales team or professional services team.\nPre-sales experience is nice to have but not required.\nComfortable with traveling up to 50%.\nWe are interested in candidates coming from AI/ ML startups and have several years of work experience after completing their MSc or PhD degrees.\n\nH2O.ai Perks!\nFlexible work hours and time off.\nH2O.ai is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.\nTo apply to this job, click Easy Apply"}, "92": {"company": "Liberty Mutual Insurance", "description": "Data Engineer/Senior Data Engineer\n\nAt Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as an Agile team within a Fortune 100 company, we are on the front edge of an IT transformation for how people work and deliver solutions.\n\nThis is a range posting. The actual internal level/grade will depend on the candidate's overall experience and skill level.\n\nGRM Information Management is actively searching for a highly productive member of a distributed, dynamic agile team to serve as a technical expert in analysis, design, coding, and testing innovative data warehouse reporting solutions and analytics. This position will support Claims within Business Data Solutions Engineering.\n\nJob Summary:\n\nData Engineer/Senior Data Engineer, you will work collaboratively on a geographically diverse agile team to develop and enhance complex systems and/or software from user stories and technical/architectural specifications. You will analyze complex technical system problems and create innovative solutions that exceed customer expectations.\n\nThis is a fast-paced environment providing rapid delivery for our business partners. You will be working in a highly collaborative environment that values speed and quality, with a strong desire to drive change and foster a positive work environment as we continue our agile transformation journey. You will have the opportunity to help lead this change with us as we grow this culture, mindset and capability.\nIn this role you will:\nWork in a dynamic and exciting agile environment with Scrum Masters, Product Owners, and team members to develop creative data-driven solutions with our ETL pipeline that meet business and technical initiatives\nImprove speed to market by focusing on current Claims data needs as well as building out the long-term strategic data solutions using SQL, Unix, Informatica and AWS, as well as other modern data technologies\nDemonstrate open minded and collaborative approach to creating innovative technical solutions\nAnalyze data and technical system problems to design and implement effective, flexible solutions\nHandle end-to-end development, including coding, testing, and debugging during each cycle\nDevelop automated tests for multiple scopes (Unit, System, Integration, Regression)\nMentor new and junior developers\nIdentify and recommend appropriate continuous improvement opportunities\nQualifications:\nBachelor's or Master's degree in technical or business discipline or equivalent experience, technical degree preferred\nGenerally, 3 - 5 years of professional experience\nExperience developing back end, database/warehouse technology solutions\nKnowledge of a variety of data platforms including DB2, Teradata, (Cloud based DB a plus)\nExperience with Unix, Informatica, SQL, and AWS (such as S3, Aurora, Athena)\nExtensive knowledge of IT concepts, strategies, methodologies.\nExperience working with agile methodologies (Scrum, Kanban, XP) and cross-functional teams (Product Owners, Scrum Masters, Developers, Test Engineers)\nVersed in diverse technologies and new technical architecture principles and concepts\nDemonstrates leadership and active pursuit of optimizing CI/CD process and tools, testing frameworks and practices\nMust be proactive, demonstrate initiative, and be a logical thinker\nMust be team oriented with strong collaboration, prioritization, and adaptability skills required\nAdditional Qualifications:\nJava, Ruby, NoSQL, Python development experience\nUnderstanding of Cloud / Hybrid data architecture concepts\nUnderstanding of insurance industry and products\nExcited by trying new technology and learning new tools\nBenefits:\n\nWe value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits\nOverview:\nAt Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.\n\nWe're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.\nStart your job application: click Apply Now"}, "93": {"company": "SageGlass", "description": "Position description\n\nSAGE is all about its people, its products and its company culture. The vision of the company is to deliver a durable, reliable and high-performance energy-saving electrochromic product for buildings and to provide a healthier indoor environment for their occupants. Its award winning electronically tintable glass solution is second-to-none and recognized by Green Building, Inc. as one of the top ten green building products available on the market place.\n\nSageGlass R&D group works with customers, Saint-Gobain R&D team, and manufacturing colleagues to develop next generation products and process for Sage electrochromic glass. You will join our new data analytics team and drive the change through the creation of innovative data analytics algorithm/software and data-driven services. You will be responsible for working with customers and SageGlass R&D and engineering team to identify opportunities for data analytics.\n\nResponsibilities Include:\nBuild infrastructure required for optimal Extraction, Transformation, and Loading (ETL) of data from a wide variety of data sources;\nIdentify, design, and implement data processing improvement: automating manual processes and optimizing data delivery, re-designing infrastructure for greater efficiency and scalability;\nDesign, implement and test data analytics algorithms: filtering, modeling, classification, and etc.;\nData visualization: build user interfaces per design specifications\nPerform debugging, troubleshooting, modifications and unit testing of integration solutions;\nDocumentation and Reporting\n\nREQUIRED QUALIFICATIONS\n\nMinimum Qualifications:\nB.S. with 2+ years of experience in Computer Science, Computer Engineering, Data Engineering, Data Science, Informatics, or Engineering related fields OR M.S. with 0+ years of experience in Computer Science, Computer Engineering, Data Engineering, Data Science, Informatics, or Engineering related fields\nCompetencies Required:\nGood communication skills in English, both written and oral;\nPassionate, self-driven team player with \"can-do\" attitude;\nWork in an agile environment accountable to deliver results;\nInterpersonal skills with the ability to work effectively in a cross functional team\nTools & Technicques:\nStrong experience with Python and SQL use for developing custom ETL solutions\nExperience with advanced signal/image processing and optimization algorithm development\nExperience working with revision control systems (Git, etc.)\nUnderstanding of machine learning, deep learning and cloud-based platform\n\nAdditional description\n\nPerks, Benefits and Compensation:\n\nWe know that talented people are attracted to companies with an amazing culture, competitive pay, comprehensive benefits and outstanding career advancement opportunities. If hired you can expect;\nStrong Compensation & Bonus Plan\nFull Medical benefits\nDental\nVision\n401K\nPaid Time Off\nOutstanding Culture!\n\nWho are we ?\n\nSageGlass\u00ae is the pioneer of the world\u2019s smartest electrochromic glass and is transforming the indoor experience for people by connecting the built and natural environments. Electronically tintable SageGlass controls sunlight to optimize daylight, outdoor views and comfort while preventing glare, fading and overheating without the need for blinds or shades. SageGlass dramatically reduces energy demand and the need for HVAC by blocking up to 91 percent of solar heat. As a wholly owned subsidiary of Saint-Gobain, SageGlass is backed by more than 350 years of building science expertise that only the world leader in sustainable environments can provide.\n\nSaint-Gobain provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Saint-Gobain is an equal opportunity employer of individuals with disabilities and supports the hiring of veterans.\n\n\n\n\n<h4>\nApply Now: click Apply Now"}, "94": {"company": "S&P GLOBAL MARKET INTELLIGENCE", "description": "Data Scientist Job Description\n\nThe Senior Data Scientist will be a part of the S&P Global Market Intelligence (SPGMI) Data Science team.\n\nThe Role:\n\n\u2022 Discover insights and identify opportunities through the use of statistics, algorithms, data mining and visualization techniques\n\u2022 Build and evaluate models, make predictions, gather results, and communicate findings to stakeholders\n\u2022 Evaluate the big picture and solve problems rather than looking at metrics alone\n\u2022 Use advanced business knowledge and advanced machine learning techniques to acquire, combine & transform multiple dataset to solve a business use case\n\u2022 Collaborate with engineering and product teams to create and build strategic models that drive product improvements while maintaining cost efficiency\n\u2022 Build and maintain re-usable machine learning and model validation procedures for the rest of the team to use\n\nExperience and qualifications:\n\n\u2022 Bachelors Degree in Mathematics, Statistics, Computer Science, Engineering, Operations Research or related fields preferred (Masters degree an advantage)\n\n\u2022 5+ years practical experience with statistical analysis and creating complex models, preferably in the financial services sector\n\n\u2022 Excellent analytical and problem solving skills\n\n\u2022 Advanced experience in at least one data analysis/data transformation package (R, Python, Alteryx)\n\n\u2022 Exposure to one or more data discovery, data visualization tools\n\n\u2022 5+ years of hypothesis testing, web analytics and python scripting\n\n\u2022 Experience with Machine Learning and Natural Language Processing\n\n\u2022 Ability to remain focused and to think logically in a fast-paced environment\n\n(NICE TO HAVE)\n\n* experience with nlp\n\n* exposure to reinforcement learning\n\n* exposure to information retrieval (search)\nStart your job application: click Apply Now"}, "95": {"company": "Master Electronics", "description": "Master Electronics has an exciting career opportunity for aData Scientist that will report to the Vice President of Data Science in Phoenix, AZ. The position involves modeling complex business problems, uncovering insights, and identifying growth opportunities using data science, machine learning, artificial intelligence, data mining, visualization, and statistical analysis. Candidates will collaborate with cross functional teams and external partners to discover and model operational efficiencies that will enable Master Electronics to better serve its customers.\n\nCandidates should be able to effectively answer a wide variety of high business impact questions, while presenting key data science and quantitative insights in a concise and effective manner to a variety of audiences. The candidate must have a high degree of creativity and independence, using a variety of data science algorithms, integrating a wide number of structured and non-structure data sources, with significant Python software development skills, to model and simulate effective solutions to challenging business issues.\n\nHow you will spend your time:\nEffectively partner with teams to build prediction models to forecast sales, product demand and performance\nBuild or select the correct algorithms to model customer behavior, purchases, and recommendation systems\nUse predictive analytics, machine learning, and artificial intelligence to solve complex business problems\nUse descriptive analytics to create reports, dashboards, and pivots to quantify historical performance\nIndependently solve analytical problems, effectively communicating results to non-technical audiences\nWe\u2019re excited if you have:\nUndergraduate degree from an accredited university in data science, supply chain management, computer science, mathematics/physics, machine learning, operations research, applied to business decision making\n3+ years professional experience in modeling and statistical analysis of large (3+ terabytes) data sets\n3+ years of experience working using AWS SageMaker, Microsoft SQL Server and Microsoft Power BI\nTrack record working in large (3+ terabytes) scale databases, data marts, and data warehouses\nProven Python 3 experience developing data science models using Machine Learning and AI\n\nWe would prefer you have:\nGraduate degree from an accredited university in data science, supply chain management, computer science, mathematics/physics, machine learning, operations research, applied to business decision making\nTrack record leading and delivering on the design and execution of data science projects\nExperience in several of the following areas: statistics, machine learning, recommendation systems, and AI\nDeep Python 3 and SQL scripting skills; Functional knowledge of AWS platforms such as S3, Glue, Sagemaker\nAdvanced skills in Python, Machine Learning, AI, Statistical Modeling, SQL, Data Warehouses, and Hadoop\nExtensive Python experience using Sci-Kit, TensorFlow, Matplotlib, Numpy, Pandas, Seaborn, Beautiful Soup\nWhy Master Electronics:\n\nAs a customer focused and driven organization, we offer attractive, competitive compensation with an increase after the 1st and 2nd year of employment in the distribution center and benefits including, medical, dental, life, paid time off, 401k match and an EAP program as well as an opportunity to grow with the company.\n\nMaster Electronics has a fast-paced and entrepreneurial environment, which requires a professional, flexible self-starter attitude.\n\nHeadquartered in Phoenix, AZ, Master Electronics is a leading global authorized distributor of electronic components. For more than half a century, our family-owned company has remained focused on strong relationships, responsive service and added value. This is howMaster Electronics has grown to serve hundreds of thousands of customers in partnership with hundreds of world-class suppliers.\n\nMaster Electronics, a leading global authorized distributor of electronic components, is committed to providing equal employment opportunities for all applicants and employees. The Company does not unlawfully discriminate on the basis of race, color, creed, pregnancy, religion, sex, national origin, age, disability, veteran, marital, or any other protected status. The Company also makes reasonable accommodations for disabled employees. Finally,Master Electronics prohibits the harassment of any individual based on their protected status. This policy applies to all areas of employment, including recruitment, hiring, training, promotion, compensation, benefits, transfer, and social and recreational programs.\nApply Now: click Apply Now"}, "96": {"company": "Elanco", "description": "Interested in joining a cause-driven, customer focused company dedicated to positively impacting the health of animals, people and the planet? Search our job listings below.\n\nPosition Description:\n\nElanco Animal Health is a global research-based company that develops and markets products to improve the health and production of animals in more than 100 countries. Elanco products enhance animal health, wellness, welfare, and performance to help the food industry produce an abundant supply of safe and affordable food. Elanco Companion Animal is the source of product innovations that enable veterinarians to help pets live longer, healthier, higher quality lives.\n\nElanco External Manufacturing (EEM) is the virtual manufacturing plant for Elanco Animal Health. Therefore, contract manufacturers produce all EEM products. The purpose of this Technical Services / Manufacturing Science position is to provide technical support and oversight for established premix and nutritional products managed by the EEM-North America organization. A high level of mastery in premix and nutritional manufacturing technologies is required to drive productivity, gross margins, and to ensure a reliable supply of quality products through robust manufacturing processes.\n\nIn addition, EEM-NA TS/MS partners with Elanco operations/supply chain, quality, launch leaders, and R&D throughout the product life cycle. EEM-NA TS/MSs role in product support offers a wide variety of technical leadership, project assignments, and work experiences.\n\nFunctions, Duties, Tasks:\nProvide technical support to contract manufacturers through knowledge of premix and nutritional product manufacturing processes, regulatory requirements, and quality requirements.\nServe as primary technical resource for premix and nutritional manufacturing processes.\nWork with cross-functional groups to troubleshoot issues arising at CM sites, including but not limited to deviations and product remediation activities.\nMember of cross functional internal and external process team(s) responsible for the technical stewardship of the process(es)\nMaintain an appropriate presence during manufacturing.\nReview process and product data for adverse trends; assess and understand process capability.\nIdentify, evaluate, and implement process improvements/remediation with a focus on capability, compliance, and cost reduction.\nConduct/support process validation/qualifications.\nAuthor Product Quality Reviews.\nDevelop and maintain manufacturing process flow documents for products.\nUnderstand business needs to determine productivity opportunities for the products supported\nParticipate in the evaluation of new business opportunities thru due diligence, product reviews, and cost modeling.\nFacilitate the Manufacturability Review process.\nLead technical transfer, process implementation, and validation activities as needed.\nSupport launches in secondary markets, ensuring regulatory commitments are aligned with process capabilities.\nMinimum Qualification (education, experience and/or training, required certifications):\nAdvanced Science degree (Engineering, Chemistry, Biology, or Pharmacy) orBachelors of Science degree with relevant work experience with 10+ years of relevant pharmaceutical/animal health manufacturing experience in premix and nutritional manufacturing\nUnderstanding of cGMP requirements for drug substance and drug product manufacturing.\nStrong problem solving skills, including strategic and creative thinking.\nStrong interpersonal skills including flexibility and ability to engage with CM partners.\nClear, concise communication skills (both written and verbal)\nCross-functional networking skills: demonstrated ability to influence others.\nStrong analytical skills.\nAbility to handle multiple priorities and deal with ambiguity.\nComputer literacy.\nDemonstrated ability to achieve results with people\nScientific curiosity\nAdditional Preferences:\nKnowledge of statistical methods and applicable software.\nUnderstanding of analytical methods.\nWorking knowledge of Regulus.\nWorking knowledge of Trackwise.\nAbility to manage projects\nElanco is an EEO/Affirmative Action Employer and does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status\nApply Now: click Apply Now"}, "97": {"company": "Presbyterian Healthcare Services", "description": "Overview\n\n\nJob Description Type of Opportunity: Full Time FTE: 1.000000 Exempt: Yes Work Schedule: Days\n\nSummary:*Works to collaborate supporting the clinical development needs of staff, residency Fellowship, and student programs throughout the PHS enterprise by providing data management, reports, e learning, project coordination, application support, and research\n\nResponsibilities\n\n\nResponsibilities:Data Analyst: *Independently drives data gathering, reporting, organization, reporting and visual graphics of complex data to assist in identifying needs for target audience*Collaborates in the identification of target audience performance needs and gaps *Defines the performance gap objectives and partners with management to achieve agreement on approach to bridge the gap*Creates optimal, budget conscious tracking and reporting to achieve performance objectives*Incorporates evidence based data to structure instructional design for e learning and how to track and report performance on content*Drives the implementation of educational technology and applications in collaboration with management and team members*Builds the approach, deployment, collection, analysis and reporting of project effectiveness*Designs new programs to meet organizational strategic objectives*At the elbow support for Clinical Education team and those we support management, staff, nurse residents, fellows, clinical contractors, assigned vendors and studentsPerformance evaluator for Clinical Education scope of services and Nursing Residency/Fellowship Programs: *Assists CPDS and CPDS Residency teams to build and implement Levels 1 through 4 evaluation tools to measure satisfaction, learning, and transfer to performance based upon performance objectives*Partners with management to assess project performance gaps and build remediation action plansProject Coordination: *Role models and coaches in the moment *Role models highest specialty standards*Mentors others in best practice to enhance outcomes and performance*Independently lead projects assigned*Incorporates best practice standards in reporting to better inform management and leadershipConsultant / Collaborator: *Works and mentors team members within Clinical Education team to accelerate performance *Initiates and or supporting changes in practice through project tracking, e-learning development, educational technology, and applications*Work with CPDS on support for nursing, allied health, and nurse residency programs*May lead projects assigned by PDS Manager Clinical Education OperationsApplications:*Works and mentors team members within Clinical Education team to use e learning applications effectively and according to best practice*Works and mentors team members within Clinical Education team on web applications assigned to accelerate performanceResearcher: *Incorporates project coordination and e learning best practices and standards into work*Supports, builds, and initiates new projects to improve the performance and outcomes of Clinical Education*Stays up to date on best practices for data cleaning, data mining, and data visualization and reporting techniquesPromise and CARES Commitment:*Participates and role models the organizational mission, and vision within all of Presbyterian Healthcare ServicesSpecialty Role Focus:Applies skills and critical thinking related to area of assignment to gather, organize and report data, project coordination, computer based training, and other assignments assigned.\n\nQualifications\n\n\nAcademic Preparation:\n\n*Bachelors degree in healthcare operations, analytics, e-learning development/instructional design, business management, and/or information technology. 6 years of additional experience can be substituted in lieu of degree.Experience: Minimum at least 6 years of healthcare in healthcare operations, analytics, e learning development, academic coordination, and or information technology\n\nAbilities: (Physical, mental, environmental requirements/demands):\n\nAssumes and maintains various postural positions including but not limited to sitting, kneeling, reaching, squatting, climbing, bending/twisting neck and/or waist, lifting and carrying or pushing/pulling objects/equipment.\n\nOn occasion will need to work extended hours.\n\nBenefits\n\n\nBenefits Benefits are effective day-one (for .45 FTE and above) and include:\nCompetitive salaries\nFull medical, dental and vision insurance\nFlexible spending accounts (FSAs)\nFree wellness programs\nPaid time off (PTO)\nRetirement plans, including matching employer contributions\nContinuing education and career development opportunities\nLife insurance and short/long term disability programs\nAbout Us Presbyterian Healthcare Services is a locally owned, not-for-profit healthcare system of nine hospitals, a statewide health plan and a growing multi-specialty medical group. Founded in New Mexico in 1908, it is the state's largest private employer with approximately 11,000 employees.\n\nPresbyterian's story is really the story of the remarkable people who have chosen to work here. Starting with Reverend Cooper who began our journey in 1908, the hard work of thousands of physicians, employees, board members, and other volunteers brought Presbyterian from a tiny tuberculosis sanatorium to a statewide healthcare system, serving more than 700,000 New Mexicans. We are part of New Mexico's history - and committed to its future. That is why we will continue to work just as hard and care just as deeply to serve New Mexico for years to come. About New Mexico New Mexico's unique blend of Spanish, Mexican and Native American influences contribute to a culturally rich lifestyle. Add in Albuquerque's International Balloon Fiesta, Los Alamos' nuclear scientists, Roswell's visitors from outer space, and Santa Fe's artists, and you get an eclectic mix of people, places and experiences that make this state great. Cities in New Mexico are continually ranked among the nation's best places to work and live by Forbes magazine, Kiplinger's Personal Finance, and other corporate and government relocation managers like Worldwide ERC. New Mexico offers endless recreational opportunities to explore, and enjoy an active lifestyle. Venture off the beaten path, challenge your body in the elements, or open yourself up to the expansive sky. From hiking, golfing and biking to skiing, snowboarding and boating, it's all available among our beautiful wonders of the west. AA/EOE/VET/DISABLED. PHS is a drug-free and tobacco-free employer with smoke free campuses.\nTo apply to this job, click Apply Now"}, "98": {"company": "EBSCO Information Services", "description": "EBSCO Information Services (EIS) provides a complete and optimized research solution comprised of e-journals, e-books, and research databases \u2014 all combined with the most powerful discovery service to support the information needs and maximize the research experience of our end-users. Headquartered in Ipswich, MA, EIS employs more than 3,300 people worldwide. We are the leader in our field due to our cutting-edge technology, forward-thinking philosophy, and top-notch workforce. EIS, a division of EBSCO Industries Inc., based in Birmingham, AL, is ranked in the top 200 of the nation\u2019s largest, privately held corporations according to Forbes magazine. EBSCO is a company that will motivate you, inspire you, and allow you to grow. We are looking for the best. If you are too, we encourage you to explore our unique opportunities.\n\nMachine Learning Data Scientist\n\nMachine Learning plays a key role in the products, services and technologies EIS offers to our customers. We are looking for a talented ML Data Scientist that will be responsible for executing EIS\u2019s strategy to deliver new ML and AI capabilities to our products, and enhance the end-user experience, while augmenting our market presence and position. This exciting opportunity is a critical balance of communicating, driving and orchestrating the vision leading to real high value product and service outcomes. It includes developing the algorithms, applications, and platforms that will deliver positive change to our customers.\n\nIn this role you will:\nWork with cross-functional teams, have exposure and visibility to senior leaders, and be able to make significant technical and business impact\nStay up-to-date on the latest ML research (actively reading research papers, blogs, etc.) and ML-related development products and tools\nStart with the voice of the customer (VoC) and user from outside the company to the rest of our organization\nBe familiar with market research design thinking methodologies\nCultivate relationships across a broad set of business functions and business units\nThere are two primary work streams in the AIML group:\nTake a hands-on role architecting, coding, developing and deploying ML solutions to deliver a variety of high business value projects\nAct as a Consultant/Mentor; guiding, coaching and inspiring individuals from across the business such that they can architect, develop and deploy ML solutions\nPrimary Responsibilities of the ML Data Scientist:\nAnalyze and understand data; serve as an ML and data subject matter expert (SME) for EIS\nEngineer and code new ML offerings; i.e., training and test sets for new models targeting live client deploy through an enterprise deployment process normally based on arms-length integration through APIs into an AWS cloud environment\nWork closely with business and technical constituents to implement proposed solutions in a collaborative fashion\nPerform research that advances the state-of-the-art of ML\nIntroduce industry-leading or academic-based ideas and research to solve complex questions or fuel new business opportunities; design and own ML solutions to complex non-standard problems\nTake the initiative to use ML to solve non-obvious business problems outside of current assignment\nBuild prototypes to explore applying ML solutions to EIS opportunities\nContinuously improve high value business targets through experimentation while iterating on existing ML models\nCollaborate effectively with leaders up, down and across the organization in an open, transparent and fact-based manner\nFollow evidence-based processes for evaluating and market-testing new product ideas following Design Thinking and Lean/Agile principles\nUse event storming to accelerate development\nProvide input into, and influence, long range plans (LRPs)\nCollaborate with team to manage, track, and execute features/stories; commit to what can be accomplished in an iteration, and ensure quality delivery expectations are met\nManage A/B testing to provide feedback on systems making use of ML services; monitor the quality of the ML systems\nAdhere to technology best practices\nDemonstrate ownership of developed components from development through production\nRequired Qualifications:\nBA/BS degree in Computer Science or related technical field or equivalent practical experience\n2 years of work or educational experience in ML or AI\n1 year of relevant work experience, including software development\nExperience with one or more general purpose programming languages including but not limited to: Python or R or Java, and a nice to have C/C++\nGeneral knowledge of ML, ML Tooling (specifically, but not limited to AWS SageMaker, MLFlow etc.)\nGeneral knowledge of data wrangling/preparation and data analysis\nGeneral knowledge of scalable systems\nPreferred Qualifications:\nMS or PhD degree in Computer Science, Artificial Intelligence, Machine Learning, or related technical field\nExperience with one or more of the following: Natural Language Processing (NLP), Natural Language Understanding (NLU), Natural Language Generation (NLG) in terms of text understanding, classification, pattern recognition, recommendation systems, targeting systems, ranking systems or similar\nIn-depth knowledge of ML algorithms: how they work, their proper use cases, their limitations, etc.\nAbility to code algorithms presented in research papers in order to test out new discoveries\nHands-on experience with Cloud services (e.g., AWS, Azure, Google etc.)\nExperience in Agile methodology, Enterprise Agile, LESS, DA(D) or SAFe\nCultural Competencies:\nDrive: takes initiative, persists in the face of obstacles, and is driven to succeed. Cares about EBSCO\u2019s success and inspires others with thirst for excellence.\nPositive Attitude: displays a \u2018can do\u2019 attitude; takes action to solve problems, achieve success, and make a real difference.\nEagerness to Understand: seeks to understand our strategy, markets, customers and suppliers. Understands how work relates to company goals to make improvements consistent with these goals. Follows facts and draws logical conclusions even if those conclusions differ from the status quo.\nSound Judgement: uses logic and common sense to make sound decisions despite ambiguity. Identifies root causes and gets beyond treating symptoms to solving problems.\nCollaboration: collaborates with others to help maximize work accomplished by the group and shares information broadly so that everyone benefits. Embraces individuals\u2019 different styles and finds time to help colleagues.\nOpen Communication: is concise and articulate in speech and writing; always communicates professionally. Creates a two-way flow of information; keeps others informed and updated so they can operate at their best. Treats people with respect regardless of their views.\nAccountability: proactively does what needs to be done. Acknowledges problems, takes responsibility, determines what can be done to solve the problem, and solves it!\nTrust & Respect: consistently acts in a fair, honest, non-defensive and professional manner. Assumes the best in people and their intent to do the right thing. Takes initiative and learns from mistakes. Is reliable, credible and authentic.\nEBSCO Industries, Inc.is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. EBSCO strictly prohibits and does not tolerate discrimination against employees, applicants, or any other covered persons because of race, color, sex (including pregnancy), age, national origin or ancestry, ethnicity, religion, creed, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, training, promotion, discipline, compensation, benefits, and termination of employment.\n\nEBSCO complies with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law.\n\nView EEO PDF\n\nNearest Major Market: Boston\nJob Segment:\nDatabase, Scientific, Computer Science, Java, Developer, Engineering, Technology\nTo apply to this job, click Apply Now"}, "99": {"company": "Northrop Grumman", "description": "Are you ready to leverage your security clearance, knowledge and technical experience in a new role?\n\nAdversaries, cybercriminals and cyber terrorists, are working every hour of every day to develop new means to compromise networks, to seize valuable intellectual property and personal data, and to gain an advantage on the digital battlefield. At Northrop Grumman, our mission is to see to it that they fail. Speed, stealth and precision keys to controlling the physical domains of land, sea, air and space are imperatives in controlling the cyber domain. Our talented employees make advances every day based on these imperatives and are committed to providing the most advanced protection for our customers against the rapidly evolving cyber threat spectrum. Our company is trusted with securing some of the most high-risk systems and continues to be the trusted provider of mission-enabled solutions for the security or our nation and allies. This is without a doubt one of the most exciting times to join our team. So come join us and experience the value of performance.\n\nNorthrop Grumman Mission Systems is seeking multiple Data Scientists to support fast-paced cutting edge programs ensuring national security and defense. The positions are located in the Annapolis Junction, MD greater area.\n\nThis position represents immediate opportunities across multiple programs. Though each program has specific labor categories which must be met prior to placement, all candidates must minimally meet the knowledge, skills and abilities listed below.\n\nNGCIMSMD\n\nBasic Qualifications:\n\nBachelor's Degree in related technical discipline (including but not limited to computer science, data science, information systems, science, engineering, math, economics, or aerospace) from an accredited college or university is required. Four (4) years of additional systems engineering/architecture experience on projects with similar software processes may be substituted for a bachelor's degree.\n\n2+ years of Experience with data analysis and applications, that address a business issue or provide a competitive advantage for an organization. (2 Years with Bachelors in Science; 0 Years with Masters)\nFamiliarity with creating data mining architectures/models/protocols, statistical reporting, and data analysis methodologies to identify trends in large data sets.\nStatistical or data visualization skills.\nUS Citizen with Active TS/SCI w/Polygraph clearance\n\nPreferred Qualifications:\n\nBachelor's degree in a STEM discipline (Science, Technology, Engineering, or Math) along with 2 or more years of data science experience.\nKnowledge of statistical datasets and implementation techniques and tools for the most efficient metrics, including present and future capacity requirements.\nExperience with Tableau, SAS, Apache Spark, BigML, D3, MATLAB, or other data science tools.\nExperience taking big data and turning it into metrics or prediction information for decision making.\nStrong statistical and data visualization skills.\n\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\nTo apply to this job, click Apply Now"}, "100": {"company": "Northrop Grumman", "description": "Northrop Grumman's products support the front lines, securing our democracy and future. Our Manufacturing team's work on these cutting-edge products support the users, our military, to complete their missions and get home safely.\n\nWe are looking for a Data Scientist who will support our product development, production and leadership teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. Must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\nResponsibilities for Data Scientist\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine existing databases, create databases, tabulate and analyze data from company databases to drive optimization to manufacturing processes, product development and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to optimize current processes and improve corrective action timeliness.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\n\nMSRMM\n\nMANUMS\n\nRocktober\n\nBasic Qualifications:\n\nData Scientist\n\nBachelor's degree in Computer Science, Statistics, Mathematics, or another quantitative field with 2 years' experience in various software toolsor a Masters degree in Computer Science, Statistics, Mathematics or another quantitative field.\n\nPrincipal Data Scientist\n\nBachelor's degree in Computer Science, Statistics, Mathematics, or another quantitative field with 5 years' experience in various software tools or a Master's degree in Computer Science, Statistics, Mathematics, or another quantitative field with3 years' experience in various software tools\n\nFor Both Levels:\nExperience with C, C++, or equivalent.\nExperience creating User interfaces.\nExperience with Tableau or SAP Lumira.\nExperience with querying databases\n\nStrong problem solving skills with an emphasis on production environments\nExperience working with and creating data architectures\nExperience using statistical computer languages (Minitab, Tableau, Python, SQL, etc.) to manipulate data and draw insights from large data sets\nProven ability to learn and master new software tools, technologies and techniques\nAbility to obtain a security clearance and US Citizenship\n\nPreferred Qualifications:\n\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\n\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.\n\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\nStart your job application: click Apply Now"}, "101": {"company": "Fullpower Technologies, Inc.", "description": "Fullpower\u00ae designs, develops and operates a complete platform for hybrid Edge/Cloud AI, algorithms, big data, predictive analytics, together with end-to-end engineering services. The Company\u2019s platform is backed by a patent portfolio of 125+ patents. The Company\u2019s key areas of expertise are bio-sensing, non-invasive PSG-level sleep technology. The Company\u2019s markets are in Medical Solutions, Clinical Trials, SmartHome and Wearable. Fast growing with endless opportunities, come join the Fullpower world-class team.\n\nFullpower is looking for a passionate, team-oriented, and self-motivated Data Scientist/Applied Mathematician.\n\nResponsibilities:\nWork with health data and time-series sensor data\nDesign machine learning and statistical models and inference algorithms\nDevelop visualizations and tools for understanding and annotating data\nOptimize algorithms for running on embedded devices and in the cloud\nCollaborate with an interdisciplinary team of scientists, engineers, mathematicians for quick deployment of solutions\nSoftware skills:\nExpertise in Python and packages such as Pandas, Scikit-learn, etc.\nExperience working with databases including familiarity with SQL\nExperience with a deep learning framework such as Tensorflow, pyTorch, or equivalent\nExperience with Amazon Web Services (AWS) or Google Cloud is a plus\nLeadership qualities:\nSelf starter\nStrong interpersonal and communication skills\nEducation:\nBachelor\u2019s degree or higher in Mathematics, Statistics, Physics, Computer Science, or equivalent\nExperience:\nExperience applying data science and machine learning to real-world problems\nOther requirements:\nFullpower does not sponsor work visas - must already be authorized to work in the United States\nStart your job application: click Apply Now"}, "102": {"company": "Citizens Property Insurance", "description": "A career at Citizens is unlike a career at any other insurance company, because Citizens is unlike any other insurance company. If you are looking for an opportunity in which you can stretch to your full potential, expand your knowledge and grow your career, you have found it.\n\nAt Citizens, employees do more than live up to their potential \u2013 they exceed it. So what are you waiting for? Come discover the career you never expected \u2013 at Citizens.\n\nJOB SUMMARY\n\nResponsible for the creation and maintenance of spreadsheets, databases, manuals, and system data calls used to support the business unit and/or enterprise. The Data Analyst will compile data from multiple sources using Query tools to create dashboards, integrated views, reports that can be used to drive decision making as well as identifying improvement opportunities.\n\nModels ethical behavior and executes job responsibilities in accordance with Citizens core values, ethics, and information protection policies.\n\nUtilize business systems and database tools to define, extract, create complex queries as well as analyze and compile statistical data to prepare various reports, charts or written summaries for management to support recommendations or validate results as well as identify critical issues. When needed, provide management and outside parties with reports that analyze the metrics for emerging trends and critical issues. Serve as liaison between IT and business unit for policy data coordination.\n\nCreate, analyze, and maintain complex spreadsheets, complex databases, dashboards and reports used to measure, monitor and manage results of projects and assignments. May lead projects as needed.\n\nIdentify and understand issues, problems, and opportunities; compare data from different sources to draw conclusions and make recommendations to improve existing processes to maximize opportunities for efficiency and effectiveness. Create audit procedures to ensure data integrity.\n\nCollaborate with business unit and various levels of staff including Executive Leadership, as directed, to evaluate work processes and identify enhancements to system functions or processing to facilitate improved turn-around times and performance risk and controls.\n\nREQUIRED:\n\nKnowledge:\n\nAdvanced knowledge of COGNOS business intelligence products such as Analysis Studio, Report Studio, Query Studio, Dashboards and Cognos BI Version 8 or equivalent Business Intelligence tools.\n\nAdvanced level of knowledge of Microsoft Office Suite, specifically Excel and Access.\n\nAdvance knowledge of data management techniques and processes, data definitions, data classifications, database normalization, data modeling techniques, and data analysis methodologies, including understanding how technology can be leveraged to proactively impact business processes.\n\nSkills & Abilities:\n\nAbility to perform complex analysis on business data and deliver reports and recommendations to management with a high level of quality and attention to detail.\n\nExcellent verbal and written communication skills and ability to effectively interact with both internal and external contacts in person, by e-mail, or over the phone including facilitation and presentation skills.\n\nPerform complex data analysis using database tools such as Microsoft Access, ACL, SQL Server Management Studio or Advanced Query Tool, data warehouse, audit automation or data mining tools.\n\nExcellent interpersonal and relationship building skills, including ability to work in a team environment.\n\nAdvanced Microsoft Access/Excel database design skills\n\nAbility to manage multiple assignments and projects simultaneously with high level of attention to detail and accuracy, work independently in a highly motivated and self-directed environment with limited oversight.\n\nExcellent quantitative, data analysis, analytical, and report writing skills.\n\nAbility to read, create and interpret data flow and entity/social relationship diagrams.\n\nDemonstrated ability to solve complex problems through analytical approaches.\n\nRelevant Experience:\n\n5 or more years of experience in analytics, report writing, pivot tables, macros, working with various reporting tools such as Microsoft Excel/Access, Cognos, and/or Crystal Reports, which also includes 4 or more years of experience in data management, development projects and activities.\n\nPreferred:\n\n\u2022 Master\u2019s Degree.\n\n\u2022 5 years\u2019 experience in data management projects and activities.\n\n\u2022 6 years combined experience in developing data metrics, analytics, dashboards, complex queries\n\n\u2022 Experience in primary functional business area ( e.g., Insurance Operations, Finance, Human Resources, Vendor Management) as well as experience in a financial or insurance services organization .\n\n\u2022 Experience with data management techniques for dealing with Personally Identifiable Information (PII).\n\n\u2022 Successful completion of formal training program related to the subject of data forensics.\n\n\u2022 Actuarial and/or investigative experience, Business Analyst experience as well as experience with Scorecard and Dashboard design and defining business metrics and providing analytics for strategic KPIs is preferred.\n\nIn addition to a competitive salary, Citizens offers its employees an outstanding total rewards package, including:\nRetirement savings plan with an 8 percent company match\nMedical, dental and group life insurance\nPaid time off: vacation, sick and holiday leave\nTuition reimbursement\nProfessional and leadership development opportunities\nFlexible work schedule\nOn-site wellness activities\nEmployee recognition programs\nRelocation assistance (where applicable)\nCommunity and volunteering opportunities\nCasual dress and more\n\nCitizens is proud to be an Equal Opportunity Employer\n\nRelocation Assistance is available for this position\nApply Now: click Apply Now"}, "103": {"company": "Mars", "description": "JOB CATEGORY:\n\nInformation Services\n\nREQUISITION NUMBER:\n\n251340\n\nData Scientist\n\nA BIT ABOUT OUR DATA SCIENCE & ANALYTICS TEAM\n\nKinship\u2019s Data Science & Analytics team is core to our strategy. We\u2019re using digital, data and customer insights to transform our business by finding answers to problems that we\u2019ve often never asked ourselves before. Our vast data assets are being combined to build a 360\u00b0 view of Pets and Pet Owners to not only power Kinship\u2019s businesses but also influence the next great ideas in the Petcare space. This role will be key in helping us understand the power of our data, and how this translates into value for our company, Pets, and Pet Owners. Frequently the projects will be ambiguous, but that\u2019s part of the fun; you will determine the best way to leverage our data to tell the right story for any given audience.\n\nHOW YOU\u2019LL CREATE A BETTER WORLD FOR PETS\nApply data science approaches to understand and predict pet and pet owner behaviors\nUse machine learning techniques, visualizations, & statistical analysis to gain insight into various data sets \u2013 some readily available, and some you create and curate yourself\nCollaborate with internal and external teams to ensure we focus on pet-centric product and service recommendations\nSupport new pet technology businesses and partners by generating actionable insights from our data assets\nDevelop compelling stories that provide insight into the drivers of business performance and Pet/Pet Owner behavior\nWHO WE NEED TO CHART THE FUTURE OF PET CARE\n\nWe strive to hire people who are passionate about our mission: creating a better world for pets. For all of our Kinship roles, we look for candidates who exemplify our attributes through consistent behaviors. We believe what we do is just as important as how we do it, and we aim to hire people who are:\nOptimistic. Those who\u2019s boundlessly energy and enthusiasm for what\u2019s next shines through in everything they do. We seek to work with people who are intrinsically happy, and who will drive our vision and purpose while managing the complexities of our businesses.\nPurposefully Inquisitive. Those who are courageous and use their deep business insights to cultivate innovation. We want the trailblazers in tech. Those who are entrepreneurs at heart, ask the tough questions, adapt quickly to new situations, and analyze data in new ways to push our big ideas forward.\nOpen to All. Those who are inclusive leaders, committed to learning, and leveraging our differences as strengths. We hire people who are naturally collaborative and thrive in a flat and flexible organization. Those who are thoughtful communicators, and seek to foster meaningful relationships across our community of diverse partners.\n\n\nAnd for this role, we hope you have the following skills we require to round out our team:\n\nExceptional written & verbal communication, coupled with critial thinking skills.\nTruly inspired by, and want to live, our purpose of creating a better world for pets.\n1+ years\u2019 experience in a data science role handling varied and complex data\nProficiency in machine learning modeling and statistical thinking (random forest, decision trees, supervised and unsupervised modeling, etc.)\nHands-on experience with Python is required; Familiarity with PySpark is also desirable\nComfortable with ambiguity, with a passion for collaboration to achieve objectives\nA Bachelor\u2019s degree in quantitative field (economics, statistics, business, computer science) or equivalent experience\n\n\nIf you also had these experiences, you\u2019d knock it out of the dog park:\n\nPassion for growing and strengthening a business using data driven approaches\nFamiliarity with cloud-based computing services e.g. AWS, Databricks, etc.\nEnjoys explaining how models and systems work to both non-technical and technical stakeholders.\nWe want to understand what you're passionate about, the work you've done, and why you'd specifically like to work for Kinship. In order to be considered for this role, you must submit a cover letter and resume to Katelyn@Kinship.co. Candidates without a cover letter will not be considered.\n\nWHY JOIN US?\n\nWe offer our associates a unique opportunity to have a completely customizable career within pet care. Through Kinship you will work with and learn from a community of industry executives, pet partners, entrepreneurs, and fellow associates across our startup investment companies, outside partners, and in Mars Petcare. Our nimble and flexible approach to work allows you to make an immediate impact across businesses, while learning new skills at every stage. The diversity of our work opens doors to big opportunities and unlocks enormous potential for countless career experiences in pet care. Join us in our mission to chart the future of pet care, alongside the industry\u2019s brightest minds.\n\nKinship\u2019s offices are global, and so are our associates. We are located in NYC, San Francisco, Portland, London, Helsinki, Shanghi, and in Moscow. Many of us flex between our dog-friendly hubs and our home offices. Today, Kinship offers exceptional benefits for you, your family, and your pets, generous paid time off, exponential opportunities to build a career within pet care, and progressive reward packages. Interested? Let\u2019s take big strides, together.\n\nData Scientist\n\nJob Segment:\nDatabase, Scientific, Computer Science, Cloud, Statistics, Technology, Engineering, Data\n\nApply now \u00bb\n\nStart your job application: click Apply Now"}, "104": {"company": "Unitus Community Credit Union", "description": "At Unitus, each employee has an opportunity to make a difference for our members. As part of the Information Technology, Information Management Solutions Department at our headquarters in downtown Portland, the Business Intelligence Analyst will develop analytical models and dashboards from a wide range of business data to enable our commitment for unparalleled service \u2013 the kind that creates theUnitus difference. Our strong team of leaders, outstanding culture, above market benefits, continuous involvement in the communities we serve, and competitive pay programs make Unitus an excellent place to contribute and grow your talents.\n\nPrimary Duties:\n\n\u2022 Build and maintain knowledge of information on organizational direction, goals, and industry competitive environment and a variety of complex business unit requirements.\n\n\u2022 Create analytical models and dashboard solutions for current and future business initiatives and train end-users in generating self-service reporting.\n\n\u2022 Maximize the capabilities of business intelligence tools and data sources across the organization.\n\n\u2022Serve as a subject matter expert in various data tool sets used to measure, validate, and monitor organizational metrics, ensuring reliable results.\n\n\u2022 Assist in cross-functional special projects, one time reporting and analysis and other initiatives.\n\nAs an ideal candidate, you will have:\n\n\u2022 B.A. or B.S. degree with focus in related field of study or equivalent work experience\n\n\u2022 A minimum of 4 years of experience in performing data analytics that includes advanced competencies in SQL, Excel, reporting-writing (Tableau preferred), and working with relational databases.\n\n\u2022 A strong proficiency in and experience with MS Office tools.\n\n\u2022 Strong analytical thinking and problem solving skills required, including ability to anticipate and solve data integrity issues routinely.\n\n\u2022 Effective time management skills with attention to detail, planning, prioritization and follow-up while working independently with minimal supervision and exercising good judgment.\n\n\u2022 Well-developed interpersonal, communication, and collaboration skills to work with both technical and non-technical staff using tact and diplomacy, including the ability to lead meetings, perform presentations and/or develop concise user-friendly written documentation.\n\n\u2022 Formal process improvement methods, tools and best practices helpful.\n\nWhat\u2019s it really like to work here?\n\nOur employees are equal in importance to our members \u2013 we are a people-focused organization that places an emphasis on culture. Unitus is local, successful, and committed to continuously improving and growing!\n\nUnitus Community Credit Union (Unitus) is an equal opportunity employer. We are dedicated to a policy of non-discrimination in employment based on race, color, age, sex, religion, veteran status, national origin, sexual orientation, disability or any other classification protected by applicable federal, state or local law. Applicants may request reasonable accommodation to participate in the application process.\nStart your job application: click Apply Now"}, "105": {"company": "Oden Technologies", "description": "About Oden:\n\n\nWe are on the brink of the fourth industrial revolution.\n\nManufacturing has long been an analog world, but this is rapidly changing. There is a staggering opportunity for improving the efficiency of current manufacturing processes, and enabling the next generation of manufacturing through the effective gathering, analysis, and productionization of data and insights. Oden is driving this revolution.\n\nWe have combined industrial hardware, wireless connectivity, large-scale data processing architectures, and advanced machine learning algorithms within the Oden platform so all manufacturers can monitor, analyze and optimize their production, across their diverse set of processes. Our goal is to democratize efficiency, sustainability, and competitiveness in the manufacturing domain.\n\nWhy We Do It:\n\n\nWe like to enable those who make things - to make more, to waste less, to serve their customers, and to thrive in a competitive world. Help enough makers, and the world can give us all the abundance we want for less cost and environmental impact. We\u2019re on the verge of a 4th industrial revolution for everyone who makes things.\n\nYou:\nCare about the purpose of the product and company.\nAre never satisfied with the way things are, but excited about the way things could be.\nTinker. You embrace data and different technologies and want to see how they can work together.\nEmpathize with customer needs and enjoy novel ways of posing and solving their problems.\nLive by transparent and scientific thinking. You put in the work to find the best ideas with those around you.\nAre happy to put on steel toe boots and hit the factory floor to work with the production manager.\nThe Role:\n\n\nAs a Data Scientist on the Engineering Team you will be responsible for building statistical and machine learning models that improve the efficiency of manufacturing using telemetry collected from Oden\u2019s factory cloud. This includes real-time metrics that capture various properties of the manufacturing process, context about these metrics provided from external systems and human input, and offline measurements that describe the quality of the resulting products. Problems of interest range from diagnostic to predictive, eventually leading up to closed loop process control.\n\nYou will be working closely with Oden\u2019s data and product engineers to address customer needs. You will push the envelope on how machine learning can provide value to process engineers, operators and materials scientists. This is a crucial role for Oden, and requires someone who will uphold the highest standards of quality, accountability, and attention to detail.\n\nResponsibilities:\nInteracting with customers to understand and pose relevant data analysis problems.\nDeveloping and validating models and methods that address these problems, and working with the engineering team to deploy these as solutions\nGeneralizing solutions and innovating to create the next generation of product features\nEngaging with the technical community to present results externally, keep up to date on recent advances, and advance the state of the art\nMinimum Qualifications:\n\n\n5 years professional experience as a Data Scientist or advanced degrees (M.S. or PhD. in Statistics, Data Science, Computer Science with ML focus, or related fields)\nExperience with Python and SQL\nExperience with designing, building and deploying performant statistical models on large data sets (bonus: experience with time series data, and with real-time data analysis)\nFamiliarity with process improvement and exploratory techniques (e.g. design of experiments and optimization)\nEnthusiasm to own projects end-to-end; from experimentation to customer delivery\nExperience predictive modeling or machine learning on large datasets\nBonus:\n\n\nMaterials Science, Chemistry, or a related physical science expertise\nWhat We Offer You:\n\n\nMeasurable impact to the world and the chance to help real people - family businesses, entrepreneurs, engineers.\nExposure to many tech disciplines, most of which are rapidly evolving.\nA bridge between the physical and cloud worlds of tech. Our platform unites big data visualizations with sensors, M2M tech, and heavy industrial equipment.\nA platform that has the potential to evolve beyond what we have envisioned now.\nScientific and transparent thinking, for everyone involved.\nWe have backing by world leaders of both industry and tech that will ensure long term growth and development for us.\nWe\u2019re an equal opportunity employer (EOE).\n\nDiversity at Oden means building a team that is rich across all boundaries of race, ethnicity, gender identification, sexual orientation, disability, religion, age and thinking style. We welcome all backgrounds, life experiences, and worldviews as this is the catalyst for the rapid evolution of our product and our organization. Diversity allows us to tackle new challenges, embrace change, make well-informed decisions, and ultimately Make Things Better. In alignment with our \u201cPeople First\u201d company value, Oden has a passionate internal team dedicated to the promotion of diversity and inclusion initiatives as a core component of our culture.\n\nOur diversity initiatives apply to our practices and policies on recruiting, compensation and benefits; professional development; promotions; social activities and the ongoing development of a psychologically safe work environment.\nStart your job application: click Easy Apply"}, "106": {"company": "W3Global", "description": "Job-Title: Data Modeler\n\nLocation: Atlanta GA\n\nContract\n\nPrimary Responsibilities:\nConsult, facilitate understanding and translate data requirements into logical, physical and semantic layer models across the analytical data environment\nEnsure data structures are designed for flexibility to support future business needs.\nProfile and analyze source system data to determine data relationships, design constructs, consistency and quality.\nEnable and lead analytics user community in the understanding, location and selection of appropriate data sources to achieve key business goals\nEnsure that data designs follow architectural best practices and appropriate business rules\nFacilitate data integration, conformity, data quality, integrity and consolidation\nBe an advocate for best practices while balancing business value and reasonable practicality\nCreate and Maintain critical data documentation and metadata that allows data to be understood and leveraged as a shared asset.\nSet the strategy and repeatable process for maintaining the Enterprise Data model using automated tools.\nAnalyze and evaluate data definition and modeling environment providing key recommendations for improvement. Assist in defining data modeling standards, and foundational best practices.\nIdentify gaps and opportunities with regard to data governance and data ownership, and provide recommendations for improvements incorporating best practices.\nFacilitate understanding of high quality data management discipline throughout the corporation\nWork with the Data Governance lead to enhance/establish data stewardship and data quality management programs.\nDevelop and maintain relationships across IT and across the business with special focus on roles that are heavy consumers of data for analytical purposes; anticipate customer needs and proactively develop solutions\nOrganizational Relationship:\n\nThis position reports to the Vice President of MDM System\n\nPosition Qualifications\n\nEducation & Experience:\nA Bachelor?s Degree in a technology area of study; preferably in Computer Science, MIS or Analytics\n7+ years equivalent work experience in Information Technology\n5+ years in a structured IT organization with a strong PMO, a variety of methodologies, and strong technical environment management disciplines\n5+ years of experience in Data Analysis, Data Architecture and/or Data Warehousing; preferably in a shared or enterprise data environment\n5+ years direct experience in Data Modeling and Data Solution Development\n2+ years of experience in banking and/or financial services\nDeep experience in logical, physical and semantic data modeling\nSQL Query development skills for analyzing and profiling data\nExperience with Agile\nPlease send updated resume and details to gopal@w3global.com or call me to 972-393-4403\nApply Now: click Apply Now"}, "107": {"company": "Turnitin, LLC", "description": "Company Description\n\nTurnitin is your partner in education with integrity. Turnitin\u2019s originality checking and authorship investigation services ensure academic integrity, promote critical thinking, and help students improve their authentic writing. Turnitin provides instructors with the tools to prevent plagiarism, engage students in the writing process, and provide personalised feedback. Turnitin is used by more than 30 million students at 15,000 institutions in 140 countries. Turnitin is headquartered in Oakland, Calif., with international offices in Newcastle, U.K., Utrecht, Netherlands, Melbourne, Australia, Seoul, Korea and throughout Latin America.\n\nJob Description\n\nOakland location preferred, but also open to candidates in Pittsburgh, PA or Dayton, OH.\n\nAbout Data Science in Authorship\n\nData Scientists are responsible for converting raw data into actionable insights for our students and teachers as well as internal decision makers and stakeholders. This role will report into the Machine Intelligence team, and is expected to own data science for Turnitin\u2019s new Authorship product. The Authorship product extends Turnitin\u2019s industry leading Academic Integrity suite by providing tools to help identify and prevent the rapidly growing problem of contract cheating in student and academic writing. We do this by leveraging the latest advances in Data Science to bring forward predictions and insights on the writing style and consistency of every student, enabling educators and Academic Integrity Officers to make better decisions about the origin of a piece of writing with more context and clarity.\n\nRole and Responsibilities\n\nWe are looking for an innovative data scientist with strong data and statistical skills to own the Data Science work in the Authorship product. This role will be a vital member of the Turnitin Machine Intelligence team. Your focus will be on leveraging Turnitin\u2019s 1B+ student papers as well as our proprietary labeled datasets to understand how to detect instances of contract cheating. Being able to generate clean data from large, raw, and disparate tables is important, as well as being able to communicate your findings to teammates, colleagues and senior leadership with diverse backgrounds and skillsets. Must be able to function with high autonomy and feel comfortable owning the direction of data science within the project and helping to steer the project direction.\n\nDay-to-day, your responsibilities are to:\nWork closely with domain experts, project engineers and product owners and own the setting of Authorship data exploration directions.\nFind, extract, and clean the necessary data from Turnitin\u2019s vast data stores to answer those questions by writing efficient and robust SQL queries.\nDevelop innovative and rigorous statistical aggregation and modeling techniques to make predictions and bring forward insights from the data.\nCreate production ready data and modeling pipelines in the Turnitin AWS stack that will power key data features surfaced by the Authorship product.\nRegularly communicate project direction, status, needs and key findings to stakeholders across the company, from teammates and colleagues to senior and executive leadership.\nStay up to date with the latest advances in applied data science by reading papers, industry blogs, and attending conferences.\nFunction as a Data Science thought leader within Turnitin, helping to champion good data practices and expand the vision of data science across the company.\nMentor more junior data scientists as the team grows.\nQualifications\n\nQualifications\n\nRequired Qualifications\nExperience with the above responsibilities.\nExperience in extracting insights and predictions from large, raw data stores.\nFluency in SQL, Python + Jupyter notebooks or R + RStudio, unix systems, git, github.\nStrong applied knowledge of Statistics and predictive algorithms and fluency with general machine learning domains including classification, regression and unsupervised clustering.\nEssential software engineering fundamentals (we use Python, Unix-based systems, git, and github for collaboration and review).\nStrong data science and data exploration skills in local and cloud based workflows.\nMaster\u2019s in Computer Science, Statistics, Applied Mathematics, or related field; or 3+ years of relevant industry experience.\nDesired Qualifications\nInterest in Education Technology and Academic Integrity.\nFluency in more advanced Machine Learning techniques such as deep learning, and recommender systems.\nPrior experience in natural language processing or computational linguistics.\nAdditional Information\n\nTurnitin, LLC is committed to the policy that all persons have equal access to its programs, facilities and employment without regard to race, color, ancestry, national origin, age, gender, sexual orientation, gender identity, age, religion, creed, disability, medical condition, genetic information, marital or veterans status.\nTo apply to this job, click Apply Now"}, "108": {"company": "Karyopharm Therapeutics Inc.", "description": "The Assciate Director/Director, Pharmacovigilance Scientist supports the medical component of pharmacovigilance activities including: surveillance activities providing scientific/clinical PV expertise with a focus on the identification, evaluation and management of safety risks for Karyopharm products. They collaborate closely with the safety physician and cross-functional partners to evaluate and actively manage risks in accordance with global regulatory frameworks.\nOrganize and perform independently or collaboratively as necessary, the relevant safety data analysis for Safety Management Team meeting; ensure adequate documentation of meeting minutes\nCreate and maintain an effective signal tracking process that fully documents signaling activities and can be used for regulatory inspection\nSupport other function teams for Karyopharm investigational products; serve as PV expert and liaise with Clinical Operations, Biostatistics, Regulatory Affairs, Contract Research and other entities as needed\nProvide oversight for the safety data analysis and manage PV Scientists\nEvaluate medical coding of safety data\nContribute to health authority and other safety related query responses\nSupport study teams for Karyopharm investigational products; serve as PV expert and liaise with Clinical Operations, Medical Affairs,\nDemonstrate knowledge and ensure compliance with current and applicable global PV regulations and guidelines (e.g., CIOMS, EMA, FDA, ICH, etc.)\nEnsure compliance with Karyopharm and PVG & Risk Management policies and procedures\nPrepares aggregate safety reports (e.g. DSURs, PSURs), including project management, safety database requests, understanding and writing the content, assimilating information from other groups, and quality checks\nPlans and executes literature surveillance\nProvide leadership in the development, implementation, and maintenance of robust procedures for the planning, preparation, and submission of high quality safety reports\nSupport PV activities as needed\n\nPharmD, MD, PhD, MPH, advance healthcare degree, or equivalent professional experience\nMinimum 8 years\u2019 pharmacovigilance or relevant experience, including at least 5 years\u2019 concentration on aggregate safety report writing\nThorough understanding of the drug development process and context applicable to safety surveillance activities\nKnowledge of MedDRA terminology and its application\nExcellent written and oral communication skills, strong attention to detail, and high performance standards for quality\nAbility to analyze, interpret, and summarize complex clinical and medical literature data\nAbility to prioritize and complete work in a resourceful, self-sufficient manner while maintaining a strong mentality\nDisplays ability to understand established procedures and communicate those procedures to others\nExhibits comprehension of industry practices and regulations for drug development and pharmacovigilance\nDemonstrates awareness of related medical disciplines and an understanding of general concepts and some experiential detail within those areas\nPossesses computer skills to support use of electronic systems and development of writing deliverables\n\nKaryopharm Therapeutics is a global commercial-stage pharmaceutical company focused on the discovery and development of novel first-in-class drugs directed against nuclear transport targets for the treatment of cancer and other major diseases.\nKaryopharm Therapeutics Inc. (the \"Company\") is an equal opportunity employer. All qualified applicants will be considered without regard to age, race, color, sex, religion/creed, national origin, marital status, ancestry, citizenship, military, reservist or veteran status, pregnancy, sexual orientation or preference, gender identity, gender expression, physical or mental disability, genetic predisposition or carrier status, or any other category protected under applicable federal, state or local law. Consistent with its obligations under applicable law, the Company will make reasonable accommodations for qualified individuals with disabilities. If you require an accommodation in the application process, please contact a member of the Company\u2019s Human Resources department.\nStart your job application: click Apply Now"}, "109": {"company": "TransUnion", "description": "What We'll Bring:\n\nAt TransUnion, we have a welcoming and energetic environment that encourages collaboration and innovation \u2013 we\u2019re consistently exploring new technologies and tools to be agile. This environment gives our people the opportunity to hone current skills and build new capabilities, while discovering their genius.\n\nCome be a part of our team \u2013 you\u2019ll work with great people, pioneering products and cutting-edge technology.\n\nWhat You'll Bring:\nMaster\u2019s or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field.\nAt least seven (7) years of professional experience within the Data Science field leveraging credit or financial services related data\nMultiple examples of demonstrated success in client-facing roles over a period of at least three (3) years\nAdvanced programming skills; mastery of a statistical language such as R or SAS\nExperience using other programming and data manipulation languages (SQL, Hive, Pig, Python, C/C++, Java)\nWe\u2019d love to see:\nAbility to travel 10-20%\nVersatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization;\nStrong project management skills with the ability to manage multiple assignments effectively\nA deep understanding of current industry challenges and trends at the level needed to proactively identify customers\u2019 analytical needs and related business opportunities\nImpact You'll Make:\nYou will partner with internal and external cross-functional teams to drive new business initiatives and deliver long term value-added product propositions for B2B customers in the US financial services segment at TransUnion. This includes but is not limited to the development of predictive risk management and business intelligence solutions for credit card issuers, auto & mortgage lenders, telecommunications, collections agencies and retail banks.\nYou will design and lead client engagements involving descriptive, predictive, and prescriptive analysis leveraging a variety of techniques (such as segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis, and machine learning); this will involve delegating tasks to other team members and managing the team to meet deliverables on time\nYou will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, SAS, SQL, Hive, and Pig on Linux, PC, and mainframe computing platforms.\nYou will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience.\nYou will serve as an advisor and partner to the senior management team: proactively seek out opportunities for innovation and present new ideas and solutions on behalf of the team\n#LI-AL1\n\n#DICE\n\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.\n\nTransUnion's Internal Job Title:\n\nConsultant, Data Science and Analytics\nTo apply to this job, click Apply Now"}, "110": {"company": "PennyMac", "description": "The Data Engineer will work with the data Analyst and project managers to determine logical and physical database designs for new analytics models. The Data Engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The Data Engineer will support database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout analytics ongoing projects.\n\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability\nCreate and maintain optimal data pipeline architecture\nAssemble large, complex data sets that meet business requirements\nBuild analytics tools that utilize the data pipeline to provide actionable insights into operational efficiency, financial reports and other key business performance metrics\nWork with stakeholders including the Engineering and Analytic teams to assist with data-related technical issues and support their data infrastructure needs\nCreate data tools to support business informational technology process\nWork with the data analytics team to strive for greater functionality in our data systems\nPerform other related duties as required and assigned\nDemonstrate behaviors which are aligned with the organization\u2019s desired culture and values\n\nModerate experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\nModerate knowledge of AWS cloud services: EC2, EMR, RDS, Redshift\nExperience with object-oriented/object function scripting languages: Python, Java, C++\nExperience building and optimizing AWS data pipelines, architectures and data sets.\nStrong project management and organizational skills.\nModerate skill in business intelligence tools such as Tableau or Qlik\nModerate skills with MS Office, including Excel & PowerPoint\nMust be a team player with strong attention to detail and able to work independently\nProven track record at delivering timely and accurate information in a fast-paced environment\nExcellent critical thinking, problem solving, and mathematical skills, and sound judgment\nStrong business acumen and ability to interface with executive management\n\n\nTo apply to this job, click Apply Now"}, "111": {"company": "TZ Insurance Solutions", "description": "We\u2019re looking for a senior data scientist to drive our data science and analytics group forward! You\u2019ll be joining a group of curious, smart, technically minded yet business savvy data scientists and analysts looking to make a difference to the company by designing and building out our data decisioning capabilities from the ground up!\n\nAs a senior data scientist, you\u2019ll work collaboratively with our business, operations, analytics, and IT teams. You\u2019ll be responsible for conceptualizing, designing and building out decision making products for our business in the spaces of marketing / lead gen, business operations, and customer retention.\n\nOur ideal candidate is excited to join our fast-paced culture and is excited to contribute to our growing data science practice!\n\nWhat you\u2019ll do:\n\n\u00b7 Find new and improved ways for us to use data in our products, operations, and business strategies\n\n\u00b7 Lead new projects and initiatives starting from understanding business to carrying out projects and presenting to stakeholders.\n\n\u00b7 Design and execute data products in marketing, business operations, and customer retention spaces\n\n\u00b7 Act as a subject matter expert with all things data\n\n\u00b7 Work to build out the data science team as we grow\n\nWhat we do:\n\nWe achieve competitive advantage through data-driven marketing and full management of the customer experience.We\u2019re constantly refining our technology and our strategies, that\u2019s why we\u2019re the industry leader in delivering the best results to the top insurance brands in America.\n\nThat\u2019s not just lip service either, we\u2019re consistently awarded partner of the year from brands like AFLAC, Humana, and more. Our work has also been featured on The Dr. Oz Show, Forbes, and Vox -- to name a few.\n\nWe want people who fit within our Be Real culture. We want a diversity of programmers and writers and designers and data scientists and strategists and more. We\u2019re made up of introverts and extroverts, suits and rebels, corporate types and anti-corporate types. We\u2019re an environment where every person feels their full potential is only limited by their ability to conceive of it and make it happen.Our company grew from entrepreneurial roots but has big company resources to get amazing things done.\n\nWhat we\u2019re looking for:\n\n\u00b7 7+ years of experience in a data science role, building predictive algorithms and data products ideally related to marketing, business operations, or customer retention\n\n\u00b7 Excellent understanding of machine learning techniques and algorithms such as decision forests, logistic regression, k-means clustering, etc.\n\n\u00b7 Ability to communicate findings clearly and deep understanding of your current business\n\n\u00b7 Proficiency with Python, SQL, Excel, and data visualization tools (Tableau, Power BI, etc.)\n\n\u00b7 Experience with big data platform (i.e. Hadoop)\n\n\u00b7 Intensely curious \u2013 always asking questions and not being OK with the status quo. Obsessed with making things better and more efficient.\n\n\u00b7 A lifelong learner that is excited to learn new data science technologies and apply those to technologies to our business\n\n\u00b7 Ability to be objective and follow the facts, cut through noise and create a story with data.\n\n\u00b7 Strong organizational skills including time and project management\n\n\u00b7 Thrives in a fast-paced environment that is constantly changing\n\n\u00b7 BS/MS in a quantitative field (Computer Science, Engineering, Mathematics, Statistics, etc.)\n\nWhat\u2019s in it for you:\n\n\u00b7 Medical, dental, vision, paid time off/holidays, 401(k), and bonus opportunity\n\n\u00b7 Frequent office events and outings\n\n\u00b7 Employee development programs, conference and training reimbursement\n\n\u00b7 Work remote flexibility\n\n\u00b7 Joining a growing and exciting team making a big impact on the business!\n\nTRANZACT, aWillis Towers Watson Company is an Equal Opportunity/Affirmative Action employer and voluntarily complies with the laws and regulations related to employment without regard to race, color, religion, sex, national origin, marital status, sexual orientation, age, status as a protected veteran or individual with a disability, ancestry, gender, gender identity or expression, or any other protected group status or non-job related characteristic protected by applicable human rights or equal opportunity legislation. We are a company that values diversity. As required by law, we must record certain information to be used as part of our Affirmative Action Program. In extending this invitation you are advised that (a) response data is used for periodic government reporting and will remain confidential within Human Resources department; (b) responses are used solely to help us comply with government record keeping, reporting and other legal requirements.\nTo apply to this job, click Apply Now"}, "112": {"company": "Lancer Insurance", "description": "Lancer Insurance Company is looking for a Data Engineer to develop, maintain, test and evaluate data solutions in support of business goals. The person will also develop data models, corresponding data architecture documents and API\u2019s. The right candidate should be an excellent communicator and strategic thinker.\nDuties and Responsibilities\nCreate, design and maintain reusable datasets for analysis by data scientists.\nAssess new data sources to better understand availability and quality of data.\nProvide governance and best practices of data structures, data integrity, and querying.\nInterpret business needs from requests, and rapidly implement effective technical solutions.\nDesign, implement and enhance ETL (extract, transform and load) processes.\nWrite SQL queries to answer questions from stakeholders.\nMaintain source code repository of scripts (SQL, Python, R) and other data products (dashboards, reports, etc.).\nWork with technology teams (BA,QA, Dev and Admin) to understand data capture and testing needs.\nAutomate and improve creation/maintenance of reports and dashboards.\nSkills & Experience\nBA/BS or Master's degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Data Sciences).\nAdvanced SQL and relational databases including queries, database definition and schema design.\nPython or R experience required.\nWriting and maintaining ETL on a variety of structured and unstructured sources.\nExperience sourcing data via REST web services.\nExcellent written and verbal communication skills.\nMicrosoft SQL Server, SQL Server Integration Services (SSIS), Business Intelligence Development Studio (BIDS), Excel (pivot tables).\nInsurance experience a plus.\nStart your job application: click Easy Apply"}, "113": {"company": "Liberty Mutual Insurance", "description": "Help shape the future of Data Science across Liberty!\n\nAs a technical member of the Office of Data Science (ODS), Enablement & Collaboration unit, you will work with a team of data science (DS) and machine learning (ML) experts to solve Liberty's most challenging data science problems.\n\nThe ODS was created to provide additional centralized support and expertise to DS teams across the global organization. Our projects focus on key areas of interest to multiple teams, bleeding edge research and experimentation, common tool development, and establishing best practices to ensure the scientific community at Liberty is well-positioned to rapidly meet the challenges of modern industry.\n\nIf you are interested in making an impact on an entire culture at a Fortune 100 company, the ODS is the place for you!\n\nAs a centralized group, our project scope is vast. Possible projects include:\nDesign new language models (NLP/NLU) to understand and build predictions or summaries from customer calls, claim notes, web chats, medical records, and beyond.\nDetect property hazards from aerial imagery, customer photos, geospatial data, etc. using computer vision (CV).\nExplore the advantages and limitations of privacy-preserving ML, to accelerate experimentation and better protect our customers' data.\nPush the boundaries in fundamental experimentation to boost and augment small-sample or rare-event data, transfer learning, and similar techniques.\nEngage in theoretical research in collaboration with MIT, via Liberty's investment in the MIT Quest for Intelligence, to shape the future of AI\n\nResponsibilities:\nWork on cross-functional R&D teams, including ODS and business-unit data scientists/analysts, doing hands on ML research in areas such as computer vision, natural language processing, interpretable ML, and privacy preserving ML.\nAccelerate the deployment of reproducible ML models by helping the business set and apply current best practices, including the use of open source software, container-based or serverless cloud platforms, and self-service operating models.\nDevelop common DS/ML tools and infrastructure across the business.\nSet the standards for statistical testing and experimental design, as well as other quality standards such as testing coverage, code review, etc. for data science\n\nWork with product owners and business units across Liberty to identify new opportunities where the ODS can accelerate research and development of DS and ML tools and techniques\n\nQualifications:\n\nBachelor's degree in Statistics, Economics, Computer Science, or any quantitative discipline with relevant work experience, required; advanced degree a definite plus.\nExtensive experience analyzing data and a broad understanding of core statistical and ML techniques.\nDemonstrated experience in deep learning, computer vision, natural language processing, and/or interpretable machine learning.\nDemonstrated proficiency in R or Python required.\nPossess strong analytical, strategic, project management, decision-making and problem-solving skills.\nDemonstrated ability to perform high quality work both independently and collaboratively.\nBenefits:\nWe value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits\nOverview:\nAt Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.\nWe're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.\nStart your job application: click Apply Now"}, "114": {"company": "Cimarex Energy", "description": "JOB SUMMARY:\nOur Data science team is advancing our business to harness the full capabilities of computation, robust datasets, analytics, statistical skills and innovation for our technical subsurface and operational business decision-making to drive value. We are looking to hire a top talent candidate that is passionate and committed to collaboratively working on challenging data science solutions for our businesses, including exploration, production, midstream, drilling, completions, and environmental stewardship.\nThe Data Scientist is responsible for analyzing large amounts of raw information to find patterns that impact business decisions utilizing machine learning and other advanced statistical methods. An aptitude for math, statistics, and analysis as well as critical thinking and problem-solving are required for this role. The individual will work closely with departments across the company to support and implement high-quality, data-driven decisions. Role will specifically focus on machine learning operations and model deployment.\nESSENTIAL DUTIES AND RESPONSIBILITIES:The following represents the majority of the duties performed by the position, but is not meant to be all-inclusive nor prevent other duties from being assigned when necessary:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data\nAnalyze large amounts of data to discover trends and patterns\nBuild machine learning algorithms & advanced statistical models\nPresent information through data visualization software\nMake recommendations based on model outcomes\nDeploy models for collaborative use\nCollaborate within a multi-disciplinary team and with other teams throughout the organization\nOther duties as assigned\nSKILLS AND EXPERIENCE:\nBSC/BA in Computer Science, Engineering, or a related technical field required; Masters or PhD preferred\nMinimum of 3 years of experience in a Data Science/Machine Learning role in oil & gas\nProficient in Python & SQL (or another database management system)\nStrong expertise in exploratory data analysis\nStrong expertise in the deployment of machine learning models\nExperience in a data visualization software (Spotfire, Tableau, Seaborn/MatPlotLib etc.)\nCreativity, deductive thinking and problem solving skills are necessary\nStrong competence in performing operational due diligence\nAbility to influence scientific direction of projects\nStrong aptitude for learning a broad range of scientific disciplines and translating that into technological solutions\nExcellent verbal and written communication skills are necessary\nMust be able to create and deliver effective presentations\nStrong networking and interpersonal skills, both internal and external\nExperience in Neural Networks using Tensorflow/PyTorch/Keras preferred\nNatural Language Processing (NLP) experience preferred\nDemonstrated initiative in completing MOOC\u2019s that are Data Science related preferred\nHadoop, Spark, or another big data processing experience preferred\nCloud computing experience (AWS, Azure etc) preferred\n\nWORKING CONDITIONS AND PHYSICAL DEMAND:\nWork is typically performed in an office environment. Exposure to conditions such as extreme heat or cold is not likely, but possible. If incumbent is required to travel to operations site, personal protective equipment including but not limited to head protection, hearing protection, safety glasses, safety shoes and flame resistant clothing is required. Safety rules including OSHA and DOT requirements are strictly enforced. Some travel may be required.\nCimarex Energy Co. is an equal opportunity employer. Applicants and employees are considered for positions and are evaluated without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, marital status or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved.\n\nTo apply to this job, click Apply Now"}, "115": {"company": "Zions Bank", "description": "Data Engineer - Salt Lake City, UT\n(\nJob Number:\n\n\n048355\n)\n\nhours per week\n:\n\n40\n\n\nDescription\n\n\n\nResponsible for the analysis, design, development and maintenance of the enterprise ETL systems and applications.\nWorks closely with diverse operational data systems, external data partners, business intelligence, statistical analysts and report developers.\nActs as a technical analyst to identify and understand source data systems.\nAdapts ETL processes to accommodate source system(s) changes in source systems or new requirements.\nProvides expertise in ETL performance tuning.\nMaps source system data into data warehouse models.\nCoordinates with Technical Architects, other Data Modelers and DBAs to review design strategies for new ETL processes.\nWorks with the business partners to identify and ensure that all service level agreements are met.\nPerform ongoing monitoring of the environment and applications for capacity planning, performance tuning and improvement opportunities.\nMay assist training other developers.\nOther duties as assigned.\n\n\nQualifications\n\nRequires a Bachelor's degree in Computer Science, Information Systems or a related field and some experience with analyzing, designing and developing of ETL systems, data warehouse applications and systems, relational databases; i.e. DB2 or Oracle, SQL, database design, ETL languages.\nIBM InfoSphere Information Server (DataStage) ETL development experience is required, prior experience working with Salesforce would be a big plus.\nExperience with Big Data technologies, i.e. Cloudera, Hadoop, Hive, Kafka, and Python scripting.\nFamiliar with ANSI SQL, PL/SQL, DB2 SQL, and Unix Scripting. Linux Red Hat experience with bash scripting preferred.\nExperience in the banking/finance industry a plus.\nA combination of education and experience may meet requirements.\nBasic knowledge of data warehouse applications and systems, Logical and Physical Data Modeling, Knowledge of relational databases (DB2, Oracle, Teradata, Greenplum,) SQL, database design, ETL languages.\nKnowledge of full life cycle of applications development and support including: analysis, design, development, testing, implementation and support.\nExperience with Data mapping/conversion, loading activities, interface programs.\nExcellent problem resolution and communication skills (oral and written).\nAbility to work independently and exercise independent judgment, effectively prioritize, and execute tasks while under pressure.\nAbility to identify and solve problems.\nStrong attention to detail.\nStrong organizational and customer service skills.\nMust be able to manage resources, timelines, deliverables and expectations for related projects.\nMust be comfortable and good at interacting and communicating with all levels inside and outside of the IT department.\n\n0\n\nWork Locations\n\n\nUtah-Salt Lake City-UT - Zions Bancorporation - HDQTRS\n\nInfo Systems & Technology\n\nNov 19, 2019\nStart your job application: click Apply Now"}, "116": {"company": "Enterprise", "description": "About the Role\nThe Analytic Center of Excellence (ACE) Lead Data Scientist independently leads initiatives using extensive data science expertise to understand internal and external customers' strategic business objectives, relate those objectives to measurable indicators and focus on delivering analytic products and services to create new insights and strategies promoting continuous performance improvements for the company. The ACE Lead Data Scientist specializes in applying advanced skills and expertise to create efficiencies and improve the decision making process for internal business units by developing and implementing advanced statistical and mathematical solutions. In addition, this position proactively seeks new data technologies, opportunities for automation and or other efficiencies for the team while assisting the manager with opportunities for employee development.\n\nCompany Overview\nEnterprise Holdings is the largest car rental provider in the world as measured by revenue and fleet. The company and its affiliate Enterprise Fleet Management which combined offer a total transportation solution that includes extensive car rental and car-sharing services, truck rental, corporate fleet management and retail car sales accounted for $24.1 billion in revenue and operated 2 million vehicles throughout the world in 2018. Enterprise Holdings annual revenues also place it near the top of the global travel industry, exceeding all other rental car companies, many airlines, and most cruise lines, hotels, tour operators and online travel agencies. Enterprise Holdings regional subsidiaries and Enterprise Fleet Management currently employ more than 100,000 people worldwide.\n\nThrough its integrated global network of independent regional subsidiaries and franchises, Enterprise Holdings operates the Enterprise Rent-A-Car, National Car Rental and Alamo Rent A Car brands at more than 10,000 fully staffed neighborhood and airport locations. The Enterprise Holdings global network operates in more than 90 countries and territories, including North America, Central America, South America, the Caribbean and Europe, as well as parts of Asia-Pacific and the Middle East. Today, the companys three brands serve more than 95 percent of the worldwide car rental market.\n\nThis position is located at our Corporate Headquarters in Clayton, MO.\n\nResponsibilities:\nLead the design and delivery of end-to-end advanced analytical solutions that address the business needs\nIndependently extract, clean and manipulate both structured and unstructured datasets\nPerform exploratory data analysis, generate hypotheses and extract actionable insights\nDevelop statistical and/or mathematical models that are put in production; assess current models in production and identify opportunities for enhancement and automation\nIndependently deliver detailed documentation including descriptions of efforts, results, insights and recommendations\nPresent the findings and recommendations to other ACE members and all levels of management\nPartner with other ACE Teams to ensure successful delivery of solutions\nProvide guidance to other Data Scientists on the team; Assist the Manager with training and development\nEvaluate new data technologies to determine the effectiveness of the solution and its feasibility\nSeek to develop strategies to link the team's analytical activities with business goals and objectives\nAdditional Responsibilities\nSeek to improve job performance through self-assessment, skill development, training and goal setting\nMaintain a regular and reliable level of attendance and punctuality\nPerform miscellaneous job-related duties as assigned\nEqual Opportunity Employer/Disability/Veterans\n\nQualifications:\n\nMinimum:\nPhD in Mathematics, Statistics, Operations Research, Physics, Engineering, Economics, Computer Science or a related quantitative field required\nMust be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future\n6+ years experience data mining and developing statistical and/or mathematical models using R, Python, or CPLEX\n6+ years experience with SQL and/or Python programming or directly querying relational databases such as Teradata, SQL Server, or Oracle\n6+ years experience with building statistical and/or mathematical models that are put in production\n4+ years experience preparing and giving presentations to non-technical audiences, including all levels of management\n2+ years experience applying strategic analytics within a corporate setting\n2+ years experience with conceptualizing new analytical products or enhancing existing products by using advanced analytical techniques\nExperience guiding and mentoring other data scientists\nCompetency Based:\nResults-Oriented\nProblem Solving\nForward-Thinking\nPersuading and Influencing\nWorking With a Team\nDetail-Oriented\nTo apply to this job, click Apply Now"}, "117": {"company": "7Park Data", "description": "7Park Data is the world\u2019s leading alternative data intelligence firm. We have access to some of the most coveted alternative datasets \u2013 such as clickstream, geolocation, mobile app usage, credit and debit card, email receipt, and shipping cargo data \u2013 and we are continuously acquiring more.\n\nYou will be joining other extremely passionate data scientists, product managers, and engineers that share a common interest in tackling some of the most difficult data science and machine learning problems today. With the data products and machine learning systems you design, 7Park will arm influential decision-makers at financial and corporate giants with critical information they need to make smart, data-driven decisions. And, along the way, you will help advance the current work in artificial intelligence and predictive modeling.\n\nThe data science team has two major goals: to design and build data products that provide intelligence on real-time economic activity to our financial and corporate clients and to both research and develop machine learning systems to extract information from large volumes of structured and unstructured text.\n\nWe are looking for a talented and creative NLP Data Scientist to join our Natural Language Processing team. As an NLP Data Scientist, you will be responsible for the following:\nConducting research on some of the world\u2019s most interesting alternative datasets\nPlanning, developing, and applying cutting-edge machine learning systems and statistical modeling to extract insight from vast amounts of data at scale\nWriting production-ready code to make accurate and timely predictions on out-of-sample data\nDesigning systems to monitor the results of models in production, discover and address anomalies, and ensure the robustness and reliability of these models\nLeading projects from start to finish, collaborating with 7Park\u2019s senior management, product managers, engineers, external data partners, and clients\nThe ideal candidate will be passionate about building machine learning systems on real world data and have several years of industry experience and/or a Masters or PhD in computer science, mathematics, statistics, linguistics, physics, computational finance, or a similar quantitative field.\n\nIt is also very important that you enjoy working in a tight-knit and highly entrepreneurial startup that marries the creative, experimental problem-solving found in academia with the hacker ethos of shipping products quickly and often.\n\nRequirements\n3 - 5 years of relevant professional experience and/or a Masters or PhD in computer science, mathematics, statistics, linguistics, physics, computational finance, or similar quantitative field.\nStrong knowledge of machine learning, computer science, mathematics, and statistics.\nStrong programming skills in Python, R, and/or Scala.\nExperience with NumPy, SciPy, Pandas, Scikit-Learn, TensorFlow, and Keras. PyTorch is also acceptable.\nExperience with building distributed machine learning systems using Apache Spark and a working knowledge of MLlib.\nExperience with several of the following libraries and models: CoreNLP, NLTK, Gensim, SpaCy, Apache Lucene and Solr, Apache OpenNLP, TextBlob, Word2vec, and GloVe.\nA background in NLP, including experience with several of the following concepts: named entity recognition, named entity linking, natural language understanding, cognition, collaborative dialog, building blocks of language (morphology, syntax, semantics, pragmatics), knowledge representation, automated knowledge acquisition, formal reasoning, and sentiment analysis.\nBonus\nPublications in communities such as NIPS, ICML, or related.\nGitHub projects demonstrating your creative drive.\nKaggle wins demonstrating your competitive drive.\nExperience running or working at data-centric startups.\nExperience with knowledge graphs.\nWorking knowledge of GraphX and Spark Streaming.\nTo apply to this job, click Apply Now"}, "118": {"company": "Frontier Technology Inc.", "description": "This position requires a Secret clearance.\nFTI is currently looking for a full time Data Analyst to support the Naval Safety Center in Norfolk, VA. The Data Analyst will be working on-site to support the development, testing, and deployment of a series of advanced predictive analytics models within a CITRIX virtual desktop environment using big data sets that will help diagnose and predict precursors to Naval mishaps and safety hazards. The Data Analyst will collaborate within a diverse program team comprised of FTI team members as well as Active Duty Military and Government civilian employees.\n\nAssist in the developing, testing, and deploying of predictive analytics models utilizing R, R Studio, and/or Python. Experience with supervised learning algorithms such as linear/logistic regression. Experience with data visualization tools such as Tableau, ggplot2, Shiny, etc.\n\nEducation \u2013 Bachelor\u2019s degree in Mathematics, Computer Science, or related fields. Master\u2019s degree in Business Analytics preferred.\nMinimum of four (4) years of experience in statistical analysis, data analysis, or operational research. Two (2) years of experience with Navy safety, aviation, or ship systems preferred.\nApply Now: click Apply Now"}, "119": {"company": "Equity Methods", "description": "Senior Consultant \u2013 Data Scientist and Senior Economist\n\nWe are hiring an expert in statistical analysis to join our team. The successful candidate will possess strong technical and practical problem-solving skills to deliver creative solutions in the course of demanding client engagements of many varieties. Successful professionals at Equity Methods are analytical, resourceful, low on politics, and high on impact.\n\nMore generally, critical skills include:\nExcited to solve complex problems\nProcess oriented\nIntellectually curious\nComfortable and resourceful in ambiguous situations\nDetail orientation while still considering the big picture\nFocused on creating impact and willing to bend/stretch to deliver an A+ outcome\nHighly responsive to feedback\nOwns outcomes amid uncertainty and competing priorities\nQualifications\nMaster\u2019s in Statistics, Economics, or another related quantitative field\n3-8 years of exemplar performance doing quantitative analysis in a finance or economics role\nMastery of statistics principles\nComfort with big data and technology\nExperience with programming based statistical software packages (e.g., SAS, R, Stata, etc.)\nAbility and willingness to think critically and solve \u201cout-of-the-box\u201d problems independently\nClear oral and written communication\nSpecific experience in our functional domain (compensation) is not required.\n\nAbout the Role\n\nThe successful candidate will onboard to the role by completing training on our internal processes, algorithms, programming tools, industry ecosystem, and client engagement structures.\n\nAfter training is complete, this role will be heavily involved in projects that use statistical analysis to answer HR related questions asked by leading public and private companies, primarily Fortune 500 organizations. Examples include statistical pay equity studies to help clients test whether pay practices differ by gender or ethnicity, workforce analytics studying attrition patterns and drivers, and performance metrics that are correlated with future shareholder value creation.\n\nOver time, this role can expand to encompass a broader portfolio of project types. For example, our HR analytics consulting practice works closely with our valuation practice such that a natural extension is to valuing complex compensation and other financial instruments using Monte Carlo simulation and other best-of-breed methods.\n\nMore specific tasks underlying this role include:\nLead the team to use proper statistical techniques by bringing excellent technical skills to complex problems. Serve as a technical subject matter expert and \u201cgo-to person\u201d on the team.\nPackage technical concepts into consumable plain-English content for clients to absorb.\nLead service scaling by engineering robust processes, creating internal resource materials and documentation, and driving continuous improvements.\nSupport implementation of new clients by understanding client-specific needs and expectations; support process creation, implementation timeline management, deliverable walk-throughs and more to arrive at exceptional client experiences.\nParticipate in practice- and firm-level initiatives involving client service, thought leadership, business development, channel relationships, and risk management.\nMore about Equity Methods\n\nEquity Methods provides valuation, financial reporting, and human resources advisory services related to equity compensation and other complex securities.\n\nAt Equity Methods, we believe in the power of equity-based compensation to advance a company\u2019s strategy. We tailor reports and the processes that produce them to your specific award types, compliance objectives, reporting requirements, and systems. Since 1998, we have assisted 35 Fortune 100 companies and over 600 clients with their most pressing equity compensation valuation and reporting challenges. From pre-grant Monte Carlo modeling for relative TSR awards to fully outsourced financial reporting, we\u2019re dedicated to bringing insight, control, and expanded capability to financial reporting and human resources teams.\nTo apply to this job, click Apply Now"}, "120": {"company": "Bayview Asset Management", "description": "POSITION SUMMARY\n\n\nThe candidate will be joining the research team at Bayview Asset Management, which develops and implements statistical models for the valuation of mortgage assets. This role will be to develop, maintain, and enhance the various databases used within the Research group, and to also make the monthly data loading processes more efficient.\n\nESSENTIAL DUTIES AND RESPONSIBILITIES\n\n\nInitial projects will include:\nImprove/maintain/create various data loading/data cleaning packages to ensure data integrity and speed\nIntegrate data from multiple sources to meet business requirements\nAd hoc data analysis/data query projects\nCollaborate with IT/Traders to achieve project goals\nLonger term projects may include:\nImprove data surveillance and develop data visualization tools\nAutomated data mining\nREQUIRED SKILLS/KNOWLEDGE/ABILITIES\nUnderstanding of Relational Database Structures\nAbility to communicate ideas in both technical and user-friendly language\nStrong scientific programming skills/strong quantitative skills, and a high aptitude for problem solving\nA passion for analyzing data\nDESIRED SKILLS/KNOWLEDGE/ABILITIES\nExperience working with C#/C++ or Python\nExperience working with SAS or R\nStatistical analysis and modeling\nEDUCATION AND EXPERIENCE\n\n\nThis is a mid-level position; however more qualified individuals are also encouraged to apply.\nCandidates typically possess an undergraduate degree in a hard science, computer science, applied math, physics, statistics, and engineering. Master\u2019s degree a plus\n3-5 years of hands on experience in database development\nExperience with Microsoft SQL Server/SSIS\nAn understanding of finance and economics is preferred but not required\nPrior experience analyzing mortgages is a plus but not required\nTo apply to this job, click Apply Now"}, "121": {"company": "ProHealth Care (WI)", "description": "Sr Clinical Data Analyst - Performance Excellence\n\nLocation:\n\nWaukesha\n\nShift Type:\n\nDays - 1st Shift\n\nWeekly Hours:\n\n40\n\nProHealth Care has been the health care leader in Waukesha County and surrounding areas for the past century, providing outstanding care across a full spectrum of services. The people of ProHealth Care strive to continuously improve the health and well-being of the community by combining skill, compassion and innovation. The ProHealth family includes Waukesha Memorial Hospital, Oconomowoc Memorial Hospital, the Rehabilitation Hospital of Wisconsin, ProHealth Medical Group clinics, AngelsGrace Hospice, ProHealth Home Care & Hospice, West Wood Health & Fitness Center and Regency Senior Communities. Learn more at ProHealthCare.org\n\nSchedule: Primarily Monday - Friday 8:00 am - 4:30 pm with additional hours as needed.\n\nFull Time Benefits\n\nFTE: 1.00\n\nResponsible for supporting clinical and operational decision making via analysis of data and mathematical modeling. This role would also serve as a key data steward and subject matter expert for clinical data (such as Epic Clarity data) within the department and engage in our Analytics Center of Excellence.\n\nKey Accountabilities:\nEngage with the \"Voice of the Customer\" to understand the problem to be solved, and translate that into actions the Analytics teams can take on to support\nProvide expert advice to customers on statistics, data sourcing and mathematical modeling methods to address complex questions, such as the impact of particular programs and interventions on patient outcomes\nMentor other analysts in advanced methods to \"build the army\" to support the needed data-based decision making with limited resources, such as developing and interpreting predictive models\nWork with cross-functional teams in a consulting fashion to develop high quality reporting and analytic solutions that provide key insights on variations in clinical outcomes\nThe Senior Clinical Data Analyst is someone who can functionally use statistics and has enough experience to guide and serve as a mentor to others in this area.\n\nQualifications:\nBachelor\u2019s Degree in a related field required. Master\u2019s Degree preferred.\nAt least 2 years, with 4 or more preferred, in related experience.\nProficient in statistical analysis and software packages such as: SAS, R, MiniTab or SPSS.\nExpert-level Excel user.\nExperience with:\nRelational databases, including proficient in SQL\nData mining in various tools\nProgramming languages\nExperience in health data analysis, business analysis, technical documentation and data management in a healthcare-related field.\nProficient in medical terminology and knowledge of coding systems (ICD-10, CPT, etc)\n#LI-MD\n\n*CA\n\nProHealth Care, one of the largest employers in Waukesha County, offers work that is challenging and rewarding. The organization is dedicated to providing the highest quality service to our patients and their families and treats each individual with respect \u2013 the way they should be treated. ProHealth Care supports a Just Culture, one that encourages an open learning environment and maintaining safe systems. We have high expectations for those who join our team of nearly 5,000 employees. In return, we offer exceptional career opportunities in a dynamic, health care system where the contributions of every team member are valued.\n\nProHealth Care is an equal opportunity employer and is committed to an inclusive work environment and values the perspectives of our people. We maintain a drug-free workplace and perform pre-employment substance abuse testing. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, gender identity, sexual orientation, age, status as a protected veteran, among other things, or status as a qualified individual with disability.\n\n\nDo You Fit at ProHealth Care?\n\n\nHere at ProHealth Care, we strive to be the best we can be, while continually improving the care we deliver. With patient care at the center of all we do, it is ingrained into our culture to attract the best and the brightest to ProHealth Care. We have a promise to our patients and employees: The way you should be treated. We live by this commitment and remain dedicated to creating a warm, safe and welcoming environment.\nStart your job application: click Apply Now"}, "122": {"company": "Novartis", "description": "50-80%. The amount of time the average data scientist spends preparing data. You will help drastically reduce this number to unlock efficiencies in how we discover new drugs.\n\nPassionate about making connections between data sets at scale to unearth more needles from many more haystacks? We are looking to fill a position that sits precisely at this point in early computational drug discovery: between large-scale processed raw data on one side and individual molecular insights on the other side. If you are a versatile data scientist who enjoys casting problems into generic computational solutions to catalyze efficiencies in data-driven drug discovery, this is for you.\n\nYour responsibilities include but are not limited to:\n\u2022 Engage with computational peers across the research organization to identify recurrent problems that can be solved at scale, focusing on all data domains that are of practical use in drug discovery.\n\u2022 Design, implement, and maintain robust methods, algorithms, and packages (python, R) that help the computational community solve old and new problems with ease.\n\u2022 Define, refine and promote the computational glue that is between large-scale data processing (such as NGS pipelines) and insights at very detailed level.\n\u2022 Ideate and implement visualizations, dashboards & webservices for data dissemination to computational peers as well as to non-computational collaborators.\n\nPosting Title\nData Scientist \u2013 Data Connector\nApply Now: click Apply Now"}, "123": {"company": "Travelers", "description": "Company Information\nSolid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n\nJob Summary\nInnovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions. Thought leaders in the field of Data Science in emerging technology are at the core what we strive for to deliver business impact across the enterprise. In this role, you will work with a multidisciplinary team to design, develop & create analytical solutions through applications of Data Mining, Machine Learning, Artificial Intelligence and Emerging Technologies. The ideal candidate will increase the maturity of the groups current analytical capabilities by progressing from traditional Predictive Modeling to true machine intelligence, and take advantage of emerging technologies around Data Science and AI. This role thrives on change, exercises influence across the enterprise and can make sense of uncertainty. This candidate will be expected to be hands on as well as guide and mentor new modelers in the team.\n\nPrimary Job Duties & Responsibilities\nUnderstand business needs and apply Data Science/AI/Machine Learning technology to solve real-world business problems within and across business areas Ability to build and optimize models using machine learning techniques including feature selection & engineering, boosting, deep learning and ensembles\nAddress pain points of the business and provide additional insights across domains like Regression, Classification, Machine Vision, Natural Language Processing, Deep Learning, and/or statistical modeling\nAs a technical lead candidate will be working with various cross functional teams across the enterprise such as data engineers, data scientists, statisticians, actuaries, application developers, and several other key leadership roles\nAnalyze source data, working with structured and unstructured data (internal and external data)\nManipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships, and trends\nExtend companys data with third party sources of information when needed\nWill manage one or more initiatives simultaneously across Lines of Businesses and/or functions\nUnderstands Enterprise business needs and applies AI/Machine Learning technology to solve real-world problems that benefit horizontal goals & objectives\nPresent analysis and recommendations to a diverse group of enterprise-wide stakeholders.\nPotential to manage employees\nMinimum Qualifications\nPhD STEM (Science, Technology, Engineering, Mathematics) degree with 1 years experience or Masters STEM degree with 4 years experience or Bachelor's STEM degree with 6 yrs required. Moderate working knowledge of modeling/research/analytics or actuarial required. Relevant statistical analysis work experience required.\n\nEducation, Work Experience & Knowledge\nRelevant work experience in research and/or advanced analytic work (e.g. predictive modeling) in the insurance industry preferred.\n\nJob Specific & Technical Skills & Competencies\nAbility to read/revise/review a statistical software program (e.g. R, SAS, SPSS).\nAbility to develop advanced models and interpret model results.\nUnderstanding of advanced statistics underlying data models. Ability to apply emerging statistical procedures to work.\nWillingness to innovate with the possibility of failure.\nStrong communication, collaboration and relationship building skills with the ability to present and translate complex information to very senior leadership and non-technical teams in relevant business terms.\nExhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.\nAbility to leverage business knowledge to determine approaches to execution.\nAbility to take action in solving problems while exhibiting judgment and a realistic understanding of issues; ability to use reason; review facts, identify inconsistencies and weigh options; ability to make logical and timely decisions that address the right issues.\nPreferred Qualifications\n2+ years of experience in one or more of the following: Machine Learning Libraries, Computer Vision, Speech Recognition and Natural Language Processing\n4+ years of experience in programming with Python and/or R\n2+ years of experience in handling data and working with database tools, e.g., SQL, Hadoop or Spark\nProven ability to work creatively and analytically in a problem-solving environment\nExperience with Deep Learning Tools such as TensorFlow\nExperience with contributing to open source projects\nEqual Employment Opportunity Statement\nTravelers is an equal opportunity employer.\nTo apply to this job, click Apply Now"}, "124": {"company": "Los Alamos National Laboratory", "description": "Vacancy Name: IRC74561\n\nDescription\n\nJob Title Senior Physicist (Scientist 4)\n\nLocation Los Alamos, NM, US\n\nOrganization Name X Theoretical Design (XTD-DO)\n\nMinimum Salary 119700\n\nMaximum Salary 201700\n\nWhat You Will Do\n\nX-Theoretical Design (XTD) division members are the scientific stewards of the U.S. nuclear stockpile, applying theoretical and computational physics to the performance and safety of nuclear weapons. XTD scientists also contribute their expertise to the nation\u2019s foreign threat assessment, counter-proliferation and non-proliferation efforts through assessment of foreign devices, design of tools to address nuclear emergency response scenarios, and creation of solutions to inhibit nuclear proliferation. In addition, XTD scientists contribute to cutting edge advances in astrophysics, geophysics, high energy density physics, inertial confinement fusion, chemistry, and material science. Members of XTD use multi-physics codes, running on some of the world\u2019s fastest supercomputers, to create and analyze simulations of very complex systems. We work closely with many other organizations in a diverse variety of tasks, including experimental design and analysis, model development, code validation, and project leadership. The selected candidate will:\nDemonstrate thorough knowledge and capability with large, multi-physics codes.\nApply codes to solve problems of national security interest, exercising personal initiative to guide your own and others\u2019 efforts.\nContribute to one or more of the related tasks: leading experimental design and analysis, coordinate with model development efforts, project and/or program leadership, data evaluation, and code validation.\nDemonstrate leadership through teaming efforts.\nContribute to organizational and institutional knowledge level by mentoring others.\nContinue to expand your technical knowledge.\nDevelop/demonstrate generalist capabilities in solving problems.\nWork with a wide variety of colleagues with varying backgrounds across the laboratory and the NNSA complex on research covering multiple physics areas in order to solve difficult problems.\nDemonstrate and maintain excellence in communication, both written and verbal.\nWhat You Need\n\nMinimum Job Requirements:\nExperience with large-scale computing.\nFamiliarity with design and analysis of nuclear weapons.\nExperience in designing, analyzing and/or conducting experiments.\nDemonstrated supervisory or mentoring experience.\nKnowledge and experience relative to uncertainty and/or risk analysis.\nDemonstrated technical leadership experience.\nDemonstrated leadership experience in addressing issues related to national security.\nA documented history of technical contributions to one or more of the following fields:\nNuclear physics\nPlasma physics\nFluid dynamics\nAstrophysics\nShock physics\nEnergetic materials\nParticle physics\nMaterials science\nAbility and willingness to obtain a DOE Q-clearance, which requires US citizenship.\nDesired Skills:\nActive Q Clearance\nEducation Required:\nA PhD preferred with postdoctoral work in the following or a related field:\nEngineering\nApplied Mathematics\nMaterial Science\nBS or MS will be considered if there is significant demonstrated experience in the field of nuclear weapons.\nNotes to Applicants: Please submit a detailed cover letter with your resume addressing all required and desired skills (please save cover letter with job number and name).\n\nAdditional Details:\n\nClearance: Q (Position will be cleared to this level). Applicants selected will be subject to a Federal background investigation and must meet eligibility requirements\nfor access to classified matter.\nEligibility requirements: To obtain a clearance, an individual must be at least 18 years of age; U.S. citizenship is required except in very limited circumstances. See DOE Order 472.2 for additional information.\nNew-Employment Drug Test: The Laboratory requires successful applicants to complete a new-employment drug test and maintains a substance abuse policy that includes random drug testing.\n\nRegular position: Term status Laboratory employees applying for regular-status positions are converted to regular status.\n\nInternal Applicants: Please refer to Laboratory policy P701 for applicant eligibility.\n\nEqual Opportunity:\n\nLos Alamos National Laboratory is an equal opportunity employer and supports a diverse and inclusive workforce. All employment practices are based on qualification and merit, without regards to race, color, national origin, ancestry, religion, age, sex, gender identity, sexual orientation or preference, marital status or spousal affiliation, physical or mental disability, medical conditions, pregnancy, status as a protected veteran, genetic information, or citizenship within the limits imposed by federal laws and regulations. The Laboratory is also committed to making our workplace accessible to individuals with disabilities and will provide reasonable accommodations, upon request, for individuals to participate in the application and hiring process. To request such an accommodation, please send an email to applyhelp@lanl.gov or call 1-505-665-4444 option 1.\n\nWhere You Will Work\n\nLocated in northern New Mexico, Los Alamos National Laboratory (LANL) is a multidisciplinary research institution engaged in strategic science on behalf of national security. LANL enhances national security by ensuring the safety and reliability of the U.S. nuclear stockpile, developing technologies to reduce threats from weapons of mass destruction, and solving problems related to energy, environment, infrastructure, health, and global security concerns.\n\nOur diverse workforce enjoys a collegial work environment focused on creative problem solving, where everyone\u2019s opinions and ideas are considered. We are committed to work-life balance and personal/professional growth. Our creative and dedicated computational professionals are our greatest asset and we take pride in cultivating their talents, supporting their efforts, and enabling their success. Together we are advancing our national security mission.\n\nCompensation and Benefits\nCompetitive salaries\nFlexible work schedules\nExercise facility free for staff use\nChoice of comprehensive medical plans\nPaid maternity leave, sick time\nPaid parental leave\n401k match (100% up to 6% + kicker)\nFully vested in 401k day one\nDisability insurance\nLos Alamos National Laboratory in Los Alamos, NM enjoys excellent weather, clean air and outstanding public schools. This is a safe, low-crime, family-oriented community with frequent concerts and events as well as quick travel to many top ski resorts, scenic hiking trails, and mountain climbing. The short drive to work includes stunning views of the Valles Caldera as well as the Sangre de Cristo mountains. Many employees also live in the nearby state capital, Santa Fe, which is known for world-class restaurants, art galleries, and opera.\n\nAppointment Type Regular\n\nRegular\n\nContact Details\n\nContact Name Chavez, Raymond Ceasar\n\nEmail chavez_r@lanl.gov\n\nWork Telephone\n\nReq ID: IRC74561\nApply Now: click Apply Now"}, "125": {"company": "Callisto Media", "description": "We combine the power of Big Data, technology, and lean economics. We discover the information people are searching for and provide it. We help transform lives.\n\nCallisto Media will be unmatched in providing products, services, and experiences to a diverse universe. From mainstream populations to groups that traditional companies believe are too small or economically unfeasible to address, we will meet their needs.\n\nToday, we're the fastest growing company in the $140 billion global publishing industry, and our primary method for meeting peoples' needs is through books. But creating books for them is only the beginning.\n\nThis person will manage a team of data analysts using our proprietary, data-driven processes to produce titles. They will need to understand our internal tools and processes and supervise analysts using these processes to work with editors, designers, and marketers. They will also supervise analysts working on data analysis projects. They will work with R&D leadership and with other departments to coordinate production work and research projects.\n\nRequired Skills and Abilities:\nUnderstand tools and processes designed by the R&D team and supervise analysts using these tools.\nCoordinate tasks involving multiple departments with tight production schedules.\nDesign and supervise execution of research related to title production and marketing.\nUse our internal tools and data collection systems to perform analyses and recommend improvements to our processes that are supported by data.\nGenerate reports to convey research findings to other departments.\nConduct ad-hoc analyses for other departments to help answer questions related to production, marketing, and sales decisions.\nRequired Experience:\nBachelor\u2019s degree or higher in a relevant discipline.\n2-3 years experience managing a team.\nExperience with statistics and research methodology.\nAbility to manage multiple projects simultaneously with minimal supervision.\nExperience in Evolutionary and/or Agile development preferred.\nProven experience solving complex business issues through data-related tools.\nStrong communication skills, particularly with internal clients and managers.\nAbility to take initiative and work with a high level of independence\nJoin us! We are a team where data drives our decisions. Where culture matters. We put our customers first and they embody our core values. We\u2019re entrepreneurial and focused in our approach. We challenge each employee to experiment and drive results while feeling empowered to do their best work each and every day.\nCallisto Media offers a competitive salary, full benefits, 401k, stock options, for full-time employees, as well as a friendly working environment. This is a full-time, onsite position.\n\n\nApply\nApply Now: click Apply Now"}, "126": {"company": "LSQ", "description": "Job Title: Data Scientist (Risk)\n\nLocation: Orlando, Florida\n\nManager: Head of Data Science\n\nAbout LSQ\n\nLSQ is a technology-driven provider of accounts receivable financing to companies who need working capital but may not be able to obtain sufficient financing from their bank. Our focus is to help businesses release the liquidity tied up in their accounts receivable. With financing from LSQ, a business can purchase more inventory, fill more orders, and take advantage of new growth opportunities. Our technology and data driven approach to providing working capital, along with our accounts receivable management services, allows our clients to driving business success.\n\nJob Overview\n\nLSQ is searching for a Data Scientist (Risk) to join our growing team of analytics experts. The hire will be responsible for building data driven tools to automate and scale risk decisions decision points include, fraud detection, commercial credit analysis, and invoice payment behavior. The ideal candidate is an experienced researcher and data wrangler who enjoys applying complex theories to solve real world business problems. The Data Scientist will need to collaborate effectively with both technical (engineers, data experts) and non-technical (business users) colleagues to bring the data to life.\n\nResponsibilities of Data Scientist (Risk)\nWe have 20+ years of real-world commercial data weve observed businesses and their interactions with other businesses across market cycles, industries, and catastrophic events. Build risk tools that optimize for velocity and scale.\nBuild risk tools that optimize science & art you will work with risk experts who have been in the trenches (and learned from losses). Augment human decisions with machine.\nLay the foundation for scale. A data science framework for optimal data acquisition, model training and deployment. Dont take short-cuts. Bring quantitative and statistical rigor to your body of work.\nLead by example. You are joining a data team at ground-level. Building and inserting a data team, into a 20+ year old company (organism) will be hard, but rewarding.\nQualifications for Risk Data Scientist\nCuriosity, Grit, and Humility\n5+ years of experience of hands-on data science role\nPrevious experience of building commercial finance risk tools should be beneficial, but not required\nBachelor or Masters degree in Data Science, Operations Research, Computer Science, Industrial Engineering, Statistics, or another quantitative field\nA toolkit of modern data science techniques\nExperience with any data science tools/packages: Python, R, SAS, XGBoost, TensorFlow, NLTK\nExperience with any big data tools: Hadoop, Spark, Kafka, Data Bricks\nExperience with any reporting tools: Tableau Server, Power BI, SSRS, Excel\nExperience with any AWS cloud services: EC2, EMR, RDS, Redshift, Aurora, S3\nExperience with any Stream-processing systems: Storm, Spark-Streaming\nPosition Type and Expected Hours of Work:\n\nThis is a full-time position. Days and hours of work are Monday through Friday, 8:00 a.m. to 5 p.m. Occasional evening and weekend work may be required as job duties demand.\n\nPhysical Demands:\n\nWhile performing the duties of this job, the employee is regularly required to sit and use hands to finger, handle, or feel. The employee is frequently required to reach with hands and arms and talk or hear. The employee is occasionally required to stand; walk and stoop, kneel, crouch.\n\nTravel:\n\nThere will be minimal travel required for this position.\n\nLSQ is an Equal Opportunity Employer that does not discriminate on the basis of actual or perceived, race, religion, color, sex (including pregnancy and gender identity), sexual orientation, parental status, national origin, age, disability, family medical history or genetic information, political affiliation, military service, any other non-merit based factor or any other characteristic protected by applicable federal, state or local laws. Our leadership team is dedicated to this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, employee activities and general treatment during employment. If youd like more information about your EEO rights as an applicant under the law, please click here http://www1.eeoc.gov/employers/poster.cfm\nApply Now: click Easy Apply"}, "127": {"company": "Crossix Solutions", "description": "Crossix is seeking intellectually curious, resourceful, and collaborative Data Scientists with experience in quantitative research methods and statistical sampling to join our Advanced Analytics team. This is an excellent opportunity to help us build the technology and data science products that power our business and be at the forefront of innovation in the healthcare technology space.\n\nThe team is guided by its core values as it works to solve the most challenging problems in healthcare data and analytics:\nSingular Focus\nSpeed\nHumility\nOwnership\nChallenge\nWhat You'll Do\nLeverage quantitative research experience to design and build nationally representative datasets\nCollaborate closely with a team of data scientists, product managers, and executives to discover and deliver product offerings from prototype to massive scale\nRapidly build prototype product solutions, communicate findings, and iterate\nExplore and find meaning in high volumes of data to evaluate data quality and extract actionable insights that will help drive business decisions; execute data querying, data cleansing, and experiment design\nDraw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solved\nMaster core parts of the Crossix technology platform. Technologies include Spark, SQL, Python, R, AWS, and proprietary data mining software\nWork with engineering and development teams to improve and implement features in Crossix's platform\nWhat You've Done\nGraduate level degree in statistics, social sciences, or other quantitative discipline with at least 2 years of work experience\nExpertise in quantitative and survey research methods, sampling, designing representative panels\nAdvanced knowledge and professional experience in statistical modeling and data mining\nStrong problem-solving skills\nStrong hands-on coding skills in statistical modeling programing languages such as R and Python\nAdvanced SQL skills; expertise in best practices and tools for interacting with large data sets\nExperience with AWS for data-warehousing and processing is a plus\nExcellent written and verbal communication skills\nWho You Are\nHave a desire and preference for working in a fast-paced, entrepreneurial environment\nEnjoy having clear ownership of a goal even if the path to get there is not entirely clear\nHave a curiosity to figure out new problems\nAre humble and truly think about the success of the group before your own contribution\nAre comfortable challenging existing norms, thinking and teammates, always doing so respectfully\nAbout the Team \u2013 Crossix is the market leader in delivering hard-to-come-by insights that enable healthcare marketers to plan, measure, and optimize their marketing campaigns with confidence. Using our own proprietary technology and network of health and non-health data, our analyses pinpoint the tactics, programs, and channels that improve performance and boost sales, enabling better healthcare communications. And we do it all while protecting consumer privacy.\n\nLeadership \u2013 With decades of combined experience and an unrivaled track record of healthcare innovation, our leadership team sets the standard for us. Their knowledge and expertise continually challenge us and the industry \u2013 through their work, their speaking engagements at conferences and their thought leadership published in the top industry publications.\n\nCulture \u2013 We know that our employees set us apart. Along with competitive salaries and benefits, we invest in creating compelling opportunities for professional development and career growth. We also believe that diversity is essential to building an environment where everyone can feel they belong. We're continuously building an inclusive company where everyone feels welcome and heard. Come join our rapidly growing team!\n\nWe are an equal opportunity employer and welcome all qualified applicants regardless of race, color, religion, sex, gender identity, sexual orientation, marital status, ancestry, national origin, age, disability, genetic information, or veteran status.\nApply Now: click Apply Now"}, "128": {"company": "Helix", "description": "It's our mission to empower every person to improve their life through DNA. We believe DNA will be digitally accessible to each person so that it can be used\u2014at any time\u2014to improve health outcomes and accelerate research.\n\nHelix powers life-changing population health programs. Our world-class clinical laboratory platform and proprietary Exome+ assay enable health systems to integrate genomic information into routine clinical care and enhance the accessibility of personalized healthcare. Additionally, Helix stores and protects participants' DNA information, so that as the science evolves, health systems, patients and researchers are able to continuously benefit from a lifetime of DNA insights.\n\nOur big vision comes with big responsibility. That's why we're building a diverse team of experts in the field of genetics, engineering, design, business development, and beyond to help bring actionable insights to our customers.\n\nThe mission of the Helix Research team is to conduct cutting-edge genomics research, to collaborate with and support our clinical, health, and life science partners in population-based genomic studies, by demonstrating the capabilities of the Helix Exome+ platform and suite of bioinformatics products and services. We are also responsible for the integration, analysis, and interpretation of genomic, phenotypic, and clinical information obtained from EMRs, self-reported health outcomes, claims, quantitative biomarkers, and other digital phenotypes. We believe that everyone will be sequenced as part of routine medical care in the not-too-distant future and our fast and nimble team helps generate the evidence to turn that faith into fact.\n\nAs a Senior/Staff Research Scientist, you will:\nConduct short- and long-term research projects, varied in scale, algorithmic and data complexity, phenotype, disease, and therapeutic area\nImplement creative solutions to research problems, and be eager to learn and apply cutting-edge tools to questions.\nWork collaboratively with internal and external teams to conduct research on genomic and phenotypic data to replicate published studies in new cohorts and discover novel associations\nPresent your findings internally to key stakeholders and externally to partners and at conferences\nRequired background:\nA PhD in bioinformatics, computer science, computational biology, genomics, or a related field with 5+ years of experience\nExperience with GWAS and PheWAS of using large human genomic datasets, such as 1000Genomes, UKBiobank, TOPmed, MVP, etc.\nExperience with open-source bioinformatics tools / packages (Hail, PLINK, Bioconductor, GATK, etc)\nCandidates should possess outstanding communication skills as well as broad biological interests that will enable them to facilitate interactions between clinicians, bioinformaticians, scientists, and business and learn new areas easily.\nStrong programming and scripting abilities in languages (Python, R, etc).\nThe ideal candidate will have:\nPost-doc experience and strong publication record\nPrior experience with large observational databases (e.g., administrative claims and electronic medical records, disease registries, etc.) and observational research/epidemiology statistical methods\nWorking knowledge of OMOP and/or other CDM\nExperience working with cloud-based analytical platforms (AWS, etc)\nExperience in writing queries for SQL and document databases\nWhat Helix has to offer you:\n\nAside from working alongside brilliant, dedicated, passionate, down-to-earth, curious, warm, and thoughtful people, we also provide great benefits:\nCompetitive compensation, including meaningful equity\nHealth insurance, including medical, dental, and vision\n12 weeks of Maternity or Paternity leave\n4 weeks of paid Pregnancy Disability\n401(k) with employer matching\nOn-premise nursing room\nCommuter benefits\nCatered meals\nFlexible PTO\nHelix is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws.\nApply Now: click Easy Apply"}, "129": {"company": "Northrop Grumman", "description": "Are you ready to leverage your security clearance, knowledge and technical experience in a new role?\n\nAdversaries, cybercriminals and cyber terrorists, are working every hour of every day to develop new means to compromise networks, to seize valuable intellectual property and personal data, and to gain an advantage on the digital battlefield. At Northrop Grumman, our mission is to see to it that they fail. Speed, stealth and precision keys to controlling the physical domains of land, sea, air and space are imperatives in controlling the cyber domain. Our talented employees make advances every day based on these imperatives and are committed to providing the most advanced protection for our customers against the rapidly evolving cyber threat spectrum. Our company is trusted with securing some of the most high-risk systems and continues to be the trusted provider of mission-enabled solutions for the security or our nation and allies. This is without a doubt one of the most exciting times to join our team. So come join us and experience the value of performance.\n\nNorthrop Grumman Mission Systems is seeking multiple Data Scientists to support fast-paced cutting edge programs ensuring national security and defense. The positions are located in the Annapolis Junction, MD greater area.\n\nThis position represents immediate opportunities across multiple programs. Though each program has specific labor categories which must be met prior to placement, all candidates must minimally meet the knowledge, skills and abilities listed below.\n\nNGCIMSMD\nRocktober\n\nBasic Qualifications:\n\nBachelor's Degree in related technical discipline (including but not limited to computer science, data science, information systems, science, engineering, math, economics, or aerospace) from an accredited college or university is required. Four (4) years of additional systems engineering/architecture experience on projects with similar software processes may be substituted for a bachelor's degree.\n\n5+ years of Experience with data analysis and applications, that address a business issue or provide a competitive advantage for an organization. (5 Years with Bachelors in Science; 3 Years with Masters; 0 Years with PhD)\nExperience creating data mining architectures/models/protocols, statistical reporting, and data analysis methodologies to identify trends in large data sets.\nStatistical or data visualization skills.\nUS Citizen with Active TS/SCI w/Polygraph clearance\n\nPreferred Qualifications:\n\nBachelor's degree in a STEM discipline (Science, Technology, Engineering, or Math) along with 2 or more years of data science experience.\nKnowledge of statistical datasets and implementation techniques and tools for the most efficient metrics, including present and future capacity requirements.\nExperience with Tableau, SAS, Apache Spark, BigML, D3, MATLAB, or other data science tools.\nExperience taking big data and turning it into metrics or prediction information for decision making.\nStrong statistical and data visualization skills.\n\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\nTo apply to this job, click Apply Now"}, "130": {"company": "Takeda Pharmaceuticals", "description": "</p>\nJob Description\n\n\nTitle: Data Science Engineer - Pharma Manufacturing Science\n\nAre you looking for a patient-focused, innovation-driven company that will inspire you and empower you to shine? Join us in our Lexington office.\n\nAt Takeda, we are transforming the pharmaceutical industry through our R&D-driven market leadership and being a values-led company. To do this, we empower our people to realize their potential through life-changing work. Certified as a Global Top Employer, we offer stimulating careers, encourage innovation, and strive for excellence in everything we do. We foster an inclusive, collaborative workplace, in which our global teams are united by an unwavering commitment to deliver Better Health and a Brighter Futureto people around the world.\n\nHere, you will be a vital contributor to our inspiring, bold mission. In this role, a typical day will include:\n\nOBJECTIVES/PURPOSE\nDevelop and implement capabilities that improve knowledge management in a highly matrixed environment.\nCreate and implement processes for the Lifecycle Mangement function that efficiently collect business intelligence from publicly available sources (such as 10-Ks) through effective use of visualization and reporting\nCollect and disseminate actionable manufacturing business intelligence to inform the broader manufacturing strategy within Global Manufacturing and Supply.\nExtend the data science capabilities within Global Manufacturing Sciences through the use of programming tools such as Python\nCreate software solutions to complex operational issues and improvement of knowledge management\nACCOUNTABILITIES\nDevelop tools to optimize analysis (such a SWOT) of publicly available business intelligence (10-Ks, journals, etc) to identify business trends and opportuntities in commercial manufacturing. Communicate results on a routine basis.\nCollabrate with other GMS functions such as Strategy & Business Excellence on developing software tools to optimize and automate LCM activities.\nExpand current knowledge management capabilities\nDIMENSIONS AND ASPECTS\n\nTechnical/Functional (Line) Expertise\nAnalyze unstructured problems, identify root causes and align team objectives to drive divisional goals\nUse agile principles to reduce process complexity and increase organizational capacity\nDevelop and apply custom strategies for processing and visualizing multidimensional data\nExperience capturing and translating business requirements into technical solutions\nLeadership\nAbility to inspire others to share their vision and support them to reach a common goal\nDecision-making and Autonomy\nCreates functional strategies and goals that are closely aligned with Takeda\u2019s objectives and develops metrics to track and assess performance.\nDevelops concise, strategic plans based on a clear understanding of the organization\u2019s strengths, weaknesses, opportunities and threats.\nInteraction\nCreates a clear and unifying vision that inspires the team to excel.\nAchieves results by managing the right combination of diverse people, resources, and processes.\nBuilds teams across functions and geographies with individuals who have the right skills and experience to deliver on key organizational initiatives.\nStrong interpersonal and active problem-solving skills\nEngage partners to deliver agile and predictive results within a complex and evolving business landscape\nInterface with each Operating Unit and Region supporting lifecycle management of development and commercially approved products\nInnovation\nLeverage business analytics (such as SWOT) to identify emerging opportunities and capability needs for GMSci.\nAbility to apply first principles in chemistry, physics, and engineering to manufacturing problems and create new solution paths to manufacturing challenges.\nTranslate prior knowledge into new understanding of the development pipeline and expand the working knowledge of the essential activities for all key functional areas\nIdentify opportunities and anticipate changes in the business landscape through an understanding and ongoing assessment of the environment affecting the business.\nComplexity\nUnderstands differences in practices across organizations or countries, and balances local demands and perspectives with global strategies.\nCreates an environment that promotes information exchange and the open and honest expression of opinions, thoughts and beliefs.\nEDUCATION, BEHAVIOURAL COMPETENCIES AND SKILLS\n\nEducation / experience\nMinimum requirement of\nBachelors degree in computer science, chemistry, biology or related area.\n0-1 year experience in biopharma or related field\nSkills\nExperience working with automated data extraction\nExperience with Python SciPy tools (numpy, pandas)\nAbility to define and propose solutions to business problems\nApplication of Open Source resources for creating mobile platforms to communicate manufacturing intelligence\nAbility to work with ERP and QMS systems, such as SAP and Trackwise\nExpert knowledge of Microsoft tools (Excel, SharePoint, etc)\nStrong communication skills\nAbility to articulate complex issues and ideas with clarity to enable understanding\nBehaviors\nCreate an environment that fosters a patient-focused entreprenurial mindset\nStrategic enterprise thinking to deliver innovative patient-focused solutions that build patient trust and Takeda\u2019s reputation\nSelf-directed, accomplishment-driven individual with a strong sense of passion and urgency who can work both independently and in a cross-functional team environment\nWHAT TAKEDA CAN OFFER YOU:\n401(k) with company match and Annual Retirement Contribution Plan\nTuition reimbursement Company match of charitable contributions\nHealth & Wellness programs including onsite flu shots and health screenings\nGenerous time off for vacation and the option to purchase additional vacation days\nCommunity Outreach Programs\n\nEmpowering Our People to Shine\n\nDiscover more at takedajobs.com\n\nNo Phone Calls or Recruiters Please.\nLocations\n\n\nLexington, MA\n\nWorker Type\n\n\nEmployee\n\nWorker Sub-Type\n\n\nRegular\n\nTime Type\n\n\nFull time\n\nJob ID R0014176\nApply Now: click Apply Now"}, "131": {"company": "Grand Rounds", "description": "About us:\nGrand Rounds is a new kind of healthcare company. Founded in 2011, the company is on a mission to raise the standard of healthcare for everyone, everywhere. The Grand Rounds team goes above and beyond to connect and guide people to the highest quality healthcare available for themselves and their loved ones. Grand Rounds creates products and services that give people the best possible healthcare experience. Named a 2019 Best Place to Work by Glassdoor and Rock Health\u2019s 2018 Fastest Growing Company, Grand Rounds works with inspiring employers and doctors to empower them to be the change agents we need to make our shared vision a reality.\n\nThe Role:\n\nData Scientists at Grand Rounds work on problems that are core to the company\u2019s mission. Major challenges include developing systems and models to identify the highest quality doctors in the country as well as methodologies to uncover the subtle differences between each physician\u2019s clinical expertise. Additionally, patient-level modeling allows us to understand the specific healthcare needs of every person. With a high fidelity understanding of both patients and physicians we are able to route patients to both appropriate and high quality care.\n\nIn addition to developing the company\u2019s core technologies, data scientists provide decision support analysis for many teams across the organization including product development, sales, marketing, and strategy. Data scale ranges from small data sets that fit on a single laptop to large multi-terabyte clinical information in distributed database systems.\nIn your first 30 days, you will:\nOnboard with the Grand Rounds team in San Francisco, setup your dev environment, get access to data systems, and become familiar with the tech stack\nLearn about on-going initiatives involving data scientists, product managers, and engineers\nSpend time with members of the Analytics, Medical, and Patient Care teams and learn how our teams collaborate\nBecome familiar with the data landscape and hit the ground running on a primary project\nIn your first 60 days, you will:\nAccelerate on-going development efforts around physician quality and expertise models\nMaster the ins and outs of claims data: ICDs, CPTs, and all that\nCollaborate with engineers to improve the claims warehousing infrastructure\nCollaborate with engineers to develop a process/pipeline for model updates that seamlessly flows data to production systems\nIn your first 90 days, you will:\nIntegrate into long-term multi-data-scientist ventures and deliver on one or several short-term individual projects\nDevelop internal tools and codebases that are useful for other data scientists and/or engineers\nSpend time with Staff Physicians and other medical domain experts to learn about the world of healthcare\nDevelop an understanding of both immediate business objectives as well as longer term company aspirations to develop intuition around prioritization and trade-offs between short-term deliverables and longer term R&D efforts\nResponsibilities:\nDevelop creative solutions to diverse problems including engineering challenges, unstructured data messes, ontology development, and machine learning applicationsLead and develop major projects from end-to-end encompassing planning, design, technical implementation, debugging, roll-out to Product & Engineering, testing, and iteration\nOperate at level of sophistication in statistics, machine learning, or computer science that is publication-worthy\nRegularly monitor pull requests, perform code reviews, and produce excellent peer reviews on projects prior to shipping to Product & Engineering\nEvaluate and experiment with new technologies and tools prior to wider adoption by the team\nWork closely with analysts, data scientists, product managers, and engineers\nQualifications:\nExcellent verbal communications, including the ability to clearly and concisely articulate complex concepts to both technical and non-technical collaborators\nBS with 8+ years or MS with 6+ years or PhD with 3+ years of experience. Degree(s) should be in a technical discipline such as Computer Science, Engineering, Statistics, Physics, Math, quantitative social science\nWork experience as an engineer highly desired\nExperience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc\nRequired: SQL, Python, R, linux shell scripting\nDesired: Scala, Java, or Ruby\nExperience with machine learning and computational statistics packages (sci-kit learn, nltk, statsmodels, networkx, gephi, arules, glmnet, bigrf, caret, igraph, MLLib, GraphX, MADlib, Weka, etc)\nExperience with visualization tools (seaborn, d3, plotly, bokeh, ggplot2, rCharts, networkD3, Shiny, Tableau, CartoDB, etc)\nFrequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform\nBonus Points for: experience with web application frameworks (Shiny, Flask, Tkinter, Ruby on Rails, Pyramid, Django, etc)\nDouble Bonus Points: previous work on medical applications and/or with claims data\nThis is a full time position located in San Francisco, CA.\n\n\n-----\nGrand Rounds is an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics or any other basis forbidden under federal, state, or local law. Grand Rounds considers all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.\n\nApply Now\nStart your job application: click Apply Now"}, "132": {"company": "Advance America", "description": "Overview\n\n\nThis position reports to the Sr. Manager, Credit Risk. The responsibilities for this role will include developing statistical models, performing profitability and portfolio performance analysis, and developing test and control strategies to optimize decision making. This role works closely with management to perform analysis and prepare data as well as serves as a mentor to the more junior analysts. Furthermore, this role requires someone who quickly adapts to change and is willing to complete all duties as assigned and requested.\n\nResponsibilities\n\n\nJob Responsibilities Include:\n\nMonitor consumer loan portfolio and optimize profit-based risk management decisions at all stages of the customer credit life cycle, including (but not limited to) new customer acquisition, underwriting, conversion, collections, and retention.\nDevelop real-time fraud and collection prevention models, and strategies to minimize fraud and improve recovery rate.\nIndependently designs experiments to enable longer term optimization of decisions, line assignment, and offer terms across our menu of financial products and customer segments.\nWorks with credit bureaus to evaluate new data sources and \u201cAd-Hoc\u201d analysis as assigned.\nDevelop and implement advanced statistical and machine learning models across the customer lifecycle to include customer acquisition, onboarding (operational processes), credit underwriting, product optimization, and collections.\nCollaborate with Finance and Business Intelligence to build and improve monitoring of portfolio KPIs\nUnderstand, adhere to and enforce all corporate policies including, but not limited to, Advance America\u2019s Creed, Code of Ethics and Information Security Policies\nQualifications\n\n\nEquivalent Education and Experience Required: Master\u2019s Degree in Quantitative Field (Engineering, Statistics, Mathematics, Economics, or other comparable quantitative field) required with three (3) years of experience working in an analytical role in banking, finance, or retail or Bachelor\u2019s Degree in Quantitative Field (Engineering, Statistics, Mathematics, Economics, or other comparable quantitative field) required with five (5) years of experience working in an analytical role in banking, finance, or retail.\n\nKnowledge Required: Excellent written and verbal communications skills as would be needed to communicate in person, by phone, and through email; adaptability and flexibility to changing environment; and comfortable working in a dynamic, high volume, fast-paced environment. Ability to read, write, evaluate, and apply information. Ability to interact professionally and exhibit appropriate social skills. Ability to understand and ensure compliance with policies, procedures, and laws governing our industry/business and products. Ability to develop and maintain business relationships.\n\nBasic understanding of statistical principals (p-value, etc.). Comfortable with solving complex problems, working with computers and technology, and using higher level mathematics. Ability to quickly learn all technology needed in order to perform the role. Prior coursework in advanced mathematics, computer programming, economics, and operations research would be beneficial. Prior work with SAS, SQL, or another analytical tool preferred.\n\nPhysical Requirements: Sitting for long periods of time; standing occasionally; walking; bending; squatting; kneeling; pushing/pulling; reaching; twisting; frequent lifting of less than 10 lbs., occasional lifting of up to 20 lbs.; typing; data entry; grasping; transferring items between hands and/or to another person or receptacle; use of office equipment to include computers; ability to travel to, be physically present at, and complete the physical requirements of the position at any assigned location.\n\nTravel: 0 \u2013 10%\n\nAttire: Professional attire (as required by company standards).\n\nOther: Must be eligible to work in the USA and able to pass a background check.\n\nIND1\n\nStatistician\n\nData Science\n\nData Scientist\n\nBusiness Analytics\n\nData Analyst\n\nStatistical Analyst\n\nBusiness Analyst\n\nCredit Analyst\n\nRisk Analyst\n\nAnalyst\n\nData Modeling\n\nStatistical Modeling\n\nR\n\nPython\n\nStatistics\n\nStatistician\n\nPredictive modeling\n\nstrategy\n\nMachine learning\n\nML Modeling\nTo apply to this job, click Apply Now"}, "133": {"company": "Presbyterian Healthcare Services", "description": "Overview\n\n\nJob Description Type of Opportunity: Full Time FTE: 1.000000 Exempt: Yes Work Schedule: Days\n\nSummary:Support portfolio management of reporting/analytics solutions across the business units in the analytics organization. Identify business issues/problems, form hypotheses, plan and conduct interviews, whiteboard sessions & perform reporting/analysis to synthesize conclusions, transform them into recommendations and develop a solution. Lead and manage small cross functional team to implement, test and deploy the approved reporting/analytics solution in response to the business (clinical/operational/financial) needs. Identify reporting/analytics improvement opportunities and provide proactive, consultative strategic solutions. Responsible for mentoring junior analysts as well as coordinating various reporting/analytics initiatives with end business users. Support reporting/analytics projects prioritization and planning as well as cconduct due diligence concerning business implications of planned solutions.\n\nResponsibilities\n\n\nResponsibilities:Consultation and Communication:*Ability to collaborate and partner with management, project managers, and IT to develop, implement and manage reporting/analytics portfolio with the vision & goals of specific Hub/Spoke core teams*Effective communication skills across the organization and at different levels, strategic thinking and actions to influence key stakeholders and business decisions *Support day-to-day consultation to business users and participate and contribute cross-functional project teams*Work with business stakeholders to identify business needs and support creation of the use cases and user stories satisfying those needs Project Management and Execution:*Coordinate with other departments across the AO such as IM governance & EDW and support conceptualization and development of reporting/analytical methodologies, solutions and initiatives*Aid in the development of project plans and strategies as well as execute assigned project plans to deliver solutions in a timely manner*Support collaboration on roadmaps, dependencies, and execution plans across analytical units and with applicable teams in the organization *Manage the intake requests across the business units; track and monitor the work to ensure critical milestones are met, identify and report/escalate risks to management appropriately; manage stakeholder relations*Obtain data, direct/execute reporting/analysis, perform interpretations and conclusions, and prepare recommendations. *Assist in determining business needs by effectively conducting fact-finding interviews and leveraging various tools and analytical methods and then summarize findings in a coherent manner to develop and propose appropriate solution *Conduct research studies that include collecting data from various sources, analyzing, trending and presenting the findings and recommendations to management *Support translation of business requirements and unstructured business issues into data analytic problems*Perform overall program evaluations (i.e., planning-implementation-completion/analysis-reporting) and other assessments such as change management assessments, workflow optimization assessments, etc. Training and Guidance:*Manage and support teams to structure data and analysis to analyze issues and proactively identify improvement opportunities*Responsible for the work flow management of analysts and ensuring reliability, integrity, and timeliness of end products*Support coordination of training for analysts in core and expanded business departmentThought Leadership:*Support in development of presentations/publications/point-of-views with senior leadership within the AO *Contribute towards and assist senior leadership in developing a year-end value story to demonstrate value of the team and their contribution to progress towards the AOs and PHSs goals\n\nQualifications\n\n\nOther information:SKILLS: Bachelors degree in a quantitative, business, or healthcare related subject. A Masters degree is highly preferred. Four or more years of combined experience in business intelligence, reporting and analytics preferably in a healthcare setting. Demonstrated project management skills as well as the ability to efficiently work and manage teams and resources. Experience working on complex analytical projects with diverse teams and developing data driven and outcome based initiatives to improve business decision making and operational efficiencies. Knowledge of health plan and delivery system operations, health care informatics, and healthcare benefits and terminology (e.g., care management). Understanding of operations in the Health Care industry and a strong acumen of business processes, including operations, delivery models and revenue models. Understanding of program evaluation life cycle, predictive modeling, data mining, and clinical best practices preferred. Content knowledge related to program outcomes evaluation, BI tools (e.g., BO), data visualizations tools (e.g., Tableau), statistical software such as SAS and Modeling techniques, as well as general health service research and outcomes reporting/analytics. Working knowledge of healthcare industry and healthcare information standards such as HL7, LOINC, FHIR, ICD 9/10 and CPT codes, industry standard groupers (e.g., ETGs, DRGs, DCGs, etc.) as well as of health care delivery system processes. Excellent written and oral communications is a MUST.\n\nPreferred Qualifications:\nHealth Plan/Finance Experience\nStrong Communicator\nSAS/SQL Coding Experience\nMicrosoft Access experience preferred\nVBA(Visual Basic for Applications) experience is a plusNote: They will not be building new databases but one of our key customers is heavy utilizer of Access in order to best support them they need an understanding of how Access works and the challenges/pitfalls that exist with Access & VBA\nCompetencies and skills:Essential:* SKILL-Demonstrated ability to communicate effectively in person and via telephone with members, employer groups, brokers, physicians, and physician office staff using strong dialogue and customer service competencies. * SKILL-Written communication Nonessential:* Analytics skills* SKILL-Decision Making* SKILL-Project management methods and tools in support of managing Scope, Time, Cost, Quality, Communication, Risk, and Procurement Management;\n\nBenefits\n\n\nBenefits Benefits are effective day-one (for .45 FTE and above) and include:\nCompetitive salaries\nFull medical, dental and vision insurance\nFlexible spending accounts (FSAs)\nFree wellness programs\nPaid time off (PTO)\nRetirement plans, including matching employer contributions\nContinuing education and career development opportunities\nLife insurance and short/long term disability programs\nAbout Us Presbyterian Healthcare Services is a locally owned, not-for-profit healthcare system of nine hospitals, a statewide health plan and a growing multi-specialty medical group. Founded in New Mexico in 1908, it is the state's largest private employer with approximately 11,000 employees.\n\nPresbyterian's story is really the story of the remarkable people who have chosen to work here. Starting with Reverend Cooper who began our journey in 1908, the hard work of thousands of physicians, employees, board members, and other volunteers brought Presbyterian from a tiny tuberculosis sanatorium to a statewide healthcare system, serving more than 700,000 New Mexicans. We are part of New Mexico's history - and committed to its future. That is why we will continue to work just as hard and care just as deeply to serve New Mexico for years to come. About New Mexico New Mexico's unique blend of Spanish, Mexican and Native American influences contribute to a culturally rich lifestyle. Add in Albuquerque's International Balloon Fiesta, Los Alamos' nuclear scientists, Roswell's visitors from outer space, and Santa Fe's artists, and you get an eclectic mix of people, places and experiences that make this state great. Cities in New Mexico are continually ranked among the nation's best places to work and live by Forbes magazine, Kiplinger's Personal Finance, and other corporate and government relocation managers like Worldwide ERC. New Mexico offers endless recreational opportunities to explore, and enjoy an active lifestyle. Venture off the beaten path, challenge your body in the elements, or open yourself up to the expansive sky. From hiking, golfing and biking to skiing, snowboarding and boating, it's all available among our beautiful wonders of the west. AA/EOE/VET/DISABLED. PHS is a drug-free and tobacco-free employer with smoke free campuses.\n\nAD123\n\n#CB\nTo apply to this job, click Apply Now"}, "134": {"company": "ManTech", "description": "Secure our Nation, Ignite your Future\n\nJob Summary\n\nEach day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of big data solutions to promote efficient trade and travel. Further, effective big data solutions help CBP ensure the movement of people, capital, and products is legal, safe, and secure.\n\nIn response to this challenge, ManTech, as a trusted mission partner of CBP, seeks a capable, qualified, and versatile Chief Data Scientistto lead the development and delivery of high-quality predictive modelling solutions. A successful applicant will serve as recognized Subject Matter Expert in the application of quantitative methods, machine learning algorithms, and predictive models to address complex national and homeland security challenges. They will help our team to leverage large structured and unstructured datasets to develop and operationalize models, tools, and applications that drive optimized decision making. Project tasks include data collection, mining, data and text analytics, clustering analysis, pattern recognition and extraction, automated classification and categorization, and entity resolution to implement and enhance automated risk assessment. The products we develop provide actionable insight with real and immediate impact on the safety and security of the United States, its citizens, visitors, and economy.\n\nRequired Qualifications\nSignificant experience in developing machine learning models and applying advanced analytics solutions to solve complex business problems in dynamic, threat/risk driven operating environments.\nProficiency with statistical software packages: SAS, SPSS Modeler, R, WEKA, or equivalent.\nExperience with programming languages: R, Python, Scala, Java, SQL, or equivalent.\nExperience constructing and executing queries to extract data in support of EDA and model development.\nExperience with unsupervised and supervised machine learning techniques and methods.\nExperience working with large-scale (e.g., terabyte and petabyte) unstructured and structured data sets and databases.\nExperience performing data mining, analysis, and training set construction.\nExperience working in a team and deploying solutions in an iterative or agile/DevOps continuous integration and delivery environment using lifecycle management methods and tools.\nStrong ability to work closely and collaboratively with mission stakeholders; respond to emergent, mission-driven changes in priorities and expected outcomes; and, apply new and emerging tools and techniques.\nBachelors Degree in operations research, industrial engineering, physics, mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience.\nClearance: Active Top Secret\nDesired Qualifications\nExperience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop).\nProficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc.\nProficiency with Supervised Machine Learning methods including Decision Trees, Support Vector Machines, Logistic Regression, Random/Rotation Forests, Categorization/Classification, Neural Nets, Bayesian Networks, etc.\nExperience with pattern recognition and extraction, automated classification, categorization, and entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation).\nExperience with visualization tools and techniques (e.g., Periscope, Business Objects, D3, ggplot, Tableau, SAS Visual Analytics, PowerBI).\nMasters or Ph.D. degree\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS clearance is required as well as CBP suitability.\n\nMust be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) Background Investigation.\n\n#LI-FA1\n\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\n\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.\nApply Now: click Apply Now"}, "135": {"company": "7Park Data", "description": "7Park Data, a Vista Equity portfolio company, is the world\u2019s leading alternative data intelligence firm. We have access to some of the most coveted alternative datasets \u2013 such as clickstream, geolocation, mobile app usage, credit and debit card, email receipt, and shipping cargo data \u2013 and are constantly acquiring more.\n\nYou will be joining other extremely passionate data scientists, product managers, and engineers that share a common interest in tackling some of the most difficult data science and machine learning problems today. With the data products and machine learning systems you design, 7Park will arm influential decisionmakers at financial and corporate giants with critical information they need to make smart, data-driven decisions. And, along the way, you will help advance the current work in artificial intelligence and predictive modeling.\n\nThe data science team has two major goals: to create and build data products that provide intelligence on real-time economic activity to our financial and corporate clients and to research and develop machine learning systems to extract information from large volumes of structured and unstructured text.\n\nWe are looking for a talented and creative Data Scientist to join our data science team. As a Data Scientist, you will be responsible for the following:\nConduct research on some of the world\u2019s most interesting alternative datasets\nPlan, develop, and apply cutting-edge machine learning systems and statistical modeling to extract insight from vast amounts of data at scale\nWrite production-ready code to analyze, structure, and make accurate and timely predictions\nDesign systems to monitor the results of models in productions, discover and address anomalies, and ensure the robustness and reliability of these models\nLead projects from start to finish, collaborating with 7Park\u2019s senior management, product managers, engineers, external data partners, and clients\nAn ideal candidate will be passionate about building machine learning systems on real world data and have several years of industry experience and/or a Masters or PhD in computer science, mathematics, statistics, linguistics, physics, computational finance, or a similar quantitative field.\n\nIt is also very important that you enjoying working in a lean, tight-knit, and highly entrepreneurial startup that marries the creative, experimental problem-solving found in academia with the hacker ethos of shipping products quickly and often.\n\nCompensation package: includes highly competitive salary, bonus and 401(k) plan.\n\nRequirements\nAt least 5 years of relevant professional experience and/or a Masters or PhD in computer science, mathematics, statistics, linguistics, physics, computational finance, or similar quantitative field.\nStrong knowledge of machine learning, computer science, mathematics, and statistics.\nStrong programming skills in Python, R, and/or Scala.\nExperience with NumPy, SciPy, Pandas, Scikit-Learn, TensorFlow, and Keras. PyTorch is also acceptable.\nExperience with building distributed machine learning systems using Apache Spark and a working knowledge of MLlib.\nExperience with several of the following concepts: decision trees, random forests, and gradient boosting; linear regression; logistic regression; linear and non-linear dimensionality reduction using PCA, kernel methods, and dictionary learning; clustering with K-means, hierarchical clustering, and DBSCAN; autoencoders; generative models; and sequential data modeling.\nBonus\nPublications in communities such as NIPS, ICML, or related.\nGitHub projects demonstrating your creative drive.\nKaggle wins demonstrating your competitive drive.\nExperience running or working at data-centric startups.\nExperience with knowledge graphs.\nWorking knowledge of GraphX and Spark Streaming.\nTo apply to this job, click Apply Now"}, "136": {"company": "Helix", "description": "It's our mission to empower every person to improve their life through DNA. We believe DNA will be digitally accessible to each person so that it can be used\u2014at any time\u2014to improve health outcomes and accelerate research.\n\nHelix powers life-changing population health programs. Our world-class clinical laboratory platform and proprietary Exome+ assay enable health systems to integrate genomic information into routine clinical care and enhance the accessibility of personalized healthcare. Additionally, Helix stores and protects participants' DNA information, so that as the science evolves, health systems, patients and researchers are able to continuously benefit from a lifetime of DNA insights.\n\nOur big vision comes with big responsibility. That's why we're building a diverse team of experts in the field of genetics, engineering, design, business development, and beyond to help bring actionable insights to our customers.\n\nThe mission of the Helix Research team is to conduct cutting-edge genomics research, to collaborate with and support our clinical, health, and life science partners in population-based genomic studies, by demonstrating the capabilities of the Helix Exome+ platform and suite of bioinformatics products and services. We are also responsible for the integration, analysis, and interpretation of genomic, phenotypic, and clinical information obtained from EMRs, self-reported health outcomes, claims, quantitative biomarkers, and other digital phenotypes. We believe that everyone will be sequenced as part of routine medical care in the not-too-distant future and our fast and nimble team helps generate the evidence to turn that faith into fact.\n\nAs a Senior/Staff Research Scientist, you will:\nbe the internal expert on medical real world data, defining how we should abstract and integrate data from our research partners, and ensuring that we're meeting established standards.\ncollaborate with scientists, clinicians, and analysts from our partners who have expertise in various clinical and disease areas\nas part of a team, conduct research on genomic and phenotypic data to replicate published studies in new cohorts and discover novel associations\ndrive the development of Real World Evidence (RWE) approaches, techniques, and standards, together with genomic data\npresent your findings internally to key stakeholders and externally to partners and at conferences\nRequired background:\nMD, PhD, or MD/PhD in relevant field (e.g. genetics, health informatics, epidemiology, biostatistics, bioinformatics, pharmacology, etc)\nPostdoc plus 3+ years relevant experience acquired at a healthcare provider / Payer / HTA, pharmaceutical companies, academia, or relevant consultancy companies\nPrior experience with large observational databases (e.g., administrative claims and electronic medical records) and observational research/epidemiology statistical methods.\nStrong programming and scripting abilities in languages (Python, R, etc).\nExcellent communication skills, with the ability to translate complex concepts to different audiences\nDemonstrated track record of executing research projects using RWE from claims, electronic health records, registries, biobanks, or digital applications, including publications\nFamiliarity with genetics and genomics\nDemonstrated ability to learn and embrace new technologies, applications, and solutions\nEntrepreneurial mindset and willingness to jump in where needed\nThe ideal candidate will have:\nExperience with medical record coding practices, ETL implementation(s), OMOP CDM, ontologies\nExperience with genomic analysis techniques including GWAS and PheWAS\nExperience with Natural Language Processing\nExperience with Health Economics and Outcomes Research\nWhat Helix has to offer you\n\nAside from working alongside brilliant, dedicated, passionate, down-to-earth, curious, warm, and thoughtful people, we also provide great benefits:\nCompetitive compensation, including meaningful equity\nHealth insurance, including medical, dental, and vision\n12 weeks of Maternity or Paternity leave\n4 weeks of paid Pregnancy Disability\n401(k) with employer matching\nOn-premise nursing room\nCommuter benefits\nCatered meals\nFlexible PTO\nHelix is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws.\nStart your job application: click Easy Apply"}, "137": {"company": "JJR Solutions", "description": "Do you have a passion for data and discovering how it can be turned into useful information? Do you consider yourself someone who loves the details and bringing order to data chaos?\n\nIf this sounds like you, we've got the perfect job!\nWe are currently looking for the right person to join our team. This role requires someone who can assess complex data, processes, and programs and come up with more efficient solutions for our clients. You will help to produce output and sustain operations. You will basically be a rock star!\n\nWhy you should work with us.\nOur mission is to build partnerships with clients to advance their organization's performance. This position will play a key role in advancing our client's organization. You will have an opportunity to create high-impact, meaningful value for a growing company inspired by something greater. Also, we are really cool people who love our fellow coworkers. Culture is kind of our thing, and we are committed to the well-being of each employee.\n\nNeed proof? Its in the pudding. Here's what people are saying!\n\nWe are rated 4.1 out of 5 stars on Glass Door.\n\nLeadership is willing to listen. anonymous comment on Glass Door\n\nIncredible company that does things the right way for the right reasons. anonymous comment on Glass Door\n\nEmployee engagement scores are consistently higher than industry average (independent third party assessment)\n\nYou in? Here are the details.\nTitle: Data Analyst\nLocation: Dayton, OH\nClassification: Salary, Exempt\nTravel: 0%-5%\nSecurity Requirement: Must provide favorable background check; must be eligible to receive a National Agency Check with Inquiries (NACI).\n\nPosition Expectations:\n\nPerform all required responsibilities and duties in accordance with our code of conduct\nActively engage in your role, make informed decisions, and be accountable for all outcomes\nDeliver exceptional service to internal and external clients, partners, teammates\nDuties:\n\nCollects, organizes, models, and analyzes healthcare related data using analytical and/or statistical tools\nApplies fundamental concepts, processes, practices, and procedures on technical assignments\nProvides correct and appropriate interpretation of data, applying knowledge to evaluation, analysis, and interpretation of data\nDevelops useful methodologies for analyzing and presenting data analysis products using statistics, graphs, images and lists that communicate results to leadership\nResponsible to take identified, adjudicated data elements through the process of research, analysis, documentation and creation of various cleansing/conditioning techniques to deliver user/system ready data\nPerforms data quality assessments, identifies and prioritizes improvements\nAssists other functional area analysts as needed with data analysis and generation of SQL to be used in that analysis\nIdentifies and solves issues concerning data management to improve data quality\nImproves data foundational procedures, guidelines and standards\nAssists with conversion coding in ETL tool and support conversion design as required\nAssists with executing data conversions for multiple functional areas within multiple IT environments\nWorks with management and/or client to develop and understand work product specifications\nCommunicates effectively, both orally and written, to varied levels of the organization to include technical personnel, business managers, and leadership\nAdditional duties' as assigned\nRequired Education, Experience, & Skills:\n\nBachelor Degree in business, operations research, management science, information science or related field\n4 years' experience\nJJR may choose to substitute education with relevant experience\nStrong Oracle SQL skills\nPreferred Education, Experience, & Skills:\n\nWorks well with geographically separated teams\nSelf-starter\nInquisitive\nStrong analytical skills\nGeneral understanding of healthcare International Classification of Diseases (ICD) codes and related healthcare data\nGeneral understanding of decision support systems\nFamiliar with data profiling, analysis, conditioning, and cleansing\nFamiliar with data management and governance\nFamiliar with relational database concepts and structured query language (SQL)\nCertified Health Data Analyst (CHDA)\nAbility to design and build relational and dimensional databases\nPast experience working in a data warehouse environment\nExperience reviewing and developing objects and data models and the metadata repository\nAbility to support other corporate general IT initiatives (IT Help Desk, Microsoft Cloud tools, software and hardware)\n\nEOE Statement\nWe are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law.\n\nDisclaimer\nThis description in no way implies that the duties listed here are the only ones the employee can be required to perform. The employee is expected to perform other tasks as dictated by their supervisor or JJR leadership.\nStart your job application: click Apply Now"}, "138": {"company": "Travelers", "description": "Company Information\nSolid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n\nJob Summary\nThe Claim Business Intelligence & Analytics organization has an exciting opportunity for a Data Engineer. This role will focus on data analysis and preparation as well as model implementations for Worker's Comp and General Liability advanced analytics projects. We work closely with our research department and information delivery teams, and this role will lead projects supporting those areas over time. Successful candidates will be able to perform analyses and complex data transformations on internal and external data sources (both structured and unstructured). You should be familiar with Linux based environments and be comfortable working with SQL and Python. Experience in a cloud platform (i.e. AWS) a plus.\n\nMarketing Description\n\nPrimary Job Duties & Responsibilities\nIndependently perform Data Acquisition, Prep and Exploration: reviews, prepares, basic design, and integrates data.\nAble to correct minor problems and implements data cleansing/quality solutions.\nApply moderate and develops basic data derivations, business transformation rules, and data requirements.\nPresent simple data visualizations to help support data exploration as needed.\nOperationalize and automate well defined simple data products independently.\nBuild, test, and implement simple analytic processes, including pilots and proof of concept.\nAssist in training business users on data products/analytic environment.\nDelivers basic training.\nApply knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects.\nContinue to develop insurance and business intelligence knowledge while learning how work assignments address business issues.\nUnderstand Travelers standards, processes, and environmental landscape\nMinimum Qualifications\n3 years of relevant experience with data tools, techniques, and manipulation required.\n\nEducation, Work Experience & Knowledge\nIntermediate knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to): Big data and Cloud platforms Programming languages - SAS, SQL, Spark, Python, Hive, AWS Visualization platforms: QlikView, Tableau, MicroStrategy and Qlik Sense\nExperience: 4 years of relevant experience with data tools, techniques, and manipulation preferred.\nDegree in STEM related field preferred.\nJob Specific & Technical Skills & Competencies\nAbility to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.\nExhibits active and effective communication skills with team members\nAble to leverage previous experience to consider a variety of alternatives to arrive at a timely, practical, and cost-effective solution to resolve defects or incidents.\nAbility to foster relationships with peers to achieve objectives.\nPractices objectivity and openness to others' views.\nAble to recognize and support team priorities.\nAbility to manage time and competing priorities and provide management with accurate and timely status information.\nAble to effectively evaluate and estimate routine tasks with clear precedent.\nPhysical Requirements\nOperates standard office equipment - Continuously Sitting (Can stand at will) - Continuously Use of Keyboards, Sporadic 10-Key - Continuously.\n\n#Dice\n\nEqual Employment Opportunity Statement\nTravelers is an equal opportunity employer.\nApply Now: click Apply Now"}, "139": {"company": "Atara Biotherapeutics, Inc.", "description": "Position Summary\nThe Scientist \u2013 CAR-T Development will serve as a technical expert in the generation and characterization of novel CTL and Chimeric Antigen Receptor (CAR) T cell therapies within the Preclinical and Translational Sciences group. The successful candidate will independently perform experiments to support new product development and IND-enabling activities for Atara\u2019s early engineered T cell pipeline.\nReports to: Principal Scientist \u2013 CAR-T Development, Preclinical & Translational Science\nLocation : Thousand Oaks, CA\nPrimary Responsibilities:\nPerform retroviral (gamma retrovirus and/or lentiviral) transductions of primary T cells and propagation\nEvaluation of allogeneic CAR T cell activity, efficacy, and alloreactivity\nPrimary immune cell isolation and multi-parameter immunophenotyping by flow cytometry\nDesign and execution of assays to evaluate target-specific T cell characteristics and function\nMammalian cell culture and production of recombinant transient and stable mammalian cell lines\nContribute to experimental design and project direction\nFacilitates the establishment of a molecular and cellular lab infrastructure and routine operations\nMaintains detailed documentation of laboratory procedures and experiments\nPrepares data presentations for internal group meetings\nTravel:\nTravel required (up to 10%)\nPhysical Requirements:\nSubject to extended periods of sitting and/or standing, vision to monitor and moderate noise levels. Work is generally performed in an office, laboratory, or manufacturing environment. Car and airplane (see above) travel is an essential part of the job\n\nProfessional Qualifications and Position Requirements:\nBS w/7 years experience, MS w/5 years experience, or Ph.D. in cell biology, immunology, molecular biology or related discipline\nAbility to generate and characterize genetically modified primary T lymphocytes using standard immunological assays including flow cytometry\nExpertise with retroviral/lentiviral transduction and primary cell transformation\nExpertise in Immune cell-based assays including proliferation and cytotoxicity\nExpertise in culturing PBMCs, human lymphocytes, and mammalian cell lines\nExperience with propagation of gene modified T cell cultures\nExcellent record keeping and communication skills and computer skills including experience with FlowJo, Microsoft Excel, PowerPoint, and Graphpad Prism\n\nWe launched Atara Biotherapeutics in August 2012 to help patients with serious diseases and few therapeutic options. We\u2019re named after Atara Ciechanover who suffered from cancer before passing away. We are considered a leading off-the-shelf T-cell immunotherapy company (Nasdaq ATRA) developing novel treatments for patients with cancer, autoimmune and viral diseases.\nWe\u2019re proud of our team of 350+ Atarians co-located by design in South San Francisco (corporate headquarters) and Southern California (R&D and manufacturing headquarters in the northwest Los Angeles area) with a newly-established European headquarters in Zug, Switzerland. Atara also has a R&D site in the Denver, Colorado area and an office in New York City. Our Southern California hub is anchored by a new 90,000 sq. ft., state-of-the-art Atara T-Cell Operations and Manufacturing (ATOM) facility in Thousand Oaks, California.\n\nOur mission \u2013 \u201cTransform the lives of patients with serious medical conditions through pioneering science, teamwork and expertise.\u201d\nVisit www.atarabio.com to learn more.\n\nAtara Bio is an equal opportunity employer and makes employment decisions on the basis of merit and other lawful factors. In accordance with applicable law, the Company prohibits discrimination based on race, color, religion, creed, sex, gender (including pregnancy, childbirth or medical condition related to pregnancy or childbirth), gender identity, expression or dysphoria, marital status, age, national origin or ancestry, physical or mental disability, medical condition, genetic information, veteran status, caregiver status, sexual orientation, transgender status or any other classification protected by federal, state or local laws or because of the individual\u2019s association with a member of a protected group or connection to an organization or group related to a protected group.\n\nWe comply with all applicable national, state and local laws governing nondiscrimination in employment as well as employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must have authorization to work for Atara Bio in the United States.\nApply Now: click Apply Now"}, "140": {"company": "ProKarma", "description": "ProKarma currently has exciting opportunities for Data Analysts that would like to join our team as a full-time employee in Seattle, WA.\n\nGenerate business impact by creating new business intelligence and analytics\nAnalyze data of cellular technologies and geo-locations for service coverage and user experience\nWrite requirements for additional data collection through a mobile application\nTechnical problem-solving and innovative design of analytics solutions with the constraints of data and time\nEngage with business stakeholders to present the analysis results and make sound recommendation\nDocument the analysis workflows and data dictionary\nCollaborate with data engineers to optimize the data platform to product the analysis results in the quickest way possible\nProactively reach out stakeholders across teams for additional information and data to maximize the effectiveness of the analysis results\n\nQualifications\nBachelor\u2019s degree in computer science, mathematics or scientific field requiring statistical\n5-7 years of industry experience, at least 4 years of which must be in analytics, business intelligence, AI, data science, operations research, or data-driven business strategy\nHands-on ability to manipulate data and build analytical data sets\nExpert proficiency in one or more of data analysis and data wrangling tools such as SQL, Alteryx, Power BI, Tableau, MS Excel, MapInfo, Python and R.\nDemonstrated ability to effectively engage, collaborate, and consult with stakeholders, including effective prioritization.\nPortfolio of with a range data visualization techniques.\nAbility to translate quantitative and qualitative data into insights and strategy to drive the product development roadmap.\nProven experience managing standards, processes and procedures to ensure agile delivery and consistent clear communication with delivery of actionable data-derived insights.\nExcellent verbal and written communication skills.\n\n~ In order to provide equal employment and advancement opportunities to all individuals, employment decisions at ProKarma are based exclusively on merit. ProKarma does not discriminate in employment opportunities or practices on the basis of race, color, religion, sex, including gender identity and identity expression, national origin, age, or any other characteristic protected by law.\nStart your job application: click Apply Now"}, "141": {"company": "My Job Tank", "description": "Our Mission\n\nWe make it fly! Join us and build the future of aviation, changing the way people and goods move around the world.\n\nSoon, aircraft will deliver packages to your doorstep, air taxis will fly you around cities, and emergency medicine will be flown more quickly to accidents.\n\nWe're building the digital traffic management to make it all possible.We\u2019re a diverse crew of aviation enthusiasts, Bay Area startup veterans, and professionals from multiple industries who\u2019ve come together to build really cool things.\n\nWant to help us usher in the era of flying cars?\nGoing beyond developing software, hardware, and aircraft, we aim to build a unifying vision and suite of products that enable the next generation of aviation. As a fast-moving, iterative team and a leading innovator in aerospace, our goal is to leave a lasting impact by updating how objects, information, and people move in a new, exciting world.\n\nData Scientist\n\nWe\u2019re using large datasets of real UAS flights to create and validate risk models that our services will use to ensure safe operations. You\u2019ll work with our partners to onboard data to an architecture that you specify, including designing and implementing ETL processes, auditing processes and analytics frameworks.\nSet up our database infrastructure and data pipeline, managing all aspects from ingest and ETL to advanced analytics.\nDetermine the best algorithms to apply to the data, including machine learning tools as appropriate.\nWorking with our statisticians, create computational models for vehicle behavior and performance.\nIn collaboration with the Safety & Risk Architect, you\u2019ll identify safety-related trends and determine the best way to represent them in the Open Risk Framework and underlying risk models.\nCollaborate with development engineers to incorporate your models/pipelines/architectures into deployed products.\nQualifications:\nBS, MS or PhD in Statistics, Computer Science, Data Science or a related field.\nExtensive experience working with various data sets, knowledge of state of the art in machine learning, and understanding of the power and shortcomings of data\nExperience using TensorFlow or other large scale machine learning frameworks in production\nExtensive experience building, running and maintaining database infrastructure\nExperience working with Hadoop, Spark and other tools for distributed computing is essential.\nAdditional Considerations:\nExperience implementing best practices in data security, integrity, workflow traceability, and auditing\nExperience with optimization and statistical data analysis tools\nExperience with one or more programming languages (Python, R, Julia)\nYour experience has been in the context of an early stage effort. This could be at a startup or a new project in a more established company.\nComfortable working as part of a cross-functional team with shifting priorities as needs change and new opportunities arise.\nExperience with software engineering concepts in a small, tightly coupled team--and how these evolve with growth of the team\nDeadlines are your friend, and you\u2019re a natural communicator who can articulate bottlenecks and challenges.\nOutstanding technical leadership and communication skills\nInnate curiosity leads you to keep up with the latest research, news and developments in your field.\nIf you\u2019ve published journal articles, conference papers or technical reports, that\u2019s a plus. We expect you to share the insights, best practices and paths forward that you develop with the rest of the world, including at relevant industry conferences.\nWe're proud to be an equal opportunity workplace celebrating unique talents, backgrounds, and differences. We\u2019re dedicated to building a healthy and sustainable culture, while solving big problems that really matter.\n\nWe take care of our people, offer work life balance, and offer neat perks like flight training!\nTo apply to this job, click Easy Apply"}, "142": {"company": "ClearEdge IT Solutions", "description": "ClearEdge\nApply Now\nTo apply to this job, click Apply Now"}, "143": {"company": "Novartis", "description": "Two companies and one incredible alliance.\n\nNovartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop transformative medicines faster and more cost-effectively for patients worldwide.\n\nWe are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics. In this newly formed alliance with Microsoft, you will lead Visualization capabilities for Novartis .\nYour responsibilities:\nIn this newly created role, you will:\n\u2022 Build Novartis\u2019 Visualization center of excellence to make it a team of international reputation\n\u2022 Take a hands-on role and coach data science teams to deliver on highly visible multiple projects\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Coach and mentor associates\n\u2022 Inspire others on culture change\n\nWhy consider Novartis?\n\n750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\n\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data. Where you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us reimagine medicine.\n\nPosting Title\nHead Data Scientist \u2013 Visualization Lead, Novartis AI Innovation Lab\nStart your job application: click Apply Now"}, "144": {"company": "Arrow Electronics", "description": "Position:\nData Science Intern\nJob Description:\n\n\nData Science Intern - Full-time - Summer 2020\n\nApplications: September 2019 - November 2019\n\nInterviews: October 2019 - February 2020\n\nInternship: Approximately 11 weeks; mid-May/mid-June to August/September. Candidates must be available to be in Denver, CO on June 17-18, 2020 and August 12-13, 2020 (travel is provided for interns whose work location is out of state)\n\nBased on your experience and interests, you will interview with and work on a team for approximately 11 weeks during the summer. Interns may be considered for potential full-time opportunities on based on their internship performance.\n\nWho is Arrow Electronics?\n\nArrow Electronics is a global provider of products, services and solutions to industrial and commercial users of electronic components and enterprise computing solutions. Arrow serves as a supply channel partner for more than 150,000 original equipment manufacturers, value-added resellers, contract manufacturers, and commercial customers through a global network. The company maintains over 300 sales facilities and 45 distribution and value-added centers, serving over 80 countries.\n\nA Fortune 109 company with 18,800 employees worldwide, Arrow brings technology solutions to a breadth of markets, including telecommunications, information systems, transportation, medical, industrial and consumer electronics.\n\nArrow provides specialized services and expertise across the entire product lifecycle. Arrow does this by connecting customers to the right technology at the right place, right time and right price\n\nArrow provides extraordinary value to customers and suppliers - the best technology companies in the world - and connects them through the company's industry-leading services.\n\nWhy Be an Intern?\nHands-on approach to learning and applying your degree\nChance to network with 100+ interns across the U.S.\nSmall forums with our Executives and past interns\nStretch your presentation skills in front of our VPs and Directors\nRequirements & Skills\nCurrently enrolled and pursuing a Bachelors or Masters Degree in Information Technology, Computer Science, or Equivalent with a graduation date no earlier than May/June 2020\nAvailable to work full-time (40 hours/week) during the summer (May or June through Mid-August)\n3.0 GPA or Higher\nStrong verbal and written communication skills\nAbility to prioritize based on opportunities and effectively multitask\nExperience using Microsoft Office\nDetail oriented mindset\nThis position will be part of Arrow Data Science team, a group of analysts, developer and scientists who primarily uses big data relevant technologies to provide data driven solution to the rest of the organization. This data science group is very lean and focus on evolving and revolutionizing all aspects of Arrow's business operations.\n\nFor someone fresh out of college, this position offer this unique opportunity exposing you to many different new topics, fields and various professionals for you to better reflect and calibrate your career path. Most importantly, you will the opportunity of supporting or being supported to make a material impact given all the exciting challenges that we are conquering every day.\n\nResponsibilities:\nFacilitating the rest of the team regarding all kinds of workloads (adhoc requests, material preparation, and others)\nUnderstand, identify and locate the data sources.\nExtract, transform and load large scale dataset across systems.\nPerform analysis to the curated datasets (reporting, visualization, hypothesis testing, machine learning)\nIf necessarily, prototype relevant applications (API, websites and others)\nComfortable documenting and presenting research progress to relevant stakeholders\nQualifications:\nStrong verbal and written communication skills\nGreat flexibility working in an agile environment and work cross functionally\nSelf motivator and comfortable learning new field (different aspect of business processes)\nProven academic success in STEM or quantitative related field (projects/GPA)\nMeet the criteria in one of the following items with proven record:\nStrong knowledge in one of the programming languages (Python/R/Java)\nStrong knowledge in any type of SQL and database (MySQL/MSSQL)\nStrong knowledge in any of the reporting tools (PowerBI / Tableau / Qliksense)\nPreferred Qualifications:\nProfessional experience in relevant fields (previous internships, projects, open source projects, volunteer work)\nWorking experience in the Hadoop ecosystem (Cloudera/Hortonworks)\nKnowledge in machine learning and predictive analytics\nCompensation\n\nThis is a paid position.\n\nArrow is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, gender, sexual orientation, gender identity, national origin, veteran or disability status. (Arrow EEO/AAP policy)\n\n#Dice\n\n#LI\n\nLocation:\nDenver (Panorama)\nTime Type:\nFull time\nJob Category:\nBusiness Support\nTo apply to this job, click Apply Now"}, "145": {"company": "ProKarma", "description": "Who We Are\nLenati, a pk Company, is a premier consultancy helping companies develop innovative and disruptive customer experiences. We work across the customer lifecycle \u2013 acquisition, engagement, CX, and loyalty \u2013 to build stronger customer connections. As the strategy & design service line of ProKarma, we have a global footprint that enables us to scale solutions across strategy, design, prototype, and development using cutting-edge technology to deliver high-value experiences. A career at Lenati means you have the opportunity to provide insight, guidance, and winning strategies to Fortune 100 clients while building your personal brand as a thought leader.\nThe Advanced Analytics Manager will lead designing and delivering innovative analytics and data science solutions to clients in a variety of verticals. This role will be responsible for building relationships with current clients to find new opportunities for the team. You\u2019ll assist strategy-side leadership in crafting a vision for data science on strategy projects as well as driving your own relationships with client-side technical decision-makers. You will be responsible for managing a team of data scientists, analysts, and technical managers to implement that vision.\n\nWhat You'll Do\nBe an authority on data science industry best practices and practical applications for the team and the organization\nAssist business development teams with project estimation, scoping, and planning\nServe as the engagement lead - manage all client interactions and expectations while keeping the projects on track\nLead team - facilitate workshops, encourage collaboration, assign workflows, provide feedback, and mentor 3-8 consultants\nWork with strategy-side teams to create solutions, as well as other functional practice areas at Lenati, including Design and Digital, Reporting Services, and Insights\n\nWhat You Bring\nAbility to provide strategic input on all projects the team is involved with, from business development and proposals to solution execution\nExpertise at communicating with data scientists and business decision-makers, able to translate a business problem into a technical solution\nThe desire to engage in business development, sales, and building relationships with clients\nPrevious experience developing and implementing solutions in R, Python, and SQL\n4+ years of experience working on data science, advanced analytics, and machine learning topics in a business context\n2+ years of experience leading a technical team, managing competing deadlines\nBS or MS in a quantitative field such as computer science, data science, statistics, or engineering\nPreferred experience in other languages in addition to R, Python, and SQL, including F#, Scala, Java, C#, or Go\nPreferred experience with other database tools such as Hadoop, Spark, or MapReduce, as well as experience in database design\nStart your job application: click Apply Now"}, "146": {"company": "DOCOMO Innovations", "description": "Responsibility\nThe ideal candidate will be responsible for real world Data Science problems, including but not limited to: Data planning/collections,\nannotation strategies and developing the state-of-the-art deep learning algorithms in the field of both computer vision/NLP to operate\non large data sets that provides robust situational assessment and predictive capabilities.\n\nPerform prototype implementation of the algorithms developed, solid engineering and classical CS knowledge is the key to success for this position.\nShare knowledge by clearly articulating ideas through papers and presentations to technical staff, management.\nQualifications\nBasic CS background (Algorithms/Data Structure) is absolutely essential, Engineering skill needs to be solid and will be tested.\nHeavy exposure computer vision/Open CV\nGood understanding of scikit-learn\nMust be professional level in Python and C++/C.\nFluency in Pytorch or Tensorflow/Keras, skills will be assessed\nMaster/Ph.D in the field of Computer Science, Computer Engineering, Electrical Engineering, Mathematics or related field"}, "147": {"company": "Travelers", "description": "Company Information\nSolid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n\nJob Summary\nThe Claim Business Intelligence & Analytics organization is looking for a Data Engineer to join our Analytic Platform team. This position will focus on implementing predictive models within our models as a service framework and will work with and develop APIs, batch services and real-time services. This position will support all lines of business and will partner closely with the Claim Technology group. The role will work with many different tools and technologies, and successful candidates should be comfortable working with SQL and Python. Experience working in an agile and/or test-driven development framework, experience working with a big data platform (i.e. Hadoop) and/or experience working with a cloud platform (i.e. AWS) are all pluses.\n\nMarketing Description\n\nPrimary Job Duties & Responsibilities\nData Analysis, Acquisition, Preparation, and Exploration: Independently perform Data Acquisition, Prep and Exploration: reviews, prepares, basic design, and integrates data. Able to correct minor problems and implements data cleansing/quality solutions. Apply moderate and develops basic data derivations, business transformation rules, and data requirements. Present simple data visualizations to help support data exploration as needed. Data Solutions & Analytic Implementations: Operationalize and automate well defined simple data products independently. Build, test, and implement simple analytic processes, including pilots and proof of concept. Assist in training business users on data products/analytic environment. Delivers basic training. Apply knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects. Data Culture: Continue to develop insurance and business intelligence knowledge while learning how work assignments address business issues. Understand Travelers standards, processes, and environmental landscape. Incorporate core data management competencies - data governance, data security, data quality. Share knowledge with peer users on data or analytic products. Perform other duties as assigned.\n\nMinimum Qualifications\n1 year of relevant experience with data tools, techniques, and manipulation required.\n\nEducation, Work Experience & Knowledge\nEducation: College Degree in STEM related field Technical Knowledge: Intermediate knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to): Big data and Cloud platforms Programming languages - SAS, SQL, Spark, Python, Hive, AWS Visualization platforms: QlikView, Tableau and Qlik Sense Experience: 3 years of relevant experience with data tools, techniques, and manipulation preferred.\n\nJob Specific & Technical Skills & Competencies\nCommunication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Problem Solving & Decision Making: Able to recognize and analyze business and data issues of intermediate complexity with minimal supervision. Recognize when escalation is necessary. Able to leverage previous experience to consider a variety of alternatives to arrive at a timely, practical, and cost-effective solution to resolve defects or incidents. Relationship Management: Ability to foster relationships with peers to achieve objectives. Practices objectivity and openness to others' views. Able to recognize and support team priorities. Planning and Project Management: Ability to manage time and competing priorities and provide management with accurate and timely status information. Able to effectively evaluate and estimate routine tasks with clear precedent.\n\nPhysical Requirements\nOperates standard office equipment - Continuously Sitting (Can stand at will) - Continuously Use of Keyboards, Sporadic 10-Key - Continuously.\n\n#Dice\n\nEqual Employment Opportunity Statement\nTravelers is an equal opportunity employer.\nStart your job application: click Apply Now"}, "148": {"company": "HouseCanary", "description": "At HouseCanary, we\u2019re using data and analytics to predict the future of US residential real estate. Our goal is to help people make better decisions by offering innovative and unparalleled insights. HouseCanary\u2019s platform accurately forecasts values 36 months into the future for four million residential blocks and more than 100 million properties.\n\nWe\u2019re seeking a passionate Machine Learning Engineer to join our research team and help build out the backend analytics platform powering the most accurate real estate analytics tools in the world.\nWhat you'll do:\nMake meaningful contributions to all phases of research including - building, scaling and pipelining models and analytics\nCollaborate with talented data scientists to research, optimize, scale and deploy to production predictive models\nCreate new features leveraging text mining, computer vision and geospatial techniques for every single family residential property in US\nDevelop performant and reliable distributed services to integrate core research outputs into products across the company\nDesign elegant and efficient solutions that handle and expose large datasets and complex model frameworks\nArchitect fault tolerant pipelines to cleanse, standardize, and process data\nWhat you have:\n3+ years of software engineering experience\nExpertise in Python development\nMastery in working with complex datasets\nInterest in implementing and improving statistical/machine learning models\nSolid SQL knowledge\nComfort with Linux command line\nExperience with AWS\nSpecial consideration given for:\nExpertise in R\nKnowledge of real estate markets\nGeospatial development experience\nFantastic sense of humor\nHouseCanary is the authoritative source for accurate, uniform information, analyzed and visualized real-time to make better, faster decisions.\n\nHouseCanary - one platform, infinite insights.\nApply Now: click Apply Now"}, "149": {"company": "Integral Ad Science", "description": "As a Data Analyst at IAS you will join an ambitious, close-knit team responsible for producing client insights and internal business intelligence used to drive decision making at all levels of the organization. Your role will primarily focus on maintaining and optimizing the data model on top of which Power BI sits to produce insights both internally and externally. The role also has room to expand into business analytics and informing key business decisions.\n\nWhat you'll do:\nPropose and develop solutions independently and in collaboration with others to:\ncollect disparate external and internal data sources,\naggregate structured and unstructured data repositories,\nprocess the data to form a fluent data model, and\ngenerate insight into a multi-million-dollar product line\nDiscover actionable insights from data and present them through rich visualization\nProduce insights that fuel strategic initiatives in corporate strategy, product development, and lead generation\nImmerse in frequent collaboration with leadership in Sales, Marketing, and Product as well as with our Executive team\nWho you are and what you have:\nBachelor's Degree in mathematics, statistics, finance, economics, computer science, or a related math-centric discipline\n2-3 years of experience in an analytical role\nStrategic, innovative thinker with an interest in the ad tech and media industry\nA go-getter mentality and the desire to take ownership of your project roadmap\nPassion for using data to make well-informed business decisions\nTakes pride in data integrity and efficient, scalable processes\nAbility to clearly and efficiently communicate ideas\nAffinity for high-paced, dynamic environments\nAbility to analyze complex data models\nStrong project management skills\nEager to contribute\nHigh proficiency in SQL, Python, Excel, and a data visualization software. PowerBI is a plus.\nAbout Integral Ad Science\n\nIntegral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 17 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.\n\nEqual Opportunity Employer:\n\nIAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.\n\nTo learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN\n\nAttention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.\nTo apply to this job, click Apply Now"}, "150": {"company": "Genentech", "description": "The Position\n\n\nAs a Senior Data Scientist within our Personalized HealthCare function you will work with imaging and -omics data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access.\n\nYou will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions. You will design, develop and program methods, processes, and systems to consolidate and analyse unstructured, diverse data sources; you will code software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources. The data will be dynamic in type the focus will be on clinical imaging data, which needs to be linked and integrated with real-world longitudinal data, including patient registries, electronic medical records, claims, biobanks, and clinical trials, as well as deep patient-level digital pathology, -omics (e.g. genomics, proteomics), and digital health data.\n\nThe evidence and insights will be used to inform the research and development of our molecules, and support healthcare decisions by patients, physicians, health authorities, payers, and policy-makers. You will also contribute to functional, cross-functional, enterprise-wide or external initiatives that craft our business and healthcare environments. This will require a deep understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical data science expertise. You will need strong strategic, collaboration and communication skills, as well as an entrepreneurial mindset, to transform the way we use data and analytics to develop and deliver medicines for our patients.\nIdentify evidence needs & recommend data solutions: Proactively ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.\nDevelop data strategy & gain access to data: Develop strategic plans to access fit-for-purpose data sources to support evidence generation, and gain access to data through collaboration or data generation.\nDive into data: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.\nBe an expert in applying methods, especially to raw and preprocessed clinical imaging data. Be able to interpret the fine details of the images, understand the processes from sample acquisition to clinical interpretation and report, as well as understand the underlying biology captured by the image. Stay current with and adopt emergent analytical methodologies, tools and applications to ensure fit-for-purpose and impactful approaches.\nProduce high quality analyses: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to improve impact and interpretability; implement and/or lead the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.\nInterpret and share results: Communicate findings to internal partners, regulatory, health technology assessment (HTA) bodies and scientific communities; publish results; participate in external meetings and forums to present your insights (e.g. congress/conference).\nCollaborate and create: contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaboratives, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.\nMinimum qualifications\nPhD in a quantitative data science discipline (e.g., statistics/ biostatistics, computer science, mathematics, epidemiology, bioinformatics, health economics, computational biology, outcomes research, public health, biology, medicine, psychology)\nShown examples of developing and executing data science research projects involving medical imaging (Digital pathology, OCT, color fundus, MRI, PET, and/or CT) using traditional analytical methods as well as deep learning AI, and experience with integrating imaging results with patient-level data analyses (e.g., transcriptomics, metabolomics, WES/WGS, real world data, surveys, clinical trials, registries, claims, digital pathology, and digital health data) with publications and presentations\nExperience with all steps of semi-automated analysis and interpretation of clinical images (QC, preprocessing, segmentation and prediction) using state of the art methods (e.g., deep learning AI).\nExperience with the analysis of large-scale clinical RNASeq, metabolomics, WGS, WES and other types of -omics data\nProven experience with implementing a range of statistical modeling techniques (multivariate modeling, longitudinal data analysis, time-to-event analysis, machine learning, causal inference, etc.) as well as an understanding of advanced analytics applied to images, -omics or to integrated data sources\nFluency in statistical programming languages (R, Python, SAS etc.), experience producing interactive outputs (Shiny, R, Markdown, etc.) and visualization tools.\nContributor to open source packages, libraries or functions\nExperience with technologies required to undertake analyses on large data sources or with computationally intensive steps (SQL, parallelization, Hadoop, Spark, etc.)\nExperience implementing reproducible research practices like version control (e.g., using Git) and literate programming\nExperienced in scoping projects and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges\nStrong collaboration skills and excellent communication skills and stakeholder management in a complex and ambiguous environment\nDemonstrated entrepreneurial mindset and self-direction, ability to teach others and ability to learn new techniques\nProficiency in English, both written and verbal\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\n#LI-PDHB2\n\nWho We Are\n\n\nA member of the Roche Group, Genentech has been at the forefront of the biotechnology industry for more than 40 years, using human genetic information to develop novel medicines for serious and life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious illnesses. Please take this opportunity to learn about Genentech where we believe that our employees are our most important asset & are dedicated to remaining a great place to work.\n\nThe next step is yours. To apply today, click on the \"Apply online\" button.\n\nGenentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.\nTo apply to this job, click Apply Now"}, "151": {"company": "Teaching Strategies, LLC", "description": "About us\n\nTeaching Strategies is a high growth,privateequitybacked, market leading business in early childhood education. The Company provides the most innovative and effective curriculum, assessment, professional development, and family connection resources to programs serving children from birth through 3rd grade. With ground-breaking print and SaaS solutions and a strong belief that the most powerful way to impact child outcomes is to improve teacher effectiveness, Teaching Strategies has been supporting the critical work of early childhood educators for over 30 years.\n\nLocated in downtown Bethesda, MD, our company's headquarters are within steps from Bethesda Row and the Bethesda Metro stop. Candidates who fit with our values, vision, and mission will find a work environment that fosters creativity, innovation and career growth. We are building a team of results-oriented individuals who will thrive in a collaborative, work-hard/play-hard culture. We pride ourselves on the impact we have on the early childhood field through supporting teachers who are doing the most important work there is, teaching children to become creative, confident thinkers.\n\nPosition Overview\n\nTeaching Strategies is looking for a highly talented, innovative and creativeDataEngineer to join its technology team. We are looking for engineers that want to make a real impact in early childhood education. Our platform is evolving, so you need to be someone who cananalyze, architectandbuild newdata centric capabilities,learn new technologiesandmaintain and extend existingdata models andETL processesto support organizational needs.TheDataEngineer will workto design and implement data architectures in support of new analytical and predictive cloud-based systems. The candidate will become a part of theSoftware Engineeringteam and will use existing relational, dimensional, and NoSQL databases as data sources for a cloud-based managed data solution. These will support enterprise information management, business intelligence, machine learning, data science, and other business interests.\n\nOur Software Engineering team is responsible for building SaaS solutions usedby early childhood providers.This work impacts outcomes for millions of children while supporting and providing great tools for our educators.The team works on a wide variety of projects, solving existing problems anddelivering onnew business objectives. If you thrive in a fast-paced environment, workingwith data andon software that supports millions of users daily, then you have an opportunity to join the technology group at Teaching Strategies.\n\nWhat's in it for you:\nTeaching Strategies offers our employees a robust suite of benefits and other perks which include:\nBeautifully designed, open office space\nEndless cereal and coffee\nFree on-site gym\nCasual dress environment\nCompany sponsored events\nProfessional development and growth opportunities\nTuition assistance\nCompetitive compensation package\nMedical, dental, and vision coverage for spouses, domestic partners, and children\nPre-tax medical and dependent care flexible spending accounts (FSA)\nHealth savings accounts with employer contributions\n401(k) plan with employer match\nCompany sponsored life,short and long termdisability insurance\nVoluntary life and critical illness insurance\nCommuter benefits\nPaid parental leave programs\nGenerous paid time off (which includes Winter Break)\nSpecific roles and responsibilities:\nDesign and development ofETLprocessesfrom desperate data stores into a managed data warehouse / data lake\nDesign anddevelopment of data warehouse/datalakearchitecture\nImplements and supports AI/ML modelsto support BI initiatives\nParticipates in planning, analysis and design of newdata centricsolutions\nInvestigates, troubleshoots and remediesissues\nLearns new technologies and keeps up with both traditional and emerging best practices\nWorks independently and collaborates with other members of the team to ensure successful delivery of projects\nAbout you:\n5+ years of production experience indata architectureengineering and development\nWorking knowledge of:\nAWS Redshift / Athena / Lake formation\nRelationaldb's(SQL Server,Postgresql,MySql)\nNo SQLdb's(MongoDB, DynamoDB, Cassandra, etc.)\nStreaming data\nProduction experience with PostgreSQLand SQL Server\nHands-on experience with Git version control system\nExcellent debugging and testing skills, and interest to quickly learn new technologies\nExperience with Agile methodology and software development\nCommitment to following security and performance best practices\nStrong sense of collaboration, teamwork, and accountability\nTeaching Strategies, LLC is committed to creating a diverse workplace and is proud to be an equal opportunity employer of Minorities, all Genders, Protected Veterans and Individual with Disabilities.\nApply Now: click Easy Apply"}, "152": {"company": "Los Alamos National Laboratory", "description": "Vacancy Name: IRC72601\n\nDescription\n\nJob Title Theoretical Design Scientist 2 (Scientist 2)\n\nLocation Los Alamos, NM, US\n\nOrganization Name XTD-DO/X Theoretical Design\n\nMinimum Salary 89900\n\nMaximum Salary 148300\n\nWhat You Will Do\n\nX-Theoretical Design (XTD) division members are the scientific stewards of the U.S. nuclear stockpile, applying theoretical and computational physics to the performance and safety of nuclear weapons. XTD scientists also contribute their expertise to the nation\u2019s foreign threat assessment, counter-proliferation and non-proliferation efforts through assessment of foreign devices, design of tools to address nuclear emergency response scenarios, and creation of solutions to inhibit nuclear proliferation. In addition, XTD scientists drive cutting edge advances in astrophysics, geophysics, high energy density physics, inertial confinement fusion, chemistry, and material science. Members of XTD use multi-physics codes, running on some of the world\u2019s fastest supercomputers, to create and analyze simulations of very complex systems. We work closely with many other organizations in a diverse variety of tasks, including experimental design and analysis, model development, code validation, and project leadership. The selected candidate will:\nDevelop/demonstrate a thorough knowledge of and capability with large, multi-physics codes.\nApply multi-physics codes to solve problems of national security interest.\nContribute to one or more of these related tasks: experimental design and analysis, model development efforts, data evaluation, and code validation.\nContribute to both individual and team efforts.\nLearn and develop skills in complementary disciplines to demonstrate generalist capabilities.\nWork with a wide variety of colleagues with varying backgrounds on research covering multiple physics areas in order to solve difficult problems.\nDemonstrate a commitment to quality research, technical and scientific excellence, professional integrity, and personal initiative.\nWhat You Need\n\nMinimum Job Requirements:\nGraduate level training in multi-disciplinary sciences.\nA desire to contribute to issues related to national security.\nExperience with one or more of these related tasks: experimental design and analysis, model development efforts, data evaluation, and code validation.\nDemonstrated commitment to quality research, technical and scientific excellence, professional integrity, and personal initiative.\nAbility and willingness to obtain a DOE Q-clearance, which requires US citizenship.\nDesired Skills:\nActive Q Clearance\nExperience with large-scale computing.\nFamiliarity with design and analysis of nuclear weapons.\nExperience in designing, analyzing and/or conducting experiments.\nTechnical leadership experience.\nSupervisory or mentoring experience.\nKnowledge and experience relative to uncertainty and/or risk analysis.\nEducation Required:\nMS or PhD degree in science from an accredited college or university required.\nPhD preferred with postdoctoral work in one of the following or in a related field: Physics, Engineering, Applied Mathematics, or Materials Science.\nNotes to Applicants: Please attach a resume, a detailed cover letter addressing all required and desired skills, and a transcript (unofficial is acceptable) with your application . Please note that without a resume, cover letter and transcript your application will not be considered.\n\nAdditional Details:\n\nClearance: Q (Position will be cleared to this level). Applicants selected will be subject to a Federal background investigation and must meet eligibility requirements\nfor access to classified matter.\nEligibility requirements: To obtain a clearance, an individual must be at least 18 years of age; U.S. citizenship is required except in very limited circumstances. See DOE Order 472.2 for additional information.\nNew-Employment Drug Test: The Laboratory requires successful applicants to complete a new-employment drug test and maintains a substance abuse policy that includes random drug testing.\n\nRegular position: Term status Laboratory employees applying for regular-status positions are converted to regular status.\n\nInternal Applicants: Please refer to Laboratory policy P701 for applicant eligibility.\n\nEqual Opportunity: Los Alamos National Laboratory is an equal opportunity employer and supports a diverse and inclusive workforce. All employment practices are based on qualification and merit, without regards to race, color, national origin, ancestry, religion, age, sex, gender identity, sexual orientation or preference, marital status or spousal affiliation, physical or mental disability, medical conditions, pregnancy, status as a protected veteran, genetic information, or citizenship within the limits imposed by federal laws and regulations. The Laboratory is also committed to making our workplace accessible to individuals with disabilities and will provide reasonable accommodations, upon request, for individuals to participate in the application and hiring process. To request such an accommodation, please send an email to applyhelp@lanl.gov or call 1-505-665-4444 option 1.\n\nWhere You Will Work\n\nLocated in northern New Mexico, Los Alamos National Laboratory (LANL) is a multidisciplinary research institution engaged in strategic science on behalf of national security. LANL enhances national security by ensuring the safety and reliability of the U.S. nuclear stockpile, developing technologies to reduce threats from weapons of mass destruction, and solving problems related to energy, environment, infrastructure, health, and global security concerns.\n\nOur diverse workforce enjoys a collegial work environment focused on creative problem solving, where everyone\u2019s opinions and ideas are considered. We are committed to work-life balance and personal/professional growth. Our creative and dedicated computational professionals are our greatest asset and we take pride in cultivating their talents, supporting their efforts, and enabling their success. Together we are advancing our national security mission.\n\nCompensation and Benefits\nCompetitive salaries\nFlexible work schedules\nExercise facility free for staff use\nChoice of comprehensive medical plans\nPaid maternity leave, sick time\nPaid parental leave\n401k match (100% up to 6% + kicker)\nFully vested in 401k day one\nDisability insurance\nLos Alamos National Laboratory in Los Alamos, NM enjoys excellent weather, clean air and outstanding public schools. This is a safe, low-crime, family-oriented community with frequent concerts and events as well as quick travel to many top ski resorts, scenic hiking trails, and mountain climbing. The short drive to work includes stunning views of the Valles Caldera as well as the Sangre de Cristo mountains. Many employees also live in the nearby state capital, Santa Fe, which is known for world-class restaurants, art galleries, and opera.\n\nAppointment Type Regular\n\nRegular\n\nContact Details\n\nContact Name Vigil, Jessica Marlene\n\nEmail jessica_m@lanl.gov\n\nWork Telephone\n\nReq ID: IRC72601\nApply Now: click Apply Now"}, "153": {"company": "Q-Centrix", "description": "Data Scientist \u2013 Statistics and Machine Learning\nWho are we?\n\nQ-Centrix is a leading healthcare information solutions provider with offices in Portsmouth, NH, Chicago, and San Diego, plus more than 900 clinical experts working remotely in 49 states. Our team of smart, ambitious, and fun-loving healthcare professionals are 100% focused on improving the quality of patient care at hospitals throughout the country.\n\nAbout the Job\n\nWe are looking for a Data Scientist to join us at our San Diego office. We are an engineering team with a growing Data Science discipline. We are a data driven organization that loves to gain new insights from the massive amount of structured and unstructured data that we are collecting on a daily basis.\nAs a Data Scientist, you will:\n\n\nWork closely with our business operations teams and clinicians to provide statistical analysis, implementation and interpretation of the results\nDevelop and operationalize a new sampling methodology to ensure confidence in our registry data capture workflows\nLeverage your experience working with supervised machine learning methods such as ensemble tree classifiers, support vector machines, neural networks, and Bayesian methods to create state-of-the-art predictive models for categorical variables\nPlay a key role in the development of an automated data capture auditing software to ensure quality of work at completion\nCommunicate your successful efforts through documentation and white papers\nKnowledge, Skills, Abilities and Qualification Requirements:\nB.S. in Applied Statistics and 3+ years of prior experience or M.S. in Applied Statistics and 1+ years of prior experience in an applied statistics discipline\nQuality Requirements:\nPositively contribute to our work environment values of professionalism, mutual respect, teamwork, and collaboration.\nKey Competencies:\n\n\nProfessionalism and customer service orientation\nAbility to manage multiple projects\nPlanning, organization and excellent time management\nAttention to detail and unrelenting passion for delivery\nFlexibility, adaptability, and teamwork\nYou\u2019re our dream candidate if you:\n\n\nHave a passion for applying your statistical knowledge and experience to solve business problems\nHave a proven track record for developing sampling strategies\nAre passionate about automation and consider yourself an advanced python software developer\nAre intimately familiar with the latest techniques in predictive data modeling including deep learning\nLove data science competitions and are an active participant in kaggle competitions\nLove writing detailed documentation of your completed research, and lastly,\nYou love dogs and cats!\nQ-Centrix LLC is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\nStart your job application: click Apply Now"}, "154": {"company": "S&P Global Ratings", "description": "The Team: The Data science team is a newly formed applied research team within S&P Global Ratings that will be responsible for building and executing a bold vision around using Machine Learning, Natural Language Processing, Data Science, knowledge engineering, and human computer interfaces for augmenting various business processes.\n\nThe Impact: This role will have a significant impact on the success of our data science projects ranging from choosing which projects should be undertaken, to delivering highest quality solutions, ultimately enabling our business processes and products with AI and Data Science solutions.\n\nWhats in it for you:\nThis is a high visibility team with an opportunity to make a very meaningful impact on the future direction of the company. You will work with senior leaders in the organization to help define, build, and transform our business.\nYou will work closely with other senior scientists to create state of the art Augmented Intelligence, Data Science and Machine Learning solutions.\nThe team actively participates in top-tier academic and industry conferences by publishing research and organizing workshops. Depending on your interest, you can be part of these efforts.\nResponsibilities: As an NLP Data Scientist you will be responsible for building AI and Data Science models with a main focus on mining insights from text corpora. You will need to rapidly prototype various algorithmic implementations and test their efficacy using appropriate experimental design and hypothesis validation.\n\nBasic Qualifications: BS in Computer Science, Computational Linguistics, Artificial Intelligence with a heavy focus on NLP/text mining, or related field with 5+ years of relevant industry experience. There is some flexibility in adjusting the seniority to your level of education and experience.\n\nPreferred Qualifications:\nMS in Computer Science, Computational Linguistics, Artificial Intelligence with a heavy focus on NLP/text mining with 3+ years of relevant industry experience.\nExperience with Financial documents such as SEC filings, financial reports, credit agreements, business news, or S&Ps credit ratings process is a plus.\nWhat we look for in your background:\nCreativity, resourcefulness, and a collaborative spirit.\nKnowledge and working experience in one or more of the following areas: Natural Language Processing, Clustering and Classification of Text, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Knowledge Engineering, Search Rank and Recommendation.\nDeep experience with text-wrangling and pre-processing skills such as document parsing and cleanup, vectorization, tokenization, language modeling, phrase detection, etc.\nProficient programming skills in a high-level language (e.g. Java, Scala, Python)\nBeing comfortable with rapid prototyping practices.\nBeing comfortable with developing clean, production-ready code.\nBeing comfortable with pre-processing unstructured or semi-structured data.\nExperience with statistical data analysis, experimental design, and hypotheses validation\nProject-based experience with some of the following tools:\nNatural Language Processing (e.g., Spacy, NLTK, ClearTK, ScalaNLP/Breeze, ClearNLP, OpenNLP, or similar)\nApplied machine learning (e.g. libSVM, Shogun, Scikit-learn, SparkML, H2O, or similar)\nInformation retrieval and search engines, e.g. ElasticSearch/ELK, Solr/Lucene\nDistributed computing platforms, such as Spark, Hadoop (Hive, HBase, Pig), GraphLab\nDatabases (traditional and noSQL)\nProficiency in traditional Machine Learning models such as SVMs, LDA/topic modeling, HMMs, graphical models, etc.\nOptional: familiarity with Deep Learning architectures and frameworks such as PyTorch, Tensorflow, Keras.\nTo all recruitment agencies: S&P Global does not accept unsolicited agency resumes. Please do not forward such resumes to any S&P Global employee, office location or website. S&P Global will not be responsible for any fees related to such resumes.\n\nS&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment.\n\nIf you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.\n\nThe EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdfdescribes discrimination protections under federal law.\nTo apply to this job, click Apply Now"}, "155": {"company": "Plymouth Rock Assurance", "description": "The Senior Data Scientist independently develops statistical models that will enable future growth and profitability for our book of business through appropriate pricing and underwriting of risk. He/she is responsible for the formulation of statistical models and direct application of models to address insurance business issues.\nEssential Functions and Responsibilities\nProduces complex predictive models which enable the creation of rating plans and evaluation of risk and profitability.\nDevelops studies that evaluate new business models for customer retention and growth initiatives as well as estimate the lifetime value of customer segments.\nIdentifies drivers of insurance costs, understanding the economics of customers\u2019 behavior and estimating the expected losses for segments of risks using advanced statistical and analytical techniques on large data sets.\nDevelop or participate in the development of the overall analytical framework to support the company\u2019s strategy for growth\nCommunicates analysis, strategy and recommendations to diverse audiences, including technical and non-technical.\nCollaborates with upper management to assess the potential effects of proposed solutions and incorporates these considerations into recommendations.\nManages projects of high complexity.\nPerform other job-related duties as assigned.\nAdvanced skills and training in predictive modeling, data mining and other quantitative and research analytics (Non-Linear Regression Analysis, Multivariate Analysis, Bayesian Methods, Generalized Linear Models, Decision Trees, Non Parametric estimations, etc.).\nAbility to apply various predictive modeling techniques to develop solutions to various real-world problems.\nHands-on experience developing and delivering structured, methodology projects.\nExceptional programming ability in SAS, SQL, R or other programming languages.\nExcellent written and oral communication and presentation skills.\nIn-depth understanding of database principles and experience working with large databases.\nAbility to influence and guide across departmental boundaries.\nQualifications and Education\n3 or more years of experience developing and implementing multivariate predictive models using GLM and other statistical methods. PhD in economics, statistics, or related field required.\nOr in the alternative, a Master\u2019s degree in Statistics, Engineering, Mathematics, Economics, or a related field (foreign educational equivalent accepted) and five (5) years of experience as indicated above.\nHigh level of organizational and project management experience handling multiple projects simultaneously\nAbout the Company\nThe Plymouth Rock Company and its affiliated group of companies write and manage over $1.4 billion in personal and commercial auto and homeowner\u2019s insurance throughout the Northeast and mid-Atlantic, where we have built an unparalleled reputation for service. We continuously invest in technology, our employees thrive in our empowering environment, and our customers are among the most loyal in the industry. The Plymouth Rock group of companies employs more than 1,800 people and is headquartered in Boston, Massachusetts. Plymouth Rock Assurance Corporation holds an A.M. Best rating of \u201cA-/Excellent\u201d.\n\n\nStart your job application: click Apply Now"}, "156": {"company": "ManTech", "description": "Secure our Nation, Ignite your Future\n\nJob Summary\n\nEach day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of big data solutions to promote efficient trade and travel. Further, effective big data solutions help CBP ensure the movement of people, capital, and products is legal, safe, and secure. In response to this challenge, ManTech, as a trusted mission partner of CBP, seeks capable, qualified, and versatile data scientists to help lead the development and delivery of high-quality predictive modelling solutions.\n\nAs a Senior Data Scientist on our team, you will utilize your subject matter expertise in the application of quantitative methods, machine learning algorithms, and predictive models to address complex national and homeland security challenges. You will help your team to leverage large structured and unstructured datasets to develop and operationalize models, tools, and applications that drive optimized decision making. Project tasks include data collection, mining, data and text analytics, clustering analysis, pattern recognition and extraction, automated classification and categorization, and entity resolution to implement and enhance automated risk assessment. The products we develop provide actionable insight with real and immediate impact on the safety and security of the United States, its citizens, visitors, and economy.\n\nJob Description\nLead and perform hands-on analysis and modeling involving the creation of intervention hypotheses and experiments, assessment of data needs and available sources, determination of optimal analytical approaches, performance of exploratory data analysis, and feature generation (e.g., identification, derivation, aggregation)\nCollaborate with mission stakeholders to define, frame, and scope mission challenges where big data interventions may offer important mitigations and develop robust project plans with key milestones, detailed deliverables, robust work tracking protocols, and risk mitigation strategies\nDemonstrate proficiency in extracting, cleaning, and transforming CBP transactional and mission data associated within an identified problem space to build predictive models as well as develop appropriate supporting documentation.\nLeverage expert knowledge of a variety of statistical and machine learning techniques and methods to define and develop programming algorithms; train, evaluate, and deploy predictive analytics models that directly inform mission decisions.\nExecute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching.\nBrief project management, technical design, and outcomes to both technical and non-technical audiences including senior government stakeholders throughout the model development/ project lifecycle through written as well as in-person reporting.\nRequired Qualifications\nSignificant experience in developing machine learning models and applying advanced analytics solutions to solve complex business problems\nProficiency with statistical software packages: SAS, SPSS Modeler, R, WEKA, or equivalent\nExperience with programming languages: R, Python, Scala, Java, SQL, or equivalent\nExperience constructing and executing queries to extract data in support of EDA and model development\nExperience with unsupervised and supervised machine learning techniques and methods\nExperience working with large-scale (e.g., terabyte and petabyte) unstructured and structured data sets and databases\nExperience performing data mining, analysis, and training set construction\nMasters degree in operations research, industrial engineering, mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience\nDesired Qualifications\nExperience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop)\nProficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc.\nProficiency with Supervised Machine Learning methods including Decision Trees, Support Vector Machines, Logistic Regression, Random/Rotation Forests, Categorization/Classification, Neural Nets, Bayesian Networks, etc.\nExperience with pattern recognition and extraction, automated classification, categorization, and entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation)\nExperience working in a team and deploying solutions in an iterative or agile/DevOps continuous integration and delivery environment using lifecycle management methods and tools\nExperience with visualization tools and techniques (e.g., Periscope, Business Objects, D3, ggplot, Tableau, SAS Visual Analytics, PowerBI)\nPh.D. degree preferred\nActive Top Secret Clearance\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS clearance is required as well as CBP suitability.\n\nMust be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) Background Investigation.\n\n#LI-FA1\n\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\n\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.\nApply Now: click Apply Now"}, "157": {"company": "Traeger Wood Pellet Grills", "description": "Company Description:\n\nTraeger Grills, headquartered in Salt Lake City, has been revolutionizing BBQ grilling and outdoor cooking for 30 years. We obsess over providing world-class experiences to not only our customers, but also to our retail partners and vendors. Recently voted as a 2016,2017, & 2018 Best Company to Work For, and a Top 25 Fastest Growing Company by Utah Business Magazine, we're looking for individuals who are committed to winning. We pride ourselves on maintaining a culture based around teamwork, quality, innovation and constant growth and development. We cook together and we win together!\n\nJob Description:\n\nDrive the design and delivery of world-class data solutions that will increase experiences for the company and customers. Ideal candidate will have a solid understanding of cloud and data computing with the relevant technology platforms. Will have technical ownership of digital experience all types of analytics for data in motion and at rest. Should have a positive attitude, communication skills, and deep technical knowledge to strategically guide the company towards success. Passion for reducing costs, maximizing performance, and delivering quality solutions.\n\nThis position will report to the Director of Cloud, IoT and Data.\n\nMachine Learning Engineer Responsibilities:\nBe the go-to-person for all descriptive, predictive, and prescriptive analytics.\nEngineer each solution with serverless technology when possible, with maximum performance and lowest cost.\nTake ownership of all analytics and deep learning charter to enhance the digital experience.\nExecute analytics strategy, requirements, and adapt processes as needed.\nSupport requests from all internal and external business units.\nPerform DevOps and orchestration for all data hub and analytical processes.\nMonitor and secure usage of data while tracking product analytics.\nAdvise and collaborate in internal partnerships to deliver accurate, available, and accessible data.\nCreate, document, and promote deep learning throughout company.\nEnsure all security, governance, and compliance standards are met.\nQualifications:\nPreference given to candidates with AWS certifications.\n1-5 years of experience building A.I, data science, and/or machine learning solutions.\nExperience using SQL, Python, AWS SageMaker, R, TensorFlow, Jupyter Notebook, etc.\nExperience with cloud operations, big data, data engineering, analytics, and business intelligence.\nDeep knowledge in relevant applied mathematics, data mining, proper testing and research.\nUnderstand data collection, streaming, preparation, analysis, visualization, modeling, algorithms, evaluation, optimization, and implementation.\nProtect and contribute to company culture by keeping a positive attitude and growing relationships.\nBachelor's degree in a relevant field.\nWhat We Offer:\nGenerous 401(k) plan\nFull medical/dental/vision package to fit your needs\nOpen-PTO Policy\nTuition Reimbursement\nCell Phone Reimbursement\nIndividual professional development programs and initiatives that help you grow and develop professionally\nA positive and supportive team to work with\nCompany provided meals throughout the week, Utah Gold Ski and SLC City Golf passes, Discounted Gym Memberships, generous Employee Discount Program, company sponsored Community Service opportunities, and much more!\nStart your job application: click Apply Now"}, "158": {"company": "Zions Bancorporation", "description": "Senior Data Scientist\n(\nJob Number:\n\n\n046663\n)\n\n\nDescription\n\n\n\nZions Bancorporation is currently looking for an experienced Data Scientist to join our Enterprise Data Science team. This role focuses on delivering insight from data that is actionable and will drive revenue growth, cost reduction, and meet new regulatory requirements. The team works on strategic projects with tactical components that aim to drive all business decisions to be data driven.\n\nThe Data Scientist will be responsible for end-to-end analytic projects including:\nThe understanding of business and data needs\nDiscovering, cleaning, and transforming data as needed\nDesigning and building analytical models\nPrototyping\nPerforming statistical analyses\nProviding diagnostic, descriptive, prescriptive, and predictive analytics\nDetermine opportunities and needs around the use of machine and deep learning for help in prescriptive and predictive analytics, automation, and model training\n\n\nQualifications\n\n\nBachelor's Degree in Computer Science, Engineering, Statistics or other related area of study\nMasters or PhD in Computer Science, Engineering, Statistics or other related area of study is preferred\n8+ years' experience preferred\nStrong quantitative background with applied statistics skills, such as distributions, statistical testing, regression, etc.\nFamiliarity with predictive modeling, machine learning, and data mining techniques and algorithms\nSoftware skills\nExperience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable\nData visualization tools, such as GGplot, Tableau, D3.js\nScripting language experience, such as Java, Perl, PHP, or Python\nProficiency with SQL\nHadoop/Hive/Pig/Spark is a plus\nETL workflows and scheduling is a plus\nStrong analytical, organizational, and problem solving skills\nStrong interpersonal, presentation, and communication skills, both verbal and written along with an understanding of how to present results such that they are meaningful across multiple levels of management\nAbility to function in a consultative role and lead a team or project\nAbility to effectively teach and train fellow team members on models, processes or tools\nAbility to collaborate and coordinate with multiple teams and team members\nMust be able to meet deadlines and work with little or no supervision\nExperience in banking or financial services preferred\nExperience working with formal project management methodologies or a project management certification preferred\n\nWork Locations\n\n\nUtah-Salt Lake City-UT - Zions Bancorporation - HDQTRS\n\nBusiness Operations\n\nSep 16, 2019\nApply Now: click Apply Now"}, "159": {"company": "Cadent", "description": "Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sourcescable, broadcast, and digital mediaour technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns.\n\nRight now we are looking for a highly motivated Data Scientist who will be responsible for the applying scientific methods to identify business optimization strategies, developing, evaluating and demonstrating prototypes of empirical software including but not limited to machine learning, signal processing and optimization based numerical methods.\n\nData Scientists collaborate directly with the Business Intelligence, Data Engineering and Development team members to productize research as reporting and business software. This is a critical mathematical engineering role whose work is leveraged by other engineers and by senior executives to define the future of Cadent.\n\nOur ideal player will:\nDesign, train and apply statistics, mathematical models, and machine learning techniques to create scalable solutions for predictive learning, forecasting and optimization\nWork with Software development team to deploy models as micro-services leveraged inside of business software products\nMonitor, maintain, and refine predictive models as necessary, including re-training\nWork with product team to align software goals with KPI's via empirical measure of effectiveness\nParticipate in the agile / scrum process\nFollow the CRISP-DM process to generate robust documentation associated with iterative work\nPresent results to technical and business stakeholders.\nCollaborate effectively with other members of the engineering research team and broader data services group including but not limited to Data Engineers, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence analysts\nOur ideal player will have:\nM.S. or higher in computer science, mathematics or related discipline with a focus on machine learning or the equivalent of 4 years of experience in machine learning, forecasting and\nPractical expertise building evaluating and deploying machine learning pipelines as with python, preferably with the scikit-learn ecosystem\nExperience with SQL, accessing and organizing data drawn from relational databases\nExperience in cloud computing ecosystems (preferably in AWS)\nPractical experience in deep learning architectures and frameworks is a plus\nProven background answering open ended research questions using data\nExperience with computational statistics and understanding of theoretical fundamentals of statistics\nStrong analytical and quantitative problem-solving ability.\nFundamental understanding of the mathematical workings of standard feature engineering and machine learning algorithms.\nDemonstrated communication skills including the ability switch between technical and business contexts.\nPreferably a background in software development\nExtra Credit if you have:\nMedia Experience\nAWS\nIf the leading edge of media technology is the place you want to be, please contact us today and let's start the conversation!\n\n/CADENT/ is an EOE M/F/D/V. We do not work with 3rd Party Staffing Agencies.\n\n]]>\nApply Now: click Apply Now"}, "160": {"company": "TrueAccord", "description": "Why TrueAccord?\n\nDebt collection is failing consumers. Every year, 77 million Americans have negative experiences with the collections process, and they deserve a better approach - one that is more relevant, more digital, and less abrasive. That\u2019s why banks, lenders, and industry leaders are coming to TrueAccord for innovative solutions recovering outstanding receivables.\n\nTrueAccord is a category-defining company. We combine machine learning with a human based approach to assist both clients and consumers through a challenging financial process. With a world-class leadership team, passionate and driven team members, and a diverse and growing client base, TrueAccord is well positioned for continued success. Come join our team and disrupt a multi-billion dollar industry that's been waiting for change.\n\nThe Role:\n\nTrueAccord is looking for a Data Scientist, Experimentation to join our Data team.\nYou will join a multi-functional team of data scientists, data engineers and Python developers dedicated to creating a data driven culture, improving the efficiency and dependability of the way we make decisions, and developing our automated debt collection strategy.\n\nWe make product and business decisions based on what we learn from experiments. Therefore, it is essential that we ask the right questions and gauge the right metrics to answer them. As a data scientist focusing on experimentation, you will apply statistical methods to design and analyze experiments, both for the consumer-facing product as well as machine learning models. You will work cross-functionally with product managers, designers, engineers and data scientists to cultivate a shared practice for running experiments, as well as to maximize their efficiency and impact. As a result of your efforts, you will proactively influence product decisions and our team will be better equipped to design and analyze experiments.\n\nWe\u2019re looking for someone with an excellent grasp on statistical techniques and a product focused mindset. You should be passionate about using data to create positive customer experiences, a strong self-starter, and determined to have a huge impact at TrueAccord.\nKey Responsibilities:\nDesign effective experiments for product and machine learning models, while collaborating with product managers, designers, engineers, and data scientists\nCreate actionable metrics for analyzing experiments and build dashboards to track and visualize them\nMaintain and monitor live experiments, and verify the integrity of data used for analysis\nExplain experiment results to both technical and non-technical stakeholders\nCollaborate with engineering to improve the experimentation pipeline and platform\nYou should have:\n1-2 years of relevant industry experience | Advanced degree in Statistics, Mathematics, Economics, Computer Science, or equivalent professional experience | Completed graduate level coursework in statistics-related fields, experimental design, or quantitative social sciences | Equivalent training\nStrong statistical knowledge of hypothesis testing, statistical distributions and sampling methodologies\nDemonstrated ability to design and analyze experimentation, as well as to present results and make recommendations\nSolid programming skills (Python preferred) as well as high command of SQL for data processing and analysis\nExperience with stakeholder-accessible visualization tools (e.g., Looker, Tableau, etc.)\nStrong cross-functional communication skills, and ability to communicate technical statistical concepts clearly to technical and non-technical partners\nDesire to work in San Francisco\nYou might also have:\nProven understanding of machine learning techniques, such as regression, classification, recommendation systems, optimization, etc.\nProficiency with statistical or data management Python libraries (scikit-learn, statsmodels etc.)\nZeal for data driven product development and data evangelism\nA strong business mind or consulting background\nBenefits and Perks:\nWork with talented and motivated people in a fast paced mission driven environment\nMedical/dental/vision insurance, 401k (with match), flex spending plan, and life insurance\nFamily friendly policies - parental leave, flexible work from home Unlimited PTO\nTransportation benefits\nTeam lunches and happy hours\nWhat TrueAccord offers you + Culture & Benefits\n\nTrueAccord is headquartered in San Francisco and has a newly opened a location of excellence in Lenexa, KS. We offer a healthy work environment that continuously builds an inclusive and diverse culture where everyone is able to develop the best version of themselves. We are a dynamic group of people who are subject matter experts with a passion for change.\n\nWe offer:\n*** Generous paid time off\n*** Paid training\n*** We promote work/life harmony\n*** Paid holidays\n*** Health, dental and vision benefits\n*** 401K with matching\n\nOur teams are crafting solutions to big problems every day. If you\u2019re looking for an opportunity to do impactful work, join TrueAccord and make a difference.\n\nOur Dedication to Diversity & Inclusion\n\nTrueAccord is an equal opportunity employer. We promote, value, and thrive with a diverse & inclusive team. Different perspectives contribute to better solutions and this make us stronger every day. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nStart your job application: click Apply Now"}, "161": {"company": "Avlino", "description": "Job Description\n\n\nAvlino Inc. is seeking experienced data scientists to join our growing team\nof AI engineers, analysts, and quantitative developers. The role involves\nmodel construction, information extraction, prediction and finding solutions\nto large-scale problems for mission critical applications using large\nderived from a broad spectrum of domains for industry specific sectors. The\nideal candidate will have comprehensive expertise in machine learning,\ntime-series analysis modeling, statistical data analysis, and deep neural\nnetworks. Experience with dynamic programming and reinforcement learning is\na plus.\n\nDemonstrate your experience in creating real-world artificial intelligence\napplications using pulsing customer data sets!\n\nThis is a great opportunity for an experienced Data Scientist with 4+ years\nof relevant experience to work in a fast-paced environment where they can\nshare their passion for numbers and AI.\n\nResponsibilities\nDevelop, implement, and use a broad set of machine-learning models and\nquantitative techniques for prediction and classification for mission\ncritical applications.\nTo find problems in industrial and service sector applications.\nStrong background in numerical techniques, optimization, and gradient\nmethods.\nDevelopment of new machine learning algorithms and/or substantial\nmodification of pre-existing techniques.\nAnalysis of high-volume, noisy, heterogeneous real-time data.\nCollaborate with business analysts to transform customer needs into\nactionable insights.\nDesign custom end user reports that are easy to read and interpret for\nmultiple business unit audiences.\nArchitect the next generation analytical platform.\nCapable of de novo implementation of mathematical models, or to avail\nwidely used open source programming platforms and libraries (Scala, R,\npython, TensorFlow).\n\nRequirements\nMUST: Solid 5 years of experience in machine learning, statistical\nmodeling, data mining, time-series forecasting, and neural networks.\nMUST: Solid 5 years of experience working with big data technologies\ndistributed computing such as Hadoop/Spark, Map/Reduce, TensorFlow.\nMUST: Solid 5 years of experience in multiple programming languages \u2013\nC#/.NET, C++, C, Scala, Python, R, Java.\nExperience in developing or implementing enterprise class Data Analytics\nand BI solutions.\nExtremely analytical and able to solve problems independently.\nAssesses customer requirements and translate them to appropriate\ndeliverables.\nMUST: Have an analytical mind, and on point with detailed specifics.\nMUST: Education: MS/Ph.D. (Preferred) in Computer Science, Physics, or a\nrelated discipline.\nPLUS: Experience in the logistics or transportation industry.\n\nTo apply to this job, click Easy Apply"}, "162": {"company": "PEMCO Insurance", "description": "Why We Need You:\n\nAs a valued member of the Product Pricing Support team you will be instrumental in empowering Product analysts with a fast, reliable, easy-to-understand pricing support environment for rate/product changes and product related reporting by developing, maintaining, and continuously improving of the product pricing support environment.\n\nWhat You'll Be Doing:\nDevelop the ETL process for pulling and processing data used in rating risk.\nDevelop and maintain rating engines used in pricing Insurance Products.\nCollaborate on new rating algorithm implementations with the Product, Underwriting, and IT teams.\nEstablish, maintain, and implement programmatic verification methodologies/processes along with corresponding documentation.\nTranslate business logic and requirements into comprehensive documentation.\nWhat You'll Bring:\nETL experience in data engineering, business intelligence, or related field.\nExperience manipulating, processing, and extracting value from large datasets.\nHands on experience using SSIS, T-SQL, SSMS, and Stored Procedures.\nStrong communication and interpersonal skills: Our team is responsible for working across multiple departments with challenging rules/requirements which necessitate excellent communication.\nA high level of initiative and motivation with strong attention to detail and driven by a desire for accuracy and thoroughness.\nAbility to build and maintain data/process flow and data architecture documentation.\nDesire to learn and become a Subject Matter Expert in the process of acquiring the data required for risk based rating.\nExperience with algorithm development.\nExcellent quantitative skills.\nProperty & Casualty Insurance knowledge/experience a plus.\nKnowledge/experience with MS Visio and/or JIRA a plus.\nJob Conditions\n\nThis job requires the ability to use desktop computers. May require a flexible schedule to include some evening and weekend hours. Some travel may also be required.\n\nOur employees enjoy many benefits:\nCompetitive salary\n200% match on your 401(k) up to 6% of your pay\nGenerous medical, dental, disability and life insurance plans\nA friendly, professional work environment\nThe opportunity to work at a place of integrity, where customer service is emphasized\nAt PEMCO, we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our products and our community to flourish. PEMCO is honored to be an equal opportunity workplace. We are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national orientation, age, citizenship, marital status, disability, gender identity, sexual orientation or Veteran status.\nApply Now: click Apply Now"}, "163": {"company": "Specialized Bicycle", "description": "Are you a natural leader with the ability to bounce back and forth between strategic planning and getting into the weeds on a specific data projects? Do you have a passion for harnessing diverse datasets to drive consumer experiences and business outcomes? Are you simultaneously comfortable with statistical analysis/inference and modern deep learning and machine learning approaches? Can you combine a diverse array of data science techniques and tools to ultimately create personalized recommendation engines? If you were able to answer yes to these questions then we want to talk to you!\n\nWe are searching for a Data Scientist to join our team and be a leader that will ultimately build a modern data function for Specialized!\n\nHOW YOU'LL MAKE A DIFFERENCE\nEnd-to-end deep learning/machine learning application: data analysis and idea conceptualization, model definition and refinement, creation of proof of concept, production development and deployment.\nBenchmark, investigate, and propose newest techniques and approaches to harnessing AI for personalized recommendations.\nCreate specific algorithms to drive product and experience recommendations.\nBig data analysis and support of multiple teams, including product development and operations planning.\nDefine necessary data architecture to support application of models/algorithms and data analysis.\nWHAT YOU NEED TO WIN\nGraduate degree and/or multiple years experience in Data Science or related field (Computer Science, Mathematics, Statistics, Engineering).\nExperience with a variety of machine learning / deep learning techniques, including model development and production deployment.\nExperience with SQL/Python/R\nExperience with recommendation algorithms\nExperience with data analysis tools and techniques, particularly big data approaches\nFirst and foremost, we are riders. We share the core belief that bikes change lives. From product development and operations, to finance and marketing - every role at Specialized contributes to a culture of sustainable, global growth and innovation. We are always looking for passionate people to join the team who are interested in learning and growing far above the scope of the position. You'll be challenged in many different ways and have a tremendous amount of opportunity. All with an eye towards growing people and expanding careers.\n\nYou'll be working alongside a passionate, driven team and there are some great benefits including daily lunch rides, onsite yoga classes, and all of the bagels your heart desires on Friday mornings. Come ride with us!\n\nSee what we are up to on LinkedIn, Instagram, and most importantly, our #DogsofSpecialized.\nTo apply to this job, click Apply Now"}, "164": {"company": "Enterprise Holdings", "description": "About the Role\nThe Analytic Center of Excellence (ACE) Lead Data Scientist independently leads initiatives using extensive data science expertise to understand internal and external customers' strategic business objectives, relate those objectives to measurable indicators and focus on delivering analytic products and services to create new insights and strategies promoting continuous performance improvements for the company. The ACE Lead Data Scientist specializes in applying advanced skills and expertise to create efficiencies and improve the decision making process for internal business units by developing and implementing advanced statistical and mathematical solutions. In addition, this position proactively seeks new data technologies, opportunities for automation and or other efficiencies for the team while assisting the manager with opportunities for employee development.\n\nCompany Overview\nEnterprise Holdings is the largest car rental provider in the world as measured by revenue and fleet. The company and its affiliate Enterprise Fleet Management which combined offer a total transportation solution that includes extensive car rental and car-sharing services, truck rental, corporate fleet management and retail car sales accounted for $24.1 billion in revenue and operated 2 million vehicles throughout the world in 2018. Enterprise Holdings annual revenues also place it near the top of the global travel industry, exceeding all other rental car companies, many airlines, and most cruise lines, hotels, tour operators and online travel agencies. Enterprise Holdings regional subsidiaries and Enterprise Fleet Management currently employ more than 100,000 people worldwide.\n\nThrough its integrated global network of independent regional subsidiaries and franchises, Enterprise Holdings operates the Enterprise Rent-A-Car, National Car Rental and Alamo Rent A Car brands at more than 10,000 fully staffed neighborhood and airport locations. The Enterprise Holdings global network operates in more than 90 countries and territories, including North America, Central America, South America, the Caribbean and Europe, as well as parts of Asia-Pacific and the Middle East. Today, the companys three brands serve more than 95 percent of the worldwide car rental market.\n\nThis position is located at our Corporate Headquarters in Clayton, MO.\n\nResponsibilities:\nLead the design and delivery of end-to-end advanced analytical solutions that address the business needs\nIndependently extract, clean and manipulate both structured and unstructured datasets\nPerform exploratory data analysis, generate hypotheses and extract actionable insights\nDevelop statistical and/or mathematical models that are put in production; assess current models in production and identify opportunities for enhancement and automation\nIndependently deliver detailed documentation including descriptions of efforts, results, insights and recommendations\nPresent the findings and recommendations to other ACE members and all levels of management\nPartner with other ACE Teams to ensure successful delivery of solutions\nProvide guidance to other Data Scientists on the team; Assist the Manager with training and development\nEvaluate new data technologies to determine the effectiveness of the solution and its feasibility\nSeek to develop strategies to link the team's analytical activities with business goals and objectives\nAdditional Responsibilities\nSeek to improve job performance through self-assessment, skill development, training and goal setting\nMaintain a regular and reliable level of attendance and punctuality\nPerform miscellaneous job-related duties as assigned\nEqual Opportunity Employer/Disability/Veterans\n\nQualifications:\n\nMinimum:\nPhD in Mathematics, Statistics, Operations Research, Physics, Engineering, Economics, Computer Science or a related quantitative field required\nMust be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future\n6+ years experience data mining and developing statistical and/or mathematical models using R, Python, or CPLEX\n6+ years experience with SQL and/or Python programming or directly querying relational databases such as Teradata, SQL Server, or Oracle\n6+ years experience with building statistical and/or mathematical models that are put in production\n4+ years experience preparing and giving presentations to non-technical audiences, including all levels of management\n2+ years experience applying strategic analytics within a corporate setting\n2+ years experience with conceptualizing new analytical products or enhancing existing products by using advanced analytical techniques\nExperience guiding and mentoring other data scientists\nCompetency Based:\nResults-Oriented\nProblem Solving\nForward-Thinking\nPersuading and Influencing\nWorking With a Team\nDetail-Oriented\nApply Now: click Apply Now"}, "165": {"company": "Marlette Funding", "description": "Data Scientist\n\nNewark, CA\n\nFull-Time, Direct Hire(sorry, visa sponsorship not available at this time)\n\n0-5 years experience\n\nMarlette Funding, LLC is a financial technology (fintech) provider for the Best Egg\u00ae consumer loan platform. Marlette has experienced tremendous growth since its inception in 2014, with over $8B in consumer loans originated through the Best Egg platform.\n\nToday, we\u2019ve grown to over 200 employees, enjoy strong employee engagement scores and have been recognized numerous times as a best workplace.\n\nThe Job\n\nThe Data Scientist will be part of Decision Science team and will partner with various business units to research and develop machine-learning models or any other tools leveraged in the strategies.\n\nDuties& Responsibilities\n\n\u00b7 Design, develop, document and maintain machine learning tools (e.g. models) to extract hidden insights in the vast amount of data that Credit, Marketing and/or Operations can use to make their respective strategies and processes more efficient and effective.\n\n\u00b7 Be the subject matter expert in machine learning algorithms and their applicability.\n\n\u00b7 From time to time, be involved in search of relevant big data and in assessing 3rd party vendor\u2019s capabilities.\n\n\u00b7 Cultivate collaborative environment with other business units and internal stakeholders.\n\n\u00b7 Identify risk and opportunities in different areas of the business.\n\nRequirements\n\nDevelopment\n\n\u00b7 Master\u2019s or PhD in quantitative fields. Data science related major is a big plus.\n\n\u00b7 Proficiency in statistics (e.g. experimental design, hypothesis testing).\n\n\u00b7 Know how to obtain and use big data (structured and unstructured).\n\n\u00b7 Proficiency in machine learning techniques (Gradient Boosting, Random Forest, Neural Network, etc.). Proficiency in NLP and graph databases is a big plus.\n\n\u00b7 Experienced with end-to-end machine learning pipeline: From data extraction, feature engineering to model building, performance evaluation and implementation.\n\n\u00b7 Proficiency in SQL, Python and its machine learning libraries (panda, scikit-learn, matplotlib, etc.).\n\n\u00b7 Practical; grabbing small wins frequently.\n\n\u00b7 Creative and curious.\n\n\u00b7 Desire and ability to learn new tools and techniques.\n\n\u00b7 Able to work independently and collaborate remotely.\n\nCulture\n\n\u00b7 Be confident and willing to challenge status quo but also willing to concede and execute other\u2019s ideas when necessary\n\n\u00b7 Capable of teaching and learning from others to promote continuity of knowledge and personal development\n\n\u00b7 Ability to work effectively independently and as a team member\n\n\u00b7 Excellent English written and verbal communication skills\n\n\u00b7 Able to travel to East Coast as needed.\nStart your job application: click Easy Apply"}, "166": {"company": "CardinalCommerce", "description": "Let's face it. Everyone prefers shopping in their pajamas at home over traveling to the mall. CardinalCommerce, a Visa company, works to make online shopping as safe and easy as possible. For over two decades, we've been bringing merchants, issuers, and shoppers together in an experience where everybody wins. With singular focus, proven technology, and dedicated service, we are continuously raising the bar for payment authentication around the world. We put authentication first because we believe digital commerce should be safe, rewarding and engaging for everyone involved in the process.\n\nJoin us on this journey. At Cardinal, we're a group of genuine, dependable, and hardworking people who are treated right with flexible work schedules, a fun company culture and unbeatable benefits. See why we're one of the leading FinTech companies in Northeast OH.\n\nAs a Data Analyst here at Cardinal, you will work with one of the richest data sets in the world, cutting edge technology, and the ability to see insights turned into real world impact.\n\nWhat you'll do:\nBuild reports and performing analyses to draw insights and work with the appropriate parts of the organization to implement changes based on those insights\nPerform \"what if\" and ad-hoc analyses and question existing assumptions and processes\nDevelop and track key metrics that represent the key performance indicators for Cardinal products and the ecommerce marketplace\nSupport development of self-service analytics through interactive dashboards and other data tools\nDesign and analyze A/B, Before/After tests to quantify the impact of customer-facing changes\nPerform Quality Assurances checks or studies\nWhat we need you to have:\nBachelor's degree with an emphasis in Finance, Mathematics, Economics, Statistics or a related discipline\no In lieu of degree, a high school diploma/equivalent with four or more years related experience and/or training or equivalent combination of education and experience will be considered\n2+ years' experience in a business analytics role\nIntermediate to advanced computer skills including MS Office with advanced skills in Excel (knowledge of spreadsheet functionality: v-look-up, pivot tables, charts, graphing and macros)\nExperienced in manipulating, visualizing, and providing analysis of data\nStrong statistical background, and basic knowledge in machine learning and data science\nExpertise in SQL with ability to conduct advanced query analysis\nExperience in handling large scale, unstructured data and working with distributed computing\nKnowledgeable of ETL Practices and Concepts\nKnowledgeable of Transactional and Multi-Dimensional Databases, Data Warehousing, Star and Snowflake Schemas, OLAP Cubes\nWhat we'd like you to have:\nPayments industry knowledge\nAWS services and tools\nExperience in working with the Apache web server environment: Hadoop, Hive, Python, Spark, Pig, MySQL, etc\nAdvanced data programming\nPhysical Requirements\n\nThis position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers, and reach with hands and arms. Cardinal/Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Cardinal/Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.\nApply Now: click Easy Apply"}, "167": {"company": "MITRE", "description": "Why choose between doing meaningful work and\nhaving a fulfilling life? At MITRE, you can have both. That's because MITRE\npeople are committed to tackling our nation's toughest challenges\u2014and we're\ncommitted to the long-term well-being of our employees. MITRE is different from\nmost technology companies. We are a not-for-profit corporation chartered to\nwork for the public interest, with no commercial conflicts to influence what we\ndo. The Research & Development centers we operate for the government create\nlasting impact in fields as diverse as cybersecurity, healthcare, aviation,\ndefense, and enterprise transformation. We're making a difference every\nday\u2014working for a safer, healthier, and more secure nation and world.\n\nThe candidate should possess extensive experience analyzing\nlarge scale datasets from prominent and emerging domains as well as complex\nsocial networks using unique and innovative methodologies. The candidate should have a strong knowledge\nof data science, various programming languages, and open source\ntechnologies. Skills sought include\nUtilize\nexisting open source social media methodologies to apply specialized tools and\ncapabilities in support of the Department of Homeland Security (DHS) national\nsecurity mission\nExperience\norganizing analytic results for further analysis\nAbility to\nfind patterns in data and clearly articulate the entire analysis (e.g.,\nmethodology, results, assumptions, constraints) using various suites of tools\nExperience\nwith databases technologies (e.g., PostgreSQL, Oracle, MySQL, SQL Server,\nMongoDB, Neo4j)\nExperience\nmanipulating datasets with at least one modern programming language or business\nintelligence platform like Python, SAS, MATLAB, C , R, Java, SQL, PL/SQL\nCreatively\napply visualizations to large datasets using tools like Tableau, Power BI, or Qlik\nAbility to\nunderstand and map data relationships\nAbility to\nassess the quality of data or tool against a set of requirements\nAbility to\nprepare comprehensive written reports, presentations, and charts based on\nresearch, collection, and analysis of intelligence data\nExcellent\nwritten and verbal communication skills, adapted to a variety of audiences and\ntechnical understanding\nAdvanced and\nproven ability to:\nAssess the\ngaps between current capabilities and target business/IT needs\nAnalyze and\nalign business and technology strategies\nIdentify,\nanalyze, and recommend high-impact alternative solutions and prototypes\nRequired Business/Soft Skills\nExperience\nin a customer-facing environment\nAbility to\nleverage both MITRE and team knowledge effectively\nAbility to\nwork in a \u201cwar room\u201d environment (i.e., close quarters within an open team room\nwith multiple conversations)\nAbility to\nwork with a variety of audiences to include sponsors, vendors, and partner\ncontractors\nStrong\ncommunications and interpersonal skills\nMust have\ngood analytical, written, presentation skills\nStrong\ninterpersonal communication skills to interact with senior Government staff,\ntechnical peers, and MITRE team members\nAbility to\nwork in a dynamic fast-paced environment\nRequirement - DOD Secret or higher and DHS Suitability\nSecret or higher (preferred)\nTo apply to this job, click Apply Now"}, "168": {"company": "Genentech", "description": "The Position\nPurpose\n\nAs a Data Scientist/Senior Data Scientist within our Personalized HealthCare function you will work with meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access.\n\nYou will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions. The data will be varied in type -- patient-level clinical data, supplemented with deep patient data such as omics (e.g. genomics, proteomic), imaging, digital health, etc. Source data will be diverse -- real-world data, including patient registries, electronic medical records, claims, biobanks, and clinical trials. The evidence and insights will be used to inform the research and development of our molecules, and support healthcare decisions by patients, physicians, health authorities, payers, and policy-makers. You will also contribute to functional, cross- functional, enterprise-wide or external initiatives that shape our business and healthcare environments. This will require a good understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical data science expertise. You will need strong strategic, collaboration and communication skills, as well as an entrepreneurial mindset, to transform the way we use data and analytics to develop and deliver medicines for our patients.\n\nAs Senior Data Scientist you will typically be expected to contribute to the molecule/disease area for multiple or complex projects with minimal supervision. You will contribute to the development of new concepts, techniques, and standards.\n\nWe will look to you as a positive role model for peers and you will coach colleagues to improve in their role with both technical and interpersonal skills.\n\nResponsibilities\nIDENTIFY EVIDENCE NEEDS & RECOMMEND DATA SOLUTIONS: Ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.\nDEVELOP DATA STRATEGY & GAIN ACCESS TO DATA: Develop strategic plans to access fit-for-purpose data sources to support evidence generation, and gain access to data through collaboration or data generation.\nDIVE INTO DATA: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.\nBE AN EXPERT IN APPLYING METHODS: Stay current with and adopt emergent analytical methodologies, tools and applications to ensure fit-for-purpose and impactful approaches.\nPRODUCE HIGH QUALITY ANALYSES: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to maximize impact and interpretability; implement and/or oversee the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.\nINTERPRET AND SHARE RESULTS: Communicate findings to internal stakeholders, regulatory, health technology assessment (HTA) bodies and scientific communities; publish results; participate in external meetings and forums to present your insights (e.g. congress/conference).\nCOLLABORATE & SHAPE: Collaborate and contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaboratives, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.\n\nQualifications\nMSc, PhD or similar qualification in a quantitative data science discipline (e.g., statistics/ biostatistics, epidemiology, bioinformatics, health economics, computational biology, computer science, mathematics, outcomes research, public health, biology, medicine, psychology) with at least 2 years (if PhD) and 3+ years relevant work experience\nDemonstrated track record of developing and execution of data science research projects, patient-level data analyses (e.g., real world data, surveys, clinical trials, registries, claims, genomic or imaging data) with publications and presentations\nDemonstrated experience with managing project scope and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges\nDemonstrated strong collaboration skills and excellent communication skills\nDemonstrated entrepreneurial mindset and self-direction, ability to teach others and willingness to learn new techniques\nProficiency in English, both written and verbal\nTrack record of effectively working in a matrix environment with global, international team members coming from scientific, business and operational backgrounds, using influence without authority\nFluency in statistical programming languages (R, Python, etc.)\nExperience implementing advanced analytics approaches (machine learning, longitudinal data analysis, etc.)\nExperience with technologies required to undertake analyses on large data sources or with computationally intensive steps (SQL, parallelization, Hadoop, Spark, etc.)\nExperience producing interactive outputs (Shiny, etc.)\nContributor to open source packages, libraries or functions\nExperience implementing reproducible research practices like version control (e.g., using Git) and literate programming\nExperience analyzing RWD (non- interventional studies, electronic medical records, claims, disease registries etc.) is essential. Additional data types, such as omics (next generation sequencing data, proteomics, etc.) also desired.\n\nWho We Are\n\n\nA member of the Roche Group, Genentech has been at the forefront of the biotechnology industry for more than 40 years, using human genetic information to develop novel medicines for serious and life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious illnesses. Please take this opportunity to learn about Genentech where we believe that our employees are our most important asset & are dedicated to remaining a great place to work.\n\nThe next step is yours. To apply today, click on the \"Apply online\" button.\n\nGenentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.\nApply Now: click Apply Now"}, "169": {"company": "Dailymotion", "description": "Company Description\n\nDailymotion is the leading video discovery destination & technology that learns about your tastes over time, constantly surfacing the best, most relevant content on the web. Our mission is to provide the best video user experience for consumers on the market, connecting publishers and advertisers to engaged viewers who turn to Dailymotion for their daily fix of the most compelling music, entertainment, news and sports content around.\n\nThrough partnerships with the world's leading publishers and content creators, including CBS, CNN, Fox Sports, GQ, Mashable, Universal Music Group, VICE and more, Dailymotion commands 4 billion monthly pageviews across its mobile app, desktop and connected TV experiences. Dailymotion is owned by Vivendi, one of the largest mass-media corporations in the world.\n\nAs part of our growing activities, we have built our own ad stack (SSP) to enhance our programmatic advertising capabilities, deliver new monetization solutions for our ecosystem of online, mobile and TV, and provide innovative marketing solutions for advertisers.\n\nJob Description\n\nAre you someone with a passion for digging into large distributed pools of data, unearthing insights, and transforming them into a visually compelling form that appeals both to technical and non-technical audiences? Then this is the job for you!\n\nOn a daily basis, you will be responsible for:\nPerforming data analysis on products managed by Dailymotion\u2019s AdTech tribe, including our SSP that serves billions of requests daily, and extract actionable insights that will be used to drive decisions across the business\nStatistically validating and A/B testing hypotheses generated by Business, Product and Data Science teams.\nDriving the collection of new data that would help build the next generation of algorithms (E.g. audience segmentation, contextual targeting, bidder behavior monitoring)\nBuilding easy to use dashboards (E.g. Tableau) to help visualize insights and KPIs interactively\nAutomating analysis into monitoring and alerting tools to continuously drive value for business owners\nProactively owning the end-to-end delivery of projects, from design, to development, testing, and operations.\nQualifications\nBachelor\u2019s degree, or higher, in Business, Finance, Statistics, or related field.\n3 years of business / data analysis experience\nPrevious ad-tech experience (required)\nExtensive experience solving analytical problems using quantitative approaches\nComfortable with manipulation and analysis of complex, high volume, high dimensional data from varying sources (E.g. SQL, AWS/GCP, Excel)\nSolid Experience of Data Visualization Tools (E.g. Tableau suite)\nStrong intellectual curiosity and ability to structure and solve difficult problems with minimal supervision\nAbility to communicate complex quantitative analysis in a clear, precise and actionable manner in English. French is a plus.\nA background in Machine Learning and Statistics is a plus\nProgramming in Python is a plus\nAdditional Information\n\nLocation: New York\nType of contract: Full-time\nStart Date: ASAP\n\n\u2022 Flexible time off, vacation, holidays, sick-leave so you can take time off when you need to\n\u2022 Fitness club membership to NY Health & Racquet Club\n\u2022 100% healthcare coverage starting on day 1\n\u2022 Commuter benefits\n\u2022 401k Contribution\n\u2022 Paid parental leave\n\u2022 Fully stocked kitchens with free snacks and drinks\n\nIf you want to explore Dailymotion culture a little further please check out:\n\n1./ Our BuiltIn page: https://www.builtinnyc.com/company/dailymotion\n\n2./ Our Recent Global Hackathon in November 2018. https://www.dailymotion.com/video/x70val9\n\n3./ Welcome to the Jungle page: https://www.welcometothejungle.co/companies/dailymotion/team\n\nDailymotion is a global champion of diversity and inclusion. We pride ourselves in being an equal opportunity employer that provides an environment of mutual respect\nApply Now: click Apply Now"}, "170": {"company": "Varen Technologies", "description": "At Varen, our performance is measured by the success of our clients, and our reputation for service, superior quality, objectivity, integrity and results. Our reputation is everything to us as we are committed to being a trusteisor to our nations decision makers in a day in age that demands acute attention to detail in a fast-paced environment. Varen is sed adveking to add the sharpest technical professionals who share our passion for ensuring the mission success of our customers at all times.\n\nPOSITION DESCRIPTION:\n\n\nVaren is seeking candidates with analytics expertise to help realize a program that measures organizational drivers of success and focuses on data driven decisions. The candidate(s) shall support the analytics team in identifying and developing actionable insights through problem definition, application of statistical models, and analysis against existing and future data. They will collect and convey information about language acquisition, maintenance and testing to improve the language and learning function at an Enterprise level. This foreign language related data will be displayed in the Personalized Language Dashboard and the upcoming Language Lifecycle tool. This team will provide language analytics using innovative research methodologies and tools to enable stakeholder decisions, increase the quality and effectiveness of Learning Enterprise (LE) products and services, establish relationships between the LE and mission execution, implement data collection and data visualization tools, and produce internal/external reporting.\n\nREQUIRED EXPERIENCE:\n\nDemonstrated experience designing and conducting research to answer key business questions, to include structured interviews, focus groups, and surveys.\nDemonstrated experience identifying metrics of relevance to leadership and aligned with organizational strategy.\nDemonstrated experience deriving insights from data and presenting conclusions to non-technical audiences.\nDemonstrated experience identifying and obtaining datasets needed to answer key business questions.\nDemonstrated experience visualizing data and conveying complex research findings in both written and oral formats to stakeholders at all levels.\nDESIRED EXPERIENCE:\n\nFamiliarity with Sponsors data systems as they relate to foreign language acquisition and maintenance, human resources (HR) or learning.\nExperience leveraging programming languages to script the extraction, formatting and transformation of data from a wide variety of organizational systems.\nDemonstrated experience working in a learning environment.\nDemonstrated experience working across Sponsor units effectively in support of an end goal.\nCLEARANCE REQUIREMENT:\n\nTS/SCI clearance in JPAS is required\n\nTo apply to this job, click Apply Now"}, "171": {"company": "Juvo", "description": "Juvo was founded with an overarching mission: to establish financial identities for the billions of people worldwide who are creditworthy, yet financially excluded. In partnership with mobile network operators, Juvo's proprietary Identity Scoring technology uses data science, machine learning and game mechanics to create an identity-based relationship with anonymous prepaid users, opening up access to otherwise unattainable mobile financial services.\n\nSince emerging from stealth in September 2016, Juvo has increased its global reach five times over, from 100 million to 500 million, and has steadily grown its operations and employee base worldwide with 100 employees today. To date, Juvo has enabled over 400M transactions in 25 countries and 4 continents, with 1M active subscribers a day. Juvo's mobile operator partners include Telefonica, Millicom, Sprint, Deutsche Telekom and Cable & Wireless.\n\nIn 2017, Juvo completed a $40 million USD Series B funding round with funding from Samsung NEXT and top-tier VCs including NEA, Wing Venture, and Freestyle Capital. Early investors in the company include the former CEOs of AT&T Wireless, NYSE, Sprint, Telefonica International and Vodafone Group. Juvo is frequently profiled in top tier tech and business press and our proprietary technology, Identity Scoring, is award winning.\n\nAbout the Job\n\nWe are looking for a talented Senior Data Scientist with a minimum of seven years of experience to help Juvo convert user data into personalized credit scores. You will play a central role not only in ensuring Juvo's success, but improving the financial landscape of millions, if not billions of people. As you lead key Data Science and platform initiatives, you will play a major role in the planning and construction of Juvo's technical stack.\n\nQualifications\nMS/PhD in a quantitative field e.g., Physics, Astronomy, Chemistry, CS, Math or have worked in Data Science, Quantitative Research or Software Development for 7 years.\nComfortable in Unix computing environments and have a handful of your favorite BASH tricks. You are fluent in one or more of the following programming languages: Python, Scala, R, Java.\nFamiliar with distributed computing frameworks such as Hadoop, Spark, Hive.\nYou know your way around AWS and regularly use one or more of their services e.g., S3, EC2, EMR, Redshift, DynamoDB, Kinesis, etc.\nYou like working in a fast-paced collaborative environment where the mantra is to push to master, make sure it makes sense...and doesn't break!\nPerks & Recreation\nWork towards a mission that matters \u2013 join us in creating the YES economy\nCompetitive cash and equity compensation\nGreat medical/dental/vision benefits, with dependent coverage\nPre-tax commuter benefits\n401(k) available\nPaid holidays and flexible paid time off\nMonthly reimbursement for internet or mobile phones\nConveniently located office in the Financial District of San Francisco\nFully stocked kitchens with organic and healthy snacks\nWeekly catered lunch\nYour choice of the best and newest tech (Apple products, Sennheiser Noise Canceling headphones, Stand-up desks, etc)\nEmployee discount on Samsung products (Samsung is an investor)!\nJuvo is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Juvo is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.\nTo apply to this job, click Apply Now"}, "172": {"company": "Science 37", "description": "Science 37 is accelerating the research and development of breakthrough biomedical treatments by bringing clinical trials to patients' homes. Backed by venture investors such as Glynn Capital, Google Ventures, Redmile Group, dRx Capital and Lux Capital, we are seeking a razor-sharp Data Scientist eager to make an impact within a mission-driven organization changing the world of clinical research.\n\nAs part of the Science 37 Tech team, you will collaborate with motivated, energetic, and entrepreneurial individuals working together to achieve Science 37's mission of changing the world of clinical research through patient-centered design. You will have a hands-on role with the architecture and development of NORA\u00ae (Network Oriented Research Assistant), the technology that enables Science 37's groundbreaking Metasite\u2122 clinical research model and collaborates with Product, Data, Clinical Operations, and other relevant stakeholders to define study specific NORA requirements.\n\nResponsibilities\n\nDuties include but are not limited to:\nUnderstand business stakeholders' needs and translate those into a data insights program with solutions for each stakeholder\nDeliver on data analytics and insights by planning and performing end-to-end analysis: including aggregating and processing data, exploring data, building and validating predictive models, and presenting to business.\nAnalyze our existing data model/structure and provide recommendations to the Tech team for optimization to support our data strategy\nDesign and implement statistical algorithms and predictive analysis\nExplain data analytics and data science findings and machine learning models to internal and external stakeholders\nWork with Data Analysts, Product Managers and Software Engineers to gather data insight requirements, set goals and influence the product roadmap.\nMinimum Qualifications\nB.S. or M.S. in computer science, Mathematics, Statistics, Physics, Economics or equivalent experience\n4+ years of industry experience in predictive analysis and modeling, data analysis and science\n3+ years of industry experience in data analytics\nKnowledge of data engineering, database architecture and ETL process\nExperience building ML models\nProficient in either Python or R or both.\nExperience using ML libraries such as scikit-learn, caret\nKnowledge of machine learning frameworks and toolsets\nExperience writing and optimizing SQL\nExperience using data visualization tools.\nExperience presenting data findings\nPreferred Qualifications\nPhD in computer science, Mathematics, Statistics, Physics, Economics, Bio-Engineering/Science field\n6+ years of industry experience in predictive analysis and modeling, data analysis and science\n4+ years of industry experience in data analytics\nProven ability to tackle business problems with data science solutions\nExpert programming skills in Python and/or R\nProficient programming skills in Javascript or JAVA\nAbility to develop analytic plans for data modeling process\nAbility to accurately determine correlations\nExperience with AWS data technologies such as Redshift, S3, Data Pipeline\nExperience with Tableau\nSkills and Competencies\nAbility to think critically\nAbility to translate business problems into data questions, create solutions and drive results\nAbility to aggregate and analyze data from multiple data sources and build a holistic view\nAbility to build clear visualizations to explain complex ideas and analysis result to executives and business unit leaders\nAbility to provide guidance to other program and project managers\nAbility to resolve conflicts and negotiate agreement\nAbility to proactively identify impediments in project/program delivery and craft solutions.\nAbility to set metrics for the project and program for performance and goals.\nCapabilities\nStrong written and oral communication skills\nReporting\nThe incumbent is required to work under the guidance and direction of the VP, Engineering with little to minimal supervision.\nDirect Reports\nNo direct reports\nScience 37 values the well-being of its employees and aims to provide team members with everything they need to succeed. Enjoy healthy catered lunches, snacks and beverages, and top-notch equipment such as the latest Macbook Pro, 4k monitors, and adjustable standing desks. Submit your resume to apply!\nTo apply to this job, click Easy Apply"}, "173": {"company": "Tapjoy", "description": "Join the Mobile Future with Tapjoy\n\nTapjoy is a creative workplace, comprised of people with different backgrounds, cultures, skill sets, and global perspectives. With offices all over the globe, Tapjoy provides mobile engagement and monetization services for leading advertisers and app developers. Advertisers rely on Tapjoy's diverse suite of rewarded Interplay ads including video and rich media to impact performance. Developers utilize our technology and mobile expertise to acquire and monetize users. The Tapjoy SDK is currently embedded in over 20,000 mobile apps, reaching 620 million monthly active users. Additionally, Tapjoy works with Fortune 500 brands and the Top 200 grossing app developers.\n\nHere at Tapjoy, we promote a Joyful, Engaged, Trustworthy, and Innovative workplace with our company core values, and regularly celebrate and recognize the people who embody our values. Tapjoy believes its people are its greatest investments and we take extra care to support your time inside and outside of work with a multitude of benefits. In order to maintain what makes us so special here, we are committed to continued education and involvement in our community to protect and expand our one-of-a-kind workplace.\n\nPosition Title: Staff Data Scientist\n\nPosition Description/Responsibilities:\n\nEssential duties and responsibilities may include, but are not limited to, the following as additional roles and/or focus will be needed as the company and department continues to grow and evolve:\nBuild a data/stats-driven ad machine learning models, working closely with the product team\nConstantly experiment and improve machine learning models for the recommendation/ad optimization system\nInvent and analyze big data for given business cases and help implement them in production\nWork with the product/engineering team to implement, test and deploy the solution on Google Cloud Platform Core\nCompetencies:\nPassionate about machine learning and big data\nGreat Communicator about complex algorithmic works as easy-to-understand story telling\nMotivated to test at billions scaled data and follow up machine learning models in product\nRequirements:\nPh. D in Computer Science or Statistics or similar working experience applied technical field five years or more.\nMust be hands-on Machine-learning related industry projects\nSolid programming skill of scripting language Python\nAbility to work in a fast paced, test-driven collaborative and iterative programming environment\nUnderstand major recommendation algorithms (Collaborative Filtering, Matrix factorization, Gradient Boosting, etc.)\nSolid understanding of Algorithms, Data Structures and Machine Learning / Data Mining\nUnderstanding of RDBMS, SQL and NoSQL alternatives\nUnderstand various ad optimization algorithms (CTR prediction, eCPM optimization, user targeting and segmentation, RTB and real-time optimization) is a plus\nExperience with Hadoop/Hbase/Pig or PySpark is a plus\nCore Competencies include:\n\nRequirements:\n\nTapjoy is a one-of-a-kind workplace, comprised of people with different backgrounds, cultures, skill sets and global perspectives. In order to maintain what makes us so special here, we support work-life balance both inside and outside the office in many ways.\n\nIf you want to learn about building an amazing team with industry-leading technology, you want to surround yourself with brilliant, passionate entrepreneurial teammates at Tapjoy.\n\nTapjoy is an equal opportunity employer. We believe that diversity and inclusion lead to stronger, more innovative teams and better business results; we want to draw from the broadest talent pool possible and encourage qualified applicants. Tapjoy does not discriminate on the basis of sex, race, ethnicity, color, age, sexual orientation, gender (including identity and expression), disability (mental or physical), religion, national origin, citizenship, marital status, military or veteran status, or any other protected classification protected by applicable law; we will provide reasonable accommodations for qualified individuals with disabilities, and pursuant to applicable fair chance ordinances, we will consider for employment qualified applicants with arrest and conviction records.\n\nFor more information, please visit www.tapjoy.com.\n\n]]>\nStart your job application: click Apply Now"}, "174": {"company": "Woodruff Sawyer", "description": "The Commercial Lines BI team at WS is a newly founded capability to enhance the organization\u2019s capacity in providing data-backed insights to its clients seeking P&C and liability insurance. The members of this team will work closely with the VP of Commercial Lines Business Intelligence and other enterprise stakeholders to develop and roll out analytics solutions. A successful candidate will apply data science methodologies, actuarial methods, knowledge of insurance, and the latest technological tools to create reusable business intelligence assets.\n\nWhat you will be doing:\n\nWith limited guidance from the leaders, managers, or project leads:\n\n\u203a Primarily collects, prepares and analyzes data from various sources.\n\n\u203a Executes formal exploratory data analysis for data science projects.\n\n\u203a Develops re-usable templates and reports for the review and feedback by other team members.\n\n\u203a Prepares analysis summaries and provides to the colleagues and leaders.\n\n\u203a Conducts data research and presents findings.\n\n\u203a Identifies areas of more in-depth analysis and builds prototypes for IT implementation.\n\nRequired Qualifications:\n\n\u203a A graduate degree in any of the quantitative disciplines, e.g., Actuarial Science, Math, Engineering, Stats, Finance, or a related discipline.\n\n\u203a Knowledge of basic data science algorithms demonstrable through internships, coursework, or a combination.\n\n\u203a 2+ years of experience in visual analysis packages such as Tableau / Power BI.\n\n\u203a 2+ years of experience in programming using Python or R.\n\n\u203a Skilled in developing presentations in PowerPoint or equivalent.\n\n\u203a 2+ years of work experience in an insurance or FINTECH environment as a data scientist or BI analyst. (4+ for an undergraduate).\n\n\u203a Knowledge of common insurance terminologies. A couple of actuarial exams is a plus.\n\nWhat you'll be getting from us:\n\n\u203a The opportunity to work with sharp, motivated co-workers in a collaborative and entrepreneurial team\n\n\u203a A flexible work schedule\n\n\u203a A fun office in vibrant downtown San Francisco\n\n\u203a Security for your future: Employee Stock Option Program (ESOP), 401K with company match and profit sharing\n\n\u203a Medical, Dental and Vision benefits for employees and families (including domestic partners)\n\n\u203a Life Insurance, short term and long-term disability benefits\n\n\u203a A Flexible work schedule\n\n\u203a Paid vacation, holiday and sick days\n\n\u203a Tuition reimbursement\n\n\u203a Access to an Employee Assistance Program\n\n\u203a Fun company and team outings\nStart your job application: click Apply Now"}, "175": {"company": "Translate Bio", "description": "Company Overview\n\nTranslate Bio is a leading mRNA therapeutics (MRT) company developing a new class of potentially transformative medicines to treat diseases caused by protein or gene dysfunction. Our MRT platform is designed to deliver mRNA carrying instructions to produce proteins for therapeutic benefit and may potentially be applicable to a broad range of diseases caused by insufficient protein production or where production of proteins can modify disease. Our lead mRNA product candidate is in development for the treatment of cystic fibrosis (CF). Beyond CF, the primary focus of our research efforts is the evaluation of targets in additional pulmonary diseases utilizing our proprietary lung delivery platform with other discovery efforts in diseases that affect the liver, eye and central nervous system.\n\nJob Summary\n\nTranslate Bio is seeking an experienced Analytical Scientist to join our CMC group. This individual in this role will contribute to the analytical development function within CMC and overall CMC strategy of drug development at Translate Bio. He/She will support the development, validation and transfer of analytical methodologies for incoming raw materials, in-process, drug substance, drug product release and stability testing. The successful individual will have expertise in pharmaceutical analytical chemistry as well as experience in authoring CMC sections of regulatory submissions.\n\nJob Responsibilities\n\nManage analytical chemistry activities both internally and at external contract laboratories\nGuide CRO to design and perform method development and validation, employing phase-appropriate approaches at different stages of development\nDevelop phase-appropriate quality control strategy for drug substance and drug product\nManage product stability study programs\nDemonstrate extensive knowledge in state-of-the-art analytical technologies\nAuthorize/review analytical method development reports, validation protocols/reports, instructions/SOP\u2019s for relevant analytical functions, and analytical sections in IND and IMPD filings\nManage internal analytical development laboratory and analytical personnel to support pipeline programs\nProvide technical advice to analytical scientists and associates to assure the highest quality of data is developed and presented\n\nRequired Skills & Qualifications\n\nPhD in analytical chemistry with 2+ years or MS with 7+ years\u2019 of analytical development experience in the pharmaceutical industry.\nExcellent scientific knowledge in analytical chemistry, strong analytical development experience for drug substance and drug product.\nFamiliarity with a full range of analytical techniques for characterization of pharmaceuticals including RP/IEX/SEC HPLC, UPLC, LCMS, Karl Fisher, solid state characterization, CE spectrophotometry.\nExperienced in CMC product development process including; cGMP manufacturing, validation, and process development.\nDemonstrated competency and hands-on experience of typical chemistry manufacturing and controls (CMC) activities.\nExperience drafting analytical sections of INDs and NDAs.\nKnowledge of GMP/ICH/FDA regulations is required.\nExperience managing CROs and CMOs.\nPrevious experience/knowledge of routine mRNA and LNP production and testing in support of Process Development and Research activities is preferable, but not required.\nReviews, interprets and communicates data cross-functionally within CMC and project teams.\nAbility to meet deadlines and demonstrate effective use of time.\nAbility to be flexible and responsive to change, be a results-driven problem solver.\n\n</br>\nTo apply to this job, click Easy Apply"}, "176": {"company": "The Buffalo Group", "description": "Data Scientist\nUS Citizenship and a current TS/SCI clearance are required for the position.\n\nJob Description: Candidate will provide support to the Department of the Army Intelligence Information Services (DAIIS) Open Source Intelligence (OSINT) Team and assist in its requirement to answer enduring/ standing requirements and ad hoc Requests for Information for publicly available information that answer worldwide intelligence requirements. The intent of this program is to provide intelligence consumers access to publicly available information on the networks on which they operate so that analysts spend less time conducting searches and building queries on the internet and more time conducting all-source intelligence analysis. Candidates will provide data management functions in the form of data governance, data architecture, data warehousing, data quality management, metadata management, data security management, data development management, data operations management, data refinement, integrated data services, data transformation services, data discovery services, data tradecraft services, advanced data analytics, and technology pursuit. Candidates will continuously identify new sources of publicly available information using multiple sources including websites, databases, and email distribution lists\n\nRequired Skills:\nAbility to collect, process, analyze and report large amounts of quantitative and qualitative data, and identify trends anomalies with minimal supervision\nAbility to Evaluate performance management and formulate recommendations for senior leadership with minimal supervision\nAbility to explain mathematical formulas and statistical findings to non-technical users and decision makers\nExtract business insights from analysis of data and communicate (orally, written, or visually) those insights to business leaders\nProficiency in Microsoft Excel (e.g Pivot Tables and Pivot Charts, Multiple criteria Lookups, Nested logical/IF formulas, etc...), and Microsoft PowerPoint\nProgramming experience with Python for data analysis (e.g. Pandas, NumPy, matplotlib, etc...); particularly in processing and analysis of different sources of quantitative and qualitative data\nHoned presentation and product demo skills\nWork cross functionally\nMatch analytic solutions to business needs\nInput and manipulate data using a dashboard (e.g. Tableau, SharePoint, etc.) visualization system\nBasic programming and scripting experience with JSON is not mandatory, but is considered a plus\nBachelor\u2019s degree is required\nThe Buffalo Group is an Equal Opportunity Employer\nStart your job application: click Apply Now"}, "177": {"company": "DOCOMO Innovations", "description": "Responsibility\nThe ideal candidate will be responsible for real world Data Science problems, including but not limited to: Data planning/collections,\nannotation strategies and developing the state-of-the-art deep learning algorithms in the field of both computer vision/NLP to operate\non large data sets that provides robust situational assessment and predictive capabilities.\n\nPerform prototype implementation of the algorithms developed, solid engineering and classical CS knowledge is the key to success for this position.\nShare knowledge by clearly articulating ideas through papers and presentations to technical staff, management.\nQualifications\nBasic CS background (Algorithms/Data Structure) is absolutely essential, Engineering skill needs to be solid and will be tested.\nHeavy exposure computer vision/Open CV\nGood understanding of scikit-learn\nMust be professional level in Python and C++/C.\nFluency in Pytorch or Tensorflow/Keras, skills will be assessed\nMaster/Ph.D in the field of Computer Science, Computer Engineering, Electrical Engineering, Mathematics or related field"}, "178": {"company": "CyberSearch", "description": "Data Analyst\nStart: ASAP\nInterview: Face to Face\nOverview:\nAs a Data Analyst on the Corporate Data, Research & Reporting team, you will act as an internal consultant to the business with regards to technology based solutions. The position is responsible for full life cycle development of internally developed solutions (including requirements gathering and analysis), implementation and maintenance of vendor packages (including their integration into the overall Data/Application architecture of the firm), integration and maintenance of internal and external data sources that populate the firm\u2019s data warehouse and its various interfaces.\nRequired Skills:\nBachelor\u2019s degree (Computer Science or another technical field preferred)\n3-5 years\u2019 relevant professional software development experience\nMicrosoft Visual Studio.NET 2017 (C#) and Microsoft SQL Server (2014+)\nExperience delivering BI initiatives using the SQL Server 2014+ BI stack, including SQL Server Analysis Services and SQL Server Reporting Services\nPowerPivot/Power BI experience\nSolid understanding of Object Oriented Programming and database fundamentals\nSolid data extract, transform, and load (ETL) development experience\nHighly motivated selfstarter who takes initiative with minimal supervision in leading complex assignments.\nAbility to communicate effectively, including with nontechnical users\nCurious about new ideas and new technologies\nComfortable working through all stages of the applicationdevelopment life-cycle, including requirements gathering, development, testing, deployment, and support\nFinancial industry experience preferred\nStart your job application: click Easy Apply"}, "179": {"company": "Purchasing Power", "description": "Data (Decision) Scientist\nLocation\n\n\nAtlanta\n\nDepartment\n\n\nFinancial Planning and Analysis\n\nEmployment duration\n\n\nFull time\n\nApply Now\n\nPurchasing Power, Midtown Atlanta, GA\n\nData Scientist\n\nPurchasing Power is seeking a data scientist that will help us discover the information hidden in vast amounts/multiple locations of data, and help us make smarter and faster decisions to deliver better results. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems that identify areas to drive incremental revenue and predict long term performance and customer activity.\n\nWhat you\u2019ll do.\n\nThe Data Scientist supports client data integration across the company\u2019s global enterprise. Manages the retrieval, transformation, delivery, and exchange of data between both internal and external business systems across all business units and client base. Provides daily operational production support. Requires a strong understanding of discipline. Able to apply knowledge and experience to complex problems and develop recommendations. Makes decisions within broad parameters. Acts as an informal resource for others with less experience. Works with team members to provide operational support, documentation, and knowledge sharing of best practices.\n\nResponsibilities\nProvides data driven input, with insight and forward-thinking recommendations to business leaders.\nInterpret, evaluate and interrelate company and research data and develop integrated business analyses and projections for incorporation into strategic decision making\nConsistently provide proactive and prescriptive analytics\nMonitor daily/weekly/monthly metrics and alert business leaders to issues and trends\nConduct insightful, ad hoc analyses to investigate ongoing or one-time operational issues\nAnalyze business activities and present results and recommendations to enhance operational strategies both for awareness, effectiveness and overall financial benefit.\nReview business processes via analysis and involvement to develop optimization strategies the focus on value-add work.\nDevelop predictive models of customer value, behavior, and responsiveness based on various business activities related to Fraud, Fed Gov, Account Management, Account Recovery, Sales, HR, and Underwriting\nRecognizes and communicates financial implications of business decisions and strategy.\nProvides support related to data needs stored within databases, including Domo reports.\nMaintains relationship with IT and Finance teams to assure data accuracy and integrity.\nConduct and coordinate financial, product, market, operational and related research to support strategic and business planning within the departments you support\nCreates process procedures, standards, and flows for current and future state initiatives/analysis.\nCompletes special projects as assigned for various departments such as Fed Gov, Account Management, Account Recovery, Sales, HR, and Underwriting\nEnsure all deliverables adhere to department quality and delivery standards.\nMaintaining and staying up to date on the latest analytical tools and trends.\nLead meetings and develop presentations to easily explain analysis and drive actionable results.\nActively participate and partner in operational department financial related meetings.\nIncorporate proven modeling that provides future predictions on business operations and financial status.\nPreferred Competencies\nSelecting features, building and optimizing classifiers using machine learning techniques\nData mining using state-of-the-art methods\nEnhancing data collection procedures to include information that is relevant for building analytic systems\nProcessing, cleansing, and verifying the integrity of data used for analysis\nDoing ad-hoc analysis and presenting results in a clear concise manner\nCreating automated anomaly detection systems and constant tracking of its performance\nDeveloping a robust forecasting model that will predict revenue over a 18 month period based customer behavior, historical activity, and known future improvements/changes\nAssisting with the development and implementation of an EDM process\nAssist with training and coaching team members on advancing their predictive analytics skills\nQUALIFICATIONS:\nBachelor\u2019s Degree (preferably in Business, Analytics, Mathematics, or relevant field)\nMaster\u2019s Degree in Data Analytics/Data Science preferred\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\nExperience with common data science toolkits, such as R, Python, MatLab, etc. Excellence in at least one of these is highly desirable.\nExtensive experience with SAS. (Current tool primarily used)\nGreat communication skills and the ability to communicate complex concepts in simple terms\nExperience with data visualization tools, and the ability to visualize data in an executive consumption format\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\nData-oriented personality\nWhy Purchasing Power?\n\nWe are the leading specialty e-retailer offering consumer products, vacations and online education services through an easy and convenient payment plan. Our customers love us because we make paying for their purchases stress- and hassle-free. The automatic payments help them to avoid penalty fees and ballooning interest associated with other payment options. While the fixed payment duration options empower them to budget more efficiently. Ours is a revolutionary e-commerce experience that gives customers access to a better life combined with a responsible way to buy.\n\nPurchasing Power is \u2018Powering People to a Better Life\u2122\u2019 through its employee purchase program, financial literacy efforts and charitable contributions.\n\nFor more information, visit www.PurchasingPower.com\nOur people! We are very proud of our people, we \u201cPower People to a better life\u201d\n100% company paid benefits for employees\nKitchen stocked with gourmet coffee, teas and free snacks\nCasual work environment\nSummer Hours\nFlexible PTO\nTop of the line hardware\nPurchasing Power is an equal opportunity employer. At Purchasing Power, we make all employment decisions, which include hiring, promoting, transferring, demoting, evaluating, compensating and separating, without regard to sex, sexual orientation, gender identity, race, color, religion, age, national origin, pregnancy, citizenship, disability, service in the uniform services, or any other classification protected by federal, state or local law.\nTo apply to this job, click Apply Now"}, "180": {"company": "Pindrop", "description": "The Pindrop R&D team solves tough problems and invents new ways to battle fraud using machine learning, big data and audio science in the cloud. Pindrop creates innovative products to solve global problems, and we are looking for an expert Research Scientist with in-depth Machine Learning expertise to join the Data Analytics Research team as we continue to develop ways to fight fraud and improve security in voice channels.\n\nIn this role, you will get to work in a cross functional Research team and interact with the Engineering teams and Product teams to frame the problem that are most relevant for fraud detection and authentication. You will decide which data sets are important, design sophisticated features and machine learning models to analyze the data, and present actionable results and intelligence back to internal and external clients.\n\nwhat you'll do\nPerform an in depth exploratory analysis on any given data set using machine learning and data science tools\nExplore multiple machine learning algorithms and develop improvements to existing algorithms to improve performance on a dataset\nInteract with non technical team (like Customer Success, Product) to understand customer pain points and areas of focus\nIdentify and explore different problems and datasets that are fundamental to improving Pindrop's product portfolio\nReduce most successful experiments to a working prototype that can be implemented in realtime for production customers\nCollaborate and communicate with Engineering counterparts to develop and transition the prototype solution\nWork with collaboration tools such as JIRA, Github and wikis\nRepresent the team via press conferences, internal lunch-and-learn talks, research blog posts and public presentations\nwho you are\nResearch Scientist with strong experience in machine learning and data science algorithms\nMasters degree at a minimum, PhD preferred\nStrong experience with Big Data technologies such as Spark or Hadoop\nStrong software engineering skills with experience in multiple programming languages, Python and Go preferred\nExperience with machine learning packages like scikit-learn, numpy, pandas and keras\nProven track record of providing machine learning systems that work on real world data\nKnowledge of Docker and container orchestration frameworks such as Kubernetes is ideal\nExperience with relational databases and document stores (SQL + NoSQL)\nExperience developing with AWS managed services such as S3, ElastiCache and DynamoDB\nHave the ability to deal with ambiguity in a fast-paced dynamic environment\nwhat we offer\n\n\nAs a part of Pindrop, you'll have a direct impact on our growing list of products and thus the future of security in the voice driven economy. We hire great people and take care of them. Here's a snapshot of benefits we offer:\nRecognized top employer\nAJC Top Workplaces 2017\n51 Startups to Bet Your Career On\n50 Startups That Will Boom in 2018\nHealth plans and 401k\nContinued education budget\nFlex schedules\nBest in class tools\nPaid commuter options\nFun outings to celebrate our accomplishments as a team\nAll the good karma you can rack up for fighting bad guys (our conference rooms are named after the ones we've busted)\nwho we are\n\n\nPindrop is a company founded on research and continues to innovate new ideas to market. Our solutions are leading the way to the future of voice by establishing the standard for security, identity, and trust. Pindrop products secure the future of voice, making technology more human from the call center to IoT devices.\n\nwhat we live by\n\n\nPindrop is driven by our DEPTH values. These are reflected in our goals and the base of our team's peer awards.\n\nAct with Deliberate urgency.\nCreate Evangelical customers.\nPassionate about the fight.\nPlaying for the Team.\nMake Hard easy.\n\nPindrop is an Equal Opportunity Employer.\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status; and will not be discriminated against on the basis of disability.\nApply Now: click Apply Now"}, "181": {"company": "ATPCO", "description": "ATPCO is building the infrastructure and systems to support the next iteration of revenue management capabilities in a continuous/dynamic pricing world. This role will work within the ATPCO R&D team to help develop compelling real-world models to support the new capabilities and data points required to deliver this strategy.\nThe Strategy division defines and enables the long-term vision of the ATPCO product portfolio, creates and defines industry processes and standards to help achieve the future of ATPCO.\nAs a Data Scientist you will identify trends, patterns and value in data that would benefit internal initiatives and provide products or tools of value to our customers. You will work across functions to develop, maintain and revise views of data looking for valuable information that would support airline fare management analyses. You will work with the R&D team to solve complex business problems that require an operations research approach of large-scale data modeling and regression analysis.\nThe ideal candidate:\nExperience in airline inventory/yield management or revenue management\nBachelor\u2019s degree in mathematics or similar work experience\nHas expert knowledge of analytic business optimization\nExtensive experience in statistical modeling, experimental design, sampling, clustering, predictive modeling or other related techniques\nStrong ROI optimization, dashboard design, metric selection and definition experience\nHas extensive experience using data analysis tools to analyze and present data in a compelling manner\nAbout ATPCO:\nWhen it comes to data and content, ATPCO is the powerhouse of the airline industry, with the world's largest air price content repository. Our strength has always been in distributing that content throughout the air travel ecosystem. We lead the industry into the future by delivering all air price content via New Distribution Capability (NDC) APIs.\nATPCO is the airline industry\u2019s trusted partner in driving innovation, reducing complexity, and delivering network economics to the entire distribution ecosystem through standards, technology, and effective governance. Our Vision is to fuel the future of air travel, leading the industry into the next generation of distribution, by empowering smart connection of all content through all channels\n\nTo apply to this job, click Apply Now"}, "182": {"company": "UFG Insurance", "description": "UFG offers you an award-winning workplace and a trustworthy, financially stable company. While we\u2019ve always known our commitment to employees and financial stewardship, it is good to have others recognize our dedicated efforts. We've been named an Iowa Top Workplace by the Des Moines Register for four consecutive years, and included on Forbes\u2019 \u201cAmerica\u2019s Most Trustworthy Financial Companies\u201d every year since 2014. Additionally, UFG is a super-regional property and casualty insurer rated \u201cA\u201d (Excellent) by A.M. Best Company.\nThe UFG Enterprise Analytics Department is focused on delivering strategically-impactful results by building analytically based solutions that integrate a wide range of internal and external data assets. The ultimate objective of the Enterprise Analytics organization is to help UFG gain and maintain a competitive advantage in how it prices risk and identifies potential loss.\nWe are seeking an Associate Data Scientist to facilitate the development of Analytics solutions in support of UFG\u2019s strategic plan. This individual will work closely with business units throughout the organization to develop and implement strategies that leverage data to enable enhanced decision making. The ideal candidate will possess strong technical and communication skills, as well as proven experience in predictive modeling, change management, and the insurance industry in general.\n\nWork with management to prioritize modeling needs\nSupport research and development efforts in a diverse set of challenges as we rapidly prototype and build new models\nExtensive experience analyzing data and a broad understanding of core statistical and ML techniques\nDesign, build, and deploy Machine Learning (ML) systems aligning to business objectives\nTranslate and champion ML capabilities for non-technical audiences\nStay current with modeling techniques/technologies\nMaintain positive, professional business acumen and relationships with cross-functional teams and external customers\nTrain end users on new models\nResearch opportunities for data acquisition and new uses for existing data\nCollaborate with data architects, analysts and IT team members on project goals\n\nEducation:\nCompetencies typically acquired through a Ph.D. (in Statistics, Computer Science, Mathematics, or other scientific field of study)\nExperience:\n1-3 years of relevant commercial P&C modeling experience\nExtensive experience analyzing data and a broad understanding of core statistical and ML techniques\nPast experience implementing complex data-driven solutions is preferred.\nDeep experience with GLMs as well as modern machine learning methods.\nDemonstrated experience in handling large datasets, structured and semi-structured data formats\nKnowledge, skills & abilities:\nThis role will require the candidate to be extremely hands on with building models and data driven tools.\nAdvanced Python skills. Should be familiar with Python\u2019s scientific computing ecosystem.\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.\nAbility to translate technical concepts into non-technical, lay terms.\nUnderstanding of star/snowflake schemas as general data warehousing methodologies (i.e. Kimball).\nStrong written and verbal communication skills.\nAbility to deliver incremental value via an Agile Development Methodology.\nAbility to thrive in a fast-paced environment with significant uncertainty\nStart your job application: click Apply Now"}, "183": {"company": "LendingHome", "description": "LendingHome is re-imagining the mortgage process from the ground up by combining innovative technology with an experienced team. Our goal is to create a seamless, transparent process that transforms the mortgage process from end to end.\n\nThe Team\n\nWith our built-from-scratch technology that covers every stage of the loan process, LendingHome has opened access and simplified a way for people to get financing and generate wealth through real estate. Since 2013, LendingHome has funded over $3.5 billion dollars worth of loans across 15,000+ projects, making it the largest fix and flip lender in the country. Combining the best technology and the most knowledgeable people, LendingHome has raised $167MM in venture capital, has grown to a team of over 300, and has been featured on the Forbes Fintech 50 list for two years running. LendingHome is uniquely positioned to become the next great financial services brand powered by the most advanced mortgage platform in the world.\n\nThe Role\n\nLendingHome is seeking a highly analytical and innovative Data Scientist to join our Data team. Data drives every area of LendingHome including marketing, sales, operations, and credit, and you will be collaborating closely with all of these groups to tackle the highest priority strategic questions and to enable excellent, robust data-driven decision making.\n\nResponsibilities\nDefine, create, and improve metrics and dashboards that precisely and accurately measure the pulse of the business\nProactively initiate in-depth, rigorous analysis to derive meaningful insights the business can clearly act upon\nDrive improvements in business outcomes by testing new and different strategies through systematic planning and execution of experiments\nContinually explore and iterate statistical models and features to advance our understanding of key underlying business drivers\nBuild production grade machine learning pipelines and data products that solve critical, complex problems and deliver business value\nIdentify, research, and analyze new data sources that complement and enrich the quality of the data platform\nSupport ad hoc analysis requests\nQualifications\nA graduate degree in Computer Science, Statistics, Math, or related quantitative discipline\nExcellent grasp of fundamentals in statistics and probability\nExpertise in SQL and proven comfort and an intellectual curiosity for working with large sets of data\nProficiency in coding and software engineering concepts. Fluency in Python/R preferred\nExperience with basic classes of machine learning techniques and algorithms (e.g. regression, classification, boosting, clustering, time series, NLP)\nAbility to partner, collaborate, and communicate well with a diverse set of colleagues, both technical and non-technical, at all levels\nA resourceful and pragmatic approach to problem solving and recognition that the best solutions are sometimes the simplest\nExperience in Hadoop/Spark or other distributed parallel computing paradigms is a plus\nAbility to transform technical analysis into easily digestible visualization is a plus\nLendingHome in the News\nWinner: Forbes Fintech 50\nLendingHome Passes $3 Billion in Mortgage News\nHow Wall Street, Silicon Valley Institutionalized Home Flipping\nA Tour of LendingHome's New San Francisco Headquarters\nRiding the House Flipping Boom, Mortgage Lender Adding More Jobs on North Side\nBenefits and Perks\nCareer Growth: We foster an environment that encourages opportunities to use your voice, make an impact, and move towards your long-term goals.\nLunch & Snacks: Hungry? We have you covered! Enjoy catered lunches and Bagel Wednesdays\u2014and don't forget to take your pick of healthy snacks and drinks daily from our fully stocked kitchen.\nWork-life Balance: With our flexible time off policy, you can enjoy a well-rounded lifestyle while easily balancing work, travel, loved ones, and passions.\nFamily Matters: We know your role here might not be the only one you have. Enjoy your job as a parent and welcoming your new bundle of joy with our competitive parental leave policy.\nCommuter Benefits: Travel from A to B without the stress. We help you save money on your commute to work with pre-tax deductions and a monthly stipend.\nProduct Ownership: We recognize your hand in making our business great. With offered equity, you can claim your stake in our growth.\nHealth Insurance: Your well-being is important to us. Our comprehensive medical, dental, and vision plans ensure that your mind and body are in good keeping.\nIf you'd like to see more about what LendingHome has to offer or explore additional opportunities, visit us at LendingHome.com/Careers.\n\n\nLendingHome is an Equal Opportunity Employer\nSan Francisco Fair Chance Ordinance Police Code, Article 49\nTo apply to this job, click Easy Apply"}, "184": {"company": "Systems Evolution Inc.", "description": "WHO WE LOOK FOR\n\nAn SEI Consultant is a master communicator and active listener who understands how to navigate an audience. Self-aware, almost to a fault, SEI consultants keenly understand how to adjust their approach based on the situation. Following a logical, fact-based approach, our consultants possess the superior ability to see correlations others may not, ask the right questions and drive solutions.\n\nAs super-connectors, our consultants connect not only people, but data, trends and experiences. Mature, humble, and genuine, SEI Consultants frequently go above and beyond for both their clients and their colleagues. SEI Consultants are ethical and trustworthy individuals who do what they say. SEI Consultants have an insatiable curiosity and love to learn. These individuals are commonly tech savvy and early adopters. Their passion for learning is infectious and excites others.\n\nAs every project is different, an SEI Consultant must be adaptable and comfortable with unexpected situations. An SEI Consultant must be at ease with ambiguity because although a client knows that a problem exists \u2013 they need SEI to figure it out and drive a solution. SEI Consultants define ambition differently. SEI Consultants are authentic, low-maintenance individuals who like to hang out with colleagues outside of work. Whether it be cooking, traveling, hiking, or volunteering, SEI Consultants enjoy working with genuine, thoughtful folks who want to steer clear of the traditional grind and share the joy of day-to-day life and activities with colleagues, friends and family.\n\nWHAT WE DO\n\nOur consultants work with clients at all levels of the organization, from the C-suite to the shop floor, helping them to deliver on their most strategic initiatives. We\u2019re known for making realistic, data-driven decisions that deliver value in tangible ways to our clients. Our clients ask for us on projects that require a superior combination of technical and business capabilities, people and management skills, and a collaborative mindset. We excel in understanding complex programs and strategic initiatives and breaking them into actionable pieces.\n\nWe are actively looking for professionals in the following areas:\nData Strategy and Governance\nDatabase Architecture and Development\nData Analysis\nReporting and Data Visualization\nThe ideal candidate will:\nHave experience understanding and solving real business problems\nSolid writing and speaking skills to support data storytelling\nIdeal candidates may call themselves Data Engineers, Data Scientists and Analysts and Data Governance professionals. Experience may include but is not limited to the following:\nExperience with statistical and mathematical modeling, artificial intelligence and machine learning software and methods\nSpecialization in architecting enterprise solutions with visualizations and data-discovery tools such as Tableau, QlikView, Spotfire, Amazon Web Services, Cloud, Salesforce\nTechnical capabilities that include designing scalable data architectures, solution performance tuning, and hardware sizing\nExperience and knowledge of programming and scripting languages, such as , Python, Java, C#, PL/SQL, R and SAS\nExperience and knowledge of relational and dimensional database structures, theories, principles, and practice used in data warehousing and analytics solutions\nExperience managing, populating, and querying database technologies including RDBMS, NOSQL, and big data platforms and experience working with these technologies' ecosystems\nQUALIFICATIONS\n\nRequired\nDemonstrated business and technology acumen\nProven track record of delivering results\nExperience working with and/or leading a team\nAbility to work independently\nAbility to work across industries, roles, functions & technologies\nPositive can-do attitude\nA curiosity for new technology\nAuthorization for permanent employment in the United States (this position is not eligible for immigration sponsorship)\nPreferred\nBachelor\u2019s degree (Mathematics, Computer Science, or related field preferred)\n8+ years professional experience\nConsulting experience\nExperience across our service offerings\nStart your job application: click Apply Now"}, "185": {"company": "Press Ganey", "description": "Data Scientist\nLocation\n\n\nIL - Chicago\n\nFunctional Area\n\n\nResearch & Analytics\n\nEmployment Status\n\n\nRegular\n\nApply Now\n\nAbout Press Ganey\n\nPress Ganey pioneered the health care performance improvement movement more than 30 years ago. Today, Press Ganey offers an integrated suite of solutions that enable enterprise transformation across the patient journey. Delivered through a cutting-edge digital platform built on a foundation of data security, Press Ganey solutions address safety, clinical excellence, patient experience and workforce engagement. The company works with more than 33,000 health care facilities in its mission to reduce patient suffering and enhance caregiver resilience to improve the overall safety, quality and experience of care.\n\nJob Overview\n\nPress Ganey is looking for an energetic, creative and curious data scientist to join its Data Science team! We have an opening for a data geek (statistician, data scientist, economist, etc.) interested in producing novel \u2013 and impactful - data-driven insights, and developing world-class analytic products, from our database of over 1 billion patient experience and employee engagement results, representing over 20 thousand healthcare facilities. Positions are available for our Boston, Chicago, Charlotte, or Baltimore office.\n\nDuties & Responsibilities:\nFunction as technical lead, in collaboration with other business partners serving the analytic client, to develop deliverables requirements\nIndependently write programs in appropriate language (e.g. R, SQL, Python), to develop data (sets), from multiple databases, needed to support deliverables\nIndependently produce analysis (e.g. basic data analysis, statistical test, statistical modeling) or analytics (e.g. a dashboard), with appropriate tools (e.g. Excel, R, Python, HTML, Tableau)\nDocument work\nProduce written reports, for internal constituents, which summarize analytic deliverable; including methods, interpretations, and business implications\nProvide ad-hoc analytic support to internal clients (e.g. sales, account management, advisory services, product management, and consulting), including answering data and methodology questions, interpretation of results and\nStay abreast of contemporary analytics, such as big data technologies (e.g. Azure, AWS, Hadoop, OLAP tools), analytic technologies (e.g. SAS, R, Python, Tableau, etc.), and statistical (including data-mining) methods\nIn collaboration with business partners (e.g. Knowledge Management, Engineering, Product Management, and Custom Reporting), develop prototypes of scalable, novel analytic solutions that address important business questions\nDevelop and prototype novel data sets that integrate existing PG or external data, for the purpose of developing novel analytic solutions\nStay abreast of healthcare industry issues affecting PG clients (e.g. value based reimbursement programs, meaningful use, \u201cPopulation Health\u201d)\nDevelop internal network of colleagues, and a corresponding reputation for collaboration, that removes barriers to analytic production and enables problem solving\nQualifications:\nIntermediate to advanced proficiency with SQL, SAS, R, STATA or other high level data programming language\nBasic proficiency with Python, PHP, Perl, VB, JavaScript, C++ or other programming language\nFormal training or extensive applied experience with advanced statistical methods such as regression-type modeling and data-mining methods (e.g. classification trees)\nProficiency with data visualization\n2+ years developing data that merges relational tables, either within a relational database or related \u201cbig data\u201d environments (e.g. SQL Server, Hadoop)\n2+ years of data and statistical analysis\n1-2 years project management experience, including demonstrated success with cross-functional collaboration\n1-2 years implementing novel analytics with minimal supervision\nMinimum Education:\nBachelors or higher in Mathematics, Statistics, Engineering, Economics, or other quantitative discipline.\nAll positions at Press Ganey require an applicant who has accepted an offer to undergo a background check. The specific checks are based on the nature of the position. Background checks may include some or all of the following: SSN/SIN validation, education verification, employment verification, criminal check, search against global sanctions and government watch lists, fingerprint verification, credit check, and/or drug test. By applying for a position with Press Ganey, you understand that you will be required to undergo a background check should you be made an offer. You also understand that the offer is contingent upon successful completion of the background check and results consistent with Press Ganey's employment policies. You will be notified during the hiring process which checks are required for the position.\n\nFor more information about Press Ganey, visit our web site at pressganey.com .\n\nPress Ganey Associates, Inc. is an Equal Employment Opportunity/Affirmative Action employer and well committed to a diverse workforce. We do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, veteran status, and basis of disability or any other federal, state or local protected class.\n\nPay Transparency Non-Discrimination Notice \u2013 Press Ganey will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information.\nApply Now: click Apply Now"}, "186": {"company": "Billy Casper Golf", "description": "Billy Casper Golf is one of the largest privately owned golf course management companies in the U.S. that prides itself on being an industry leader in advancing the marketing science of the industry. This position will be a key member of the analytics team developing capabilities leveraging the CRM and a suite of marketing technologies to drive conversion and grow revenue for clients. The ideal candidate will have strong ability across the full data lifecycle: from data extraction via queries and API integration through model development, implementation, and measurement. This role will require close collaboration with both marketing and IT team members.\n\nQualifications:\nA degree in Computer Science, Physics, Mathematics, Electrical Engineering, or related discipline.\n3+ years of experience as a Data Scientist.\nExpertise in Python and R with proficiency using PyCharm, Jupyter Notebook, and RStudio environments.\nAdvanced SQL knowledge.\nExperience with cloud storage and computing, preferably Amazon Web Services.\nDemonstrated ability to use predictive modeling and machine learning algorithms to solve business problems.\nCapability with business intelligence and data visualization tools such as Shiny, Tableau, or Domo.\nFamiliarity with Java and/or C++ a plus.\nAbility to convey analysis and results in a clear manner.\nResponsibilities:\nWrite software that extracts and transforms data across disparate sources into unified and centralized systems.\nBuild and deploy algorithmic solutions across various marketing technologies and applications that improve the customer experience and result in increased engagement.\nDevelop and implement models for pricing optimization by channel.\nGenerate methods to evaluate and measure the true business value of marketing tactics.\nPropose reporting formats to effectively communicate meaningful data trends and relationships.\nPresent complex analysis across various organizational levels and external clients.\nStart your job application: click Apply Now"}, "187": {"company": "Practice Fusion", "description": "Overview\n\n\nWelcome to Allscripts! Our Mission is to be the most trusted provider of innovative solutions that empower all stakeholders across the healthcare continuum to deliver world-class outcomes. Our Vision is a Connected Community of Health that spans continents and borders. With the largest community of clients in healthcare, Allscripts is able to deliver an integrated platform of clinical, financial, connectivity and information solutions to facilitate enhanced collaboration and exchange of critical patient information.\n\nThe primary purpose of this role is responsibility for normalizing data, structuring data for predictive analytics, building framework in Azure to facilitate analytics, machine learning, data extraction from structured and unstructured data utilizing NLP, predictive model development for embedment into Allscripts Products.\n\nResponsibilities\n\n\nBusiness Requirements\nWorks with stakeholders to identify business requirements and expected outcomes\nModels and frames business scenarios that impact critical business processes/decisions\nData Requirements\nIdentifies relevant and available data including internal and external data sources\nCollaborates with SMEs to select relevant sources of information\nWorks with teams to support data collection, integration and retention requirements incorporating business knowledge and best practices\nAnalysis\nSolves client analytic problems and communicates results and methodologies\nWorks in iterative processes with the client and validates findings\nDevelops experimental design approaches to validate findings and test hypotheses\nValidates analysis by comparing appropriate samples\nQualification and Assurance\nAssesses expected qualification and assurance of information\nDefines validity of the information and how long the information is meaningful\nAccess Management and Control\nWorks to ensure information is used in compliance with regulatory and security policies\nPerformance\nProvides on-going tracking and monitoring of performance decision systems and statistical models\nSupport\nTroubleshoots and implements enhancements as needed\nQualifications\n\n\nAcademic and Professional Qualifications:\nBS Degree in Computer Science, Mathematics, Statistics or related field\nMasters in mathematics, statistics or computer science or related field\nExperience:\n3-5 years experience of relevant quantitative and qualitative research and analytics experience\nSolid knowledge of statistical techniques\nStrong programming skills (such as Hadoop, Hive, Spark)\nStrong skills and experience with Big Data, Cloud-based computing, neural networks\nStrong proficiency in statistical analysis, quantitative analysis, and predictive analytics\nExperience using machine learning algorithms\nHigh proficiency in use of statistical packages\nIn depth industry/business knowledge\nTravel Requirements:\nNo usual travel\nTravel to educational conferences as needed\nWorking Arrangements:\nWork is performed in a standard office environment with minimal exposure to health or safety hazards\nAt Allscripts, our greatest strength comes from bringing together talented people with diverse perspectives to support the technology needs of 180,000 physicians, 1,500 hospitals and 10,000 post-acute organizations across the globe. Allscripts offers a comprehensive compensation and benefits package, including holidays, vacation, medical, dental, and vision insurance, company paid life insurance and retirement savings.\n\nAllscripts policy is to provide equal employment opportunity and affirmative action in all of its employment practices without regard to race, color, religion, sex, national origin, ancestry, marital status, protected veteran status, age, individuals with disabilities, sexual orientation or gender identity or expression or any other legally protected category. Applicants for North American based positions with Allscripts must be legally authorized to work in the United States or Canada. Verification of employment eligibility will be required as a condition of hire.\n\nFrom a \"VEVRAA Federal Contractor\" We request Priority Referral of Protected Veterans\nApply Now: click Apply Now"}, "188": {"company": "Alector", "description": "At Alector, our mission is to develop therapies that empower the immune system to cure neurodegeneration. Our team is solely focused on developing cures for some of the most challenging diseases facing our society. We are supported in this mission by experienced and accomplished scientists and board members, leading healthcare investors and some of the most innovative pharma companies.\nUse your cutting-edge analytical skills and biological insights to help us achieve our mission of saving lives by curing neurodegenerative diseases and cancer.\n\nAs a Scientist for the bioinformatics team, you will play an important role in every aspect of Alector scientific mission, from target discovery to pre-clinical and clinical phases. You will work closely with - and under the mentorship of - our scientists to discover and develop novel drugs targeting neurodegenerative disorders and cancer. As part of a talented and multi-disciplinary bioinformatics team you have a transversal role and interact closely with scientists from different fields. You will carry out valuable analyses which will further Alector\u2019s collective scientific understanding. You will apply your existing technical skills, and learn new skills. As an early hire, you\u2019ll be influential in championing and developing Alector\u2019s culture.\n\nDuring the first year, your goals will include:\nClosely collaborate with research and clinical scientists to develop informatics analysis approaches and independently execute bioinformatics analyses that support discovery and pre-clinical studies such as new target identification and biomarker development\nIdentify relevant internal and external data and knowledge resources and execute integrated data mining analyses\nKeep track of the current analytical methodologies and introduce them when appropriate\nCommunicate analytical analysis verbally and in writing to teammates\nWe'd love to hear from you if:\nYou take pride in being persistent, self-motivated, and efficient\nYou thrive in an environment where we work independently and on teams\nYou demonstrate a track record of learning new things and troubleshooting independently\nYou are fluent in scientific scripting languages such as R, Perl/Python, and very adept at working in both linux and windows environments\nYou have hands-on experience in genomics and genetic databases, in data analyses using existing and custom pipelines\nYou have an in-depth knowledge of current technologies for genetic, transcriptomic and proteomic data generation and analysis, including single-cell RNAseq, in silico deconvolution or eQTL analysis.\nYou have experience in performing statistical analysis\nYou are familiar with human genetics concepts and analytics\nYou have a solid background in immunology, oncology or neurodegenerative disorders\nYour academic background includes a PhD in bioinformatics, immunology, neuroscience, biology or a related scientific field\nYou have a point of view but are low ego\nYou have excellent communication skills\nAt Alector, we believe that high-performing teams include people from a wide variety of backgrounds and experiences who can challenge each other\u2019s assumptions with fresh perspectives and bring creative ideas to the table. We are committed to building an open, diverse, and inclusive environment for all employees. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, sexual orientation, age, marital status, veteran status, or disability status, or any other characteristics protected under applicable federal, state, or local laws.\nAlector is a phenomenal place to learn and experiment. If you excel in a dynamic environment where everyone is committed to finding a cure, where you\u2019ll drive growth, this is the role for you. There is no limit to how far you can go with us.\n\nBenefits\nWhile we\u2019ve focused on what to look forward to during the first year and beyond, Day One is great, too: committed and driven colleagues, a bold and important company goal, state-of-the-art brand-new brightly-lit offices in the heart of the biotech area, competitive compensation and benefits. But these matter only if you\u2019re excited to build and own something great, and tackle these challenges with us. Come join us.\nApply Now: click Apply Now"}, "189": {"company": "Just Auto Insurance", "description": "Just Auto Insurance (Just) is a young, fast-growing start-up, looking to revolutionize the auto insurance industry. Our customers will pay fair premiums, based on how they drive and what conditions they drive in, rather than how old they are or what zip code they live in.\n\nWe score how our customers drive using telematics data, gathered from our app running on their smartphones, to determine an individual price per mile for each customer. Our vision is to ingest and interpret ever-more data sources, including audio and video data, to improve driver safety, lowering the risk of accidents and the cost of insurance. Our data science platform and strategy are critical to achieving this mission. You will be a senior member of the data science team, providing this capability.\nWhat you'll do:\nSenior member of the Data Science team\nImplement data science strategy\nWork with large, complex data sets\nSolve complex, non-routine analysis problems, applying advanced analytical methods\nHelp to architect a secure, scalable and performant data warehouse and data science platform\nBuild and prototype analysis pipelines iteratively to provide insights at scale\nBuild out the technology and processes\nWhat we're looking for:\nMasters in Data Science, Computer Science or similar\n5+ years of hands-on technical experience in cross-functional Data Science roles\nExperience working with telematics datasets\nDeep understanding of statistics and experimental design\nExperience of going through an aggressive phase of growth\nStrong programming and architectural skills\nExperience in integrating models into existing systems\nSome experience with deploying on scalable cloud-based systems\nStrong standards for software engineering practices\nAbility to break down complex problems\nCreativity in sourcing datasets\nExperience in non-academic, commercial Data Science projects\nExperience in signal processing, including sensor data, time series methods and filtering\nHighly regarded but not a prerequisite:\nPhD in Data Science, Computer Science or similar.\nExperience working for a telematics-based auto insurer\nVideo or audio processing experience\nFrom a personal point of view, we're looking for someone who is innovative, collaborative and has passion for what they do. You'll be expected to roll up your sleeves and get stuck in from day one.\n\nSo that's what we need, what about what we can offer you.\n\nYou'll be joining a highly talented, focused and energetic team. Following agile principles, the data science, software engineering and stakeholders work closely and collaboratively together.\n\nAs we believe in collaborative working, we ask employees to come into the office five days a week. We start at 08:30 to align with our London, UK office a little better. Our Los Angeles office is based in trendy Brentwood with excellent access to stores, restaurants and surrounding West LA suburbs.\n\nWe believe in work-life balance, and as such, you'll get your birthday and the days between Christmas and new years off, in addition to your 20 days vacation allowance.\n\nYour remuneration is made up of salary (up to $160k), healthcare and a generous share options package.\n\nThis is an extraordinary opportunity to get in at the ground floor of a business that seeks to revolutionize a $222B industry - and that's in the US alone. If you are passionate about making a difference and have a hunger to shake up a market that is ripe for change, this is the role for you."}, "190": {"company": "Enterprise", "description": "About the Role\n\nThe Center of Excellence for Data and Analytics (CEDA) Senior Data Scientist leads initiatives using advanced analytics expertise to understand internal and external customers' strategic business objectives, relate those objectives to measurable indicators and focus on delivering analytic products and services to create new insights and strategies promoting continuous performance improvements for the company. The CEDA Senior Data Scientist acts as a resource and mentor for less experienced Data Scientists and applies expert analytics to create efficiencies and improve the decision making process for internal business units by developing and implementing advanced statistical and mathematical solutions.\n\nCompany Overview\nEnterprise Holdings is the largest car rental provider in the world as measured by revenue and fleet. The company and its affiliate Enterprise Fleet Management which combined offer a total transportation solution that includes extensive car rental and car-sharing services, truck rental, corporate fleet management and retail car sales accounted for $24.1 billion in revenue and operated 2 million vehicles throughout the world in 2018. Enterprise Holdings annual revenues also place it near the top of the global travel industry, exceeding all other rental car companies, many airlines, and most cruise lines, hotels, tour operators and online travel agencies. Enterprise Holdings regional subsidiaries and Enterprise Fleet Management currently employ more than 100,000 people worldwide.\n\nThrough its integrated global network of independent regional subsidiaries and franchises, Enterprise Holdings operates the Enterprise Rent-A-Car, National Car Rental and Alamo Rent A Car brands at more than 10,000 fully staffed neighborhood and airport locations. The Enterprise Holdings global network operates in more than 90 countries and territories, including North America, Central America, South America, the Caribbean and Europe, as well as parts of Asia-Pacific and the Middle East. Today, the companys three brands serve more than 95 percent of the worldwide car rental market.\n\nThis position is located at our Corporate Headquarters in Clayton, MO.\n\nResponsibilities:\nLead the design and delivery of end-to-end analytical solutions that address the business needs\nExtract, clean, and manipulate both structured and unstructured datasets\nPerform exploratory data analysis, generate hypotheses, and extract actionable insights\nDevelop statistical and/or mathematical models that are put in production\nDeliver detailed documentation including descriptions of efforts, results, insights and recommendations\nPresent findings and recommendations to other CEDA members and various levels of management\nPartner with the other CEDA teams to ensure solutions are delivered successfully\nProvide technical guidance and mentoring to other Data Scientists\nIdentify and offer strategies to link the team's analytical activities with business goals and objectives\nAdditional Responsibilities\nSeek to improve job performance through self-assessment, skill development, training and goal setting\nMaintain a regular and reliable level of attendance and punctuality\nPerform miscellaneous job-related duties as assigned\nEqual Opportunity Employer/Disability/Veterans\n\nQualifications:\n\nMinimum:\nMust have a Master's Degree or greater in Mathematics, Statistics, Operations Research, Physics, Engineering, Economics, Computer Science or a related quantitative field\nMust be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future\nMust have 4+ years experience data mining and developing statistical and/or mathematical models using R or CPLEX\nMust have 4+ years experience with SQL and/or Python programming or directly querying relational databases such as Teradata, SQL Server or Oracle\nCompetency Based:\nForward-Thinking\nResults-Oriented\nWorking With a Team\nProblem Solving\nCommunication\nApply Now: click Apply Now"}, "191": {"company": "Cognite", "description": "#data-scientist #data-viz #data-engineer #data-ops #data-products\n\nWhile you cruise through life in a digital bliss, the industrial world is stuck in a swamp of legacy applications running on some windows server in some basement. Forget about scaling and operationalizing machine learning models, even getting an overview of your data is close to impossible.\n\nAt Cognite, we liberate data from their legacy cages, use machine learning to figure out how data from different sources fit together, design company-wide data models, build high-performing and scalable storage and streaming solutions, help industry deploy analytics at scale across all their assets, and use gaming technology to visualize it all.\n\nWe have proven Cognite Data Fusion and technologies and in 2019 are looking to scale across Power, Oil and gas and other sensor rich industries. Working as a part of Cognite\u2019s cross-functional customer facing teams, you will have a unique opportunity to build and deploy solutions (not just demos and slides) that augment to improve operations.\n\nWe believe in open culture, open source, and open data (see #dataliberationfront) but why the open application? At Cognite we live the idea that data science is a team sport. Our teams need to be as diverse as the problems we solve, covering\nModel development\nDesign thinking\nData engineering\nDevOps\nData visualization\nIndustrial domain expertise\nFront end development\nSomething we have not yet learned!\nFor this role, we\u2019re looking for various levels of experience. Candidates should possess 2+ years of experience (including masters, PHD, and relevant work experience). You will be evaluated for technical competency (github), drive (self training / projects) and customer empathy (project experience). Offers will be competitive and commensurate with experience and competency.\n\nWant to know more? You should! Check out our website and then write to us and tell us what you\u2019ll bring to our cross-functional customer facing teams and why you\u2019re excited to help guide our customers through industrial digitalization.\n\nRequirements\n30-50% travel. We don\u2019t build solutions in isolation. We sit with the subject matter experts day to day and build solutions together.\nHumility and integrity\nTeam-oriented\nRole to be based in Houston or Austin, TX\nBenefits\n\nWe are an exciting fusion of the technological and the industrial, fast growth and sustainable innovation.\nCompetitive salary and benefits (including 401K plans, health insurance, and more)\nOpportunity to work with great people on projects that create real impact\nOpportunity to be part of- and participate in global projects\nMinimal bureaucracy and overhead, with focus on agility and speed\nRegular internal or external tech-talks\nAll the tools you need to be productive\nOpen and friendly company culture\nEmphasis on individual health, with competitive health insurances\nFlat structure with direct access to decision-makers\nHigh level of autonomy and ability to influence decisions\nNew, attractive offices\nStart your job application: click Easy Apply"}, "192": {"company": "Rally Health", "description": "Rally Health\u2122 is all about putting health in the hands of the individual. It's our mission, and it drives everything we do, which is to empower people with easy-to-use online and mobile tools that help them take charge of their health and health care, from improving their diet and fitness to selecting health benefits, and choosing the right doctor at the right price for their needs.\n\nOur culture is built on a deep and sincere dedication to helping people live healthier lives. To do this, we are committed to innovating continuously at every level. We know that some of the things we do are not going to work, and that's okay. We're not trying to build something that is churn and burn. We're building something that supports people over their lifetime. Every day, we get to work with amazing people on something that directly impacts the lives of millions of people for the better.\n\nAt Rally Health, we believe that two heads truly are better than one. Rallyers understand the importance of communication and collaboration, ensuring that we work we produce is the best that it can be. Every opinion is valid and valued, and we share ideas that elevate the way we work. We know that the big picture and the small details are tied together, and we keep both in mind. Everything we do is executed with our users in mind, so we make sure that all of our work has a human touch. Here at Rally, we take advantage of the opportunity to build strong relationships with each other, because it makes us better.\n\nAbout the Team: The Data Sciences team is seeking a senior data scientist to support our Find and Price Care product, which enables and rewards consumers to find, price, schedule, and pay for the care they need. We work with diverse data to generate insights and develop strategies that help our products evolve to better serve our customers and users, informing them about their healthcare options and engaging them in their own healthcare.\n\nYour day to day:\nYou'll bring your knowledge of health data and machine learning algorithms to understand how our users search for Care and make recommendations on personalizing the search experience.\nYou'll closely collaborate with product leaders, leveraging data and strategies to measure and improve our search offerings through algorithms that optimize search results, metric development and instrumentation, data investigations, designing and interpreting experiments, exploratory research, and impact evaluation.\nYou'll be empowered to mine our data which includes user interactions, activity, and achievements in our wellness product; lifestyle and health status from our comprehensive health assessment survey; search terms when seeking care; and direct health information such as biometrics, health risk, and medical claims.\nYour core responsibilities:\nBuild robust and interpretable models that predict how digital search engagement leads to real-world health outcomes.\nWork with Product and Engineering to find new opportunities for predictive modeling and to improve our search infrastructure.\nDevelop replicable analyses and a reusable code base for understanding and enhancing search performance.\nSharpen our data science capacity by mentoring team members in areas of your expertise whether it's NLP, network analysis, search algorithms, or personalization.\nAbout you:\nDegree in a quantitative field with 5+ years of experience as a data scientist supporting product development using machine learning, Natural Language Processing, Network Analysis, or ElasticSearch to power high impact customer-facing features.\nEffective communicator, with and without data, paired with a dedication to understanding user problems and technical challenges.\nExperience building and evaluating machine learning-powered search applications.\nHistory of successfully driving analytic projects and investigations independently, owning them from design to delivery of results with a strong focus on quality and analytic integrity.\nDemonstrated experience with data-driven personalized product development (A/B testing, time series analysis, propensity modeling, etc).\nPreferred:\nHealthcare or wellness specific business knowledge and/or experience with behavioral and claims data\nExperience implementing machine learning models in consumer-facing applications\nExperience working with a variety of data environments, e.g., Hadoop, HDFS, SQL, Mongo, DataBricks, ElasticSearch, etc.\nPhD degree in NLP or Network Science\nWhy join Rally? On top of an innovative work atmosphere and a chance to help people change their lives, we offer competitive pay, daily catered lunches, and an extensive benefits package for all full-time employees (including medical, dental, vision and 401(k)). In addition, we offer the ability to grow, while truly making an impact in the healthcare system.\n\nRally knows that we are strongest when our employee population reflects the diversity of the world around us, and we are a place where all voices are valued. A diverse workforce will enrich us with the talent, energy, perspective and inspiration we need to achieve our mission. Rally Health believes in a policy of equal employment and opportunity for all people. It is our policy to recruit, hire, train, and promote individuals in all job titles, and administer all programs, without regard to race, color, religion, national origin or ancestry, citizenship, sex, age, marital status, pregnancy, childbirth or related medical conditions, personal appearance, sexual orientation, gender identity or expression, family responsibilities, genetic information, disability, matriculation, political affiliation, veteran status, union affiliation, or any other category protected by applicable federal, state or local laws.\n\nIndividuals with disabilities and veterans are encouraged to apply. Applicants who require an accommodation related to the application and/or review process should notify Talent Acquisition (recruiting@rallyhealth.com).\nStart your job application: click Easy Apply"}, "193": {"company": "NetImpact Strategies", "description": "JOB SUMMARY\nTitle: Data Scientist\nClearance Requirement: Active Top Secret\nRequisition Number: 1909-1202\nLocation: Vienna, VA\nRemote Flexibility: 100% on client site\nJob Type: Full-Time, Salaried\nSUMMARY\n\nWe are looking for a Data Scientist who will support our customer with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\nRESPONSIBILITIES\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nDevelop company A/B testing framework and test model quality.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nREQUIRED SKILLS\n5-7 years of experience manipulating data sets and building statistical models,\nMaster's or Ph.D. in Statistics, Mathematics, Computer Science\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\nCoding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.\nKnowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.\nExperience querying databases and using statistical computer languages: R, Python, SLQ, etc.\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience visualizing/presenting data for stakeholders using: Hue or Kibana\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams.\nA drive to learn and master new technologies and techniques.\nWORKING AT NETIMPACT STRATEGIES, INC.\n\nNetImpact Strategies specializes in Strategy and Business Transformation, IT Modernization, Data-Driven Intelligence, Cloud Services, and Cybersecurity. We are a team of skilled Consultants who listen to our clients' needs. We design and implement comprehensive, tailored solutions which are both mindful of the client culture and organizational dynamics. As mission needs change, new priorities emerge, technologies advance, and methodologies evolve; NetImpact stands out as a trusted advisor that can solve the challenges of today while looking for the opportunities of tomorrow. Our professionals stay abreast of these changes to provide agile, outcome-focused results for federal agency strategic and tactical needs. Approaching engagements as a partner, we provide solutions which empower our clients to achieve results that align with their mission and strategic vision.\n\nINCLUSION & EQUAL OPPORTUNITY EMPLOYMENT\n\nNetImpact Strategies, Inc. is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other basis prohibited by applicable law. Recruitment, training and development, transferring and promotion practices are performed without regard to the above-listed items.\n\nON THE JOB\n\nIn compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\n\nWork Environment: All employees are responsible for their own safety, as well as that of others in the workplace. To help us maintain a safe workplace, everyone must be safety-conscious at all times. This position is performed in a typical office environment. The noise level in the work environment is usually quiet to moderate.\n\nPhysical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\n\nWhile performing the duties of this job, the employee is regularly required to talk or hear. The employee frequently is required to stand; walk; use hands to finger, handle or feel; and reach with hands and arms.\n\nDisability Specifications: NetImpact Strategies will make reasonable accommodations in compliance with the Americans with Disabilities Act of 1990.\nStart your job application: click Easy Apply"}, "194": {"company": "Grid Dynamics", "description": "As part of the Enterprise Data team, the Data Scientist supports the development of next-generation data platforms by employing data analytics and various data science capabilities (i.e. machine learning). Incumbents will be part of an innovative and energetic team that develops capabilities which will influence our business model and help our customer build the next generation data platform. The Data Scientist will have access to the vast amount of data stored in heterogeneous formats. This person is supposed to handle complex problems independently and demonstrate analytical thinking. Data Scientist should be able to make judgments and recommendations based on the analysis and interpretation of data.\n\nResponsibilities:\nInvestigate and analyze business and technical problems (application architecture), requirements for a new solution\nDrive the collection, cleaning, processing and analysis of new and existing data sources\nDesign a new solution architecture for manufacturing, sales\nCollaborate with development, testing, release engineering teams\nPlan phases of R&D towards the final architecture state\nSupport decision making on process layout through the data analyzing\nRequirements:\nStrong practical knowledge of analytical techniques and methodologies such as machine learning(supervised and unsupervised techniques), segmentation, time series modeling, response modeling, lift modeling\nExperience in manufacturing, marketing & sales, pricing, demand forecasting\nTechnologies: Python, Pytorch/Tensorflow, Keras, Spark\nEnglish level Intermediate and higher\nWe offer:\nOpportunity to work on bleeding-edge projects\nWork with a highly motivated and dedicated team\nCompetitive salary\nFlexible schedule\nMedical insurance\nBenefits program\nCorporate social events\nProfessional development opportunities\nNB:\nPlacement and Staffing Agencies need not apply. We do not work with C2C at this time.\nAt this moment, we are not able to process H1B transfers. Applicants with CPT and OPT visas are welcome to apply.\n\nAbout us:\nGrid Dynamics is the engineering services company known for transformative, mission-critical cloud solutions for retail, finance and technology sectors. We architected some of the busiest e-commerce services on the Internet and have never had an outage during the peak season. Founded in 2006 and headquartered in San Ramon, California with offices throughout the US and Eastern Europe, we focus on big data analytics, scalable omnichannel services, DevOps, and cloud enablement.\nApply Now: click Apply Now"}, "195": {"company": "Qualys", "description": "We are looking for a Senior Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\n\nResponsibilities:\nDesigning and deploying deep learning algorithms and predictive models\nDevelop custom data models and algorithms to apply to data sets\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\nDevelop processes and tools to monitor and analyze model performance and data accuracy\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\nQualifications:\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\nAbility to drive a project and work both independently and in a team\nStart your job application: click Apply Now"}, "196": {"company": "SharpSpring", "description": "Data Engineer\nGainesville, FL\nSite Reliability \u2013 Data Engineering\nFull-Time\nApply for this job\nSharpSpring is seeking a talented Data Engineer to join our Data Engineering team on-site in Gainesville, FL. As a Data Engineer, you will be responsible for the code and processes required to load data into our data lake and transform it for use by our Data Analysts and Software Engineers. You should possess knowledge of schema design, concurrency, API design, distributed processing, and aggregation. This role represents an opportunity to directly shape and impact a newly-created team within our business and bring fresh ideas to the table regarding our long-term data strategy.\nAs a key member of our Data Engineering team, you\u2019ll work across departments to assist with the provisioning, analysis, and interpretation of business intelligence data as it relates to the adoption of our flagship SaaS platform. You will also work alongside our development team to provide centralized access to our customers\u2019 data which we use for realtime reporting inside of our application.\nYou\u2019ll also be responsible for evaluating the available ecosystem of Big Data tools and for advising our senior technical staff members regarding which tools best fit the needs of our organization. You\u2019ll assist with the implementation and deployment of the solutions we collectively decide upon.\nThe Responsibilities\nExtract data from multiple data sources, such as SQL, MongoDB, Google Analytics, and other platform APIs, and load them into a centralized data lake to facilitate unified reporting.\nAssist with the creation of dataflow pipelines in Apache Airflow or similar tools, to regularly aggregate and summarize data sets for consumption by our application and other business intelligence tools.\nWork alongside other departments such as Finance, Customer Success, and Marketing, to understand trends and key performance indicators affecting the health of our business and the available data to measure them.\nAssist our product and development teams with data needs as they relate to our reporting functionality in the SharpSpring application.\nMaintain data feeds for ad hoc reporting tools.\nProvide consultation regarding Big Data toolsets and storage solutions.\nAssist in maintaining the company data model and documentation.\nAdminister and maintain our data infrastructure.\nThe Person\nDegree in Computer Sciences, Mathematics, Statistics, or similar discipline (or significant industry experience).\n3+ years of professional, industry experience as a Software Engineer. Please provide source code samples.\nExperience with the design and operation of large distributed systems.\nExpert in a programming language such as Python or Golang, and their respective standard data processing libraries.\nStrong working knowledge of relational databases and SQL.\nExperience with at least one queueing system, such as ActiveMQ, SQS, etc.\nRigor in high code quality, automated testing, and other Software Engineering best practices.\nHigh level of comfortability with command-line tools and data pipeline processing from a terminal.\nKnowledge of build systems and version control systems such as Git.\nBasic business acumen, customer empathy, and a team-player attitude.\nExcellent spoken and written communication skills.\nEnjoys a fast-paced work environment and the challenges it brings.\nSelf-starter with the ability to work independently, take initiative, and learn new skills.\nFind Out What It's Like to Work at SharpSpring\n\nSharpSpringers are dedicated, diverse individuals working to provide the best product and service possible to our customers. SharpSpring (NASDAQ: SHSP) provides excellent benefits, an engaging workplace, and talented, friendly coworkers. Join our team!\nApply for this job\nTo apply to this job, click Apply Now"}, "197": {"company": "Pivotal Software", "description": "About Us VIDEO\n\nFounded in 2013, Pivotal Software, Inc. combines our leading cloud-native platform, tools, and methodology to empower the world's largest organizations to adapt to change and build great software. Our technology unleashes developer productivity, while fulfilling our mission to transform how the world builds software.\n\nYou\n\nAs a data scientist on Pivotal's Data Science team, you'll be working on a wide variety of data problems for a diverse range of clients. You will often be asked to learn new technologies and domains on the fly. You should be comfortable working under deadlines and making tough decisions. Consequently, you will frequently have to balance achieving an immediate goal with scalability and productionalizability.\n\nThe role offers room for personal and professional growth, and you won't be working in isolation. Data Science at Pivotal is an encouraging and supportive team, where ideas and challenges are addressed collaboratively. We're looking for the kind of person who will try and solve a problem on their own first, but isn't afraid to ask for help or say \"I don't know.\"\n\nUs\n\nThe Data Science team at Pivotal is primarily a consulting practice; we are tool agnostic, working with our customers to solve real world problems. Our customers, like us, are cross-disciplinary. We service engagements with use cases running from customer churn to optimization to detecting fraud and misconduct. We are not just doers, we are also educators and enablers.\n\nYour Day\n\nWhile there is no such thing as a \"typical day\", these are activities we frequently find ourselves doing:\nWorking with clients to uncover and frame new opportunities for data science. Clients often come to us without a clear understanding of what we can do, so this is our chance to open their eyes to new possibilities for their businesses.\nExploring client datasets, looking for actionable insights we can present.\nEngineering features, training models, tuning hyperparameters and evaluating the results. We emphasize rigor, because data science done right at this stage leads to models that shine in production.\nTaking the models we build into production. This is an exciting stage for anyone who likes collaborating with engineering teams and seeing their model become real when users interact with it.\nHelping our clients develop their internal data science practices, from hiring and recruiting to data capturing, so that they can be successful when we hand off the project.\nRequired Skills / Experiences\nClear and empathetic communicator. You'll be the one sharing your insights with clients and stakeholders at check-ins, documenting your work, and even explaining your model to client data teams as part of a handoff. As such, communication and empathy are essential parts of your toolkit.\nAdvanced knowledge of statistical modeling and/or machine learning methods. These are the tools we need to go from analysis to prediction.\nStrong programming skills. Left to our own devices most of us work in Python, but learning the client's tech stack is an important part of the job.\nStrong exploratory data analysis skills. Every engagement starts with an investigation of the data, and thorough EDA saves us a lot of headaches in the long run.\nSome travel is expected, depending on location and skillset. We mostly work out of the Pivotal office closest to the client, but sometimes we have to be on site for an extended period of time.\nAt least a bachelor's degree in an analytical or technical field. This could be applied mathematics, statistics, computer science, operations research, economics, etc. Higher education welcome and encouraged.\n\nThis role will support US government clients that require US citizenship. Given this, US citizenship is required for you to apply.\nDesired Skills / Experiences\n2+ years of work in a data-centric field (data science or data engineering).\nExperience with relational databases.\nExposure and experience working in a Linux environment.\nYou have a specialization in an area like NLP, optimization, or image processing.\nHands-on experience working in a distributed computing environment or proven theoretical understanding of parallelism.\nPivotal is an Equal Employment Opportunity employer that will consider all qualified applicants, regardless of race, color, religion, gender, sexual orientation, marital status, gender identity or expression, national origin, genetics, age, disability status, protected veteran status, or any other characteristic protected by applicable law.\nStart your job application: click Apply Now"}, "198": {"company": "Coffee Meets Bagel", "description": "Coffee Meets Bagel\n\nCoffee Meets Bagel's mission is to inspire singles to share and connect authentically. The app curates quality matches with fuller profiles that result in real conversations. Globally, CMB has generated millions of real dates and thousands of lasting relationships. Coffee Meets Bagel was named one of the Top 10 Dating apps by Time Magazine and the Best Dating App for Women by Refinery29. It has also been voted the #1 recommended dating app for singles looking for relationships.\n\nJob description\n\nEach day, our users visit our app with the hope of connecting authentically with someone. These interactions generates millions of data points that can be used to help us better understand our customers\u2019 experiences. We need you to ask and answer the questions that will transform this data into a better understanding of what our customers find delightful and what they find painful so that you can help drive changes that further our vision of helping singles form meaningful connections with other amazing singles!\n\nThe Senior Product Analyst will be responsible for partnering with our product and growth teams to provide the facts needed to make better decisions and a well thought point of view to help push our products and services to better serve our customers. You will be responsible for building a strong understand of our ecosystem, working with the product team to determine which projects are the most important, and being willing to use the right tool (a scripted model, a dashboard, a presentation) to find and explain the relevant and timely findings that help us operate better.\n\n\nResponsibilities\nWork cross-functionally with product, design, finance, and engineering teams to provide data-driven insights that will help define the product & marketing roadmap and drive significant increase in core business KPIs (growth, revenue, engagement)\nCreate internal dashboards to monitor the health of the product and business KPIs (growth, revenue, engagement).\nDeliver ad-hoc analyses and reports to support business needs, investigate, triage and resolve metrics-based issues without heavy guidance\nAssist in feature development from ideation to execution, including helping with user research, designing and analyzing A/B tests, and running deep analysis of feature performance post launch\nCreate and share compelling presentations that motivates and inspires the team to build with conviction\nWhen necessary, build models in R, Python, or other systems that help us better measure and understand the results of experiments or user flows.\nQualifications\nBachelors and 5+ years post-collegiate work experience within tech, finance, consulting or related industry\n3+ years working as a product analyst working with a team to understand and sharpen a product\nExperience working in a fast-paced environment such as startup\nExpert level in SQL & business intelligence tools (e.g., Mode, Tableau, etc)\nCompetency in R, Python, or another scripting language\nStrong analytical skills, with experience solving ambiguous problems using data\nAbility to analyze data and condense data to tell a persuasive story\nProven ability to effectively communicate with cross functional teams\nSelf-starter, with ability to thrive in a dynamic, fast-paced environment, drive change through influence, and collaborate effectively with a variety of cross-functional stakeholders. Excited and hungry to try new tools and processes to achieve results.\nPassionate about building delightful products for our customers.\nApply Now: click Apply Now"}, "199": {"company": "Sandia National Laboratories", "description": ":\n\nWe are seeking a Software Systems Engineer to participate on a strategic Sandia project that requires development and deployment of legacy application functionality into a new Microsoft Cloud environment. This front-end Software Systems Engineer will participate in the analysis of software system requirements that will enable IT systems to be put in place to support this project. This position will focus on front-end IT solutions that integrate with back-end software and COTS/SaaS tools, in addition to performing front-end development on Data Science tools/capabilities being built for Sandia data Scientists and/or customers. You will be working on the IT systems being implemented in external Microsoft Azure and O365 Cloud environments and on Data Science solutions being deployed at Sandia. All these efforts are managed from the Sandia Data Sciences Department via oversight from the Departments Manager and an IT Project Manager.\n\nOn any given day you may be called on to:\nParticipate in the analysis of software system requirements that will enable IT systems to be put in place to support both the cloud project and Data Science tools.\nFocus on front-end IT solutions that integrate with back-end software and COTS/SaaS tools.\nPerform front-end development on Data Science tools/capabilities being built for Sandia Data Scientists and/or customers.\nAre you ready for your next challenge? Join us and achieve your dreams while making a difference.\n\nRequired:\nBachelors degree in Computer Science; Information Systems, Software Engineering, or relevant discipline\nPlus, five or more years of experience, or equivalent: experience and/or achievements that demonstrate the knowledge, skills and ability to perform the duties of the job\nExperience with SDLC:\n\nsuch as: planning, defining, designing, building, testing, and deployment of applications/tools, or data-related products in a production environment\nAbility to obtain and maintain a DOE Q-level Security Clearance\nDesired:\n\nExperience in the following:\n\nSoftware engineering in Microsoft Azure or O365, or other cloud vendor environments\nAngular front-end development, React, or vue\nClaim-based authentication OAUTH\nnpm, yarn, or another package management solution\nCode repository use and agile lifecycle tools and technique\nREST, SOAP, RPC, AJAX, WebSockets, etc.\nWorking knowledge of Systems Engineering, ITIL standard methodologies, and Scrum/Agile delivery\nProven ability to perform requirements gap analysis against out-of-the-box application/system functionality and suggest standard methodology solutions\nDepartment Description:\n\nThe primary mission of the Data Sciences Department is to increase the value that Sandia obtains from information assets. To accomplish this mission, the Department focuses on streamlining data access with governance, integrating and federating data, data quality issues, data virtualization, and the creation of a scalable analytic service architecture. Data Sciences provides data analytics and visualization services, and software engineering of applications in support of analytic tools. The goal is to enable Sandia to obtain actionable insights from data and make high-confidence decisions. We are dedicated to creating quality data and analytics products that have positive mission/corporate impact. New data delivery and analytics technologies and methods are persistently evaluated for inclusion within the portfolio of Data Science services the Department offers..\n\nAbout Sandia:\n\nSandia National Laboratories is the nations premier science and engineering lab for national security and technology innovation, with teams of specialists focused on cutting-edge work in a broad array of areas. Some of the main reasons we love our jobs:\nChallenging work withamazingimpact that contributes to security, peace, and freedom worldwide\nExtraordinary co-workers\nSome of the best tools, equipment, and research facilities in the world\nCareer advancement and enrichment opportunities\nFlexible schedules, generous vacations,strongmedical and other benefits, competitive 401k, learning opportunities, relocation assistance and amenities aimed at creating a solid work/life balance\\\nWorld-changing technologies. Life-changing careers._ Learn more about Sandia at: http://www.sandia.gov\n\n*These benefits vary by job classification.\n\nSecurity Clearance:\n\nSandia is required by DOE to conduct a pre-employment drug test and background review that includes checks of personal references, credit, law enforcement records, and employment/education verifications. Applicants for employment need to be able to obtain and maintain a DOE Q-level security clearance, which requires U.S. citizenship. If you hold more than one citizenship (i.e., of the U.S. and another country), your ability to obtain a security clearance may be impacted.\n\nApplicants offered employment with Sandia are subject to a federal background investigation to meet the requirements for access to classified information or matter if the duties of the position require a DOE security clearance. Substance abuse or illegal drug use, falsification of information, criminal activity, serious misconduct or other indicators of untrustworthiness can cause a clearance to be denied or terminated by DOE, resulting in the inability to perform the duties assigned and subsequent termination of employment.\n\nEEO Statement:\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.\nApply Now: click Apply Now"}, "200": {"company": "Gigster", "description": "What We Do At Gigster and Why\n\nGigster accelerates the delivery of digital transformation applications, giving companies the agility to thrive in a software-defined world. Simply put: we build applications that matter, at startup speed. We're a series B, Andreessen Horowitz backed company on track to hit $50MM in revenue by the end of 2019. Other investors include Redpoint Ventures and Greylock Partners.\n\nWhether from our office in downtown San Francisco, which features stunning views of the Bay, or from remote home offices, our team works together to disrupt systems integrators like Accenture by offering customers fixed-price projects. We employ a unique talent model, powered by a technology platform and a proven development methodology that enables virtual teams to deliver high-impact software applications quickly and consistently.\n\nGigster's unique business model creates many opportunities for personal and career growth. We partner with several world renowned companies like Google and Dentsu and drive digital transformation for global businesses and brand leaders like Canon, Clorox, GlaxoSmithKline, Harley Davidson, Prudential, and Staples, AND we empower the workforce of the future - top global talent in our Gigster Talent Network. We enable these talented individuals to work on projects that matter and that matter to them (at competitive rates and with ultimate flexibility and independence) and to belong and thrive in the Gig Economy regardless of where they call home.\n\nWe are intentional about a diverse and inclusive culture. We care about being \"whole humans\" and about bringing all of ourselves to work - humans first, professionals second.\n\nLike most fast-growing start-ups in the tech industry, we have a constantly changing environment. We value passionate and resourceful team members with a growth mindset who enjoy working collaboratively to solve hard problems.\n\nAbout the Role\n\nFor the first time, it is now possible to measure team performance as well as the end-to-end process of developing software and truly understand how teams and software ultimately drive business impact. After delivering over 1000 software projects for both large enterprises and startups, Gigster has amassed a one of a kind data set about software teams, productivity, and business impact. We invite you to come and drive industry-leading thought leadership based on this data set with answers to age-old questions in software and management science as well as product related questions around what truly drives business impact. What investments should be made to engage customers? What makes software teams productive? How does remote work impact outcomes? What aspects of the software process can be automated? What is quality and how can it be incentivized?\n\nYou will work closely with Sales, Marketing and delivery and have access to Gigster's data from software projects, teams, and real-time collaboration tools. You will be crucial to unearthing and communicating insights. You will work directly with the Co-founder & CTO and have end-to-end autonomy. Your findings will drive Gigster's ability to communicate value to clients in a data-driven way as well continuously improve its software development platform. Your work will have visibility across the company as well as outside of it via thought leadership articles and conferences.\n\nCore Responsibilities\nCommunicate data-driven insights about how to build impactful software via articles and physical events\nPerform analyses to understand key drivers of customer outcomes as well as pointers for streamlining tools and processes\nCarry out specific investigations to uncover insightful correlations and patterns\nDrive sessions with key customers\nQualifications\n5+ years experience in lead product, engineering or data roles\nStrong oral and written communication skills\nSound statistical intuition and analytical skills\nExtensive experience using data to influence business outcomes\nExperience with Python, R, Julia or similar\nExperience with relational databases\nSolid grasp of modern technologies and experience using them to drive enterprise scale business outcomes\nAn undergraduate degree in Engineering, Computer Science, or Mathematics\nScrappiness and ability to work autonomously.\nHighly Preferred Competency\nMachine learning expertise\nExperience with non-relational databases\nAn MS or PhD in a quantitative field\nTOTAL REWARDS\n\nYou should not have to spend any time worrying about whether you are paid more than fairly for what you contribute to our team (and to the world!). We offer competitive cash and equity compensation. We frequently review whether our compensation is competitive to market and to ensure internal parity and we make thoughtful and discretionary adjustments accordingly and during frequently scheduled reviews and cycles.\n\nCURRENT BENEFITS & PERKS\n\nIn addition to competitive compensation, we offer:\nCompetitive health, dental, and vision coverage\nWellness and fitness stipend(s)\nFlexible time off - work hard, but take time away when you need it for moments that matter in your life that require you to disconnect from work\n401K Plan - invest in your future\nCommuter Contributions - we all rely on different ways to commute\nShared experiences and meaningful offsites vs. meaningless perks\nAt HQ:\nHealthy drinks and snacks for whenever you need sustenance\nCatered meals daily\nLife-changing work you'll want to brag about - solving real, challenging problems in partnership with exceptional and unique colleagues\nOUR COMMITMENT TO EQUAL OPPORTUNITY\n\nWe are excited to work with and welcome applications from anyone who shares our values and who are qualified for the role that they apply for regardless of: race, color, national origin, citizenship, ancestry, familial pedigree, education, religion, gender, sexual orientation, age, marital status, disability, or veteran status.\nApply Now: click Apply Now"}, "201": {"company": "C2G Partners", "description": "Data Scientist\n\nJob Title\n\nData Scientist\n\nJob\nID\n\n27066981\n\nDuration\n\nLocation\n\nColumbia,\n\nMD\n\nOther Location\n\nBoston, MA\n\nDescription\n\nDynamic, Entrepreneurial Consulting Company seeking Data Scientists! If you\u2019ve got entrepreneurial spirit and passion, are driven by results, and want to be a part of significant growth, we\u2019re looking for you!\n\nBLEND360 is recognized as an award-winning consulting firm and has provided services to some of the world\u2019s best known and most respected organizations. While BLEND360 has worked primarily with clients that are Fortune 500 and mid-sized companies, we also extend services to smaller businesses and non-profits.\n\nBLEND360 is a marketing and analytic consulting company that places consultants in highly strategic marketing and analytic roles, and one of the fastest growing Inc 5000 companies.\n\nIf you are ready to embrace the challenge and would like to join our team as one of our Data Scientists, please keep reading!\n\nAs Data Scientists, we work with business leaders to solve clients\u2019 business challenges and improve clients\u2019 business results using advanced analytics techniques. We contribute our Advanced Data Science subject matter expertise to the recommendations and solutions delivered to our clients.\n\nWe spend most of our time on getting data into proper shape, performing statistical analyses, developing predictive models and machine learning algorithms to solve clients\u2019 business problems. We evaluate different sources of data, discover patterns hidden within raw data, create insightful variables, and develop competing models with different machine learning algorithms. We validate and cross validate our recommendations to make sure our recommendations will perform well over time.\n\nMain Responsibilities\nWork with practice leaders and clients to understand clients\u2019 business problem, industry context, data sources, potential risk and constraints\nProblem solve with practice leaders to translate the business program into a solvable Data Science problem, formulate different approaches, outline pros and cons for each approach\nWork with practice leaders to get client feedback, get alignment on approaches, deliverables, and overall timeline\nDevelop a project plan including key milestones, timeline, and contingency plan\nGather data from client and external data vendors\nPerform data cleaning/hygiene, data QC, and integrate data from both client internal and external data sources on Advanced Data Science Platform\nConduct statistical data analysis, including exploratory data analysis, data mining, and document key insights and findings\nCreate insightful and/or predictive summary variables from granular-level data\nDevelop, validate, and cross-validate predictive models and/or machine learning algorithms using Advanced Data Science techniques and tools\nDocument predictive models / machine learning results that can be incorporated into client-deliverable documentation\nDocument key insights, recommend actions client could take, and quantify business impact\nAssist client to turn models and algorithms into implementable production codes\nQualifications:\nMS or PhD degree in Statistics, Math, Operation Research, Economics, Advanced Analytics, Computer Sciences, Engineering\n2-10 years\u2019 professional experience in Advanced Data Science, such as predictive modeling, statistical analysis, machine learning, Neural Nets, text mining, geo-spatial analytics, time series forecasting, optimization\nExperience with one or more Advanced Data Science software languages (R, Python, Matlab, SAS, Perl, Java, PHP)\nExperience with structured or un-structured data analysis and tools (SQL, Hadoop, Spark, NoSQL, MySQL, MariaDB, Hive, Pig, etc)\nComfortable with cloud-based platforms (AWS, Azure, Google)\nExperience with Google Analytics, Adobe Analytics, Optimizely a plus\nExperience in digital marketing a plus\n**This role will require 30-40% travel.\n\nStart your job application: click Apply Now"}, "202": {"company": "Better.com", "description": "About Better.com:\n\nWe're one of the fastest growing homeownership companies in America. Why? Because we're making homeownership simpler, faster \u2014 and most importantly, more accessible for all Americans.\n\nBy combining smarter technology with a desire to not just change one piece of the journey but the entire makeup of what it's like to buy and own a home in this country, we're building things that don't exist yet.\n\nBetter.com by the numbers:\nWe fund $600 million in home loans per month\nNearly $5 billion in loans funded since our inception in 2016\n2 years running, we're one of Crain's \"Best Places to work\"\nWe're #11 on Fortune's Best Places to Work in NYC\nAnd #964 on Inc.'s 2019 \"5000 Fastest-Growing Companies\"\nWe've secured over $254 million from our investors to date\n...and counting\nWe continue to outpace the industry at every turn. Our backers have helped build some of the most transformative tech and finance companies in history. Kleiner Perkins, Goldman Sachs, IA Ventures, Ally Bank, American Express, Citigroup, Activant Capital, and others have all invested in our vision of redefining the entire home buying journey.\n\nA Better opportunity:\n\nHelp us hack a thirteen trillion dollar industry by building a product that will allow more people than the status quo to own a home and build wealth rather than rent for life. Our tech team is small, and you will be a big part of defining the technical direction and culture. We encourage proposals for projects off the beaten path, experimentation with different frameworks and libraries, and doing as you see fit to solve problems. We also offer above-market compensation and equity, as well as full benefits.\n\nSome projects you could be working on:\nWork extremely closely with our product team to understand user behavior and come up with product ideas\nPresent conclusions to the executive team that can impact the strategic direction of the company\nBuild a lead scoring model to help our customer support team prioritize\nModel the time-lag of conversions using fun math like Gamma distributions\nDesign experiments to understand causal impact\nBuild web scrapers to track price data for competitors\nBuild scalable infrastructure to deploy machine learning models and serve predictions\nBuild infrastructure for ingesting data into our data warehouse continuously and as close to real-time as possible\nWho you are:\nYou have at least 4 years experience writing Python, not limited to small scripts, but also working on larger codebases\nYou have a few years experience with SQL\nYou have experience working with open-ended questions and have a track record of turning fuzzy problems into actionable data\nYou are business-driven, and care about getting to the bottom of how to make a startup successful\nYou have an interest in statistics and machine learning\nBetter Technology:\nWe do continuous deployment and we ship code 50-100 times every day\nThe data stack is all in Python 3.7\nWe use TypeScript and Python for services\nRedshift for our data warehouse, Postgres for the production databases\nKubernetes, for deployment and devops\nAWS for infrastructure, leveraging EC2, S3, Redshift, CloudFront, Route53, and much more\nBetter Team:\nThe tech team is currently 50 engineers but growing quickly\nThe data team is 5 people but with the plan to grow it to 25 in the next year\nErik Bernhardsson (CTO) used to run the data team and the music recommendation team at Spotify. He is the open source author of a few popular projects like Annoy and Luigi and writes a blog about (mostly) data\nThings we value:\nCuriosity. Why? How? Repeat.\nNerdiness. Financial news and trends are fascinating. Seriously.\nRelentlessness. No one here gives up. We try. We fail. We try again.\nPassion. If you don't get excited about homeownership, mortgages, and real estate, it simply won't work.\nSmarts: book and street. We have to use all the tools at our disposal to build Better.\nEmpathy and Compassion. You understand that people's biggest dreams are in your hands.\nCommunication. Can you ask for help or put your hand up when you don't understand?\nStart your job application: click Easy Apply"}, "203": {"company": "Stratagem Group", "description": "Data Scientist\nValley Forge, PAApply Now\nAre you interested in supporting the ever-changing technology needs of the U.S. Government by providing services that support defense initiatives? Come look at Stratagem, where we help the U.S. Government solve some of the most difficult and fun problems in the world.\n\nStratagem is hiring motivated, creative, and technically-minded individuals with a passion and skill for building the state-of-the-art in emerging technologies. We understand that candidates may not be able to check the boxes for all desired qualifications, but what is most important to us at Stratagem is that candidates have exceptional problem-solving skills, creative out-of-the-box thinking, and comfort with quickly learning, evaluating, and deploying new technologies. Successful employees are self-starters, excellent communicators and positive individuals with a passion for delivering uncompromising quality products.\n\n** TS \u2013 SSBI Required **\n\nThis is a data scientist position in Valley Forge, PA, and we are not hiring your average Java Joe\u2019s. We\u2019re looking for the Americano with a double pump. You will be given substantial feature ownership, and we'll expect you to contribute product ideas as well as occasional code. Your ideas will help shape the future of Stratagem.\n\nResponsibilities & Skills\nOur ideal candidate is a data scientist with a love for learning, the ability to pivot directions quickly, and someone with a conceptual understanding application development. You should love manipulating data, running statistical analysis, and getting your hands dirty by working in a multitude of environments.\nAs a data scientist, your responsibilities include:\nIntegrating with a diverse team to deliver in an agile-like manner\nUsing statistics tools to analyze data\nUnderstanding and modeling the relationship between different metrics to identity key insights\nIdentifying opportunities for data science products\nConsulting with developers to run tests and algorithms\nYour core skills/experience include:\nExpertise in one of the following: R, Python, Java, or Scala\nWorking in a software development environment\nExpertise at data mining and analysis for structured and unstructured data\nAbility to produce data visualizations on findings\n3-15 years experience\nYou are the proud owner of a TS/SCI SSBI clearance or you can be granted one\nBonus points if you have experience in any of the following:\nExperience with systems like Hadoop and Spark\nBachelor Degree in Data Science, Statistics, Mathematics, Computer Science, or related discipline or equivalent business experience in a professional service related to Big Data\nDevOps experience\nMission Management\nSIGINT experience\nAbout you\nYou are an exceptional problem solver, a quick learner, and a creative out-of-the-box thinker who values team work. You are comfortable with the pace and ever-changing requirements of a small development company while maintaining a healthy work life balance.\n\nWho is Stratagem\nStratagem is a small and fast-growing technology company built around the idea that we can make a lasting impact for our customers and employees. We believe in a culture of innovation, fun, empowerment, and family. We want you to learn new skills so you can become more fulfilled in both your personal and professional life.\n\nAt Stratagem, our goal is to make our company the last company you work for!\nApply Now: click Apply Now"}, "204": {"company": "Marin Software", "description": "Software Engineer, Data Science (Optimization)\n\nat Marin Software\n\nSan Francisco, CA\n\nMarin is the Advertising Management Platform of choice for global brands such as General Motors, American Express, Macy's, REI, Sephora, Salesforce.com, and 500 other top consumer and B2B companies.\n\nOptimizing ad targeting and performance starts with having the right data, and the Big Data engineering team makes it happen. Combining thousands of reports from Google, Facebook, Bing, and other publishers, over 100M click events per day from our in house performance tracking system and customer reporting systems, and 5+ billion advertising campaign objects, we power our proprietary bidding systems and financial models to maximize value and return for our customers.\n\nMarin is rapidly building out our Big Data infrastructure. We've already built out a 100+ node, petabyte size cluster, and now is a great opportunity to join as a key member of the team and be at the center of the action. We are in an active search for a Data Science Engineer, Bidding to bring real world experience of data analysis and machine learning techniques on vast datasets. We enjoy intense mathematics and computer science challenges and approach these problems with creativity and teamwork. We believe Marin's explosive growth should not compromise its agility in responding to market trends. We are a company that believes in building a product for the long-term, and creating a company that can grow as the market matures.\n\nResponsibilities\nChallenging Machine Learning problems in Bid Prediction in the search advertising space.\nAnalyze large datasets on Spark. Contribute to open source, work on mlib & Presto!\nWork on convex portfolio optimization techniques in the display advertising space.\nMatrix Factorization methods at scale comparable to the Netflix Challenge, to identify target audiences for product segments\nRequirements\n2+ years relevant work experience\nExperience with Scala, Spark, functional programming.\nStatistical Programming (Matlab, R, Python)\nIndustry experience with data analytics projects involving machine learning/optimization in production\nIndustry experience working with or developing distributed systems, especially distributed data stores a plus (Spark, HBase, Presto)\nBS/MS/Ph.D. in Computer Science/Mathematics/Statistics or other quantitative discipline\nCompensation\n\nThis is an on-site, full time salaried position located in our San Francisco world headquarters office. Marin Software provides Equity participation, best in class comprehensive health plans including medical, vision and dental, in addition to flex time off and reimburses 50% of monthly commuting costs for parking and/or mass transit up to the IRS limitations. Marin Software's world headquarters is located in the financial district of San Francisco, with remote offices in Chicago, New York, Austin, and Portland. European headquarters are located in London, with additional offices in Singapore, Paris, Hamburg, Sydney and Tokyo.\n\nAbout Marin Software\n\nMarin Software Incorporated's (NYSE: MRIN) mission is to give advertisers the power to drive higher efficiency, effectiveness, and transparency in their paid marketing programs that run on the world's largest publishers. Marin provides industry leading enterprise marketing software for advertisers and agencies to measure, manage, and optimize more than $7.8 billion in annualized ad spend across the web and mobile devices. Offering an integrated SaaS ad management platform for search, social, and display advertising, Marin helps digital marketers improve financial performance, save time, and make better decisions. Advertisers use Marin to create, target, and convert precise audiences based on recent buying signals from users' search, social, and display interactions. Headquartered in San Francisco, with offices in eight countries, Marin's technology powers marketing campaigns around the globe. For more information about Marin Software, please visit: marinsoftware.com.\n\nMarin Software embraces diversity and is proud to be an equal opportunity employer. As part of our commitment to diversifying our workforce, we do not discriminate on the basis of age, race, sex, gender, gender identity, color, religion, national origin, sexual orientation, marital status, citizenship, veteran status, or disability status, and we operate in compliance with the San Francisco Fair Chance Ordinance.\nStart your job application: click Easy Apply"}, "205": {"company": "Purchasing Power", "description": "Senior Data Decision Scientist - Merchandising\nLocation\n\n\nAtlanta\n\nDepartment\n\n\nFinancial Planning and Analysis\n\nEmployment duration\n\n\nFull time\n\nApply Now\n\nPurchasing Power, Midtown Atlanta, GA\n\nData Decision Scientist - Merchandising\n\nAt Purchasing Power the merchandising team is about driving demand and increasing profitability by new concept development, strategizing, planning, modeling, testing, and validation of the initiatives, including pricing, inventory, brand affinity, and promotions as related to customer behavioral patterns.\n\nAre your talents ready to make a real and measurable difference in the life-time-value of customers?\n\nPurchasing Power needs your creative, predictive, and quantitative \u201cWOW skills to surface the hidden insights.\u201d You discovery efforts are an integral component of our team's ultimate goals of increasing sales efficiency and effectiveness, by targeting the right promotion to the right customer with personal relevancy, enabling forecasting inventory to reduce overstocking and associated cost of effective advertising strategies, and expanding our competitive advantage in today\u2019s marketplace.\n\nResponsibilities\n\nPricing, Branding Affinity, and Inventory / Assortment Optimization\nResearching, designing, and implementing analytical models and algorithms that will be utilized for pricing across promotion, product, shipping sensitivities, and optimization.\nAnalyzing & distilling loyalty insights from diverse data sets (member, segment & program level)\nEnabling best in class offer generation (customer targeting & offer assignment) & optimization based on all the available data, scores & model outputs including dynamic attributes.\nUse time-based demand forecasting to augment cross-sectional binary classification\nProvides in-depth and sophisticated analytic capabilities to support retail business problems by understanding business challenges\nCollects, cleans, transforms, and restructures data for statistical analysis; performs statistical summaries and tests for relevant business questions\nCreates analytic solutions by exploring innovative data and techniques; conducts exploratory data analysis and modeling\nBuilds predictive and prescriptive models supporting a vast array of customer and business scenarios; performs statistical tests to enhance the predictability of deployed models\nCommunicates insights to leaders by summarizing conclusions and solutions; translates analytics and statistics into clear, understandable themes for business leaders; identifies specific analytic results that drive actionable insights\nMaintains consistency in analytic practices by brainstorming and partnering with other areas within the Data Analytics and Consumer Insights COE\nResponsible for continuously learning and sharing analytic methodology and techniques new to Purchasing Power\u2019s Decision Science Team\nDevelops robust hypotheses, in collaboration with business partners, on how value can be created; builds analytical models to validate/disprove these hypotheses and develops actionable recommendations for the business\nQualifications\nBachelor\u2019s or Master\u2019s degree in Statistics, Econometrics, Information Sciences, Applied Quantitative equivalent combination of education and experience or related field.\nMinimum of 3 years of directly related experience and strong proficiency of predictive modeling techniques, test/learn, base, shipping, and promotional lift and price optimization, affinity modeling, and inventory stock and assortment market basket analysis.\nExperience working with analytic tools/software (e.g., Base SAS, SAS Enterprise Miner, R, Python) and performing advanced data modeling, data mining and exploratory data analysis (e.g., logistic regression, Hyndman Package \u2018forecast\u2019, Affinity Analysis, MNL, NL, LC, ED, Sentiment scoring, NLP, Heuristics, DP, IP)\nSuccessful track record of applying sophisticated analytics techniques in a retail company, eCommerce, or consumer brand.\nStrongly motivated to be a player in a team which is constantly working to improve themselves through discovering new analytics techniques and software tools to improve the quality of our work.\nSuperior research, statistical, analytical, processing, and mathematical skills with the ability to structure and conduct analyses.\nStrong verbal and written communication skills; ability to present complex information in an easy-to-understand manner with clear recommendations based on data insight.\nAdaptability and the capability of multi-tasking and strong time management.\nThrive in a fast\u2010paced, entrepreneurial environment.\nWhy Purchasing Power?\n\nWe are the leading specialty e-retailer offering consumer products, vacations and online education services through an easy and convenient payment plan. Our customers love us because we make paying for their purchases stress- and hassle-free. The automatic payments help them to avoid penalty fees and ballooning interest associated with other payment options. While the fixed payment duration options empower them to budget more efficiently. Ours is a revolutionary e-commerce experience that gives customers access to a better life combined with a responsible way to buy.\n\nPurchasing Power is \u2018Powering People to a Better Life\u2122\u2019 through its employee purchase program, financial literacy efforts and charitable contributions.\n\nFor more information, visit www.PurchasingPower.com\nOur people! We are very proud of our people, we \u201cPower People to a better life\u201d\n100% company paid benefits for employees\nKitchen stocked with gourmet coffee, teas and free snacks\nCasual work environment\nSummer Hours\nFlexible PTO\nTop of the line hardware\n\nTo apply to this job, click Apply Now"}, "206": {"company": "ACI Worldwide", "description": "DETAILS: ACI Worldwide is looking to fill one Data Scientist\nposition to be based out of its Waltham, Massachusetts office located at 880\nWinter Street, Suite 110, Waltham, MA 02451.\nPosition responsible for the following:\nDesigns, develops, and programs methods, processes, and systems to\nconsolidate and analyze unstructured, diverse big data sources to generate\nactionable insights and solutions for client services and product enhancement.\nInteracts with product and service teams to identify questions and issues for\ndata analysis and experiments. Develops and codes software programs, algorithms\nand automated processes to cleanse, integrate, and evaluate large datasets from\nmultiple disparate sources. Identifies meaningful insights from large data and\nmetadata sources; interprets and communicates insights and findings from\nanalysis and experiments to product, service, and business managers. Job Responsibilities: Develops predictive models for customers\nutilizing a variety of statistical and machine learning algorithms. Holds\nresponsibility for projects of a moderate degree of complexity. Executes all\nstages of model development and delivery including data definition, sampling,\npreprocessing, feature selection, model generation, and validation and support\nor production model release. Validates and prepares data for model development,\nperforms exploratory data analysis and data cleaning on large datasets and\nqueries and visualizes data with a variety of tools. Works with a team of\nscientists and engineers responsible for the development and deployment of the\nstate-of-the-art predictive models for a variety of financial applications.\nThis includes the design, development, and deployment of statistical predictive\nmodels. Understand and adhere to all corporate policies to include but not\nlimited to ACI Worldwide Code of Ethics and Global Information Security.\nPerform other duties as assigned.\n\nMINIMUM REQUIREMENTS: Bachelor\u2019s Degree (foreign\nequivalent accepted) in Bioinformatics, Computer Science, Electrical\nEngineering, Applied Statistical Mathematics, Physics, Computational Chemistry\nor related field plus 3 years\u2019 experience in the specialty or an IT-related\noccupation. Experience must include 3\nyears\u2019 experience with Predictive Modelling and Data Analysis (Hadoop, Pig,\nHive, SQL, and Oracle); 3 years\u2019 experience with ETL Procedures and Tools\n(Oracle Di, Sqoop, and SSIS); 3 years\u2019 experience with Business Analytics\n(HADOOP, Hive, and Oracle); 3 years\u2019 experience with Data Modelling (Hive and\nPig); and 2 years\u2019 experience with developing standards and best practices.\n\n*Current employees eligible\nfor referral bonus as per company policy with regard to this position.\nApply online at www.aciworldwide.com; AutoReqID 19003066.\n\nACI Worldwide is an AA/EEO\nemployer in the United States, which includes providing equal opportunity for\nprotected veterans and individuals with disabilities, and an EEO employer\nglobally.\n\nVEVRAA Federal Contractor\n\nRequest Priority Protected Veteran Referrals\nEOE \u2013 Veteran/Disabled/Minority/AA/F/M/SO\n#LI-DNI\nApply Now: click Apply Now"}, "207": {"company": "Expedition Technology, Inc.", "description": "Machine Learning Engineer\n\nUS Citizenship is required due to security clearance requirements.\n\nAre you a motivated engineer who is passionate about embracing new challenges and solving the hardest technical problems in a team-oriented environment? Every day, the engineers at Expedition Technology work together to solve our Nation's defense and intelligence challenges by using Machine Learning and Deep Learning to demystify data obtained from signals and images.\n\nOur applied research and development mindset afford our people the opportunity to work on the most cutting-edge methods of optimizing deep learning networks, developing state-of-the-art algorithms and ultimately producing software products that are critical to our nation's defense infrastructure.\n\nThe success we have already achieved has made Expedition Technology one of the top Machine Learning/Deep Learning research organizations in the Defense and Intelligence communities and we need additional intelligent, passionate, creative people to join our team.\n\nWhen you join our team, you'll have the opportunity to:\nDive directly into the latest computer vision and signal processing research to replicate new techniques published in academia and find ways to make those ideas work on a larger scale\nUse your strong Python coding skills to research, design, develop and expand upon algorithms that will train neural networks to deliver actionable intelligence faster and more effectively\nDevelop deep-learning software prototypes that demonstrate potential usefulness to our customers\nAnalyze data from disparate sources including images, video, radar, signals and more\nBrainstorm solutions to the toughest problems alongside a team of smart, creative, passionate engineers\nParticipate in machine learning brownbag sessions and other forms of collaborative learning to keep abreast of the constant changes in Machine and Deep Learning\nRequired skills:\nStrong problem-solving skills combined with deep intellectual curiosity and the desire to push technical boundaries\nStrong coding skills- preferably in Python, C/C++, Julia or other object-oriented language in a Linux environment\nSoftware development skills and the desire to work on cutting edge development in a Cloud environment\nDeep understanding of data structures and algorithms\nKnowledge of computer vision and/or signal processing including techniques for classification and feature extraction\nExcellent oral, written, presentation and communication skills\nBachelor's degree in Computer Science, Computer Engineering, Electrical Engineering or related field. Advance degrees welcome\nUS Citizenship- Must be a US Citizen eligible to maintain a US Government security clearance\nDesired skills:\nExperience with deep learning frameworks like Tensorflow, PyTorch, Caffe or Keras\nAbout Expedition Technology\n\nAt Expedition Technology, we push the boundaries of what is possible every day. Our engineers work on the most challenging problems in Computer Vision, Digital Signal Processing and Software Engineering from a Machine Learning/Deep Learning perspective and collaborate to find the answers. We are a research-focused company whose mission it is to solve our customer's most pressing needs in a creative, novel manner.\n\nExpedition Technology offers self-directed, company-paid Medical, Dental and Vision benefits and the freedom to allow you to select which benefits matter most. We offer a 401k with a generous company match, a student loan repayment program, equity shares, paid holidays, paid time off and an education reimbursement allowance. Most importantly, we offer an environment where we are encouraged to push boundaries, take risks and enjoy the rewards.\n\nInterested in joining our team? Let's explore together.\n\nEXP is proud to be an Equal Opportunity Employer that believes a diverse range of talent creates an environment that fuels creativity and innovation. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, disability, national origin, genetic information or protected veteran status.\nStart your job application: click Easy Apply"}, "208": {"company": "Qualys", "description": "We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\n\nResponsibilities:\nDesigning and deploying deep learning algorithms and predictive models\nDevelop custom data models and algorithms to apply to data sets\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\nDevelop processes and tools to monitor and analyze model performance and data accuracy\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\nQualifications:\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\nAbility to drive a project and work both independently and in a team\nStart your job application: click Apply Now"}, "209": {"company": "MatrixCare", "description": "In this Lead Data Scientist role, you will be responsible for the design, development, implementation and delivery of the organization's Machine Learning Products, including the components required to support it and the integration with the corporate and business architecture and applications.\n\nAs our Lead Data Scientist, you will:\nOversee Machine Learning Projects across the company from end-to-end including marketing optimization and product innovation\nLead a team of Data Scientists, Data Administrators, and Data Engineers and collaborate with cross-functional teams to build products\nDevelop and use advanced software programs, algorithms, query techniques, models to solve complex business problems, and automate processes end-to-end\nProcess, filter and present large quantities (Terabytes) of data using Natural Language Process (NLP), Artificial Intelligence (AI), and Machine Learning (ML)\nDesigns and develops methods, processes, and systems to consolidate and analyze structured and unstructured, diverse sources including\"big data\" sources\nCoordinate with software developers and database developers to implement data architecture standards and practices. Help select the right technologies to maintain flexibility and deliver high business value and results\nDemonstrate up-to-date expertise in Machine Learning and apply to the development, execution, and improvement of action plans. Incorporate software and system architecture (e.g., infrastructure, network) into designs and standards.\nReview designs to ensure scalability and applicability\nImplementation of software best practices that lead to high-quality software related to test coverage, code reviews, and continuous integration and continuous delivery\nMaximize professional development, personal contribution, and performance of team.\nReview the work of others\nMentoring and training of software developers and database developers in areas pertaining to data\nMaintain knowledge of current domains and strategic roadmaps\nGood working knowledge of current application/system infrastructure\nEnsure alignment of solutions with business and IT goals/objectives\nSkills and Experience needed for this position:\nMS or PhD in Statistics, Data Science, Physics, Mathematics, or a similar quantitative field\nUnderstanding of healthcare data and healthcare opportunities\nA proven and successful track record of leading teams through the successful delivery of advanced machine learning and statistical modeling that positively impact business performance\nUnderstanding of probability and statistics, data science, machine learning, data management, and visualization technique\nExperience with leading development in programming languages commonly used for data analysis, including R, Python, and Web development, such as Python, JavaScript, CSS and HTML\nExperience with machine learning APIs and computational packages (TensorFlow, Theano, PyTorch, Keras, Scikit-Learn, NumPy, SciPy, Pandas, statsmodels)\nVery strong knowledge and experience with ETL tools, preferable SSIS\nVery strong knowledge and experience with SQL, preferably Transact SQL\nKnowledge and experience in DBMS performance and tuning\nOur ideal candidate may also have:\n10+ years of hands-on work experience in R, Python implementing statistical models and machine learning models (anomaly detection, classification, clustering, time series prediction, regression models, etc.)\n10+ years of experience with large scale computing systems like Hadoop, MapReduce, Spark, and/or similar systems preferred\nIT development experience with expertise with both transactional and data warehousing systems.\nProficient with AWS or Azure cloud computing environments.\nExperience leading technical projects and/or teams and a desire to be both a technical and people leader\nKnowledge and professional experience in data warehousing related infrastructure\nProficiency and experience with SQL relational databases, database concepts, dimensional modeling and database design.\nProficiency in MS Office (Word, Excel, PowerPoint, Outlook)\nProficiency with MS Visio\nHealthcare Industry experience\nWhy MatrixCare?Change the way technology is used to deliver healthcare. Build amazing products. Create ways to provide better care for the nation\u2019s aging population. Tackle complex questions to ensure optimal customer service. See your work improve healthcare each and every day.\n\nAbout MatrixCareMatrixCare, a wholly owned subsidiary of ResMed (NYSE, RMD, ASX: RMD), is the complete solution for growing organizations that need to successfully manage risk in care delivery outside of a hospital. Current and multi-time winner of the prestigious Best in KLAS for Long-Term Care Software award, MatrixCare solutions are trusted by more than 15,000 organizations across the spectrum of out-of-hospital care. ACOs, skilled nursing facilities, senior living organizations, life plan communities (CCRCs), and home care, home health and hospice organizations depend on MatrixCare to help them connect, collaborate and prosper as we migrate to a fee-for-value healthcare system. In addition to purpose-built EHR components for any long-term, post-acute care setting, MatrixCare also includes solutions to systematically increase clinical quality: Enterprise Analytics, robust Clinical Decision Support and the industry\u2019s first Care Coordination platform to create a true, person-centric, e-longitudinal health record and enable providers to efficiently manage the populations under their care. Visit www.matrixcare.com for more information. MatrixCare is a registered trademark of MatrixCare.\nApply Now: click Apply Now"}, "210": {"company": "Brighthouse Financial", "description": "Brighthouse Financial is on a mission to help people achieve financial security. As one of the largest providers of annuities and life insurance in the U.S., we specialize in products designed to help people protect what they\u2019ve earned and ensure it lasts. We are built on a foundation of experience and knowledge, which allows us to keep our promises and provide the value they deserve.\n\nAt Brighthouse Financial, we\u2019re fostering a culture where diverse backgrounds and experiences are celebrated, and different ideas are heard and respected. We believe that by creating an inclusive workplace, we\u2019re better able to attract and retain our talent, provide valuable solutions that meet the needs of our advisors and their clients, and deliver on our mission of helping more people achieve financial security. We\u2019re seeking passionate, high-performing team member to join us. Sound like you? Read on.\n\nHow This Role Contributes to Brighthouse Financial:\n\nData Scientists in Brighthouse Financial\u2019s Data Science organization work closely with cross-\u00adfunctional teams in marketing, distribution, actuarial, product and other functions, leveraging Brighthouse Financial\u2019s rich datasets to develop and deliver propensity models and data-\u00addriven insights, and ultimately drive Brighthouse Financial\u2019s top line growth. A successful candidate will be passionate about finding insights in data and using quantitative analysis to answer complex questions, with a collaborative and resourceful style.\n\nKey Responsibilities:\nConduct data analytics with the relevant programming / statistical package (such as R or Python) for large-scale problem solving\nWork independently and possesses exceptional technical ability.\nUnderstand complex business challenges, develop hypotheses, convert into the right analytical hypothesis, and communicate the results back to the partner teams with limited or no analytical background to drive the business strategy\nAnalyze internal / external, online / offline, and structured / unstructured data such as speech analytics, digital footprints, financial information, proprietary market research and secondary sources to identify insights\nCreate innovative solutions to business problems.\nPartner with other operational areas to identify opportunities for new projects.\nBuild strong working relationships and improve workflow and organizational issues.\nBuild complex advanced-level machine learning and advanced analytics models.\nHandle and resolve questions and issues referred by junior staff members.\nMay propose, evaluate and implement process improvements to increase efficiency and effectiveness.\nPerform other duties as required or assigned.\nEssential Business Experience and Technical Skills:\nDoctoral degree in a technical field and two plus years of related work experience, or a Master\u2019s degree in a technical field and at least 3-4 years of related work experience, or a Bachelor\u2019s degree in a technical field and at least 6-8 years of related work experience.\nSignificant professional experience required applying quantitative analysis and modeling to solving real-world business problems including experience in model validation, testing and deployment\nDemonstrated proficiency in Python/PySpark required\nDemonstrated ability to perform high quality work independently\nExcellent oral and written communication skills, including the ability to explain complicated quantitative concepts to non-\u00adtechnical stakeholders using effective story telling techniques and visualization\nAbility to translate business requirements into detailed analysis plans.\nAbility to prioritize requests to meet the most important and urgent business needs\nWorking knowledge of insurance industry is a plus\nPrior exposure to financial services or insurance industry preferred\nTravel:\n\nLess than 5%\nStart your job application: click Apply Now"}, "211": {"company": "Age of Learning", "description": "Company Overview:\nAge of Learning is a leading education technology innovator based in Glendale, California, with a talented team of 500+ individuals comprised of nationally-renowned educators, curriculum experts, designers, animators, engineers, and more. We develop engaging, effective digital learning technology and content to help children build a strong academic foundation for lifelong success.\n\nOur flagship product ABCmouse.com Early Learning Academy\u00ae is a comprehensive online curriculum and the #1 learning app and website for children ages 2 through 8. More than 20 million children worldwide have completed over 5 billion learning activities on ABCmouse. We recently launched Adventure Academy, the first educational massively multiplayer online (MMO) game, serving elementary and middle school children with thousands of learning activities in a fun and safe virtual world. Other programs include an immersive English language learning product for children in China; ReadingIQ, a world-class digital library with thousands of curated books; and a groundbreaking adaptive learning system that personalizes math instruction for every learner.\n\nWe are committed to helping all children succeed. Through our Education Access Initiatives, we make ABCmouse available at no cost to millions of children through schools, libraries, Head Start programs, and community centers\u2014including public housing authorities and after-school programs.\n\nAs we expand our global reach and increase the educational impact of our programs, we\u2019re looking for passionate, ambitious, and collaborative leaders to become a part of our growing team!\n\nSummary:\nAge of Learning is looking for a data scientist to work on our Mastery products that teach math and reading to elementary school children.\nIn this position, you will define and analyze data sets that enable the company to answer important product questions easily and effectively. You will work with questions from game designers, curriculum specialists, product owners, and learning analytics; translate analytical specifications, work with data engineers to produce data sets, and then mine them for insights. You will be directly responsible for mining data, cleaning it, creating reproducible visualizations, insights and inferences, and communicating them effectively.\nNote that this is an \u201con-site\u201d position\u2014you will be an integral part of the Mastery team, and will interface with product teams and executives, and you will be required to be located at the corporate campus.\nResponsibilities:\nWork closely with game designers, curriculum experts, and learning analysts to understand important product questions that can be answered by data. Be the go-to person for data questions for this product\nTranslate game design questions, usage questions, and learning science questions into meaningful insights, whether via A/B testing or reproducible dashboards\nWork with data engineers to design ideal data schemas and documentation\nHelp to build a reusable library of data schemas and reports that enable quick reproduction and reuse of analytical tools and ideas on other games and products\nWork closely with other analysts to share knowledge and build a repository of data analysis processes\nRequired Skills and Qualifications:\nDegree in Computer Science or a related field (statistics, economics, mathematics)\n3-5 years of experience in a data science role\nExperience in a statistical programming language (Python or R) for data cleaning, munging, analysis, and visualization\nDeep knowledge of the standard basket of machine learning algorithms (linear regression, logistic regression, random forests, regularization techniques, cross-validation) and proficiency with using machine learning algorithms in either Python or R\nStatistical fluency. You don\u2019t need to have a degree in statistics, but you should understand why ANOVA is really just linear regression and be comfortable with figuring out which goodness-of-fit tests make sense in a particular scenario\nExperience writing SQL queries and data transforms against large-scale column-oriented databases (Vertica, Redshift, Snowflake)\nStrong desire to explain what you\u2019ve learned from the data to the rest of the company using visualization frameworks including ggplot and (occasionally) Tableau dashboards\nA willingness to roll up your sleeves and do what it takes\nPreferred Skills and Qualifications:\nKnowledge of git and standard engineering processes (everything you do will be peer-reviewed and version-controlled in the company git)\nGood knowledge of classical statistics\nFamiliarity with adaptive educational technology and psychometric algorithms such as IRT (you will be creating and tuning algorithms for adaptive applications)\nExperience with standard metrics in gaming or in education\nFamiliarity with adaptive educational technology and psychometric algorithms such as IRT (you will be creating and tuning algorithms for adaptive applications)\nExperience in custom ETL design, implementation, and maintenance\nExperience with data quality frameworks and data validation and verification\nProficiency with Python and AWS Services (e.g. Lambdas, Redshift, and S3)\nProficiency with H2O and ggplot and other common R libraries; has created new R libraries before\nExperience with a Python data science framework such as scikit-learn\nExperience building reuseable dashboards and tools\nExperience writing SQL queries and data transforms against large-scale column-oriented databases (Vertica, Redshift, Snowflake, etcetera)\nIn-depth knowledge of how to write and optimize SQL statements\nKnowledge of Docker, and prior experience with using Docker containers (it\u2019s how we deploy adaptive layers in production)\nVideo game and educational gaming experience\nWe Provide:\nMedical, Dental, Vision + 401k\nHighly competitive PTO policy\nCasual Dress Code\nSnacks + Drinks (Coca Cola Freestyle Machine)\nGaming room including an Arcade (2,000+ games)\nFrequent team and company outings\nLimitless opportunities for professional growth!\n\nApply Now: click Apply Now"}, "212": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta has an immediate opportunity for Data Analysts/ Junior Data Scientist to provide support to a major federal client. This organization provides services that analyze and produce enhanced cyber security and threat intelligence information to include threats and potential threats to the customer's personnel, information, and information systems; provides timely and relevant intelligence to assist with mitigating cyber threats confronting the Department; supports evaluation, implementation, and operations of tools/technologies used in advanced data analysis.\n\nThe Data Analyst will support the customer's overall cyber threat analysis efforts. In addition, they will be responsible for applying advanced analytics and data science techniques, including statistical analysis, event correlation, anomaly detection, data visualization and dashboards, and predictive modeling in solving cyber security problems or helping others to automate their research and analysis.\n\nBasic Qualifications:\nBachelor's degree in computer science, information systems, cybersecurity, or other related technical discipline, plus 4 years of experience in technical data analysis with increasing responsibilities.\nAlternatively, a Master's degree with 1 year of experience.\nGood working knowledge of statistical data analysis techniques, including sampling, descriptive statistics, regression.\nExperience with data analysis tools and languages, such as SQL, SPSS, SAS, R, advanced Excel, or similar.\nExperience with data cleaning and preparation.\nExperience with visualization and dashboard techniques and tools, such as Power BI, Tableau, or similar.\nBasic understanding of supervised and unsupervised machine learning algorithms.\nKnowledge of computer networking concepts and protocols (e.g., Transmission Control Protocol [TCP] and Internet Protocol [IP], Open System Interconnection Model [OSI], Domain Name System [DNS]), and network security principles.\nKnowledge of cybersecurity and cyber defense principles (e.g. cyber threats and vulnerabilities, adversarial tactics, cyber attack stages).\nHighly self-motivated and capable of completing ad hoc and time-sensitive assignments.\nStrong analytical skills and the ability to effectively research, write, communicate and brief to varying levels of audiences to include at the executive level.\nDesired Skills:\nTwo years of experience in intelligence or technical analysis with a focus on cyber threat analysis and threat modeling, to include preparing and presenting results.\nExperience analyzing data sets from real-world problems.\nSoftware development experience in Python/Pandas/Scikit-learn, experience with Rapidminer or similar tools.\nExperience in natural language processing.\nExperience in Splunk or similar log storage/retrieval systems.\nPrevious experience working within cross functional and interdisciplinary project teams.\nProven experience effectively prioritizing workload to meet deadlines and work objectives\nSecurity Clearance:\nActive Secret clearance or ability to obtain a Secret clearance\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nStart your job application: click Apply Now"}, "213": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking a Data Scientist who wants to develop innovative solutions for customers and internal product teams. We look to rapidly prototype solutions and deploy the most promising of them. We identify and leverage the latest techniques (fast.ai is a team favorite) so that our customers can stay one step ahead. On every project you'll learn something new (and likely teach us something as well). If that sounds appealing to you - we'd love to chat.\n\nResponsibilities include:\nDevelop solutions spanning multiple subject areas, from NLP to Image and Video.\nMaintain awareness of state-of-the-art machine learning and techniques, methods and platforms, including commercial and open source.\nImplement, configure and test machine learning and deep learning libraries and platforms (e.g. fast.ai, TensorFlow, Keras, XGBoost, LightGBM).\nTest solutions on AWS using services such as SageMaker, EC2, and Snowball Edge.\nWrite blog posts and presentations that clearly communicate complex machine learning concepts to both technical and non-technical audiences.\nContribute to visually-appealing, web-enabled prototype applications that illustrate relevant machine learning capabilities.\nBasic Qualifications:\nExperience with Python\nExperience with machine learning or statistics\nAbility to work both independently and collaboratively.\nHigh levels of curiosity, creativity, and problem-solving capabilities.\nStrong written and verbal communication skills.\nComfortable navigating the command line.\nDesired Skills:\nResearch experience in Machine Learning specific to Natural Language Processing, Computer Vision, or deep learning.\nExperience with managing data and creating algorithms using AWS.\nExperience with R, Java, or other programming languages.\nSecurity Clearance:\nMust be eligible to obtain and maintain a TS/SCI with Poly clearance\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nTo apply to this job, click Apply Now"}, "214": {"company": "C3.ai", "description": "C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai\n\nAs a Data Scientist, you will participate in the definition of new analytics capabilities able to provide our customers with the information they need to make proper decisions to support our customers in operating the internet of things (IoT). In addition, you will help find the appropriate machine learning / data mining algorithms to answer these questions. Finally, you will be responsible for implementing this into the product and making it available to our customers.\n\nQualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve similar results at large-scale.\n\nYour Responsibilities:\nDriving adoption of Deep Learning systems into next-generation of C3.ai products.\nDesigning and deploying Machine Learning algorithms for industrial applications such as fraud detection and predictive maintenance.\nCollaborating with data and subject matter experts from C3.ai and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.\nRequirements:\nMS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields.\nApplied Machine Learning experience (regression and classification, supervised, and unsupervised learning).\nStrong mathematical background (linear algebra, calculus, probability and statistics).\nExperience with scalable ML (MapReduce, streaming).\nAbility to drive a project and work both independently and in a team.\nSmart, motivated, can do attitude, and seeks to make a difference.\nExcellent verbal and written communication.\nPreferred\nExperience with JavaScript and prototyping languages such as Python and R. Experience with Java and Scala is a plus.\nKnowledge in electrical engineering and cyber-physical systems is a plus.\nA portfolio of projects (GitHub, papers, etc.) is a plus.\nC3.ai provides a competitive compensation package and excellent benefits including:\nCompetitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people.\nC3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.\n\nStart your job application: click Apply Now"}, "215": {"company": "ADP", "description": "Position Description\n\nADP is hiring an experienced Data Scientist for the Implementation Automation Center of Excellence. Candidate should have relevant professional experience with document classification, entity recognition, and optical character recognition (OCR).\n\nTwo (2) years of experience must include:\nKnowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, Deep learning social network analysis, etc.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nKnowledge of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nExperience querying databases and using statistical computer languages: SQL, R, Python, TensorFlow, Scikit-learn etc\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience visualizing/presenting data for stakeholders using: Tableau, ggplot, etc.\nExcellent written and verbal communication skills for coordinating across teams.\nA drive to learn and master new technologies and techniques.\nEducation & Experience Requirements:\n\nMaster's or PHD in Statistics, Mathematics, Computer Science, predictive analytics or another quantitative field plus two (2) years of related experience\n\n#LITECH\n\nWe're designing a better way to work, so you can achieve what you're working for. Consistently named one of the 'Most Admired Companies' by FORTUNE\u00ae Magazine, and recognized by DiversityInc\u00ae as one of the 'Top 50 Companies for Diversity,' ADP works with more than 740,000 organizations across the globe to help their people work smarter, embrace new challenges, and unleash their talent. \"Always Designing for People\" means we're creating platforms that will transform how great work gets done, so together we can unlock a world of opportunity.\n\nAt ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.\nApply Now: click Apply Now"}, "216": {"company": "ADP", "description": "Principal Data Scientist\n\nLocation: 71 Hanover Road, Florham Park, NJ 07932\n\nPosition Summary:\n\nThe SBS Principal Data Scientist will be responsible for the design, planning and execution of major data science and analytics initiatives which span the enterprise and drive measurable business outcomes.\n\nTheir focus will on development, validation and business adoption of statistical and machine learning models to identify trends within structured, semi-structured and time-series data; all heavily leveraging our existing big data infrastructure, making use of leading edge analytical approaches.\n\nThis individual will be a senior member of the SBS Data Insight team, a highly collaborative team, which provides data science and deep analytics expertise to solve the most challenging business problems here at SBS ADP.\nUnlock Your Career Potential: Technology at ADP. Do you enjoy exploring, identifying and inspiring the future of the workplace and the lives of millions of people? At ADP, the world's largest B2B cloud company, our Technology team is comprised of brilliant engineers, architects, data scientists, infrastructure experts, and more. We were first in our industry to offer a SaaS solution and continue to push the envelope utilizing the latest operating platforms to deliver the highly automated, intelligent and predictive solutions that are redefining what is possible. Named one of Forbes' \"Most Innovative Companies\" and one of Computerworld's \"100 Best Places to Work in IT\", we are committed to leading the way in product development and research, empowering you to bring to life the latest innovations that will forever change the way businesses manage their most vital asset, employees.\n\nWe strive for every interaction to be driven by our CORE values: Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility.\nQualifications:\nEducation & Certification: An advanced degree in computer science or equivalent subject, PhD preferred.\nTrack record in designing and delivering useful, consumer-oriented big data and machine learning applications\nTrack record in top-tier publications (e.g., NIPS, ICML, T-PAMI, ACL, ICDM, AAAI, etc.)\nFoundational knowledge about statistics and computational probability.\nStrong foundational knowledge and experience with Machine Learning and Data Mining such as\nKernel machines, ensemble learning, deep learning, regularization theory\nActive and semi-supervised learning\nTransfer learning\nClustering\nFeature selection and dimension reduction\nStatistical analysis and hypothesis tests\nStrong knowledge and experience with NLP such as POS tagging, chunking, named entity recognition, parsing, sentiment analysis, topic detection, etc.\nStrong knowledge and experience with recommendation such as learning to rank, collaborative filter, etc.\nSolid knowledge on numeric computation and scientific optimization including linear programming, convex programming, dynamic programming, etc.\nExperience with OO and functional languages (e.g. Scala, Python, etc.)\nExperience with big data framework (e.g., Hadoop, Spark, etc.)\nExperience with scientific computing packages and machine/deep learning libraries (e.g., scikit-learn, tensorflow, pytorch, deeplearning4j, h2o.ai, spark ML, etc.)\nExperience with data visualizations\nExperience with NLP libraries (e.g., nltk, corenlp, etc.)\nEssential Duties and Responsibilities:\nDefine how analytics solution will be constructed: which existing will be integrated, how they will be integrated and what gaps in capability need to be filled.\nServes as design authority at a project level by understanding the business goals and technology constraints and designing appropriate solutions that create measurable impact to business.\nExtract, merge, clean and normalize large-scale data from disparate sources in preparation for exploratory data analysis, model building and validation -- within a big data environment.\nDevelop, validate ML classification, regression models using Python or similar in order to directly answer business needs, and to positively impact business operations.\nPrepare appropriate data visualizations and presentations to highlight findings and recommendations for both a technical and executive audience.\nPromote a unified approach leveraging existing data sets and efforts while also ensuring collaboration throughout the organization to ensure adoption and common standard approach\nEstablish credibility as a trusted advisor to key stakeholders across the enterprise in order to drive business actions and outcomes based on results of your analysis.\nApply good business and financial acumen to create and assess business cases.\nImplement appropriate mechanisms to track, measure the business impact of your work.\n\n________________\nreq 186040\n#LITECH\n</P>\n\nWe're designing a better way to work, so you can achieve what you're working for. Consistently named one of the 'Most Admired Companies' by FORTUNE\u00ae Magazine, and recognized by DiversityInc\u00ae as one of the 'Top 50 Companies for Diversity,' ADP works with more than 740,000 organizations across the globe to help their people work smarter, embrace new challenges, and unleash their talent. \"Always Designing for People\" means we're creating platforms that will transform how great work gets done, so together we can unlock a world of opportunity.\n\nAt ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.\nTo apply to this job, click Apply Now"}, "217": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking a Data Scientist (Senior)) in the role of the Maritime Safety Office.This position is to provide both digital and hardcopy maritime products, services, and data to support worldwide Safety of Navigation. Without accurate and up-to-date nautical products, military platforms are at increased risk when they conduct operations, transport personnel and deliver material. The U.S. Navy has made it clear to NGA that it will continue to require both digital and hard copy maritime products for the foreseeable future. Services procured under this contract will primarily support the production and maintenance of Maritime GEOINT at NCE facilities.\n\nResponsibilities include:\nStrong data management skills, including SQL, NoSQL (MongoDB), and triplestore/graph\ndatabases\nExperience createing and managing ETL processes using Ni-Fi or similar software using both\nstructured and unstructured data\nAWS experience, particularly with EC2, S3, Cloudwatch, RDS\nExperience with data visualization tools\nExperience with or working knowledge of ElasticSearch or similar\nPerform ad-hoc analysis and present results in a clear manner\nConduct undirected research and frame open-ended industry / customer questions\nRecommend cost-effective changes to existing procedures and strategies\nCreate / maintain tools to extract features from a variety of sources including raster to vector,\nvector to vector, text to vector, and text to database.\nWrite / maintain Python Scripts in ARCGIS to improve efficiency of the production process.\nSupport Business Processing Re-Engineering\nPerform Data Conversion/migration\nPerform Business Analytics\nWork with the Government on new production capabilities / services\nStrong data management skills, including SQL, NoSQL (MongoDB), and RDF\n(triplestore/graph) databases\nLinux experience\nBasic Qualifications:\nStrong data management skills, including SQL, NoSQL (MongoDB), and triplestore/graph databases\nExperience createing and managing ETL processes using Ni-Fi or similar software using both structured and\nunstructured data\nAWS experience, particularly with EC2, S3, Cloudwatch, RDS\nExperience with data visualization tools\nExperience with or working knowledge of ElasticSearch or similar\nPerform ad-hoc analysis and present results in a clear manner\nDesired Skills:\nExperience with combining digital cartography, computer technology, GIS, cartographic and geospatial\nproduction techniques, remote sensing, photogrammetry, and digital data formats.\nAbility to clean / prune data to discard irrelevant information\nAbility to examine data from a variety of angles to determine hidden value, weaknesses, trends, and / or\nopportunities\nAdvanced knowledge of ESRI ArcGIS and ArcServer.\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nApply Now: click Apply Now"}, "218": {"company": "Tradeweb Markets LLC", "description": "Working as a data scientist, you will be part of the Data Solutions and Analytics team within Market Data at Tradeweb. With live and extensive historical data across the Institutional, Wholesale, and Retail fixed income markets globally, you will have the unique opportunity to produce models to advance the fixed income marketplace. Working in partnership with platform business heads, product managers, and the market data team, you will develop models that will improve executions and generate ideas for our clients. Your models will produce live data both within our trading platforms as well as generate independent commercial data products. You are comfortable working in a results-driven environment and want to be part of an innovative team that is forging new ground and redefining the world of investment and trading in fixed income securities.\n\nJob Responsibilities:\nCreate predictive models using current and emerging methodologies in data science. Candidates will possess a deep understanding of statistics, machine learning, causal predictive modeling, and ideally optimization.\nCollaborate across the organization to drive projects from beginning to end: frame business questions, collect and analyze data, research, prototype, build pipelines, and share insights.\nWork with technology to ensure robust translation to production environments and create solutions that operate effectively live and at scale.\nQualifications\n7+ years of experience in applying statistical and machine learning techniques such as regression and classification models, cluster analysis, neural networks, ensembles, random forests.\nAdvanced degree (MS or PhD) in a quantitative field such as Statistics, Computer Science, Mathematics, Physics, Engineering, Economics, or similar.\nExpert programming skills for data analysis and machine learning. Experience using version control and general software development best practices for contributing to a collaborative code base.\nStrong communication and collaboration skills. Ability to communicate technical modeling concepts and relevant aspects of modeling platforms to non-technical audiences.\nWillingness to learn fixed income and improve across all technical skill areas.\nAbility to work in a start-up environment that is fast paced and maintain a focus on rapid prototyping of capabilities.\nDemonstrated leadership and self-direction.\nEnjoys teaching and collaborating with others.\nExperience using the python data science stack a plus, e.g. Pandas, Jupyter notebooks, scikit-learn, Tensorflow, Anaconda etc.\nAbout Tradeweb:\n\nTradeweb Markets Inc. (NASDAQ: TW) is a leading, global operator of electronic marketplaces for rates, credit, equities and money markets. Founded in 1996, Tradeweb provides access to markets, data and analytics, electronic trading, straight-through-processing and reporting for clients in the institutional, wholesale and retail markets. Advanced technologies developed by Tradeweb enhance price discovery, order execution and trade workflows while allowing for greater scale and helping to reduce risks in client trading operations. For more information, please go to www.tradeweb.com .\n\nTradeweb Markets LLC (\"Tradeweb\") is proud to be an EEO Minorities/Females/Protected Veterans/Disabled/Affirmative Action Employer.\n\nhttps://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf\nTo apply to this job, click Apply Now"}, "219": {"company": "PayScale", "description": "Company Description\n\nPayScale is the world leader in modern compensation software. We believe data-informed discussions about compensation benefit both employers and employees and that greater pay transparency promotes equity, engagement and employee retention. We are bringing the dark art of compensation into the light by helping individuals understand the right pay for their position and more than 7,000 businesses retain and manage their largest investment: their people.\n\nWe\u2019re transforming the compensation industry and are looking to bring on talented data professionals like you with diverse perspectives. At PayScale, we acknowledge and value our differences as well as our combined strengths. We want all employees, regardless of their background, to feel respected personally and professionally. We foster a working environment that generates new ideas, promotes ownership and experimentation, and encourages highly motivated individuals to be truly creative.\n\nJob Description\n\nDoes empowering a company to make data driven decisions excite you? We are looking for a Data Scientist to do just that. We are a small team working on high impact projects that drive innovation in our customer facing products and across the organization. The Data Science team partners closely with data engineers, product managers, and other external partners to design and develop the machine learning applications that power our compensation tools.\n\nIn this role you will focus on building and improving algorithms around salary prediction, record matching, recommendations/search, client retention, and lead scoring.\n\nWhat You'll Be Doing\nAcquire, clean, and process data with reliable, maintainable code\nContribute to the development of a robust understanding of compensation strategies for the company with in-depth exploratory analyses\nIdentify how to maximize the value of and improve our products with data by collaborating with Product, Sales, Marketing and other internal teams.\nIteratively design, code, train, test, deploy, and improve machine learning algorithms\nEvangelize your machine learning services with written and oral presentations.\nIf you enjoy seeing a project all the way from concept to production this is an excellent opportunity within a collaborative SaaS company.\n\nTechnologies We're Using\nPython (pandas, scikit-learn, NumPy, SpaCy), SQL, Elasticsearch, Tensorflow, Snowflake, Postgres, Spark, Azure, AWS, Git, and Docker\nQualifications\n\nWe'd love to hear from you if:\nYou have 4+ years experience building machine learning models/services\nYou are thoughtful in the evaluation of your models, improving them over time as they interact with real users\nYou have excellent coding skills, especially in Python or R\nYou care about the reliability and maintainability of your code.\nFamiliarity/experience with unit testing and crafting testable code.\nYou have a working understanding of database systems and experience writing SQL queries.\nYou have some experience with cloud providers (AWS, Azure, or Google Cloud).\nYou can effectively communicate and share results with both technical and non-technical partners.\nYou have the ability and desire to work with a team of people solving complex problems that often require independent research with minimal supervision.\nYou have strong critical thinking and communication skills.\nAdditional Information\n\nPayScale provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. PayScale complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\n\nBenefits:\nFlexible Paid Time Off policy\n100% company paid medical/vision/dental/prescription premiums for employees (50% for eligible dependents and partners)\nFour Flexible Spending Account (FSA) options for pre-tax employee allocations towards:\nMedical\nDependent Care (can be used towards day care costs!)\nParking\nTransit\nLong Term Disability, Short Term Disability, and Company-paid Life Insurance\nMaternity and Paternity Leave\n10 paid holidays!\nSummer Office Closure, entire week of July 4th\n401-k with company match, vests immediately\nCasual dress code\nOnsite lockers, showers, and clothes dryer\nBike storage\nCoworkers you actually like...\nGender neutral bathrooms on most floors\nMothers' Room\nSitting-Standing ergo friendly desks\nWeekly company sponsored happy hours\nWork from home Wednesdays\nFido Fridays (our canine colleagues join us the first Friday of every month. WOOF)\nTo apply to this job, click Apply Now"}, "220": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking an Senior Data Scientist who wants to develop innovative solutions for customers and internal product teams. We look to rapidly prototype solutions and deploy the most promising of them. We identify and leverage the latest techniques (fast.ai is a team favorite) so that our customers can stay one step ahead. On every project you'll learn something new (and likely teach us something as well). If that sounds appealing to you - we'd love to chat.\n\nResponsibilities include:\nDevelop solutions spanning multiple subject areas, from NLP to Image and Video.\nMaintain awareness of state-of-the-art machine learning and techniques, methods and platforms, including commercial and open source.\nImplement, configure and test machine learning and deep learning libraries and platforms (e.g. fast.ai, TensorFlow, Keras, XGBoost, LightGBM).\nTest solutions on AWS using services such as SageMaker, EC2, and Snowball Edge.\nWrite blog posts and presentations that clearly communicate complex machine learning concepts to both technical and non-technical audiences.\nContribute to visually-appealing, web-enabled prototype applications that illustrate relevant machine learning capabilities.\nBasic Qualifications:\nExperience with Python (2+ years).\nExperience with machine learning or statistics (2+ years).\nAbility to work both independently and collaboratively.\nHigh levels of curiosity, creativity, and problem-solving capabilities.\nStrong written and verbal communication skills.\nComfortable navigating the command line.\nDesired Skills:\nResearch experience in Machine Learning specific to Natural Language Processing, Computer Vision, or deep learning.\nExperience with managing data and creating algorithms using AWS.\nExperience with R, Java, or other programming languages.\nSecurity Clearance:\nActive TS/SCI with polygraph required.\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nApply Now: click Apply Now"}, "221": {"company": "Chan Zuckerberg Initiative", "description": "Founded by Dr. Priscilla Chan and Mark Zuckerberg in 2015, the Chan Zuckerberg Initiative (CZI) is a new kind of philanthropy that's leveraging technology to help solve some of the world's toughest challenges \u2013 from eradicating disease, to improving education, to reforming the criminal justice system. Across three core Initiative focus areas of Science, Education and Justice and Opportunity, we're pairing engineering with grantmaking, impact investing, policy work, and movement building, to help build an inclusive, just and healthy future for everyone.\n\nOur Values\n\n\nWe believe we can help build a future for everyone.\nWe aim to be daring, but humble: We look for bold ideas \u2014 regardless of structure and stage \u2014 and help them scale by pairing engineers with subject matter experts to build tools that accelerate the pace of social progress.\nWe want to learn fast, but build for the long-term: We want to iterate fast and help bring new solutions to the table, but we also realize that important breakthroughs often take decades, or even centuries.\nStay close to the real problems: We engage directly in the communities we serve because no one understands our society's challenges like those who live them every day.\nOur success is dependent on building teams that include people from different backgrounds and experiences who can challenge each other's assumptions with fresh perspectives. To that end, we look for a diverse pool of applicants including those from historically marginalized groups \u2014 women, people with disabilities, people of color, formerly incarcerated people, people who are lesbian, gay, bisexual, transgender, and/or gender nonconforming, first and second generation immigrants, veterans, and people from different socioeconomic backgrounds.\n\nThe Opportunity\n\n\nOur mission is to support science and technology that will help make it possible to cure, prevent, or manage all diseases by the end of the century. Interdisciplinary teams of physicians, biologists, computational scientists, and engineers can expand our understanding of the human body and illness \u2014 the very science behind medicine. CZI fosters collaboration between scientists and engineers, develops tools and technologies, and builds support for basic scientific research.\n\nThe ideal candidate will have a background in a quantitative or technical field and experience working with large data sets and making data-driven decisions. If you are mission-driven, entrepreneurial, and committed to building transformative technologies, we want to hear from you.\n\nMeta is a product that helps biomedical researchers discover literature that's important to their work and delivers it in real-time to their personal feeds. Meta uses artificial intelligence to organize and track over 67 million biomedical diseases, genes, proteins, techniques, researchers, journals, papers, preprints, and more\u2014including full coverage of PubMed and bioRxiv. We believe that the complexity and scale of scientific knowledge is limiting how quickly researchers can understand, navigate and quickly make powerful connections across what is know. This is one of the fundamental challenges hindering the rate of discovery in basic scientific research.\n\nAs Data Scientist for Meta, you'll be helping bring Meta to the broader community of researchers around the world. If you want to make a difference and help accelerate innovation in science, come and join us!\n\nYou will\nLeverage data to understand product, identify areas of opportunity, and execute projects to drive growth and engagement of science product users.\nDrive projects focusing on user retention, user engagement, product-market-fit and growth, and mobile usage - working closely with product, engineering, data, research, and leadership teams.\nExplore the feedback and data about the customer experience, develop metrics as-needed, and ensure prioritization is data-driven and accommodating of short-term and long-term strategies for incorporating into the end-to-end product development cycle.\nDerive deep (quantitative and qualitative) insights around product use, stability, and performance of the customer experience across a variety of touch-points and data sets.\nSupport product team with analysis to support decision making with reports and presentations.\nUse tools like Snowflake Computing, Mode Analytics, Adobe Marketing Cloud, Google Analytics, Python, R, ETL, Excel, and many other tools to work efficiently at scale.\nManage communication and alignment across multiple partner teams.\nPartner with engineering and design to implement changes in existing products that are impactful for the customer experience and ensure the measurement of the outcomes of new product features that will launch are high quality and risks are understood.\nInform, influence, and execute new quality strategies and tactics using sound analysis and impact metrics to support your positions.\nYou have\n4+ years work experience or equivalent within tech, finance, consulting or a related industry.\nExtensive quantitative or statistical analysis experience - building product intuition, solving problems using data, and providing practical business insight using data.\nAdvanced experience in analytics supporting marketing, advertising, or growth; communicating technical content and analytical insights to multiple audiences.\nAdvanced experience with SQL.\nAbility to process and analyze data sets, and interpret them to make business decisions.\nExcellent communication skills and ability to manage a project or product.\nTo apply to this job, click Apply Now"}, "222": {"company": "Driscoll's", "description": "About the Opportunity\nThe Sr. Data Scientist, Molecular Biology will be responsible for applying the tools of mathematics, computer science, and high performance computing to accelerate traditional plant breeding. This role will work together with a small creative team to design and conduct research. Responsibilities include discovery and application work including algorithm development, deployment, and database development. This role will also plan and assure completion of complex projects involving cross-functional teams, and will stay current with the newest bioinformatics techniques that would aid Driscoll\u2019s in accomplishing our mission.\nResponsibilities\n\n\nResearch:\nWork with the molecular biology team to develop algorithms that assist in the analysis of genetic and genomic data.\nApply open-source and custom algorithms to genetic and genomic data sets to aid in discovery of marker-trait associations.\nDevelop database systems capable of primary data storage and export for secondary analysis with other tools.\nFacilitate interaction with Driscoll's IT to maintain/enhance molecular databases and to secure primary data integrity.\nCollaboration/Communication:\nEstablish collaborative relationships with other researchers in the field through attendance of conferences and symposia.\nOccasional travel to locations in the European Union will be required.\nGeneral:\nFollow Company policies and practices while representing Driscoll\u2019s in an ethical and business-like manner in all interactions with employees, governmental agencies, growers, customers, etc.\nOther duties as assigned.\nCandidate Profile\nMaster\u2019s degree in Mathematics or Computer Science with 5+ years of work experience.\nProficiency in Java, C++, and PostgreSQL.\nStrong knowledge of Linux and bash shell scripting.\nExperience with high performance computing environments in Linux.\nExperience with routine Linux systems administration.\nExperience with R and Python or another scripting language is a plus.\nKnowledge of genetics and genomics.\nExperience in the analysis of whole genome sequence data or genotyping by sequencing data is highly desired.\nExperience in bioinformatics.\nExperience planning complex projects involving cross-functional or interdisciplinary teams.\nIndividual must possess the ability to develop strong trust in all working relationships.\nDemonstrated ability to successfully work in a cross-functional team environment.\nExcellent communication skills, including written, verbal, and presentation.\nSome travel will be required.\nA California driver\u2019s license and the ability to be covered under company-sponsored vehicle insurance program are also required.\nPassport and the ability to travel internationally without restrictions is also required.\n</br>Driscoll's\nTo apply to this job, click Apply Now"}, "223": {"company": "Riverside Research Institute", "description": "Returning Candidate? Log back in to the Career Portal and click on 'Job Browsing/History' and find the job you're looking for.\n\n2019-132-INT: Data Scientist\n\nDirectorate Intelligence & Defense Solutions\nLocation Wright-Patterson AFB, OH\nRiverside Research\u2019s Intelligence and Defense Solutions (IDS) directorate is seeking a Data Scientist to support the National Air and Space Intelligence Center (NASIC) at Wright Patterson AFB, OH. Responsibilities will include prototyping applications and implementing processes to extract knowledge or insights from both structured and unstructured data. Candidates must be technically proficient and have real-word experience devising and implementing practical and sustainable solutions. You will be working with a team of Riverside Research, government, and contractor personnel supporting artificial intelligence/machine learning (AI/ML) projects. The work is in support of both US Air Force and Intelligence Community programs.\n\nAll Riverside Research opportunities require U.S. citizenship.\n\nJob Responsibilities:\n\u2022 Assess customer systems and processes for application of data science techniques and processes to support their needs\n\u2022 Assist with implementation of AI/ML initiatives through preparing, analyzing, and visualizing structured, semi-structured, and unstructured data\n\u2022 Develop and conduct algorithm quality trade studies, identifying best case uses and characterizing performance\n\u2022 Refine the verification and validation process for analytics\n\u2022 Enhance existing models to leverage analytic output for driving automated tasking\n\u2022 Develop scripts for running and testing algorithms and analytics using a variety of programs\n\u2022 Develop machine learning, data mining, statistical, and graph-based algorithms to analyze and make sense of data sets\n\u2022 Prototype/consider several algorithms and decide upon final model based on suitable performance metrics\n\u2022 Generate reports and visualizations that summarize data sets and provide data driven insights to customers\n\u2022 Other duties as assigned\n\nQualifications:\n\u2022 Bachelors degree in a technical domain plus 5 years of experience related to the job description above; an additional 4 years of experience (for a total of 9 years) related to the job duties listed above can be substituted in lieu of a Bachelors degree\n\u2022 Minimum of 5 years\u2019 experience in data science or related field\n\u2022 Demonstrated proficiency in data analysis, modeling, and visualization\n\u2022 Proficiency with programs used for data analytics such as R or Python\n\u2022 Strong communication, organizational, and analytical skills\n\u2022 Current Top Secret clearance with SCI adjudication\n\u2022 Self-motivated, independent, detail oriented, responsible team player\n\nDesired Qualifications:\n\u2022 Doctorate degree in applied statistics, applied mathematics, computer science or related technical field with specialization in data science\n\u2022 Agile software development experience/certifications\n\u2022 Technical project management and oversight experience\n\u2022 Experience working with or in support of Department of Defense (DoD) or intelligence community (IC) organizations\n\nRiverside Research strives to be one of America\u2019s premier providers of independent, trusted technical and scientific expertise. As we continue to add experienced, technically astute staff, we are looking for highly motivated, talented team members that can help our DoD and Intelligence Community (IC) customers continue delivery of world class programs. As a not-for-profit, technology-oriented Defense Company, we believe service to customers and support of our staff is our mission. Our goal is to serve as a destination company by providing an industry-leading, positive, and rewarding employee experience for all who join us. We aspire to be a valued partner to our customers and to earn their trust through our unwavering commitment to achieve timely, innovative, cost-effective and mission-focused solutions.\n\nAll positions at Riverside Research are subject to background investigations. Employment is contingent upon successful completion of a background investigation including criminal history and identity check.\n\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability, and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.\n\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans, and requires affirmative action by covered contractors and subcontractors to employ and advance in employment qualified protected veterans.\n\nApply Now\nApply Now: click Apply Now"}, "224": {"company": "PayPal", "description": "Minimum Qualifications:\nBS/BA degree in related field required or equivalent professional work-related experience.\n3+ years related professional experience or masters degree and 1+ year.\nExperience in online fraud or consumer risk management preferred\nResponsibilities:\nWorks on assignments that are of intermediate complexity with multiple steps in execution, and guided by generally defined processes and project requirements\nFocuses primarily on completing short-term goals of a project efficiently and effectively\nPartner with Risk Analysts and provide exceptional global solutions\nFocuses primarily on how to achieve overall analytic objectives of a project with speed and quality\nSuggests ideas for operational plans and objectives\nIdentify glitches in processes and tools and develop and execute solutions to overcome general issues and obstacles with little supervision.\nLearning in-depth analysis of alternatives and applying specialized knowledge\nSeeks improvement within defined tasks. Understands, evaluates, and executes improvement ideas from managers, stakeholders and partners\nRequirements:\nHigh proficiency in fundamental technical skills (Programming language like Java/C/C++; scripting language like Perl/Python; strong UNIX background; working knowledge of Hadoop, Map-Reduce, Hive, Pig, R; data warehouse skills)\nHas working knowledge analytic tools, processes, and methodologies to achieve the expected results with minimum supervision\nHas a good understanding of Risk business trends and directions to be able to put own work in the broad business context\nData driven, and results oriented with positive outlook\nDemonstrates effective verbal and written communication skills on a defined set of technical topics. Articulately expresses technical ideas and appropriately requests clarification when questions arise. Asks open-ended questions\nInterfaces primarily with own team to get own job done or cross-functional teams when needed.\nBe transparent and accountable\nBe data-driven and outcome-focused\nPersevere but know when to change course\nStart your job application: click Apply Now"}, "225": {"company": "Covenant Eyes", "description": "Data Science plays a crucial role within our organization. If you are actively seeking opportunities within the Data Sciences field, we would love to hear from you!\n\nThe Data Scientist is responsible for researching, designing, and building software solutions to data-rich problems using data science techniques; including machine learning. This includes identifying business trends and problems through complex big data analysis as well as interpreting results from multiple sources using a variety of techniques. These techniques can range from simple data aggregation via statistical analysis to complex data mining independently.\n\nExperience we look for in a Data Scientist:\n\n\u00b7 Advanced degree in data science or machine learning fields, or equivalent experience\n\n\u00b7 Several years of hands on experience processing and analyzing big data\n\n\u00b7 Proven ability to discover problems and produce algorithmic solutions\n\n\u00b7 Experience working with machine learning for image recognition and related technologies preferred\n\nPlease feel free to submit your cover letter and resume for review.\nStart your job application: click Apply Now"}, "226": {"company": "Silicon Valley Bank", "description": "Silicon Valley Bank is the market\nleader in providing financial solutions to the world\u2019s most innovative\ncompanies, leaders and investors. Our clients are the game changers\nfueling the global innovation economy and transforming the way we live and\nwork. SVB has been an incredible growth story over the last 30 years and\ncontinues to grow and expand internationally. Come join a\ngrowing, global commercial bank at the heart of the innovation economy where\nyou will be able to help bring our clients\u2019 world-changing ideas to life.\n\nThe Enterprise Business Analytics\ngroup at SVB is responsible for providing analytical business solutions to the\nbank. We translate data into actionable analytical solutions and promote\ninformation-based decision making to support SVB's strategic goals. One\nresponsibility of the group is to create an insight foundation that is\nleveraged to develop analytical solutions and predictive modeling. In order to\ndesign and create information foundation, data scientists identify and explore\nrelevant data sources; then create business understanding of the data by\napplying data mining techniques.\n\nThe Data scientist in this role will\nbe responsible for complex data transformations and data mining efforts.\nThey will build processes for the team to be able to use insights effectively\nand efficiently.\nResponsible\nfor end to end Cards insight creation, support in Card campaign,\ndeveloping & building card related insights\nResponsible\nfor managing/maintaining Card programs i.e. Card Opportunities, Portfolio\nmanagement, Value at risk, Card Explorer, Spend program etc.\nData\nmining and developing relevant data transformation logic\nDesigning\nprocesses to integrate data from multiple sources to facilitate client\ncentric advanced analytics\nUnderstand\nand connect the dots to different aspects of Card program.\nBuild,\ndesign, and develop the insights for decision making as well as building/assisting\nthe dashboards design for Business Users.\nResponsible\nfor identifying and exploring all relevant data sources, generate the\nunderstanding, develop the logic to transforms into insights that can be\nleveraged into decision making and other needs.\nDocumenting\ndata transformation logic\nDeveloping\nefficient, scalable and repeatable processes to transform data on regular\nbasis\nCommunicating\nwith IT partners to share selected transformation processes by\nfacilitating and reviewing business requirements\nDesign,\nbuild, develop and maintain the Analytical solutions to understand Card\nClients behavior.\nDevelop\nanalytical solutions to recommend Card product team to produce meaningful\nresults.\nPartnering\nwith other data scientists/business analysts to make them familiar with\nthe transformed information so that it can be appropriately used by other\nanalysts and statisticians\nManaging\nprocesses designed and developed by the information foundation team\nUsing\nbest practices framework to ensure data quality and reconciliation checks\nare in place and are transparent to our users\nLeveraging\ncommunication skills to collaborate effectively with analysts across SVB\nEvaluating\neffectiveness of the transformation process and delivered information by\nworking with users of information\nPartnering\nwith business groups to understand the Business case/Use case to\ndevelop/design best-in-class analytical solution(s).\nAbility\nto research external insights and blend with internal insights to create\nand understanding of the market place (Clients/Prospects).\n#LI-MS1\nSolid\nunderstanding of writing and understanding of complex SQL queries\nExtensive\nknowledge and experience in Oracle SQL, PLSQL, and SAS tools/techniques\nDemonstrated\nexperience with the data mining tools SAS/Anaconda and SQL preferably\nthrough Oracle PL/SQL.\nStrong\nbackground in SAS programming and SQL coding is preferred\nExperience\ntransform business specifications and requirements into well documented\nand scripted SQL, PL/SQL processes.\nAbility\nto develop and enhance complex PL/SQL scripts, queries, and stored\nprocedures and ETL processes\nProven\nDocumentation (technical and user documentation) and Verbal and written\nCommunication skills\nGood\nunderstanding of BI Methodologies and Practice\nExperience\nwith systems integration, building system models by combining model\ncomponents and testing the integrity of modeling systems, proficient with\nmodel and systems implementation testing\nKnowledge\nof Data Governance and DQ framework is a plus\nBackground\nin data management in Banking/Finance industry is preferred\nExperience\nwith ETL and data modeling tools is a plus\nStrong\nanalytical and problem solving skills\nDemonstrated\nability to self-manage and multitask in a dynamic, ever-changing environment\nEffective\ntime management and organizational skills\nFlexibility\nto work/manage variety of projects\nBachelor/Masters\nin Computer Science, Finance, Accounting, Economics, Statistics or\noperational research\nWorking\nknowledge with Tableau is a plus\n6\nyears of experience in analytics and/or business intelligence space\nStart your job application: click Apply Now"}, "227": {"company": "Northwest FCU", "description": "The Senior Data Intelligence Specialist operates as a member of the Data Operations Team. Supports the entire Credit Union\u2019s analysis and data needs. The successful candidate will take ownership of understanding the organizations strategic business needs, running analysis and providing highly effective feedback information for the entire Credit Union. They will have a strong understanding of the data, and a high level of understanding of the Credit Union\u2019s needs to be able to provide information for decision making at all levels.\n\nDUTIES& RESPONSIBILITIES:\nCollaborate with stakeholders throughout the organization to identify opportunities for leveraging data to drive business solutions\nResearching, designing, implementing, and deploying scalable data analytics vision and machine learning solutions to challenge various business issues\nMine and analyze data to drive optimization and improvement of product development, marketing techniques and business strategies\nCommunicate results of analysis and ideas to key decision makers\nUnderstand the Credit Union\u2019s strategic goals to be able to provide analysis based on data exploration\nHelp the Credit Union to evolve into an analytical and data driven culture\nWork closely with other team members to develop standards, promote efficiency, and prioritize the work load\nPreform Analysis using Python and R\nDevelop reports and dashboards using the Credit Union\u2019s BI Tools\nDevelop SQL Queries for reports and dashboards\nAnalyzing relational and transactional databases to provide data analysis\nCreate documentation around processes and procedures and manage code reviews\nApply industry standards best practices to development activities\nWork in an agile environment (methodology)\nWork with data team to ensure solutions are successfully executed, within agreed upon time frames\nMentor Junior Team Members to provide expertise on statistical and mathematical concepts\nRemain current on research techniques and become familiar with state of the art tools applicable to your function\nREQUIREMENTS:\n5 - 8 years of experience manipulating data sets and building statistical models\nBachelor\u2019s degree in Analytics, Economics, Finance, Mathematics or related field\nExperience using statistical computer languages (R, Python, SAS etc.) to manipulate data and draw insights from large data sets\nSubject matter expertise in data modeling\nStrategic thinking and analytical capability\nAbility to translate complex technical topics into business solutions and strategies\nExperience working with natural language processing and machine learning libraries\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, etc.\nA drive to learn and master new technologies and techniques\nAble to understand various data structures and common methods in data transformation\nExperience writing SQL, preferably in SQL Server or Hive (Hadoop)\nExperience with a BI analysis and reporting tools, preferably IBM Cognos Analytics or Tableau\nExceptional analytical, problem solving, and time management skills required Strong attention to detail\nHighly proficient in Microsoft Office and expert level understanding of Excel\nExcellent quantitative and qualitative analysis skills\nAbility to handle multiple projects with tight deadlines and adaptable to changing priorities\nAbility to work both independently and within a team environment, to build good working relationships and effectively manage multiple tasks\nExcellent interpersonal and communication skills, oral and written\nAdvance knowledge of Financial Institutions and Systems\nExperience with Hadoop Ecosystem and Pentaho\nApply Now: click Apply Now"}, "228": {"company": "Dematic", "description": "Company Overview\n\n\nDematic is a leading supplier of integrated automated technology, software and services to optimize the supply chain. Dematic employs over 7,000 skilled logistics professionals to serve its customers globally, with engineering centers and manufacturing facilities located around the world. Dematic is one brand under the KION Group of companies and has implemented more than 6,000 integrated systems for a customer base that includes small, medium and large companies doing business in a variety of market sectors.\n\nHeadquartered in Atlanta, Georgia, Dematic is a member of KION Group, a global leader in industrial trucks, related services and supply chain solutions. Across more than 100 countries worldwide, the KION Group designs, builds and supports logistics solutions that optimize material and information flow within factories, warehouses and distribution centers. The company is the largest manufacturer of industrial trucks in Europe, the second-largest producer of forklifts globally and a leading provider of warehouse automation.\n\nThe Role\n\n\nPosition Summary:\n\nThis is an exciting opportunity to join the Software Center of Excellence of Dematic. As part of this global team of software experts, you will help develop robust organizational capabilities in sales, design, engineering and support to deliver exceptional software to our customers.\n\nAs a specialist, you will own end-to-end implementation of analytics & IoT engagements with Dematic customers, while driving the services pipeline as well as be a key voice internally for the further development of the analytics services program. This is both a cross-functional role within the organization as well as a key customer interfacing role. A successful candidate will have demonstrated exceptional performance, innovation, creativity and insight in a similar role.\n\nKey Responsibilities (Problem Solving, Critical Thinking):\nWorks with customer end-users to define analytics & IoT solution requirements and works with internal team to concept, design and deliver solution\nWorks independently, within teams, and with multiple types of skillsets (business, data architect, other technical resources)\nPerforms business process analysis, mapping and design\nEnsures high quality delivery of software consulting services and overall client satisfaction\nDrives development and documentation of services\nDisplays depth of knowledge to customers during sales-phase while representing breadth and depth of Dematic solutions and expertise\nSupports the sales organization and drive pipeline generation of analytics consulting services\nWhat We Are Looking For\n\n\nEducation:\n\nBachelor's Degree and/or advanced degree\n\nKnowledge / Qualifications:\n\nThe qualifications for the position of advanced analytics & IoT include proven success in Client Management, Project Management, and Consultative Selling and Services Delivery. Other important areas of experience and skills include:\nExperience working with business users to concept, generate and deliver analytics solutions, dashboards and reporting\nOverall knowledge of MHE technologies and warehouse systems or similar domains is preferred\nSpecific domain experience and knowledge in the logistics and supply chain industries is a plus\nExcellent written and verbal communication skills including presentation skills and knowledge of software tools (MS PowerPoint, MS Visio)\nStrong leadership and customer engagement skills\nA willingness to travel in order to satisfy client needs\nExperience conducting requirements analysis, meeting with business stakeholders and applying solutions to customer challenges\nWorking knowledge of advanced analytic tools such as SAS, R, or Python is required\nWorking knowledge of data visualization tools such as Tableau, QlikView, or Domo is required\nWorking knowledge of BI (business intelligence) or analytics tools preferred\nWorking knowledge of Microsoft SQL Server and/or Oracle databases is preferred\nWorking knowledge of cloud based technologies is preferred\nAt least 3 years of experience in a related role\nApply Now: click Apply Now"}, "229": {"company": "Maxar Technologies", "description": "Why us?\nWe build advanced algorithms to gain analytic insights from a large range of open source and government data.\nWe enable machine learning systems, automate workflow, and design and develop custom applications for unique national-security mission.\nWe operate an end-to-end predictive analytic platform unlike any other within the US Government.\nWe provide training to expand your skills and challenges to develop them.\nOur clients missions are vital to national security, so were mission-first always.\nOur work environment is relaxed business casual.\nAt our core we believe and practice social responsibility.\n\nWhat would you be doing?\nExtracting and transforming data using programming languages such as Java and Python and associated open source data analytics libraries\nAscertaining unique ways to apply algorithms to derive specific customer data analytic results\nApplying big data analytics tools to large, diverse sets of collection data to assess risk of adverse threat activities\nExtending existing algorithms as required to support customer requirements\nApplying data science methods to create and data feeds to generate models that perform predictive analytics using a variety of approaches (such are natural language processing, association rule mining, etc.)\n\nMinimum Qualifications:\nMust have a current/active TS/SCI and be willing and able to obtain a CI Polygraph\nRequires 5 or more years of relevant experience\nRequires a Bachelor's degree in Engineering, Math, Physics, Computer Science or related field.\nExperience in at least one of these languages: R, VBA, Java, C++, SQL, Python\nDevelopment experience in a Linux/Unix/Windows environment\nOccasional local travel to government sites for customer meetings and demonstrations\nExperience conducting model feasibility research and algorithm development for machine learning\nExperience with distributed datasets and experience analyzing both relational and NoSQL data structures\nExperience working in an Agile environment,\nExperience developing and testing models\nExperience with Data Analytics\n\nDesired Skills:\nGraduate experience working with probabilistic and stochastic statistical analysis or computational intelligence\nAscertaining unique ways to apply algorithms to derive specific customer specific data analytics results\nApplying big data analytics tools to large, diverse sets of collection data to assess risk of adverse threat activities\nExtending existing algorithms as required to support customer requirements\nKnowledge of technical aspects of ISR systems\nExtracting and transforming data using programming languages such as Java and Python andassociatedopensourcedata analytics libraries\nExceptional oral and written communications\nOrganizational skills and excellent attention to detail\nCapability to work effectively in a geographically distributed development team\nTo apply to this job, click Apply Now"}, "230": {"company": "PayPal", "description": "What does Success Look Like?\n\n\nIn your role as a Senior Data-Scientist, you will:\nWork with partners to translate business challenges into Data Science problems\nMine data and extract information in PayPals Big (!) Data environment\nLeverage Machine Learning algorithms to solve real-life problems\nWork with engineers and product managers to develop and deliver E2E data science driven solutions that bring real business value\nAnalyze various kinds of data to conclude actionable insights\nCarry out independent research and innovation in new content and technological domains, while supporting existing projects\nAbout You\nMasters, PhD, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.)\nProduct/Marketing data science work experience an advantage\nCode writing capability in any programming language (Python, R, Java, Scala, etc.) and familiarity with relevant ML packages\nHadoop experience (PIG, Hive, Spark)\nStrong analytical skills\nExcellent spoken and written English\nTeam worker, responsible, delivery-oriented\nStart your job application: click Apply Now"}, "231": {"company": "PayPal", "description": "Responsibilities:\n\nRisk Analytic Data Scientists are highly motivated team players who specialize in the investigation of fraud patterns and the creation of advanced proprietary fraud prevention components. Our researchers overcome challenges presented by big data, evolving fraud techniques and new payment technologies by leveraging domain expertise, story-based analytics and advanced mining algorithms. They lead the research and accompany the development of advanced components which help drive PayPal's competitive edge by providing accurate, split-second decision making capabilities in a high-risk environment.\n\nThe ideal candidates are problem solvers, equipped with strong analytical & quantitative skills suited to approach various kinds of challenges in complex environments. Adept at creative and critical thinking, they are able to deconstruct problems and transform personal insights into large scale, state-of-the-art solutions. Candidates must be quick learners with a strong sense of personal responsibility and a technical orientation.\n\nRequirements:\nBachelors Degree in Mathematics, Physics, Computer Science, Statistics, Engineering or similar.\nStrong analytical skills\nCode writing capability in any programming language (Python, R, Java, etc.)\n1-2 years related work experience\nExperience in Machine-Learning, Data Mining or Statistics an advantage\nHadoop experience (MapReduce, PIG, Hive, Spark) an advantage\nQuick-thinker, fast learner, wide general knowledge, problem solver\nTeam worker, responsible, delivery-oriented\nApply Now: click Apply Now"}, "232": {"company": "Alignment Healthcare", "description": "Data Scientist:\n\nAlignment Healthcare is a data and technology driven healthcare company focused partnering with health systems, health plans and provider groups to provide care delivery that is preventive, convenient, coordinated, and that results in improved clinical outcomes for seniors.\n\nWe are experiencing rapid growth (backed by top private equity firms), our Data Science team is looking for the best and brightest data scientists. Data drives the way we make decisions. We love our customers and understanding them better makes it possible to provide the best clinical outcome and care experience.\n\nThis position will play a key role in uncovering deep insights from data using advanced machine learning technologies and advanced statistical analysis, processing very large data sets using cloud-based data pipelines, variety of analytic tools, visualizations and delivering actionable healthcare insights & solutions.\n\nProblems you will work on every day will include:\nCollaborate with key business leaders to understand their business problems and come up with analytical solutions.\nBuild end-to-end data science solutions which will improve healthcare outcomes and reduce the cost for our members.\nDevelop conversational AI solutions to improve healthcare experience of our members.\nBuild customer segmentation models to better understand our customers, and tailor the clinical outcome and healthcare care experience for them.\nDevelop scalable and efficient modeling algorithms that can work in production systems.\nCollaborate with the engineering team to build end-to-end cloud based machine learning production pipelines.\nDesign and implement online experiments and experimental frameworks\nBasic Qualifications:\nMasters in Computer Science, Engineering, Mathematics, Statistics, or related field\n2+ years relevant experience in predictive modeling and analysis.\nExcellent communication, analytical and collaborative problem-solving skills\nExperience in building end to end data science solutions and applying machine learning methods to real world problems with measurable outcomes.\nDeep understanding and experience with various machine learning algorithms, including deep neural networks, natural language processing, kernel methods, dimensionality reduction, ensemble methods, HMM and graph algorithms.\nSolid data structures & algorithms background.\nStrong programming skills in one of the following: Python, Java, R, Scala or C++\nDemonstrated proficiency in SQL and relational databases.\nExperience with data visualization and presentation, turning complex analysis into insight.\nExperience in setting experimental analytics frameworks or strategies for complex scenarios.\nUnderstanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc.\nExperience with manipulating and analyzing complex, high-volume, high-dimensionality and unstructured data from varying sources\nPreferred Qualifications:\nPhD in Computer Science or related field\nHealthcare experience\nExperience in Big Data processing technologies: Hadoop, Spark, Cosmos\nExperience in Azure, AWS or other cloud ecosystems.\nExperience in NoSQL databases.\nPublished work in academic conferences or industry circles.\nDemonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic startup environment\nPosition Location:\nOrange, California\nAlignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.\n\nIf you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.\nApply Now: click Apply Now"}, "233": {"company": "MassMutual", "description": "Position Summary:\n\nMassMutuals Advanced Analytics group is seeking an exceptional, highly motivated and self-directed data scientist. In this role, you will perform data-driven research, problem solving, and algorithm development through the systematic application of mathematics, statistics and computer science as well as cutting edge data technologies. Results of this work manifest themselves in a variety of ways, including interactive visualizations, presentations, publications, web applications, predictive algorithms, and APIs.\n\nThis is an opportunity to join a small but growing high performing team with diverse backgrounds in applied math, computer science and physics that have been tasked with developing, maintaining and extracting knowledge from a strategic data asset. Our work revolves around studying fundamental and high impact business questions that directly impact the direction of the company and industry at large.\n\nOverall Responsibility:\nSet strategy and assume a leadership role in a domain of expertise\nDevelop roadmaps for projects and services, data, and technology\nOversee operations of algorithm and system deployments\nPartner with executive leadership to ensure alignment of data science initiatives and company strategy\nLead projects and research initiatives\nDevelop algorithms and predictive models, create prototype systems, visualizations, and web applications\nDesign and analyze experiments\nAssemble data sets from disparate sources and analyze using appropriate quantitative methodologies, computational frameworks and systems\nDisseminate findings to non-technical audiences through a variety of media, including interactive visualizations, reports and presentations\nMentor junior team members\n\nCandidate Requirements:\nIndustry recognized expertise\n7+ years working with data and relevant computational frameworks and systems\n7+ years developing of probabilistic models and machine learning algorithms\nProficient level of understanding in the following areas and an expert in at least one: machine learning, probability and statistics (esp. Bayesian methods), natural language processing, operations research\nExceptional problem solving skills and willingness to learn new concepts, methods, and technologies\nExpert in data analysis using R or Python (numpy, scipy, matplotlib, scikit-learn, pandas, etc.) programming languages\nKnowledge of HTML/CSS/Javascript, d3.js and web application frameworks (Flask, Django, Play!, etc.)\nKnowledge of NoSQL systems, Hadoop/map-reduce, Spark, Hbase, etc.\nExperience in database design and SQL\nAbility to work in a highly collaborative environment\nOutstanding communication skills (publication history a plus)\n\nEducation - M.S. or Ph.D. in a quantitative discipline (Computer Science, Statistics, Applied Mathematics, Electrical Engineering, Physics, etc.) is required\nApply Now: click Apply Now"}, "234": {"company": "Synechron", "description": "TECHNOLOGY\nSenior Data Scientist\nNew York, NY and Charlotte, NC, USA\n\nApply\n\nJob Description\n\n\nThe Data Science team is looking for a seasoned data scientist with a strong analytics, programming, and machine learning background. The ideal candidate will work closely with top tier financial services organizations to formulate solutions to complex business problems using multiple analytical tools and frameworks, including statistical analysis, natural language processing, machine learning, and deep learning. The ideal candidate will be able to identify client needs, propose effective solutions, and implement the solutions as part of a team.\n\nSynechron\u2019s collaborative culture and global network of Tier One banking clients provides an incredible environment for a data scientist to work on the most cutting-edge use cases in machine learning and artificial intelligence in finance. You will have the opportunity to work with some of the best data scientists anywhere in an environment which truly values innovation, creative thinking, and a proactive approach to problem solving. Exciting projects include building machine learning platforms for investment research, private wealth management, IPO underwriting, customer analytics, social AI, and retail and commercial banking. As a senior member of the Data Science team you will have the opportunity to lead teams and projects and to mentor junior data scientists in their development.\n\nResponsibilities\nDesign and develop scalable solutions to complex problems using statistical modeling, machine learning, Natural Language Processing, Optical Character Recognition, and deep learning;\nImplement solutions in Python in multiple environments including Spark, AWS, and Azure;\nManage junior data scientists in the implementation of machine learning solutions;\nMeet with clients to understand business use cases, identify needs, and formulate end-to-end solutions encompassing data ingestion, cleansing, modeling, and predictive and prescriptive analytics;\nManage the ingestion and cleansing of large data sets using big data tools such as Spark;\nTranslate solutions into business requirements;\nIndependently formulate new ideas for solving client problems or providing clients with new tools for growing revenue, reducing cost, improving customer acquisition and retention, and automating business processes.\n\nRequirements\n\n\nBasic Qualifications\nHold a MS or PhD degree in a quantitative discipline: computer science, applied mathematics, statistics, operations research, management of information systems, engineering, economics, social sciences or equivalent;\nProgramming skills in Python;\nPresentation skills including experience presenting complex ideas to clients and prospects;\nThe ability to independently formulate solutions to complex problems or to otherwise think of potential solutions without guidance;\n8+ years of total experience including 4+ years of experience developing machine learning systems in Python, Java, or a related programming language;\nHands on experience with data mining, machine learning, econometric analysis or equivalent;\nExperience in Hadoop or other MapReduce paradigms and associated languages such as Spark;\nExperience with Unix/Linux environment for automating processes with shell scripting.\nPreferred Qualifications\nStrong Python programming skills;\nKnowledge of deep learning and related open source libraries such as TensorFlow;\nFinancial Services experience and knowledge of the FS industry;\nDeep knowledge of Natural Language Processing;\nExperience with Spark and machine learning libraries such as MLlib;\nExperience in marketing and sales, being an innovator and disruptor is also a plus;\nBeing self-motivated, creative and collaborative;\nStrong presentation and communications skills.\n\nApply Now: click Apply Now"}, "235": {"company": "Silicon Valley Bank", "description": "Silicon Valley Bank is the market leader in providing financial solutions to the world\u2019s most innovative companies, leaders and investors. Our clients are the game changers fueling the global innovation economy and transforming the way we live and work. SVB has been an incredible growth story over the last 35 years and continues to grow and expand internationally. Come join a growing, global commercial bank at the heart of the innovation economy where you will be able to help bring our clients\u2019 world-changing ideas to life.\n\nThe role: as a Senior Data Scientist in Machine Learning and Predictive Analytics with the Enterprise Business Analytics team, you will be a key contributor to development and implementation of leading edge machine learning technologies. This position will be dedicated to our Early Stage Practice (\u2018ESP\u2019) which is focused on engaging and building authentic relationships with pre-Series A founders, clients, prospects and partners. Your automated machine learning solutions will ensure our ESP prospects and clients receive best practice relationship management.\nResponsibilities include:\nDevelop and implement cutting edge machine learning solutions that provide our client facing staff with foresight and direction to optimize their prospects and client interactions\nCreate and deliver clear, compelling communications to your internal business partners that demonstrate the power of your machine learning solutions\nSeek out and implement opportunities that apply machine learning to proactively alert, advise and recommend best actions to our team members.\nBachelors degree\n5 to 8 years of experience in the quantitative analytics, machine learning and/or statistics space\nDemonstrated proficiency with SQL and at least one scripting language such as Python, R, Julia or Scala\nHands on experience using machine learning techniques and deploying them into production\nSolid success integrating machine learning solutions into systems such as CRM to automatically create alerts, triggers and recommendations for client facing staff\nStrong communication skills to collaborate effectively with business partners across the company\nPreferred:\nGraduate level education in computer science, mathematics, quantitative economics, statistics or operations research, preferred\nExperience in financial services and/or an operational role in an early or growth stage company or consulting firm to early stage companies\nKnowledge of business development, customer acquisition and sales, growth, and revenue generating strategies that drive early stage company success\nMBA\nApply Now: click Apply Now"}, "236": {"company": "Optoro", "description": "Optoro is a fast-growing technology company that is revolutionizing the retail industry. Every year, more than 15% of retail goods are returned or simply never sell. This creates tons of unnecessary waste and costs retailers billions.\n\nOur mission is to make retail more sustainable by eliminating all waste from returns. Our technology platform connects every returned item to its best home, thereby increasing profitability for retailers, giving consumers great deals, and reducing environmental waste.\n\nBacked by some of the top investors in the country - including Kleiner Perkins, Revolution Growth, and UPS - Optoro is powered by its collaborative, unconventional, and resourceful employees who love solving big problems. We are looking for individuals with similar creativity and energy to help build a lasting company focused on the triple bottom line.\n\nOptoro's Data Science team is responsible for turning our massive data resources into actionable insights that inform our products and business processes. Our team values creativity, willingness to embrace new methods and technology, and the ability to solve problems independently. The team uses a wide variety of machine learning techniques - from linear regression to deep learning to hierarchical Bayesian models - while constantly pushing the bounds on real-time experimental methods including multi-armed bandits, reinforcement learning and more! Our goal is to create a step-change increase in the world's ability to efficiently and effectively optimize returns across the entire Optoro platform. We're looking for experienced Data Scientists that are passionate about helping us to achive that goal, using any and all means necessary.\n\nResponsibilities\nDevelop models via a wide variety of machine learning techniques that have demonstrable impact on business challenges.\nManipulate complex, high-volume, high-dimensionality data from varying sources to provide insights that enhance Optoro's SmartDisposition\u2122 routing algorithm and pricing approach.\nMonitor results of deployed algorithms for accuracy, drift over time, and robustness to new data and enact methods to continuously improve models.\nDesign and execute experimental tests of business logic using multi-arm bandit frameworks, traditional A/B testing and more.\nProduce reports and data visualizations using Tableau and other tools.\nRequirements\nStrong mathematical and statistical background; B.A. (graduate degree preferred) in a relevant quantitative field (e.g. applied mathematics, statistics, physics, computer science, operations research); or equivalent work experience in a relevant role.\n4+ years in a machine learning-focused role, including data extraction and cleaning, exploratory analysis, predictive modeling, and monitoring of deployed algorithms.\nDeep understanding of data analysis, machine learning, and data communication across multiple domain areas.\nExperience with the Python statistical programming stack (NumPy, Pandas, Scikit-Learn, TensorFlow, PyMC3, etc\u2026) and deploying algorithms in production environments. We also welcome candidates who come primarily from an R background but want to migrate to Python.\nAbility to deal with ambiguity in a fast-paced, dynamic environment.\nProven experience thinking creatively about challenging, analytical problems.\nExperience with supply chain, eCommerce, microeconomic theory, NLP, Ruby on Rails, Airflow, Kafka, and PostgreSQL are all a plus!\nOptoro is an equal opportunity employer.\nStart your job application: click Apply Now"}, "237": {"company": "Kareo Inc", "description": "What We Need\nA Senior Data Scientist with solid problem-solving skills to partner with the development teams.\nYour Area of Focus\nJoin a growing team of tech heads who love building things with ones and zeros\nWork in a fast-paced environment that sometimes fails fast and early, but always learns and improves\nBe unshackled by conventional thinking and allowed to use cool tech to solve hard problems\nPerform component design for a complex system or service. Considers scaling, reusability, maintainability, and performance into system or service design.\nStrong written and verbal communication skills and ability to train and mentor Junior engineers\nMake recommendations to product requirements and business solutions based on an understanding of how Kareo's products work under the hood\nWrite unit tests and integration tests for most of one's own work and ensure a high quality of deliverables\nYour Qualifications\nComputer Science Degree (or degrees) or enough experience to convince us you do not need one\nExtensive knowledge of Python or R\nAbility to understand and interpret data and programmatically make predictions\nExperience with statistical tools and visualizations techniques to extract hidden insights from large datasets\nAbility to use historical data to build models that can predict future outcomes and drive business decisions\nExperience with Microservices and CI/CD (Kubernetes is a plus)\nDeep understanding of latency, contention, computation, mutation, consistency, CAP theorem and system design trade-offs\nExperience in an UNIX environment\nExperience with SoA architectures and in SaaS products\nExtensive knowledge of RESTful APIs\nFamiliarity with relational databases such as MySQL, Oracle, and SQL Server\nExperience with data warehousing tools and technologies\nAbility to design and implement scalable big data pipelines and frameworks that can integrate external data sources and third-party APIs\nSolid experience with concurrency, multithreading, server architectures, and distributed systems\nExperience with distributed search engines like Elastic search\nStrong problem solving and critical thinking skills\nStrong attention to detail\nProcess oriented: you can teach us a thing-or-two about machine learning and real-time data analytics in high throughput environment\nDeep understanding of the inner workings of one or more programming languages and tech stack\nAbility to build REST APIs that can process and distribute data to 3rd party applications at scale\nExperience with building AI bots\nA good understanding of current industry trends and best practices\nYour Personal Characteristics\nBe Passionately Driven: We take pride in our work, inspire others to excel, and are always curious to learn more. We hold ourselves to the highest standards of quality and integrity. We work with urgency because we love what we do.\nDedicated to Customer Success: Helping our customers succeed is our number one goal and inspires every action we take. We want our customers' practices, and their patients, to thrive. We are empathetic, solution-oriented, and aligned with their needs.\nTogether We're Better:We are honest, approachable, and collaborative. We believe great teams with members that are willing to do what it takes to get the job done can accomplish more. We put the team first and win together.\nConstant Innovation: We reject the status quo. We take a unique approach and make every effort to bring clarity to a needlessly complex industry. We are creative problem solvers. And we apply the same innovative thinking to our business and healthcare as a whole. We believe in making things better.\nKareo is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\nApply Now: click Easy Apply"}, "238": {"company": "Perfect World Entertainment", "description": "The Data Scientist provides data-driven insights related to several of Perfect World\u2019s services and products, including our popular games and the global game publishing platform.\n\nHe/she identifies the opportunities that would help improve the user acquisition, retention and monetization of our games.\n\nIdeal candidates will have a deep understanding of statistics and machine learning algorithms, experience working with large datasets, and an ability to communicate actionable insights directly to non-technical audiences.\n\nKey Qualifications\n2 years of industry experience in a Data Science or Analytics role.\nExperience with visualization software.\nWorking knowledge of SQL and Python/R.\nWorking experience of Machine Learning and predictive analytics.\nFamiliarity with the Hadoop framework, including the ability to interact with data through Hive, Pig, or MapReduce preferred.\nStrong communication skills, both written and oral, and an ability to convey complex results in a clear manner.\nData Science or Analytics experience in gaming or marketing strongly preferred.\nEducation\nMajor in a quantitative field, such as Computer Science, Applied Mathematics, or Statistics, or equivalent professional experience.\nApply Now: click Apply Now"}, "239": {"company": "Foundation Medicine", "description": "Data Scientist\nJob Location\n\n\nBoston, MA\n\nReq Number\n\n10842\n\nDepartment\n\n\nData Strategy & Prod Dev\n\nApply Now\n\n\nABOUT FOUNDATION MEDICINE\n\nFoundation Medicine, Inc. (FMI) began with an idea\u2014to simplify the complex nature of cancer genomics, bringing cutting-edge science and technology to everyday cancer care. Our approach generates insights that help doctors match patients to more treatment options and helps accelerate the development of new therapies. Foundation Medicine is the culmination of talented people coming together to realize an important vision, and the work we do every day impacts real lives.\n\nABOUT THE JOB\n\nData Scientist I, Data Products researches, prototypes, and otherwise enables the next generation of real-world data products. In partnership with product managers, engineers, and domain experts in oncology and genomics, the Data Scientist leverages FMI\u2019s real-world data assets, including FoundationCORE and clinico-genomic database (CGDB) for efforts in analyzing real-world clinical and genomic data. Specifically, the incumbent examines clinical use cases, such as biomarker-based outcomes analyses, examining genomic predictors of clinical outcomes, clinical utility of next-generation sequencing, and the impact of diagnostics on patient care. The Data Scientist I collaborates with internal and external stakeholders to explore and develop opportunities to provide clinical decision support tools based on FMI\u2019s data assets.\n\nKey Responsibilities:\nDesign, execute and present data query results of large genomics, clinical and process datasets to identify correlating information.\nDesign and develop standardized data templates for reporting and visualization of validation study results.\nProvide insights and collaborate with other functions in building a centralized validation database to store and trace all analytical and clinical validation data.\nMaintain and expand knowledge of and access to available and meaningful data sources within and outside of FMI, and their application to product development needs.\nCollaborate with the Medical, Commercial and Product Teams to design and execute quantitative analyses of real-world oncology cohorts.\nCreate data visualizations communicating insights to a range of audiences.\nDevelop prototype data products for internal and external users, especially in the area of clinical decision support applications.\nContribute to the scaling of data product tools to FMI\u2019s customers that utilize real world data insights.\nCo-author case studies and peer-reviewed publications.\nProvide support on projects of increasing complexity, as needed.\nOther duties as assigned.\nQUALIFICATIONS\n\nBasic Qualifications:\nMaster\u2019s Degree in Statistics, Bioinformatics, Computer Science, Biomedical Engineering, Mathematics, or related field and 1+ year of work experience in the fields of data science, data analysis, biostatistics, or bioinformatics\nOR-\nPh.D. in Statistics, Bioinformatics, Computer Science, Biomedical Engineering, Mathematics, or related field with no professional work experience.\nPreferred Qualifications:\nExpertise in biostatistics and epidemiology data sources and analysis.\nExperience with the statistical analysis of analyzing clinical health data, particularly survival and outcomes analyses.\nExperience with the development of clinical decision support tools.\nExperience with the statistical analysis of genomic data (+/- other omics data types).\nKnowledge of Next-Generation Sequencing (NGS).\nFamiliarity with regulatory requirements, including those of GCP and ICH.\nHistory of successfully completing highly-independent work.\nAbility to collaborate within cross-functional teams.\nStrong interpersonal skills that include excellent skills in written and oral communication, and problem solving with other departments and colleagues.\nDemonstrating of integrity and a commitment to values held at FMI: patients, innovation, collaboration, and passion.\nDemonstrated history of successfully managing multiple initiatives and maintaining one\u2019s own workflow.\nUnderstanding of HIPAA and importance of privacy of patient data.\nFoundation Medicine is proud to be an Equal Opportunity and Affirmative Action employer and considers all qualified applicants for employment without regard to race, color, religion, sex, gender, sexual orientation, gender identity, ancestry, age, or national origin. Further, qualified applicants will not be discriminated against on the basis of disability or protected veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also FMI\u2019s EEO Statement and EEO is the Law and Supplement. If you have a disability or special need that requires accommodation, please let us know by completing this form. (EOE/AAP Employer)\nApply Now: click Apply Now"}, "240": {"company": "Software Resources, Inc.", "description": "Software Resources has an immediate long term contract job opportunity for a Data Scientist with a major corporation in Orlando, FL.\n\nDescription:\nRelevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, or software engineering.\nAn ideal candidate for the Lead Machine Learning Scientist role should have practical experience, a love of experimentation, and a passion for the problem we're trying to solve. In this position, you will play a central role in developing Client ways to leverage machine learning and statistical analyses. You'll use a mixture of supervised and unsupervised techniques to generate and test hypotheses and turning your results into actionable, impactful insights. You will be exposed to and incorporate a variety of statistical and machine learning techniques such as logistic regression, experimental design, generalized linear models, mixed modeling, CHAID/decision trees, neural networks and ensemble models.\n\nWhat You'll Do:\n\" Knowledge of statistical concepts such as regression, time series, mixed model, Bayesian, clustering, etc., to analyze data and provide insights.\n\" Conduct statistical analysis and build time series models using linear regression, ARIMA, DLM, VAR, and VECM. Responsible for creating and implementing AI, machine learning and deep learning algorithms to solve business problems. Design project specific custom model architectures, preprocessing and postprocessing pipelines and training and evaluation procedures. Deploy machine learning and deep learning models from prototype stage to production ready, highly scalable applications capable of real-time and batch inference. Develop models to derive information from text using natural language processing like parts of speech, named entity recognition, constituency parsing, and dependency parsing. Automatically summarize text, classify text, extract sentiment and infer latent topics from text data to predict company performance.\nResearch, prototype, and develop core machine learning and statistical analyses for commercial strategy data including revenue and capacity data.\nMix supervised and unsupervised methods to train classifiers.\nLeverage cloud-based technologies to collate and pre-process model input data.\nWork closely with our team to validate and improve experiment results.\nAbout You:\nYou're adaptable, driven, and have at least a BS in Computer Science, Statistics, Mathematics, Applied Mathematics, or a related field.\nYou're a leader: you can accomplish things on your own, but you also bring out the best in people around you.\nYou have 3+ years of experience in architecting, implementing, and evaluating machine learning and/or image processing approaches for unique datasets.\nYou're proficient in Python and common machine learning frameworks\nYou're familiar with cloud computing technologies and conducting experiments on cloud-based datasets (e.g. Amazon EC2, Amazon S3, Docker, Snowflake).\nYou have strong written and verbal communication skills to share findings with the rest of the team.\nPluses:\nMS/Ph.D. in a relevant field.\nDemonstrable experience as a primary developer for production Client solutions.\nProficiency in machine learning and statistics theory, as well as knowledge of recent advances in deep learning.\nRequired Education:\nBS Computer Science or Math\n\nDon't delay. Join the Software Resources team today!\nSoftware Resources specializes in connecting talented IT professionals with challenging job opportunities that transform jobs into careers.\nTo meet our clients hiring needs, we continuously source talented IT Professionals with all levels of expertise and in all disciplines. We offer world class major medical, dental and vision benefits, 401(k) with match, short term disability, Life Insurance and AD&D. You, our future employees, can make a tremendous difference to our company and our clients. Please apply to this job and experience the Software Resources difference. You can view all of our jobs at https://www.softwareresources.com/careers/\n\nCompany Overview\nSoftware Resources is a national staffing and recruitment firm delivering the best candidates to our clients and the best jobs to our candidates since 1992.\nWe are a certified woman owned business in business to place contract, contract-to-hire, and direct-hire talent in Technology (IT, creative, marketing), finance, accounting, and executive-level positions. We serve many vertical markets including Entertainment/Media, Cruise Industry/Leisure travel, Hospitality, Government, Personal Care, Professional Services, Energy/Utilities, Security, and Financial Services.\n\nHeadquartered in Lake Mary, FL in the Orlando metro area, we have branches and sales professionals across the US. Wherever you're located and whatever the need, count on Software Resources to provide exceptional candidates who are fully vetted and ready to go. Call (800) 774-8036 or visit us online at https://www.softwareresources.com/ and leave the recruiting to us!\n\nApply Now: click Apply Now"}, "241": {"company": "Sojern", "description": "*** Please note: This is a 12+ month PT Internship, 20 hours per week ***\n\nAbout Us:\n\nWant to join a company on the cutting edge of technology and travel? Want to be part of a fantastic and fun company that's revolutionising the online travel advertising space?\n\nSojern works with 93% of the Fortune 500 travel companies and has spent more than a decade analyzing the complete traveler path to purchase. We drive travelers from dream to destination by activating multi-channel branding and performance solutions on the Sojern Traveler Platform for more than 8,500 customers around the world.\n\nSojern made Deloitte's Technology Fast 500 list for the last 6 years in a row, and was recognised on the Top Company Cultures list by Entrepreneur Magazine and named a Best Place to Work by AdAge. The company is headquartered in San Francisco, with teams based in Dubai, Dublin, Hong Kong, London, Mexico City, New York, Omaha, Paris, Singapore, Sydney and Istanbul.\n\nNeed more convincing that Sojern is a great place to work? Check out our Glassdoor reviews!\n\nThe Role:\n\nThe Analyst & Data Science Intern role will focus on gaining an understanding of the online advertising ecosystem and use data to drive customer performance, operational efficiencies and company margin. An Analyst & Data Science Trainee will play a critical role within the Operations team by ensuring Sojern's clients' programmatic campaigns are structured and optimized in a way to drive optimal performance for Clients and Sojern. The intern will also have the opportunity to work cross functionally with Product, Engineering and Data Science. Upon completion of the program, interns who develop the necessary skill set will have the opportunity to apply for available full-time Data Science positions.\n\nIf you thrive in a fast-paced, innovative and collaborative environment, and are excited by the idea to make impactful data-driven decisions every day, then Sojern is the place for you!\n\nResponsibilities:\nManage Sojern Clients' programmatic campaigns by combining audience segmentation, bidding, delivery and pricing strategies to extract optimal conversion based performance by leveraging Sojern's travel data.\nSolve real client challenges by utilizing data mining and visualization to identify and implement new solutions.\nHave an opportunity to collaborate with the Product, Engineering and Data Science teams on a capstone project at the end of the internship.\nCollaborate with the global analyst team on automation projects and best practices.\nWhat you bring to the table:\nCurrent Graduate or Undergraduate student working towards a degree in data science, data analytics, statistics, or a related field.\nExperience with SQL and the Python Data Science toolkit (e.g. Jupyter, Pandas, Scikit-learn, Numpy).\nAbility to commit to 20 hours a week during normal business hours.\nCoursework covering topics such as sampling, hypothesis testing, regression, and Bayesian statistics.\nAbility to commit to the 12+ month program depending on current year in school.\nPerks:\nOpportunities: Be part of a growing team with training and support to help you grow\nOwnership: Lead creative and challenging projects\nGive Back: We give 40 hours a year to volunteer and organize office volunteer programs with local organizations\nCulture: Strong core business values, focus on teamwork, vibrant, social and fun environment\nSnacks: Variety of snacks in the office\nMeals: Monthly catered lunches & happy hours\nAt Sojern, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\n]]>\nApply Now: click Apply Now"}, "242": {"company": "Pactera", "description": "Looking fora Data Scientis/Architect who has 8 yrs of exp in data design, data modelling, data flow, analytics in supply chain domain.\n\nHere\u2019s the detail JD:\nExpert programming skills in Python, R\nExperience in writing code for various Machine learning algorithms for classification, clustering, forecasting, regression, Neural networks and Deep Learning\nHands-on experience with modern enterprise data architectures and data toolsets (ex: data warehouse, data marts, data lake, 3NF and dimensional models, modeling tools, profiling tools)\nStrong knowledge of Supply Chain domain, preferably in the hi-tech industry\nStrong problem solving and abstract thinking skills\nKnowledge of data architecture and design patterns and the ability to apply them\nAbility to conceptualize and articulate ideas clearly and concisely\nExcellent communication, presentation and interpersonal skills\nApply Now: click Easy Apply"}, "243": {"company": "Pivotal Software", "description": "LOCATION: Remote (home based) with some travel to New York, Washington DC, Boston.\n\nAbout Us VIDEO\n\nFounded in 2013, Pivotal Software, Inc. combines our leading cloud-native platform, tools, and methodology to empower the world's largest organizations to adapt to change and build great software. Our technology unleashes developer productivity, while fulfilling our mission to transform how the world builds software.\n\nYou\n\nAs a data scientist on Pivotal's Data Science team, you'll be working on a wide variety of data problems for a diverse range of clients. You will often be asked to learn new technologies and domains on the fly. You should be comfortable working under deadlines and making tough decisions. Consequently, you will frequently have to balance achieving an immediate goal with scalability and productionalizability.\n\nThe role offers room for personal and professional growth, and you won't be working in isolation. Data Science at Pivotal is an encouraging and supportive team, where ideas and challenges are addressed collaboratively. We're looking for the kind of person who will try and solve a problem on their own first, but isn't afraid to ask for help or say \"I don't know.\"\n\nUs\n\nThe Data Science team at Pivotal is primarily a consulting practice; we are tool agnostic, working with our customers to solve real world problems. Our customers, like us, are cross-disciplinary. We service engagements with use cases running from customer churn to optimization to detecting fraud and misconduct. We are not just doers, we are also educators and enablers.\n\nYour Day\n\nWhile there is no such thing as a \"typical day\", these are activities we frequently find ourselves doing:\nWorking with clients to uncover and frame new opportunities for data science. Clients often come to us without a clear understanding of what we can do, so this is our chance to open their eyes to new possibilities for their businesses.\nExploring client datasets, looking for actionable insights we can present.\nEngineering features, training models, tuning hyperparameters and evaluating the results. We emphasize rigor, because data science done right at this stage leads to models that shine in production.\nTaking the models we build into production. This is an exciting stage for anyone who likes collaborating with engineering teams and seeing their model become real when users interact with it.\nHelping our clients develop their internal data science practices, from hiring and recruiting to data capturing, so that they can be successful when we hand off the project.\nRequired Skills / Experiences\nClear and empathetic communicator. You'll be the one sharing your insights with clients and stakeholders at check-ins, documenting your work, and even explaining your model to client data teams as part of a handoff. As such, communication and empathy are essential parts of your toolkit.\nAdvanced knowledge of statistical modeling and/or machine learning methods. These are the tools we need to go from analysis to prediction.\nStrong programming skills. Left to our own devices most of us work in Python, but learning the client's tech stack is an important part of the job.\nStrong exploratory data analysis skills. Every engagement starts with an investigation of the data, and thorough EDA saves us a lot of headaches in the long run.\nSome travel is expected, depending on location and skillset. We mostly work out of the Pivotal office closest to the client, but sometimes we have to be on site for an extended period of time.\nAt least a bachelor's degree in an analytical or technical field. This could be applied mathematics, statistics, computer science, operations research, economics, etc. Higher education welcome and encouraged.\n\nThis role will support US government clients that require US citizenship. Given this, US citizenship is required for you to apply.\nDesired Skills / Experiences\n2+ years of work in a data-centric field (data science or data engineering).\nExperience with relational databases.\nExposure and experience working in a Linux environment.\nYou have a specialization in an area like NLP, optimization, or image processing.\nHands-on experience working in a distributed computing environment or proven theoretical understanding of parallelism.\nPivotal is an Equal Employment Opportunity employer that will consider all qualified applicants, regardless of race, color, religion, gender, sexual orientation, marital status, gender identity or expression, national origin, genetics, age, disability status, protected veteran status, or any other characteristic protected by applicable law.\nApply Now: click Apply Now"}, "244": {"company": "QuantumBlack", "description": "Analytics\nSenior Data Scientist - QuantumBlack\n\nBoston\n\nApply Now\n\nQualifications\n\nMSc or PhD level in the field of Computer Science, Machine Learning, Applied Statistics, Mathematics\nExperience in statistical modelling and machine learning techniques\nProgramming experience in at least two of the following languages: R, Python, Scala, SQL\nExperience in applying data science methods to business problems\nExperience in applying advanced analytical and statistical methods in the commercial world\nGood presentation and communication skills with the ability to explain complex analytical concepts to people from other fields\n\nWho You'll Work With\n\n\nAs a Senior Data Scientist at QuantumBlack in Boston you will work with other Data Scientists, Data Engineers, Machine Learning Engineers, Designers and Project Managers on interdisciplinary projects, using Maths, Stats and Machine Learning to derive structure and knowledge from raw data across various industry sectors.\n\nWho you are\n\nYou are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritizing impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.\n\nWhat You'll Do\n\n\nYou will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally.\n\nYou will influence many of the recommendations our clients need to positively change their businesses and enhance performance.\n\nRole responsibilities\nWork on complex and extremely varied data sets from some of the world\u2019s largest organisations to solve real world problems\nDevelop data science products and solutions for clients as well as for our data science team\nWrite highly optimized code to advance our internal Data Science Toolbox\nWork in a multi-disciplinary environment with specialists in machine learning, engineering and design\nAdd real-world impact to your academic expertise, as you are encouraged to write \u2018black\u2019 papers and present at meetings and conferences should you wish\nAttend conferences such as NIPS and ICML as one global team as well as Data Science retrospectives where you will have the opportunity to share and learn from your co-workers.\nWork with one of the largest and most advanced data science teams, support the Lead Data Scientists to develop data science products\nWhat you\u2019ll learn\nHow successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines\nBuild products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations\nBe able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.\nBest practices in software development and productionize machine learning by working with our Machine Learning Engineering teams which optimize code for model development and scale it\nWork with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualizations\nUsing new technologies and problem-solving skills in a multicultural and creative environment\nYou will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.\nReal-World Impact\u2013 No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.\nFusing Tech & Leadership\u2013 We work with the latest technologies and methodologies and offer first class learning programs at all levels.\nMultidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.\nInnovative Work Culture\u2013 Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.\nStriving for Diversity\u2013 With colleagues from over 40 nationalities, we recognize the benefits of working with people from all walks of life.\nOur projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimizing a Formula1 car\u2019s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture:\nHealthcare Efficiency\u2013 We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.\nEnvironmental Impact\u2013 We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.\nProduct Development\u2013 We worked with the CEO of an elite automotive organization to reduce the 18-month car development timeframe by improving processes, designs and team structures.\nVisit our Careers site to watch our video and read about our interview processes and benefits.\n\nMcKinsey & Company is an equal opportunity employer.\n\nIndustries\nHigh Tech\n\nFunctions\nTechnology\n\nApply Now\nshare this job\n\nJob Skill Group - CSS Associate\nJob Skill Code - SPDS - Specialist, Data Science\nFunction - Technology\nIndustry - High Tech\nPost to LinkedIn - Yes\nPosted to LinkedIn Date - Sun Sep 08 20:00:00 GMT 2019\nLinkedIn Posting City - Boston\nLinkedIn Posting State/Province - Massachusetts\nLinkedIn Posting Country - United States\nLinkedIn Job Title - Senior Data Scientist - QuantumBlack\nLinkedIn Function - Consulting;Information Technology;Science\nLinkedIn Industry - Computer Software;Information Technology and Services;Management Consulting\n\nApply Now: click Apply Now"}, "245": {"company": "Genomic Health", "description": "Genomic Health, a subsidiary of Exact Sciences is seeking an exceptional individual with strong statistical skills to participate in the development of genomic biomarker assays that help cancer patients and their physicians make better treatment decisions. The Data Scientist II will directly support more senior personnel in pursuit of all Nonclinical Biostatistics (NCB) efforts across our various internal customer groups. In particular, these efforts will support Process Engineering, New Technologies development, and R&D efforts across multiple projects.\n\nAdditional responsibilities may include but are not limited to: relevant study support for Assay Development and the Development Lab work (e.g., initial data display and analysis), Analytical Chemistry/Analytical Sciences, Commercial Lab support and data monitoring, and clinical data QC for clinical studies. The candidate will interact with more senior staff of NCB and under their direction/supervision, establish close working relationships with our internal customer groups.\n\nRESPONSIBILITIES / DUTIES:\n\n\u2022 Primary responsibility will be to support the NCB staff and our internal customers in the development of any and all assigned projects, including but not limited to:\nNew Technologies and their evaluation\nProcess monitoring subsystems\nGHI Commercial Lab data monitoring and QC\nTable formation and development of descriptive statistics as required\n\u2022 Support will consist of but will be limited to:\nCode development in SAS, R, or Python as directed\nData review under the guidance of the NCB designated technical lead\nProcess improvement and automation\nProcess troubleshooting under the direction of the NCB designated technical lead\n\u2022 Secondary responsibilities will include when appropriate, direct support for our customer base, and under some supervision provide statistical guidance and advice with respect to initial analyses, data visualization, and tabularization.\n\nQUALIFICATIONS:\n\n\u2022 MS or Ph.D. in Biostatistics / Statistics\n\u2022 A minimum of 2 (Ph.D.) or 6 (MS) years of relevant work experience in industry or academia\n\u2022 Sound knowledge of theoretical and applied statistics\n\u2022 Experience in analyzing high dimensional data, designing/performing DOE studies\n\u2022 Statistical process control, analytical method development, and validation\n\u2022 Good written and oral communication skills\n\u2022 Able to integrate and apply feedback in a professional manner\n\u2022 Able with direction to prioritize and drive to results with a high emphasis on quality\n\u2022 Ability to work as part of a team\n\u2022 Experience with Machine Learning, and Deep Learning frameworks desirable\n\nPHYSICAL REQUIREMENTS:\n\n\u2022 Use of computer, and or telephone for long periods of time may be necessary.\n\u2022 Considerable periods of time may be spent concentrating and or analyzing data\n\u2022 Considerable periods of time may be spent communicating verbally and in various written forms including presentation material and email with other people\n\u2022 At times, stress may be experienced.\n\u2022 Standing or sitting for long periods of time may be necessary\n\u2022 Some lifting (greater than 25 pounds) may be necessary; Facilities, Materials and Engineering employees occasionally must lift at least 50-75 pounds.\n\u2022 May be exposed to hazardous materials, tissue specimens and instruments with moving parts, lasers, heating and freezing elements, and high-speed centrifugation (GENERALLY LABORATORY & CUSTOMER SERVICE EMPLOYEES ONLY)\n\n#LI-CB1\n\nWe are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to age, color, creed, disability, gender identity, national origin, protected veteran status, race, religion, sex, sexual orientation, and any other status protected by applicable local, state or federal law. Applicable portions of the Company\u2019s affirmative action program are available to any applicant or employee for inspection upon request.\n\nPhysical Requirements\n\n\u2022 Use of computer, and or telephone for long periods of time may be necessary.\n\u2022 Considerable periods of time may be spent concentrating and or analyzing data\n\u2022 Considerable periods of time may be spent communicating verbally and in various written forms including presentation material and email with other people\n\u2022 At times, stress may be experienced.\n\u2022 Standing or sitting for long periods of time may be necessary\n\u2022 Some lifting (greater than 25 pounds) may be necessary; Facilities, Materials and Engineering employees occasionally must lift at least 50-75 pounds.\n\u2022 May be exposed to hazardous materials, tissue specimens and instruments with moving parts, lasers, heating and freezing elements, and high speed centrifugation (GENERALLY LABORATORY & CUSTOMER SERVICE EMPLOYEES ONLY)\n\nCompany Profile:\n\n\nGenomic Health is a global provider of genomic-based diagnostic tests that address the overtreatment of cancer, one of the greatest issues in healthcare today. Our goal is to improve the lives of people with cancer by providing personalized, biological information that helps them get the right treatment at the right time, and to avoid unnecessary treatments and their side effects. In this way, our work is truly life, changing.\nOur Oncotype IQ Genomic Intelligence Platform is a portfolio of diagnostic tests that help physicians and patients answer specific and critical treatment questions throughout the cancer journey\nWe currently offer Oncotype tests addressing breast, colon, prostate and lung cancers and hundreds of thousands of patients from over 90 countries have benefited from our tests.\nThe Oncotype DX breast cancer test is considered standard of care in the US and is included in all major international clinical guidelines for breast cancer treatment.\nWe are expanding our portfolio of tests to include additional liquid- and tissue-based tests through clinical research and internal product development as well as strategic partnerships.\nJoin the Genomic Health Team, and have the unique opportunity to make a difference in the lives of patients with cancer, while developing your career potential. We embrace our unique culture characterized by our Core Values of Community, Truth Seeking, Being Ahead of the Curve and Winning to be the best in the world at what we do. We maintain competitive total rewards programs designed to satisfy our employees\u2019 work life and personal life needs.\n\nAll qualified applicants will receive consideration for employment without regard to race, sex, gender identity, color, religion, national origin, protected veteran status, or on the basis of disability.\n\nApply Now: click Apply Now"}, "246": {"company": "Assurance Careers", "description": "About Assurance\nAt Assurance we are disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosystem. We are rapidly growing as we expand our product offerings and global footprint, and this growth continues to present new and exciting challenges as we push our industry into its future. We eliminate waste throughout the industry and calculate the complex into simple, valuable solutions to improve people's lives. We are humble, driven, and committed to improving the lives of millions.\n\nAbout the Position\nAs we build the future of consumer insurance in a modern age, data is at the core of everything that we do. The role requires team members who are adept at using large data sets to find opportunities for optimization and can leverage appropriate models to test the effectiveness of different courses of action. Our team uses a variety of data mining and analysis methods, a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Team members must be very comfortable writing production-ready code to include testing and maintenance infrastructure, and able to put models and analysis into production with no support from engineering (we own our stack end to end). At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise.\nTo be successful in this role, you must possess the following:\nProficiency in either Python or R, and expertise in SQL.\nExperience working with AWS or another cloud-based computing platform.\nExperience and working knowledge of data infrastructure, pipelines, and advanced data manipulation.\nExperience with BI tools like Tableau or Looker (preferred), or any other industry tool such Qlik, PowerBI, Spotfire, etc.\nExcellent communication ability \u2013 you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.\nBusiness Acumen \u2013 you are always eager to understand how the business works, and more specifically, how your work impacts the business.\nEnthusiastic yet humble \u2013 you are excited about the work you do, but you are also humble enough to embrace feedback \u2013 you don\u2019t need to be the smartest person in the room.\nThe following additional experience is desired:\nExperience retraining a model within a few days or update a model within one day.\nCapable of performing an in-depth analysis and summarizing findings in one day.\nComfortable having conversations with our executive team and non-technical team members to distill down their needs and to deliver actionable insights.\nAbout You\nYou have a proven ability to drive business results with data-based insights and are comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. You\u2019re capable of getting data for analysis on your own, without reliance on engineering, and you can build professional dashboards as standalone software products and tools. We\u2019re growing at a rapid pace, so it\u2019s important that you embrace the opportunity to blaze your own trail. You thrive in a fast-paced environment where priorities can shift rapidly as we corner opportunity. You can work independently, with little oversight or guidance.\nIf this sounds like a good fit for you, give us a shout, we\u2019d love to chat!\nStart your job application: click Apply Now"}, "247": {"company": "Proofpoint", "description": "It's fun to work in a company where people truly BELIEVE in what they're doing!\n\nWe're committed to bringing passion and customer focus to the business.\n\nThe Role\n\nDo you have a passion for applying machine learning to hard problems in new application areas? Do you keep up with the latest on GANs, ResNets, CNNs, RNNs, and Deep Reinforcement Learning but have also mastered the classics like SVM and Random Forest? Are you looking for the opportunity to work with a great team that combines algorithm design, software engineering, and domain knowledge into products that are first of their kind? If so, we are looking for you. We need a Data Scientist who will work on analyzing data from malicious actors to help uncover cyber threats. Your primary focus will be applying your skills in various areas like anomaly detection, graph mining, clustering, and predictive analytics to help us build groundbreaking services that would revolutionize the industry.\n\nWe are a fast-paced, high-energy team where you will be given the opportunity to make a significant impact. The team has a solid engineering culture that values the craftsmanship of writing great software, enjoys learning, and solving big problems.\n\nYour day-to-day\nFeature engineering, building and optimizing classifiers, applying machine learning and deep learning expertise\nBlending data from disparate sources, mining the resulting data lake to build models\nContributing tested code to the team\u2019s git repo and working with engineering to implement models efficiently\nProcessing, cleansing and verifying integrity of data used for analysis\nConducting ad-hoc analysis and innovation around data visualization\nWhat you bring to the team\nExcellent understanding of machine learning algorithms, processes, tools and platforms including:\nSupervised methods - Na\u00efve Bayes, Logistic Regression, SVM, ConvNet, LSTM, Siamese Networks, etc.\nUnsupervised methods - K-means, DBSCAN, T-SNE, Spectral Clustering, SOM, LSH, etc.\nToolkits - numpy, scipy, scikit-learn, tensorflow, pytorch, keras, genism, vowpal wabbit, etc.\nPython proficiency\nGreat communication skills, ability to explain predictive analytics to non-technical audience\nProficiency in data exploration techniques and tools, e.g. SQL, Hive, etc.\nExcellent statistics, linear algebra, and optimization skills\nMS in Statistics, Machine Learning, Applied Physics or Computer Science (or technical degree with commensurate industry experience). PhD preferred\n#LI-JL3\n\nIf you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!\nStart your job application: click Apply Now"}, "248": {"company": "Adavance2", "description": "About the position\nAdvance2 is a fast-growing marketing optimization tech startup. We\u2019re bringing the world of marketing optimization to the next level leveraging Machine Learning. Advance2 automates data collection, model building, insights extraction and optimization of our clients\u2019 business.\nWe are looking for a Data Scientist to be part of the Product Development team. You will be working alongside a small cross-functional team of Engineers and Data Scientists. You will enjoy designing, developing and deploying to production data-based approaches to solving difficult business and product problems.\nThe Data Scientist will be responsible for leveraging their expertise in data processing, statistical modeling, ML, and AI to build product solutions at scale.\nYou will thrive in this role of you love problem-solving, analytical thinking and combining doing math on the whiteboard with coding.\n\nResponsibilities\nDesign, develop and deploy Machine Learning algorithms to production.\nCollaborate with Software Engineers to streamline and optimize model building and deployment.\nPartner with Product Managers to help prioritize and deliver product features.\nApply Machine Learning and Artificial Intelligence expertise to build prototypes and translate them into product features.\nContribute in creating a data-driven approach to complex business problems in the company.\nQualifications\nM.A./M.S. or Ph.D. degree in Statistics, Mathematics, Economics, Physics, or Engineering\n3+ years of experience in building predictive models using statistics and/or Machine Learning at scale.\nExperience with extracting and delivering causal relationship findings from predictive models.\nWorking knowledge of Python and related data science libraries (NumPy, Pandas, Scikit-learn, SciPy).\nMedia/Agency experience is a plus.\nExperience with data visualization is a plus.\n\nAbout Advance2\nAdvance2 is the next generation AI-driven marketing optimization platform. We help our clients continuously optimize their marketing budget with a holistic approach by leveraging Machine Learning and automation.\nWhile advanced Machine Learning algorithms are often perceived as black-boxes, we strive to bring a human touch to our AI engine, conveying the thought process underlying the AI recommendations with the help of advanced visualizations."}, "249": {"company": "Coinbase", "description": "Location: San Francisco, CA\n\n\nCoinbase has built the world's leading compliant cryptocurrency platform serving over 30 million accounts in more than 100 countries. With multiple successful products, and our vocal advocacy for blockchain technology, we have played a major part in mainstream awareness and adoption of cryptocurrency. We are proud to offer an entire suite of products that are helping build the cryptoeconomy, and increase economic freedom around the world.\n\nThere are a few things we look for across all hires we make at Coinbase, regardless of role or team. First, we assess whether a candidate demonstrates our values: Clear Communication, Positive Energy, Efficient Execution, and Continuous Learning. Second, we look for signals that a candidate will thrive in a culture like ours, where we default to trust, embrace feedback, disrupt ourselves, and expect sustained high performance because we play as a championship team. Finally, we seek people with the desire and capacity to build and share expertise in the frontier technologies of crypto and blockchain, in whatever way is most relevant to their role.\n\nAt Coinbase, our vision is to build an open financial system for the world, and to get there we'll need to continually learn from our data. Data scientists are focused on this critical step of converting data into learnings.\n\nYou'll spend part of your time working directly with product teams \u2014 engineers, designers, and product managers \u2014 to ensure we're focused on the biggest opportunities and interpreting our data correctly. And you'll spend the other part of your time with the Data team building analytics models and systems that help scale our insights more broadly, both throughout the company and directly in the product.\n\nWhat you'll be doing:\nMeasure business performance, develop core metrics and create dashboards to track and understand them.\nWork with product and engineering teams to design experiments for new product ideas, and analyze the results to provide actionable recommendations.\nPerform deep analyses and build models to understand customer behavior, and extract key insights that impact product decisions.\nSynthesize data learnings into compelling stories and communicate them throughout Coinbase.\nAct as a strategic partner to product and engineering leaders to help prioritize opportunities and inform product strategy.\nPrototype new analytics & machine learning models that improve both our insights and the product directly.\nWork across multiple subject matter experts to drive new data initiatives, automation of reports, establish best practices and mentor junior members in the team.\nLead analytics projects to completion.\nWork with the broader Data team to find ways to scale our insights through better systems and automation.\nWhat we look for in you:\nDemonstrate our core cultural values: clear communication, positive energy, continuous learning, and efficient execution.\nUnderstanding of statistical concepts and experience in applying them.\nExperience in data analyses using SQL.\nExperience in at least one programming language (e.g. R, Python, Java, Ruby, Scala/Spark, or Perl).\nBe able to independently create plans for analytics projects and build collaboration within the team.\n(For Senior Data Scientist)BA / BS degree or equivalent practical experience. 5+ years relevant experience, or MS degree, 3+ year or PhD degree in related fields + 2 years.\nNice to haves:\nBe able to proactively manage prioritization of work and deliver work with great quality and influence the broader team in creating leverage.\nPrevious experience working with financial services data is a plus.\nExperience with Looker, Tableau or other business intelligence platform.\nDomain experience in product, marketing or growth analytics.\nExperience manipulating large amounts of structured and unstructured data.\nCoinbase is committed to diversity in its workforce and is proud to be an equal opportunity employer and to review all of our job postings to minimize biased language. Coinbase does not make hiring or employment decisions on the basis of race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other basis protected by applicable local, state or federal law. Coinbase will also consider for employment qualified applicants with arrest and conviction records in a manner consistent with San Francisco's Fair Chance Ordinance and similar local laws.\nStart your job application: click Easy Apply"}, "250": {"company": "Nurx", "description": "Nurx is looking for a Data Scientist who loves answering complex business and health questions through data. This is a rare opportunity to help build a data-driven culture from the ground up and impact the lives of millions by helping reinvent the healthcare system. We're building a system to support delivery of medical care in a modern and truly empathetic way.\n\nThis is a hybrid role in which you will run deep analyses on structured and unstructured data and also build and maintain ETLs to fetch data into the Nurx warehouse. You will be asked to work with your peers to determine the best algorithm to solve any given problem, and be able to create your own data structures to execute the solution.\n\nOn this team, you'll work closely with Product, Operations, Finance, Marketing and Engineering. You'll be reporting to the Head of Data & Research and will engage with all aspects of Nurx to discover insights on how to drive operational efficiency, help plan for staffing, and most importantly, increase our ability to better our patient's health.\n\nWhat you'll do:\nDeliver the insights necessary to help Nurx scale its Operations and Medical teams.\nIdentify, track, and report regularly on key operational performance metrics.\nBuild intuitive dashboards to empower other team members with actionable data.\nPerform Data Cleansing, Data Mining and Data Modeling to analyze trends, and create forecasts in order to help Nurx understand more about its patients.\nPerform quantitative analysis, and ad-hoc reports to support key operations decisions, including staffing plans, process optimizations, and personnel performance management.\nTake an active role in key strategic decision making and analytics across the company.\nFlex into other areas of the organizations to help drive data driven decision making. Assist the Product, Finance, and Engineering teams derive key insights as needed.\nEngage with stakeholders to understand business problems and translate their questions into insights and easily digestible summaries.\nA bit about you:\nMinimum of 3+ years of experience in data science, business intelligence / consulting / investment banking / healthcare / public health or related experience.\nBachelor's Degree in: Math, Finance, Economics, Statistics, Data Science, Physics or related field.\nProven experience with Data Collection via ETLs and an understanding of data warehouse organization.\nExperience with machine learning tools and techniques such as clustering and classification.\nExperience with statistical modeling, and forecasting.\nProven ability to write, optimize and execute complex SQL queries.\nStrong comfort level with manipulating complex data structures in Python, R, Scala, or other programmatic data analysis languages.\nExpertise in A/B testing is ideal. Bonus points if you've used and understand Splunk, Looker, or Mode.\nAnalytical mindset, with the ability to focus on a problem, ask insightful questions, and gain expertise quickly.\nCompetent understanding of statistical principles (eg. statistical significance).\nAbility to derive meaning from raw data in order to influence product decisions and direction.\nNice to Haves:\nPrior experience with or interest in distributed data store environments.\nPassionate about improving the state of healthcare in the United States and beyond.\nAbout us:\n\nAt Nurx, we're creating a future where healthcare is easily accessible and affordable for everyone and building software that empowers people to be in control of decisions about their own health.\n\nOur platform enables doctors to give patients personalized care at lower costs and prescriptions delivered straight to their door. We are committed to disrupting the healthcare system and increasing access to healthcare for millions across the country, starting with birth control and PrEP.\n\nBenefits:\nTalented and collaborative team who will both support and challenge you.\nMarket competitive salary and equity.\nMedical, dental, commuter, wellness, and engineering technology benefits.\n401(k) retirement plan.\nPaid holiday, vacation, and sick leave.\nTake what you need vacation (and we really mean it!).\nThis position is full-time and based in San Francisco, CA.\nTo apply to this job, click Apply Now"}, "251": {"company": "National Debt Relief", "description": "Who We\u2019re Looking For:\n\nNational Debt Relief (NDR) is currently seeking an inquisitive, highly motivated, and creative Data Scientist who is passionate about helping customers get out of debt. The ideal candidate will have hands on experience transforming unique data into amazing products. At scale.\n\nAt NDR you will have access to an enormous amount of high-value business activity data including unstructured and semi-structured records around the sales process as well as post sales customer activity. You will participate in the end-to-end processes of machine learning, from proof of concept to deploying models in production. You will be asked to experiment, and conduct research work geared towards new product development.\n\nMeet some of our team members!\n\nPrincipal Duties and Responsibilities:\nWork with large, complex datasets and solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct end-to-end analysis that includes data gathering and requirements specification, data processing, analysis, and deployment to production.\nResearch and develop models to improve the quality of NDR user facing products; example application areas include lead scoring and end-user behavioral modeling.\nMake business recommendations with effective presentations of findings at multiple levels of the business through visual displays of quantitative information.\nDevelop processes and tools to monitor and analyze model performance and accuracy\nInteract cross-functionally with a wide variety of leaders and teams and work closely with Engineers and Product Managers to identify opportunities for improvement.\nBe fiercely competitive and maintain a sense of urgency, creativity, and curiosity for how to continue to improve internal and customer facing processes.\nQualifications:\nBA/BS in a quantitative discipline (Computer Science, Statistics, Bioinformatics, Math, Physics, Engineering) or an equivalent practical skillset.\nIndustry experience writing code (e.g., Python, Pytorch, SQL) and taking ML models/ algorithms to production.\n3+ years of expertise using advanced machine learning algorithms and statistics: clustering, decision tree learning, ensemble methods, regression, etc. on large data sets as well as a strong understanding of their real-world advantages/drawbacks. The successful candidate will have regularly used Python and SQL to extract data, design ETL flows and derive insights.\nA love for data - this is what we do. We are looking for people who are excited about different and unique data sets, and all the ways that they could be used to improve our business.\nDemonstrated skill in selecting the right statistical tools given a data analysis problem.\nExcellent written and verbal communication skills for coordinating across teams\nStartup experience while not essential is preferred.\nWhat We Offer:\n\nWe believe in a team-first culture, full of rewards and recognition for our employees. We are dedicated to our employees\u2019 success and growth within the company, through our employee mentorship and leadership programs.\n\nOur extensive benefits package includes:\nGenerous Medical, Dental, and Vision Benefits\n401(k) with Company Match\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\n10 weeks Paid Parental Leave\nPre-tax Transit Benefits\nDiscounted Gym Membership\nCiti Bike Annual Membership Discounts\nNo-Cost Life Insurance Benefits\nVoluntary Benefits Options\nASPCA Pet Health Insurance Discount\nAbout National Debt Relief:\n\nNational Debt Relief is one of the country\u2019s largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we\u2019re all about helping our customers through a tough financial time in their lives with education and individual customer service.\n\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\n\nNational Debt Relief is a certified Great Place to Work\u00ae!\n\nNational Debt Relief is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other status protected by law.\nTo apply to this job, click Apply Now"}, "252": {"company": "Southern California Edison", "description": "Job Description\nENERGY FOR WHATS AHEAD\n\nAre you looking to make a difference in your career? Were working on smarter grids, cleaner energy and tools to help people manage energy more efficiently.\nAbout Transmission and Distribution\n\nSouthern California Edisons (SCE's) Transmission and Distribution Organizational Unit (T & D) is responsible for planning, engineering, constructing, operating, and maintaining transmission and distribution facilities throughout the 50,000-square-mile territory. T&D is the steward of roughly $19 billion in assets that safely and reliably deliver electricity to 14 million residents via SCEs 5 million customer accounts.\nPosition Overview\n\nThe Senior Data Scientist Advisor is responsible for leading the modeling of complex analytical problems, discovering insights, and identifying opportunities using statistical, algorithmic, mining, and visualization techniques. In addition to advanced analytical skills, the senior advisor will be responsible for developing business requirements and coordinating with groups in and outside of the Transmission and Distribution group. You will be responsible for developing, presenting, and communicating results. You will also be responsible for leading and mentoring other Data Scientists.\nTypical Responsibilities:\nLead data scientists on developing models that meet or exceed business requirements.\nGenerate advanced analytical approaches using predictive modeling, optimization and simulation abilities.\nApply statistical and pattern recognition techniques to perform description, prediction, and optimization.\nDevelop and implement tools for data acquisition, extraction, transformation, management, and manipulation of large and complex data sets. Explore, model, mine, and experiment with data to answer critical business issues. And, generate and communicate business insights.\nQualifications\n\nMinimum Qualifications\nBachelors in a quantitative discipline such as Statistics, Mathematics, Engineering, Computer Science, or information sciences such as business analytics or informatics.\nTen or more years of experience in Predictive Modeling or Machine Learning or Statistical Modeling or Data Mining.\nProficient with R and Python.\nDesired Qualifications\nMS or PhD in a quantitative discipline such as Statistics, Mathematics, Engineering, Computer Science, or information sciences such as business analytics or informatics.\nExperience in leading and mentoring junior team members and guiding them on data science and advanced analytics (machine learning, predictive analytics) development.\nIn-depth industry/business knowledge in Electric Utility industry.\nProficiency with SQL and/or SAS.\nStrong Leadership skills and experience.\n\nComments\nCandidates for this position must be legally authorized to work directly as employees for any employer in the United States without visa sponsorship.\nRelocation may apply to this position.\nSouthern California Edison, an Edison International (NYSE:EIX) company, serves a population of approximately 15 million via 5 million customer accounts in a 50,000-square-mile service area within Central, Coastal and Southern California. Join the utility leader that is safely delivering reliable, affordable electricity to our customers for over 125 years.\n\nSCE is a proud Equal Opportunity Employer and will not discriminate based on race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or any other protected status.\n\nL1-EA1\nStart your job application: click Apply Now"}, "253": {"company": "Shutterfly", "description": "The Data Scientist will be responsible for designing and directing experiments and observational studies to optimize our marketing efforts. This role requires an individual with a strong ability to communicate and collaborate across functional teams, in addition to outstanding analytical and critical thinking skills. The role will have a strong focus on experimental design.\n\nResponsibilities:\nDirectly impact resource allocation decisions by designing and directing experiments and observational studies\nPartner with the marketing and business strategy teams to define and test hypotheses that answer critical business questions\nPerform deep-dive statistical analysis on large, complex, multi-dimensional datasets.\nDevelop and contribute to a base of understanding that allows us to make optimal resource allocation decisions\nQualifications:\nAdvanced degree (MS, Ph.D.) in quantitative fields, and 2-3 years of experience with a range of techniques, tools, and methods related to data mining and statistical analysis\nStrong ability with a statistical language such as R, Python or SAS, and hands-on experience using a variety of analytical methods\nExperience with or strong working knowledge of experimental design concepts, regardless of industry/discipline\nHands-on experience with SQL, working knowledge of database design\nFamiliarity with internet marketing data collection methods and marketing technology, including search marketing, social marketing, and ad serving platforms\nCreative mind with strong communication and interpersonal skills; talented with simplifying abstract business issues and large amounts of data into actionable analyses; must be able to interact with diverse groups of technical and non-technical people\nTrack record of contributing to successful end-to-end analytic solutions (clarifying business objectives and hypotheses, communicating project deliverables and timelines, and informing action based on findings)\nStrong desire to articulate business recommendations based on analytical work\nThis position is full-time and based in Redwood City, CA\nApply Now: click Apply Now"}, "254": {"company": "TransUnion", "description": "What We'll Bring:\n\nWhat We'll Bring:\n\nAt TransUnion, we have a welcoming and energetic environment that encourages collaboration and innovation \u2013 we\u2019re consistently exploring new technologies and tools to be agile. This environment gives our people the opportunity to hone current skills and build new capabilities, while discovering their genius.\n\nCome be a part of our team \u2013 you\u2019ll work with great people, pioneering products and cutting-edge technology\n\nWhat You'll Bring:\nYou come in with 1-2 years of academic or professional analytical or modeling experience with solid knowledge of statistical methods such as GLM and machine learning techniques such as random forest, GBM, XGBoost, etc.\nAdvanced proficiency with one or more statistical programming languages such as R, Python, or H2O\nIntellectual curiosity and experience writing intermediate or advanced SQL queries for data extraction\nAbility to clearly articulate ideas to both technical and non-technical audiences\nYour strong project management and time management skills including the ability to prioritize and contribute to multiple assignments simultaneously, setting clear goals, and managing customer expectations\nYou have an advanced degree in fields of quantitative discipline such as Statistics, Analytics, or any STEM field\nWhat we love to see:\nPrior Marketing Analytics experience\nStrong data visualization skills\nExperience working with large data sets and tools such as Hive, Pig, Apache Spark, etc.\nImpact You'll Make:\n\nImpact You'll Make:\nParticipate in insurance analytics tool development projects\nCollaborate with internal and external partners to develop advanced analytical solutions for insurance marketing and retention\nContribute to projects involving descriptive, predictive, and prescriptive analysis leveraging a variety of techniques\nLead small projects and/ or work streams as a part of larger projects\nExtract insights from large data sets using languages such as R, SAS, SQL, and Python\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.\n\nTransUnion's Internal Job Title:\n\nAnalyst, Data Science and Analytics\nApply Now: click Apply Now"}, "255": {"company": "Strategic Financial Solutions", "description": "Do you love numbers and finding the story in the numbers? Does the thought of tackling a complex data issue make you smile? Have you got a knack for solving problems? Do you want to help drive the results of a multi-million dollar business? If you have answered \"yes\" to these questions, the Data Scientist position at Strategic Financial Solutions may be the right fit for you.\nStrategic is looking for an experienced Data Scientist with statistical and machine learning experience to join our Data Science Team, which produces models for prescriptive and predictive analytics. The person in this role would be responsible for conducting data analysis and developing predictive models by leveraging data science and machine learning to solve various business use cases, including marketing intelligence, customer segmentation, and predictive models for operations.\nThis is a great opportunity for someone who wants to learn all aspects of business as he/she will support our product, sales, leadership and marketing teams with insights gained from analyzing company and external data.\nCandidates must have strong experience in a variety of data manipulation tools, data analysis/ mining methods to build and implement models and should be able to develop algorithms and simulation methods. A successful candidate will have the proven ability to drive business results with their data-based insights.\nResponsibilities\nResearch and develop statistical and machine learning methodologies to solve complicated business problems\nWork with stakeholders to identify opportunities by leveraging large data sets to drive business decisions. Collaborate with sales, marketing and senior executive teams for model development\nStrong communication skills and ability to clearly present ideas and technical findings to key decision makers\nQualifications\nKnowledge of statistical and machine learning techniques in regressions and classifications such as generalized linear models, classification trees, Random Forest, XGBoost, SVMs etc. Industry experience in such areas a definite plus.\nKnowledge of stochastic process in terms of transaction matrix and equilibrium distribution, etc.\nExperience in R, Python, and SQL, etc. and in variable selection and dimension reduction skills such as LASSO and PCA\nStrong problem-solving skills with an emphasis on financial risk management in sales and marketing predictive analytics\nUnsupervised learning experience such as k-means, hierarchical clustering, Bayesian network etc.\nExcellent written and verbal communication skills for coordinating across teams\nGraduate degree in Statistics, Data Science, Applied Math, Operations Research, Computer Science or other areas in STEM. Exceptional candidates with undergraduate degree will be also be seriously considered.\nAbout Strategic:\nStrategic Financial Solutions is a leading consumer finance company that specializes in helping people that have too much credit card debt. We were recently named the 21st Best Company to Work for in New York by Best Companies to Work For and have been certified as a Great Place to Work 4 times. Additional honors include being named, two times, as one of the 50 fastest growing companies in New York City and to the prestigious Inc. 500 list as one of the 500 fastest growing companies in the United States.\nApply Now: click Easy Apply"}, "256": {"company": "Genentech", "description": "The Position\nPurpose\n\nAs a Data Scientist/Senior Data Scientist within our Personalized HealthCare function you will work with meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access.\n\nYou will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions. The data will be varied in type -- patient-level clinical data, supplemented with deep patient data such as omics (e.g. genomics, proteomic), imaging, digital health, etc. Source data will be diverse -- real-world data, including patient registries, electronic medical records, claims, biobanks, and clinical trials. The evidence and insights will be used to inform the research and development of our molecules, and support healthcare decisions by patients, physicians, health authorities, payers, and policy-makers. You will also contribute to functional, cross- functional, enterprise-wide or external initiatives that shape our business and healthcare environments. This will require a good understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical data science expertise. You will need strong strategic, collaboration and communication skills, as well as an entrepreneurial mindset, to transform the way we use data and analytics to develop and deliver medicines for our patients.\n\nAs Senior Data Scientist you will typically be expected to contribute to the molecule/disease area for multiple or complex projects with minimal supervision. You will contribute to the development of new concepts, techniques, and standards.\n\nWe will look to you as a positive role model for peers and you will coach colleagues to improve in their role with both technical and interpersonal skills.\n\nResponsibilities\nIDENTIFY EVIDENCE NEEDS & RECOMMEND DATA SOLUTIONS: Ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.\nDEVELOP DATA STRATEGY & GAIN ACCESS TO DATA: Develop strategic plans to access fit-for-purpose data sources to support evidence generation, and gain access to data through collaboration or data generation.\nDIVE INTO DATA: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.\nBE AN EXPERT IN APPLYING METHODS: Stay current with and adopt emergent analytical methodologies, tools and applications to ensure fit-for-purpose and impactful approaches.\nPRODUCE HIGH QUALITY ANALYSES: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to maximize impact and interpretability; implement and/or oversee the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.\nINTERPRET AND SHARE RESULTS: Communicate findings to internal stakeholders, regulatory, health technology assessment (HTA) bodies and scientific communities; publish results; participate in external meetings and forums to present your insights (e.g. congress/conference).\nCOLLABORATE & SHAPE: Collaborate and contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaboratives, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.\n\nQualifications\nMSc, PhD or similar qualification in a quantitative data science discipline (e.g., statistics/ biostatistics, epidemiology, bioinformatics, health economics, computational biology, computer science, mathematics, outcomes research, public health, biology, medicine, psychology) with at least 2 years (if PhD) and 3+ years relevant work experience\nDemonstrated track record of developing and execution of data science research projects, patient-level data analyses (e.g., real world data, surveys, clinical trials, registries, claims, genomic or imaging data) with publications and presentations\nDemonstrated experience with managing project scope and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges\nDemonstrated strong collaboration skills and excellent communication skills\nDemonstrated entrepreneurial mindset and self-direction, ability to teach others and willingness to learn new techniques\nProficiency in English, both written and verbal\nTrack record of effectively working in a matrix environment with global, international team members coming from scientific, business and operational backgrounds, using influence without authority\nFluency in statistical programming languages (R, Python, etc.)\nExperience implementing advanced analytics approaches (machine learning, longitudinal data analysis, etc.)\nExperience with technologies required to undertake analyses on large data sources or with computationally intensive steps (SQL, parallelization, Hadoop, Spark, etc.)\nExperience producing interactive outputs (Shiny, etc.)\nContributor to open source packages, libraries or functions\nExperience implementing reproducible research practices like version control (e.g., using Git) and literate programming\nExperience analyzing RWD (non- interventional studies, electronic medical records, claims, disease registries etc.) is essential. Additional data types, such as omics (next generation sequencing data, proteomics, etc.) also desired.\n\nWho We Are\n\n\nA member of the Roche Group, Genentech has been at the forefront of the biotechnology industry for more than 40 years, using human genetic information to develop novel medicines for serious and life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious illnesses. Please take this opportunity to learn about Genentech where we believe that our employees are our most important asset & are dedicated to remaining a great place to work.\n\nThe next step is yours. To apply today, click on the \"Apply online\" button.\n\nGenentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.\nStart your job application: click Apply Now"}, "257": {"company": "VideoAmp", "description": "At VideoAmp, we are looking for a Senior Data Engineer who will be responsible for supporting our engineer team. You are passionate about all things data and tech, and have extensive knowledge of the digital space. You are accomplished in the areas of data engineering and you are ready to support the strategic objectives of a highly functional organization. This role would be based in our Los Angeles office.\n\nResponsibilities:\nYou will be involved in the design, development, deployment, and testing processes for new products. Our platform provides disruptive insights and optimizes the efficacy of our client\u2019s ad campaigns.\nYou will be a core member of our engineering team and will have a major impact on new initiatives. We\u2019re mindful of how the time and space complexities of the small parts greatly affect our services at scale and we need your help to build responsive systems.\nYou will help build, test, benchmark, and tune our distributed systems to ensure that our product is scalable, responsive, robust, cost-effective, and correct.\nQualifications:\n\nYou\u2019ll need 5 years of hands-on coding experience - Python or Scala preferred:\nExperience working with Spark, Hadoop, or other big data processing platform in high-volume environments\nA solid and demonstrable understanding of ETL workflows and data warehousing\nExperience with high-performance, low-latency, distributed systems\nSQL fluency and an understanding of relational data models\nExperience optimizing queries and developing stored procedure\nBuilding out Spark apps to support new product development\nBuilding data models to support new functionality\nBuild data pipelines to analyze, scrub, and integrate first and third party data\nProductionalizing data science models\nCoordinating data models with other engineering teams\nTuning and optimizing Spark apps to get the most out of the quickly evolving platform\nPerks:\nCompetitive compensation\nComprehensive health benefits\nMeaningful equity\n401k\nUnlimited vacation with a stipend for travel and accommodations of $2,000/year\nUnlimited in-office gym use with personal trainer\nChildcare stipend\nPlenty of snacks and beverages\nPersonal and professional development\nEpic growth\nABOUT\n\nAt VideoAmp, we believe in challenging advertising paradigms to maximize value for clients. We do this by enabling companies to execute on business outcomes across their media investment instead of more traditional media metrics. VideoAmp is the software and data solutions company powering the convergence of the linear TV and digital video advertising. Our solutions connect linear TV viewership with addressable data assets to benefit the marketing and media industries. This enable marketers and content owners to holistically plan, transact, and measure deduplicated audiences across digital video, OTT, connected and linear TV advertising.\n\nCome and join us!\nStart your job application: click Apply Now"}, "258": {"company": "CardinalCommerce", "description": "Let's face it. Everyone prefers shopping in their pajamas at home over traveling to the mall. CardinalCommerce, a Visa company, works to make online shopping as safe and easy as possible. For over two decades, we've been bringing merchants, issuers, and shoppers together in an experience where everybody wins. With singular focus, proven technology, and dedicated service, we are continuously raising the bar for payment authentication around the world. We put authentication first because we believe digital commerce should be safe, rewarding and engaging for everyone involved in the process.\n\nJoin us on this journey. At Cardinal, we're a group of genuine, dependable, and hardworking people who are treated right with flexible work schedules, a fun company culture and unbeatable benefits. See why we're one of the leading FinTech companies in Northeast OH.\n\nAs a Senior Data Engineer, you are given the ability to work with large data sets using some of the newest technologies including Spark, Kafka, Airflow, Elasticsearch all in a cloud environment. You will aid in defining the vision and direction of the Data Engineering team, helping to move us toward near-real-time data consumption, anomaly detection and on-the-fly analysis.\n\nWhat You'll Do:\n\nYou are responsible for the consumption of data from a variety of sources to a variety of end storage locations, maintaining a fast, efficient data pipeline, and supporting development, analytics and business teams in their data needs. You would be expected to stay current with best practices and tools in the industry and be able to assimilate new technologies quickly.\n\nYou will be expected to develop, maintain and monitor ETL jobs and building systems to ease this work. The position will give you the opportunity to work with all groups in Cardinal to provide necessary data for their work and help them understand the underlying data to allow them to make data driven decisions.\n\nWhat we need you to have:\nMinimum of a Bachelor's degree in Computer Science, Information Systems or other related field\no In lieu of degree, a high school diploma/equivalent with four or more years related experience and/or training or equivalent combination of education and experience will be considered\n5+ years of experience in Java, Scala or Python\n2+ years of experience with Spark\n3+ years of experience with SQL\nStrong independent development skills\nWhat we would prefer you to have:\nExperience using Spark, developing in Python or Scala, knowledge of databases including warehousing and data lakes, strong development skills, ability to design solutions and communicate designs\nKafka experience as this is the future of our work and vital to our team vision\nStrong abilities in both Python and Scala, experience using and administering Kafka, experience using Elasticsearch, experience developing visualizations in Kibana and Grafana\nPhysical Requirements\n\nThis position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers, and reach with hands and arms.Cardinal/Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Cardinal/Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.\nApply Now: click Easy Apply"}, "259": {"company": "Oden Technologies", "description": "About Oden:\n\n\nWe are on the brink of the next industrial revolution.\n\nManufacturing has long been an analog world, but this is about to change. By introducing machines to the digital world, there\u2019s a staggering opportunity for efficiency and production leaps. Oden is driving this revolution. We\u2019re on a mission to eliminate waste in manufacturing.\n\nWe have combined industrial hardware, wireless connectivity, and big data architecture into one simple platform so all manufacturers can analyze and optimize their production, from any device. Efficiency, sustainability, and competitiveness are democratized.\n\nWhy We Do It:\n\n\nWe like to enable those who make things - to make more, to waste less, to serve their customers, and to thrive in a competitive world. Help enough makers, and the world can give us all the abundance we want for less cost and environmental impact. We\u2019re on the verge of a 4th industrial revolution that begs for absolute efficiency in all factors of life. We plan to deliver that to everyone who makes things. Check out some of our team members discussing life at Oden: Oden's Culture of Empowerment and Impact\n\nYou:\nAre able to empathize with others and distill a mission into communications and strategic campaigns.\nCare about the mission of the product and company.\nHave a curious mind and excited about learning more about the industrial world and manufacturing.\nInnovative. You are not afraid to tackle new projects and take creative risks.\nLive by transparent and scientific thinking. You put in the work to find the best ideas with those around you, without ego.\nThe Role:\n\n\nAs Oden\u2019s Business Intelligence Analyst, you will work directly with the Chief Operating Officer to identify key data points that influence decision making in the company\u2019s operations through the management of and creation of unique operational reports and dashboards. This role will be crucial to Oden\u2019s operations and will play an important part in how we scale as the company continues to grow.\n\nResponsibilities:\nQuery, refine and manage large data sets from multiple sources such as our proprietary operational platform, our CRM tool, etc.\nGather intelligence on key operational and financial metrics\nCollaborate with company executives, sales team and operational team members to understand processes, identify strategic objectives and create unique operational reports and dashboards that track execution success\nRespond to direct requests for data and reporting from Chief Operating Officer and other senior-level executives\nUse data to illustrate information stories in various mediums (Google Sheets, Tableau, etc.) that aid in the development of key strategic initiatives and generate clear insights shared with company executives, industry professionals, and prospective investors\nMinimum Qualifications\nAbility to merge / combine mixed data from disparate sources\nAbility to query reports from SQL databases or familiarity with relational database concepts\nStrong Excel skills\nKnowledge generating financial, sales, and other operational reports\nExperience with scripting languages, such as Python or R, or visualization software, such as Tableau or Qlik, will be taken into consideration\nWhat We Offer You:\n\n\nMeasurable impact on the world and the chance to help real people - family businesses, entrepreneurs, engineers.\nExposure to many tech disciplines, most of which are rapidly evolving.\nA bridge between the physical and cloud worlds of tech. Our platform unites big data visualizations with sensors and heavy industrial equipment.\nA platform that has the potential to evolve beyond what we have envisioned now.\nScientific and transparent thinking, for everyone involved.\nBacking by world leaders of both industry and tech that will ensure long term growth and development for us.\nWe\u2019re an equal opportunity employer (EOE).\n\nDiversity at Oden means building a team that is rich across all boundaries of race, ethnicity, gender identification, sexual orientation, disability, religion, age and thinking style. We welcome all backgrounds, life experiences, and worldviews as this is the catalyst for the rapid evolution of our product and our organization. Diversity allows us to tackle new challenges, embrace change, make well-informed decisions, and ultimately Make Things Better. In alignment with our \u201cPeople First\u201d company value, Oden has a passionate internal team dedicated to the promotion of diversity and inclusion initiatives as a core component of our culture.\n\nOur diversity initiatives apply to our practices and policies on recruiting, compensation and benefits; professional development; promotions; social activities and the ongoing development of a psychologically safe work environment.\nApply Now: click Easy Apply"}, "260": {"company": "Wells Fargo", "description": "Job Description\n\nAt Wells Fargo, we want to satisfy our customers financial needs and help them succeed financially. Were looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where youll feel valued and inspired to contribute your unique skills and experience.\n\nHelp us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.\n\nWells Fargo Technology sets IT strategy; enhances the design, development, and operations of our systems; optimizes the Wells Fargo infrastructure footprint; provides information security; and enables continuous banking access through in-store, online, ATM, and other channels to Wells Fargos more than 70 million global customers.\n\nResponsible for very complex partner assignments to identify and define strategic business issues that require analyses and translates this information into insight, knowledge and understanding of the business and the industry. Consults and performs very complex analyses/ analysis design involving data mining from multiple sources and/or predictive modeling, regression/multivariate, financial, comparative analysis, customer/demographic analysis, etc. Analytics involved generally span multiple functional areas/business lines/data sources. Responsibilities also include identifying opportunities for additional statistical models and/or creating sophisticated computer modeling approaches to analyze and forecast business performance; participating in and/or leading management information capabilities development work; interpreting and presenting results of analyses and recommendations to senior management. Ensures adherence to data management/data governance regulations and policies. Data involved may be very large, structured or unstructured, and from multiple sources. To a certain degree, may be involved directly or indirectly in the technical build-out\nand/or support of databases, query tools, reporting tools, BI tools, dashboards, etc that enable analysis, modeling, and/or data visualization. Leads project/virtual teams & mentors lower level staff.\n\nRequired Qualifications\n6+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 4+ years of experience in one or a combination of the following: reporting, analytics, or modeling\n3+ years of Teradata experience\nDesired Qualifications\nExtensive knowledge and understanding of research and analysis\nStrong analytical skills with high attention to detail and accuracy\nExcellent verbal, written, and interpersonal communication skills\n3+ years of Tableau experience\nKnowledge and understanding of .net\n1+ year of UNIX experience\nOther Desired Qualifications\nFinancial services industry experience\nExperience as data analyst in Wholesale or Wholesale line of business.\n1+ year of experience with other database like SQL server and Oracle.\nAbility to translate and summarize complex data into understandable, actionable information and recommendations\nAbility to prioritize work, meet deadlines, achieve goals, and work under pressure in a dynamic and complex environment\nJob Expectations\nAbility to travel up to 5% of the time\nDisclaimer\nAll offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.\n\nRelevant military experience is considered for veterans and transitioning service men and women.\nWells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.\nTECHNOLOGY\nApply Now: click Apply Now"}, "261": {"company": "Dailymotion", "description": "Company Description\n\nDailymotion is the leading video discovery destination & technology that learns about your tastes over time, constantly surfacing the best, most relevant content on the web. Our mission is to provide the best video user experience for consumers on the market, connecting publishers and advertisers to engaged viewers who turn to Dailymotion for their daily fix of the most compelling music, entertainment, news and sports content around.\n\nThrough partnerships with the world's leading publishers and content creators, including CBS, CNN, Fox Sports, GQ, Mashable, Universal Music Group, VICE and more, Dailymotion commands 4 billion monthly pageviews across its mobile app, desktop and connected TV experiences. Dailymotion is owned by Vivendi, one of the largest mass-media corporations in the world.\n\nAs part of our growing activities, we have built our own ad stack (SSP) to enhance our programmatic advertising capabilities, deliver new monetization solutions for our ecosystem of online, mobile and TV, and provide innovative marketing solutions for advertisers.\n\nJob Description\n\nAre you someone with a passion for digging into large distributed pools of data, unearthing insights, and transforming them into a visually compelling form that appeals both to technical and non-technical audiences? Then this is the job for you!\n\nOn a daily basis, you will be responsible for:\nPerforming data analysis on products managed by Dailymotion\u2019s AdTech tribe, including our SSP that serves billions of requests daily, and extract actionable insights that will be used to drive decisions across the business\nStatistically validating and A/B testing hypotheses generated by Business, Product and Data Science teams.\nDriving the collection of new data that would help build the next generation of algorithms (E.g. audience segmentation, contextual targeting, bidder behavior monitoring)\nBuilding easy to use dashboards (E.g. Tableau) to help visualize insights and KPIs interactively\nAutomating analysis into monitoring and alerting tools to continuously drive value for business owners\nProactively owning the end-to-end delivery of projects, from design, to development, testing, and operations.\nQualifications\nBachelor\u2019s degree, or higher, in Business, Finance, Statistics, or related field.\n3 years of business / data analysis experience\nPrevious ad-tech experience (required)\nExtensive experience solving analytical problems using quantitative approaches\nComfortable with manipulation and analysis of complex, high volume, high dimensional data from varying sources (E.g. SQL, AWS/GCP, Excel)\nSolid Experience of Data Visualization Tools (E.g. Tableau suite)\nStrong intellectual curiosity and ability to structure and solve difficult problems with minimal supervision\nAbility to communicate complex quantitative analysis in a clear, precise and actionable manner in English. French is a plus.\nA background in Machine Learning and Statistics is a plus\nProgramming in Python is a plus\nAdditional Information\n\nLocation: New York\nType of contract: Full-time\nStart Date: ASAP\n\n\u2022 Flexible time off, vacation, holidays, sick-leave so you can take time off when you need to\n\u2022 Fitness club membership to NY Health & Racquet Club\n\u2022 100% healthcare coverage starting on day 1\n\u2022 Commuter benefits\n\u2022 401k Contribution\n\u2022 Paid parental leave\n\u2022 Fully stocked kitchens with free snacks and drinks\n\nIf you want to explore Dailymotion culture a little further please check out:\n\n1./ Our BuiltIn page: https://www.builtinnyc.com/company/dailymotion\n\n2./ Our Recent Global Hackathon in November 2018. https://www.dailymotion.com/video/x70val9\n\n3./ Welcome to the Jungle page: https://www.welcometothejungle.co/companies/dailymotion/team\n\nDailymotion is a global champion of diversity and inclusion. We pride ourselves in being an equal opportunity employer that provides an environment of mutual respect\nApply Now: click Apply Now"}, "262": {"company": "Juvo", "description": "Juvo was founded with an overarching mission: to establish financial identities for the billions of people worldwide who are creditworthy, yet financially excluded. In partnership with mobile network operators, Juvo's proprietary Identity Scoring technology uses data science, machine learning and game mechanics to create an identity-based relationship with anonymous prepaid users, opening up access to otherwise unattainable mobile financial services.\n\nSince emerging from stealth in September 2016, Juvo has increased its global reach five times over, from 100 million to 500 million, and has steadily grown its operations and employee base worldwide with 100 employees today. To date, Juvo has enabled over 400M transactions in 25 countries and 4 continents, with 1M active subscribers a day. Juvo's mobile operator partners include Telefonica, Millicom, Sprint, Deutsche Telekom and Cable & Wireless.\n\nIn 2017, Juvo completed a $40 million USD Series B funding round with funding from Samsung NEXT and top-tier VCs including NEA, Wing Venture, and Freestyle Capital. Early investors in the company include the former CEOs of AT&T Wireless, NYSE, Sprint, Telefonica International and Vodafone Group. Juvo is frequently profiled in top tier tech and business press and our proprietary technology, Identity Scoring, is award winning.\n\nAbout the Job\n\nWe are looking for a talented Senior Data Scientist with a minimum of seven years of experience to help Juvo convert user data into personalized credit scores. You will play a central role not only in ensuring Juvo's success, but improving the financial landscape of millions, if not billions of people. As you lead key Data Science and platform initiatives, you will play a major role in the planning and construction of Juvo's technical stack.\n\nQualifications\nMS/PhD in a quantitative field e.g., Physics, Astronomy, Chemistry, CS, Math or have worked in Data Science, Quantitative Research or Software Development for 7 years.\nComfortable in Unix computing environments and have a handful of your favorite BASH tricks. You are fluent in one or more of the following programming languages: Python, Scala, R, Java.\nFamiliar with distributed computing frameworks such as Hadoop, Spark, Hive.\nYou know your way around AWS and regularly use one or more of their services e.g., S3, EC2, EMR, Redshift, DynamoDB, Kinesis, etc.\nYou like working in a fast-paced collaborative environment where the mantra is to push to master, make sure it makes sense...and doesn't break!\nPerks & Recreation\nWork towards a mission that matters \u2013 join us in creating the YES economy\nCompetitive cash and equity compensation\nGreat medical/dental/vision benefits, with dependent coverage\nPre-tax commuter benefits\n401(k) available\nPaid holidays and flexible paid time off\nMonthly reimbursement for internet or mobile phones\nConveniently located office in the Financial District of San Francisco\nFully stocked kitchens with organic and healthy snacks\nWeekly catered lunch\nYour choice of the best and newest tech (Apple products, Sennheiser Noise Canceling headphones, Stand-up desks, etc)\nEmployee discount on Samsung products (Samsung is an investor)!\nJuvo is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Juvo is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.\nApply Now: click Apply Now"}, "263": {"company": "Mirion", "description": "POSITION SUMMARY\nOperate Canberra Gamma systems and NDA systems. Review data and prepare reports.\n\nESSENTIAL DUTIES:\n\n\u00b7 Operate Gamma spectroscopy systems.\n\u00b7 Operate NDA waste assay systems.\n\u00b7 Analyze data and prepare NDA results reports for final review by scientist or senior scientist, as applicable.\n\u00b7 Perform measurement control activities.\n\u00b7 Perform Independent Technical Review (ITR) of data.\n\nADDITIONAL DUTIES:\n\n\u00b7 Assist in performing field measurements and field assessments.\n\u00b7 Assist in NDA system maintenance.\n\nESSENTIAL REQUIREMENTS:\n\u00b7 Understanding of waste system theory and operation.\n\u00b7 Understanding of operation of NDA systems.\n\u00b7 Proficient in communication and drafting of reports for customer use.\n\u00b7 Proficient in use of computers.\n\nADDITIONAL REQUIREMENTS:\n\u00b7 Able to work in extreme temperatures for extended periods of time - As Required.\n\u00b7 Capable of successfully completing contractor/customer required training - As Required.\n\u00b7 Capable of maintaining work site access requirements - As Required.\n\nEXPERIENCE AND EDUCATIONAL REQUIREMENTS\n\u00b7 6 months to 1 year nuclear related experience.\n\u00b7 High School or equivalent technical training, OR 2 years nuclear related experience.\n\nStart your job application: click Easy Apply"}, "264": {"company": "Tapjoy", "description": "Join the Mobile Future with Tapjoy\n\nTapjoy is a creative workplace, comprised of people with different backgrounds, cultures, skill sets, and global perspectives. With offices all over the globe, Tapjoy provides mobile engagement and monetization services for leading advertisers and app developers. Advertisers rely on Tapjoy's diverse suite of rewarded Interplay ads including video and rich media to impact performance. Developers utilize our technology and mobile expertise to acquire and monetize users. The Tapjoy SDK is currently embedded in over 20,000 mobile apps, reaching 620 million monthly active users. Additionally, Tapjoy works with Fortune 500 brands and the Top 200 grossing app developers.\n\nHere at Tapjoy, we promote a Joyful, Engaged, Trustworthy, and Innovative workplace with our company core values, and regularly celebrate and recognize the people who embody our values. Tapjoy believes its people are its greatest investments and we take extra care to support your time inside and outside of work with a multitude of benefits. In order to maintain what makes us so special here, we are committed to continued education and involvement in our community to protect and expand our one-of-a-kind workplace.\n\nPosition Title: Staff Data Scientist\n\nPosition Description/Responsibilities:\n\nEssential duties and responsibilities may include, but are not limited to, the following as additional roles and/or focus will be needed as the company and department continues to grow and evolve:\nBuild a data/stats-driven ad machine learning models, working closely with the product team\nConstantly experiment and improve machine learning models for the recommendation/ad optimization system\nInvent and analyze big data for given business cases and help implement them in production\nWork with the product/engineering team to implement, test and deploy the solution on Google Cloud Platform Core\nCompetencies:\nPassionate about machine learning and big data\nGreat Communicator about complex algorithmic works as easy-to-understand story telling\nMotivated to test at billions scaled data and follow up machine learning models in product\nRequirements:\nPh. D in Computer Science or Statistics or similar working experience applied technical field five years or more.\nMust be hands-on Machine-learning related industry projects\nSolid programming skill of scripting language Python\nAbility to work in a fast paced, test-driven collaborative and iterative programming environment\nUnderstand major recommendation algorithms (Collaborative Filtering, Matrix factorization, Gradient Boosting, etc.)\nSolid understanding of Algorithms, Data Structures and Machine Learning / Data Mining\nUnderstanding of RDBMS, SQL and NoSQL alternatives\nUnderstand various ad optimization algorithms (CTR prediction, eCPM optimization, user targeting and segmentation, RTB and real-time optimization) is a plus\nExperience with Hadoop/Hbase/Pig or PySpark is a plus\nCore Competencies include:\n\nRequirements:\n\nTapjoy is a one-of-a-kind workplace, comprised of people with different backgrounds, cultures, skill sets and global perspectives. In order to maintain what makes us so special here, we support work-life balance both inside and outside the office in many ways.\n\nIf you want to learn about building an amazing team with industry-leading technology, you want to surround yourself with brilliant, passionate entrepreneurial teammates at Tapjoy.\n\nTapjoy is an equal opportunity employer. We believe that diversity and inclusion lead to stronger, more innovative teams and better business results; we want to draw from the broadest talent pool possible and encourage qualified applicants. Tapjoy does not discriminate on the basis of sex, race, ethnicity, color, age, sexual orientation, gender (including identity and expression), disability (mental or physical), religion, national origin, citizenship, marital status, military or veteran status, or any other protected classification protected by applicable law; we will provide reasonable accommodations for qualified individuals with disabilities, and pursuant to applicable fair chance ordinances, we will consider for employment qualified applicants with arrest and conviction records.\n\nFor more information, please visit www.tapjoy.com.\n\n]]>\nTo apply to this job, click Apply Now"}, "265": {"company": "Varen Technologies", "description": "At Varen, our performance is measured by the success of our clients, and our reputation for service, superior quality, objectivity, integrity and results. Our reputation is everything to us as we are committed to being a trusteisor to our nations decision makers in a day in age that demands acute attention to detail in a fast-paced environment. Varen is sed adveking to add the sharpest technical professionals who share our passion for ensuring the mission success of our customers at all times.\n\nPOSITION DESCRIPTION:\n\n\nVaren is seeking candidates with analytics expertise to help realize a program that measures organizational drivers of success and focuses on data driven decisions. The candidate(s) shall support the analytics team in identifying and developing actionable insights through problem definition, application of statistical models, and analysis against existing and future data. They will collect and convey information about language acquisition, maintenance and testing to improve the language and learning function at an Enterprise level. This foreign language related data will be displayed in the Personalized Language Dashboard and the upcoming Language Lifecycle tool. This team will provide language analytics using innovative research methodologies and tools to enable stakeholder decisions, increase the quality and effectiveness of Learning Enterprise (LE) products and services, establish relationships between the LE and mission execution, implement data collection and data visualization tools, and produce internal/external reporting.\n\nREQUIRED EXPERIENCE:\n\nDemonstrated experience designing and conducting research to answer key business questions, to include structured interviews, focus groups, and surveys.\nDemonstrated experience identifying metrics of relevance to leadership and aligned with organizational strategy.\nDemonstrated experience deriving insights from data and presenting conclusions to non-technical audiences.\nDemonstrated experience identifying and obtaining datasets needed to answer key business questions.\nDemonstrated experience visualizing data and conveying complex research findings in both written and oral formats to stakeholders at all levels.\nDESIRED EXPERIENCE:\n\nFamiliarity with Sponsors data systems as they relate to foreign language acquisition and maintenance, human resources (HR) or learning.\nExperience leveraging programming languages to script the extraction, formatting and transformation of data from a wide variety of organizational systems.\nDemonstrated experience working in a learning environment.\nDemonstrated experience working across Sponsor units effectively in support of an end goal.\nCLEARANCE REQUIREMENT:\n\nTS/SCI clearance in JPAS is required\n\nStart your job application: click Apply Now"}, "266": {"company": "OTR Capital", "description": "Do you want to work for one of the fastest growing companies in Atlanta? One that makes a difference on a daily basis? Do you have outstanding customer service skills with a thirst for knowledge? Then we want you to join our team! OTR Capital is a fun, fast-paced and a rewarding company that provides factoring services in the transportation industry where customers always come first.\n\nAs a Business Intelligence Analyst, you will have the opportunity to make meaningful contributions to OTR, build your expertise, analyze robust data sets, and contribute to long-term company growth. The BIA's responsibilities include conducting full lifecycle analysis to include requirements, activities and design. The BIA will work deeply with our proprietary software, as well as numerous 3rd party applications utilized by OTR. They will also monitor performance and quality control plans to identify improvements.\nInterpret data, analyze results using statistical techniques and provide ongoing reports\nDevelop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality\nAcquire data from primary or secondary data sources\nIdentify, analyze, and interpret trends or patterns in complex data sets\nFilter and \"clean\" data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems\nWork with management to prioritize business and information needs\nLocate and define new process improvement opportunities\n\n\nWhat we look for:\nBachelor's degree in MIS or Business\nStrong analytical/quantitative skills and excellent problem solving skills\nA strong team player who communicates well, is proactive, responsive and can thrive in a team environment\nKnowledge of SQL, ABBYY, RPA principles, UiPath a plus but not required\nAdvanced MS Office skills (with an emphasis on Excel) and related computer knowledge\nOrganization and effectiveness under pressure with the ability to clearly communicate issues to all levels of management\nOne-of-a-Kind Culture\n\nThe unique culture at OTR Capital is pretty hard to beat, where innovation and a hard-working environment go hand-in-hand with a casual and fun atmosphere. We promote an energetic and team-oriented workplace where collaboration and a results-driven attitude is key to our success. We dress comfortably and play music while we work - we want you to feel your best so you can do your best!\n\nDon't forget our core values:\nAlways put the customer first\nDisplay the highest level of integrity\nDemonstrate respect for others\nPossess a \"do whatever it takes\" attitude\nWork in a fun and rewarding atmosphere\nThink creatively and innovate\nEnjoy working in a collaborative, team-oriented environment\nAre resourceful and results driven\n\n\nOur Benefits:\n\nOTR Capital, LLC provides a competitive and comprehensive compensation package for our full time employees. Our benefits include:\nCompetitive Benefits\nLife / AD&D Insurance\n401(k) with Company Matching\n12 days of Paid Time Off, 3 sick days, 7 paid holidays\nCompany Paid Fitness Membership\nAbout Us\n\nDelivering Solutions. Driving Success.\n\nOTR Capital is a factoring company dedicated to offering timely, working capital solutions to transportation companies in the freight industry. We believe in straightforward, quick, easy, and reliable transactions, without hidden costs and unfair termination fees and rules. OTR Capital is focused on helping companies meet their cash flow needs and succeed in their business model while providing the best customer service and factoring experience in our industry. Established in 2011, OTR has experienced significant growth and expanded to two offices in Roswell, GA and Denver, CO. For two consecutive years, OTR Capital ranked on the Inc. 500/5000 list as one of the fastest-growing, privately-owner companies in America (2016, 2017). OTR has been recognized as a \"Top Workplace\" (2016, 2017, 2018, 2019) by the Atlanta Journal-Constitution and also won two Pacesetter Awards (2015, 2016) from the Atlanta Business Chronicle as one of Atlanta's fastest growing businesses.\n\nOTR Capital is an Equal Opportunity Employer\nStart your job application: click Apply Now"}, "267": {"company": "Science 37", "description": "Science 37 is accelerating the research and development of breakthrough biomedical treatments by bringing clinical trials to patients' homes. Backed by venture investors such as Glynn Capital, Google Ventures, Redmile Group, dRx Capital and Lux Capital, we are seeking a razor-sharp Data Scientist eager to make an impact within a mission-driven organization changing the world of clinical research.\n\nAs part of the Science 37 Tech team, you will collaborate with motivated, energetic, and entrepreneurial individuals working together to achieve Science 37's mission of changing the world of clinical research through patient-centered design. You will have a hands-on role with the architecture and development of NORA\u00ae (Network Oriented Research Assistant), the technology that enables Science 37's groundbreaking Metasite\u2122 clinical research model and collaborates with Product, Data, Clinical Operations, and other relevant stakeholders to define study specific NORA requirements.\n\nResponsibilities\n\nDuties include but are not limited to:\nUnderstand business stakeholders' needs and translate those into a data insights program with solutions for each stakeholder\nDeliver on data analytics and insights by planning and performing end-to-end analysis: including aggregating and processing data, exploring data, building and validating predictive models, and presenting to business.\nAnalyze our existing data model/structure and provide recommendations to the Tech team for optimization to support our data strategy\nDesign and implement statistical algorithms and predictive analysis\nExplain data analytics and data science findings and machine learning models to internal and external stakeholders\nWork with Data Analysts, Product Managers and Software Engineers to gather data insight requirements, set goals and influence the product roadmap.\nMinimum Qualifications\nB.S. or M.S. in computer science, Mathematics, Statistics, Physics, Economics or equivalent experience\n4+ years of industry experience in predictive analysis and modeling, data analysis and science\n3+ years of industry experience in data analytics\nKnowledge of data engineering, database architecture and ETL process\nExperience building ML models\nProficient in either Python or R or both.\nExperience using ML libraries such as scikit-learn, caret\nKnowledge of machine learning frameworks and toolsets\nExperience writing and optimizing SQL\nExperience using data visualization tools.\nExperience presenting data findings\nPreferred Qualifications\nPhD in computer science, Mathematics, Statistics, Physics, Economics, Bio-Engineering/Science field\n6+ years of industry experience in predictive analysis and modeling, data analysis and science\n4+ years of industry experience in data analytics\nProven ability to tackle business problems with data science solutions\nExpert programming skills in Python and/or R\nProficient programming skills in Javascript or JAVA\nAbility to develop analytic plans for data modeling process\nAbility to accurately determine correlations\nExperience with AWS data technologies such as Redshift, S3, Data Pipeline\nExperience with Tableau\nSkills and Competencies\nAbility to think critically\nAbility to translate business problems into data questions, create solutions and drive results\nAbility to aggregate and analyze data from multiple data sources and build a holistic view\nAbility to build clear visualizations to explain complex ideas and analysis result to executives and business unit leaders\nAbility to provide guidance to other program and project managers\nAbility to resolve conflicts and negotiate agreement\nAbility to proactively identify impediments in project/program delivery and craft solutions.\nAbility to set metrics for the project and program for performance and goals.\nCapabilities\nStrong written and oral communication skills\nReporting\nThe incumbent is required to work under the guidance and direction of the VP, Engineering with little to minimal supervision.\nDirect Reports\nNo direct reports\nScience 37 values the well-being of its employees and aims to provide team members with everything they need to succeed. Enjoy healthy catered lunches, snacks and beverages, and top-notch equipment such as the latest Macbook Pro, 4k monitors, and adjustable standing desks. Submit your resume to apply!\nApply Now: click Easy Apply"}, "268": {"company": "Presbyterian Healthcare Services", "description": "Overview\n\n\nJob Description Type of Opportunity: Full Time FTE: 1.000000 Exempt: Yes Work Schedule: Weekday Schedule Monday-Friday\n\nLocation: Cooper Center - Onsite\n\nSummary:Support portfolio management of reporting/analytics solutions across the business units in the analytics organization. Identify business issues/problems, form hypotheses, plan and conduct interviews, whiteboard sessions & perform reporting/analysis to synthesize conclusions, transform them into recommendations and develop a solution. Lead and manage small cross functional team to implement, test and deploy the approved reporting/analytics solution in response to the business (clinical/operational/financial) needs. Identify reporting/analytics improvement opportunities and provide proactive, consultative strategic solutions. Responsible for mentoring junior analysts as well as coordinating various reporting/analytics initiatives with end business users. Support reporting/analytics projects prioritization and planning as well as cconduct due diligence concerning business implications of planned solutions.\n\nResponsibilities\n\n\nConsultation and Communication:*Ability to collaborate and partner with management, project managers, and IT to develop, implement and manage reporting/analytics portfolio with the vision & goals of specific Hub/Spoke core teams*Effective communication skills across the organization and at different levels, strategic thinking and actions to influence key stakeholders and business decisions *Support day-to-day consultation to business users and participate and contribute cross-functional project teams*Work with business stakeholders to identify business needs and support creation of the use cases and user stories satisfying those needs Project Management and Execution:*Coordinate with other departments across the AO such as IM governance & EDW and support conceptualization and development of reporting/analytical methodologies, solutions and initiatives*Aid in the development of project plans and strategies as well as execute assigned project plans to deliver solutions in a timely manner*Support collaboration on roadmaps, dependencies, and execution plans across analytical units and with applicable teams in the organization *Manage the intake requests across the business units; track and monitor the work to ensure critical milestones are met, identify and report/escalate risks to management appropriately; manage stakeholder relations*Obtain data, direct/execute reporting/analysis, perform interpretations and conclusions, and prepare recommendations. *Assist in determining business needs by effectively conducting fact-finding interviews and leveraging various tools and analytical methods and then summarize findings in a coherent manner to develop and propose appropriate solution *Conduct research studies that include collecting data from various sources, analyzing, trending and presenting the findings and recommendations to management *Support translation of business requirements and unstructured business issues into data analytic problems*Perform overall program evaluations (i.e., planning-implementation-completion/analysis-reporting) and other assessments such as change management assessments, workflow optimization assessments, etc. Training and Guidance:*Manage and support teams to structure data and analysis to analyze issues and proactively identify improvement opportunities*Responsible for the work flow management of analysts and ensuring reliability, integrity, and timeliness of end products*Support coordination of training for analysts in core and expanded business departmentThought Leadership:*Support in development of presentations/publications/point-of-views with senior leadership within the AO *Contribute towards and assist senior leadership in developing a year-end value story to demonstrate value of the team and their contribution to progress towards the AOs and PHSs goals\n\nQualifications\n\n\nOther information:Bachelors degree in a quantitative, business, or healthcare related subject. A Masters degree is highly preferred. Four or more years of combined experience in business intelligence, reporting and analytics preferably in a healthcare setting. Demonstrated project management skills as well as the ability to efficiently work and manage teams and resources. Experience working on complex analytical projects with diverse teams and developing data driven and outcome based initiatives to improve business decision making and operational efficiencies. Knowledge of health plan and delivery system operations, health care informatics, and healthcare benefits and terminology (e.g., care management). Understanding of operations in the Health Care industry and a strong acumen of business processes, including operations, delivery models and revenue models. Understanding of program evaluation life cycle, predictive modeling, data mining, and clinical best practices preferred. Content knowledge related to program outcomes evaluation, BI tools (e.g., BO), data visualizations tools (e.g., Tableau), statistical software such as SAS and Modeling techniques, as well as general health service research and outcomes reporting/analytics. Working knowledge of healthcare industry and healthcare information standards such as HL7, LOINC, FHIR, ICD 9/10 and CPT codes, industry standard groupers (e.g., ETGs, DRGs, DCGs, etc.) as well as of health care delivery system processes. Excellent written and oral communications is a MUST.Preferred Qualifications:\nDemonstrated excellence in communication and presentation skills\nExperience consulting with physicians and executive leadership on their analytics requirements\nExperience with patient safety analytics (e.g., infections, complications, hospital acquired injuries)\nExperience with the Epic Clarity Data Model\nExperience with SAS, SQL, Tableau\nCompetencies and skills:Essential:* SKILL-Demonstrated ability to communicate effectively in person and via telephone with members, employer groups, brokers, physicians, and physician office staff using strong dialogue and customer service competencies. * SKILL-Written communication Nonessential:* Analytics skills* SKILL-Decision Making* SKILL-Project management methods and tools in support of managing Scope, Time, Cost, Quality, Communication, Risk, and Procurement Management;\n\nBenefits\n\n\nBenefits are effective day-one (for .45 FTE and above) and include:\nCompetitive salaries\nFull medical, dental and vision insurance\nFlexible spending accounts (FSAs)\nFree wellness programs\nPaid time off (PTO)\nRetirement plans, including matching employer contributions\nContinuing education and career development opportunities\nLife insurance and short/long term disability programs\nAbout Us Presbyterian Healthcare Services is a locally owned, not-for-profit healthcare system of nine hospitals, a statewide health plan and a growing multi-specialty medical group. Founded in New Mexico in 1908, it is the state's largest private employer with approximately 11,000 employees.\n\nPresbyterian's story is really the story of the remarkable people who have chosen to work here. Starting with Reverend Cooper who began our journey in 1908, the hard work of thousands of physicians, employees, board members, and other volunteers brought Presbyterian from a tiny tuberculosis sanatorium to a statewide healthcare system, serving more than 700,000 New Mexicans. We are part of New Mexico's history - and committed to its future. That is why we will continue to work just as hard and care just as deeply to serve New Mexico for years to come. About New Mexico New Mexico's unique blend of Spanish, Mexican and Native American influences contribute to a culturally rich lifestyle. Add in Albuquerque's International Balloon Fiesta, Los Alamos' nuclear scientists, Roswell's visitors from outer space, and Santa Fe's artists, and you get an eclectic mix of people, places and experiences that make this state great. Cities in New Mexico are continually ranked among the nation's best places to work and live by Forbes magazine, Kiplinger's Personal Finance, and other corporate and government relocation managers like Worldwide ERC. New Mexico offers endless recreational opportunities to explore, and enjoy an active lifestyle. Venture off the beaten path, challenge your body in the elements, or open yourself up to the expansive sky. From hiking, golfing and biking to skiing, snowboarding and boating, it's all available among our beautiful wonders of the west. AA/EOE/VET/DISABLED. PHS is a drug-free and tobacco-free employer with smoke free campuses.\n\nAD123\n\n#CB\nTo apply to this job, click Apply Now"}, "269": {"company": "Arcadia.io", "description": "In this position you will work with the Production Support team to provide our customers with expert level support of our big data analytics product. Working closely with our Application Analysts and Software Engineers, you will be responsible for troubleshooting and resolving requests reported by Arcadia's customers. You will leverage technologies such as SQL, Python, the Elastic Stack, JIRA, and others to solve complex big data problems.\n\nWhy do you want this job?\nThe opportunity to work for an amazing, fast-growing software company\nOpportunity to work with a highly scalable cloud platform\nYou seek a fun culture that encourages you to speak up and fosters creative thinking\nWork closely with and learn new technologies like Apache Spark/Nifi, the Elastic Stack and more to drive healthcare data integration projects\nYou enjoy working with customers and thrive as a team player\nYou want to use your skills to make an impact in healthcare\nWhat will you be doing?\nIdentify, document, triage and resolve systemic software, ETL, and configuration defects to ensure resolution\nWork with internal teams and customers to enable ETL from clinical and claims sources\nWrite code to query and manage large data sets to get technical and business insights to support ongoing analytics, ad-hoc analytics, and customer reporting\nValidate data extracted from complex healthcare systems\nExecute software and data testing and validation processes\nSupport ETL processes that utilize Apache Spark/Nifi and the Elastic stack including identification and resolutions of system and data related issues\nEvaluate and provide estimates for proposed system changes and custom reports\nInteract with customers and explain technical concepts, issue resolutions processes and product functionality clearly\nRegularly learn new skills, make timely decisions, and adapts well to change\n25% Travel Possible\nWhat's in it for you\nOpportunity to be part of a team creating a big data platform that is drastically improving healthcare analytics\nAwesome work environment (teleworking opportunities considered too)\nCompetitive compensation\nGreat benefits like flextime time off\nStocked kitchen with snacks and beverages and more\nWhat you need for this position?\nBachelor's degree in IT or related technical filed (Computer Science, Information Management, Mathematics, or other analytical discipline) or equivalent professional work experience\n2-4 years as a technical analyst or relative experience: healthcare industry experience is a plus\nExperience with one or more languages including SQL, JavaScript, Python, or others to analyze and integrate complex data sets\nExperience with Elastic Stack and Spark/NiFi is a plus\nStrong analytical, quantitative, problem solving and organizations skills\nAttention to detail and ability to coordinate multiple tasks, set priorities and meet deadlines\nKnowledge of HIPAA, experience with an EHR or experience in a secure data systems environment is a plus\nWe are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas.\n\nThis position is responsible for following all Security policies and procedures in order to protect all PHI under Arcadia's custodianship as well as Arcadia Intellectual Properties. For any security-specific roles, the responsibilities would be further defined by the hiring manager.\nStart your job application: click Easy Apply"}, "270": {"company": "SalonCentric", "description": "POSITION: Data Science Manager\n\nDEPARTMENT: Digital Marketing\n\nREPORTS TO: AVP - CRM\n\nLOCATION: St. Petersburg, FL (SalonCentric National Operations Center)\n\nJob Description:\n\nWe are is searching for a professional with strong quantitative analytic skills and experience with complex consumer data who can apply those skills to generate dashboarding, predictive models and forward looking insights in order to help the business answer key questions, including how to optimize the performance of omni-channel sales (website, store and sales reps), drive more efficient/effective marketing, improve brand/marketing ROI, achieve both short and long term brand and equity objectives, optimize CRM and loyalty channel effectiveness and better forecast business performance.\n\nCandidates need to be willing to work in fast-paced, cross-functional team environment.\n\nKey Job Accountabilities:\nDay-to-day data and project management for execution and activation of analytic initiatives\nCollaborate to determine analytic objectives, ensure data quality\nIdentify business opportunities and make recommendations on possible segments to business teams\nInterpret data, analyze results using statistical techniques and provide ongoing reports\nIdentify, analyze, and interpret trends or patterns in complex data sets\nWork closely with management to prioritize business and information needs\nEnsure data health through regular checks and troubleshoot any data flow issues with internal IT partners\nUtilize SQL to provide business partners ad hoc reporting from the DDM platform\nPilot machine learning and AI tests for optimized consumer journeys and efficient marketing performance\nJob Requirements:\nDeep understanding of SQL and ability to cull reports from complex customer data\nTechnical expertise regarding database fundamentals (design, data models, advanced SQL writing and efficient querying), data mining/profiling and segmentation techniques\nStrong knowledge of and experience with reporting and visualization tools (Tableau, PowerBI, etc.) for producing operational and executive level dashboards\nForward mindset regarding new uses of ML/AI\nKnowledge of statistics and experience using more advanced analytical techniques/languages (Python,\nR, etc.) a plus\nExcellent presentation and verbal/written communication skills; ability to communicate complex quantitative ideas to direct team and larger organization\nHands-on experience in quantitative data analysis\nSelf-motivated and able to operate independently, as well as work effectively with others\nDeep understanding of business practices and knowledge of the luxury/beauty industry a plus\nStrong analytic skills with ability to interpret analytic results and convert into insightful value for the brand\nCreative problem solver who enjoys thinking \u201coutside the box\u201d to solve complex problems.\nAbility to analyze complex analytic data sets and results and understand/diagnose potential quality issues and anomalies.\nUnderstanding of A/B and Multivariate testing techniques and measurements\nKnowledge of key digital marketing KPIs (CPC/CACs, LTRs, etc.) preferred\nStrong interpersonal written and verbal communication skills\nExceptionally organized and a self-starter who can work independently and in a team environment\nAbility to work in a fast-paced environment with flawless customer-centric focus\nProficiency with PowerPoint is a plus\nExperience working within a Marketing Division a plus\n5-7 years proven working experience as a data analyst\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts\nof information with attention to detail and accuracy\nWorking proficiency of website analytics platforms (Google Analytics, Demandware etc) a must\nSalonCentric is an equal opportunity employer and affords equal opportunity to all applicants for all positions without regard to race, color, religion, gender (including pregnancy), national origin, age, disability, veteran status, sexual orientation or any other status protected under local, state or federal laws.\n\n#SCJOB1\n\n\nJob Summary\n\nPosition Retail Data Science Manager\nTEAM Digital\nJob Type Full - Time\nJob Location Saint Petersburg, FL\n\nApply Now\n\nStart your job application: click Apply Now"}, "271": {"company": "PatientPoint", "description": "Full time position Data Engineer\n\nJoin the PatientPoint Business Intelligence & Data Science team in our new Kenwood Cincinnati headquarters office space. Work for a growing entrepreneurial organization where you can apply your critical thinking skills and your ideas and suggestions are valued. Be a part of a team that implements emerging technology and applies the latest quantitative methods to solve complex problems.\n\nWhat you will be doing\n\nFar beyond creating views and using outer table joins, this position creates fully automated data flows that ingest data from new and external APIs and transforms the data into usable formats for downstream dashboards, predictive models and machine learning.\n\nBuild data ingestion & transformation processes to support industry leading data science applications in predictive modeling and machine learning deployments. Design, create and deploy solutions that aggregate and transform - enabling the use of billions of log records from digital touchscreen devices.\n\nThis position offers you a great opportunity to build out an entire ETL architecture from the ground up, flexibility and the responsibility to develop a stable and reliable data platform. This person plays an important role in selecting technology, vendors and team role development.\n\nAs a developer, you will prototype new ideas, run experiments, and iterate to better design data driven solutions to business problems. On other projects you might create queries and scripts for deployment of features in the production database and enterprise data warehouse, including obtaining data from multiple external APIs.\n\nDesign and develop automated processes to perform scheduled tasks, ETL, data validation and maintenance activities; enabling quantitative analysts to tackle problems in sales force planning, touchscreen user interaction, predictive maintenance, operations and many other subject areas.\n\nPlus, there will be minimal travel, we have a new office space, you will have career growth opportunities, you will get interesting projects and can enjoy free coffee!\n\nWhat you need to be successful\n\nA college degree and several years of work experience. Your experience should include direct hands-on work with Microsoft SQL Server Integration Services (SSIS 2012 and higher).\n\nMastery of SQL programming and relational data extract, transformation and loading (ETL), including data definition, transformation and preaggregation techniques required.\n\nExperience with obtaining data from external APIs, JSON and XML required. You will be asked to provide several examples during the interview process.\n\nMastery of MS SQL Server 2012 and higher required, other RDMS such as Oracle or MariaDB helpful.\n\nKnowledge and demonstrated ability with database administration and performance tuning.\n\nWorking knowledge and experience with a general-purpose programming language such as Python.\n\nExperience with storage and retrieval of data in NoSQL databases helpful.\n\nKnowledge of other ETL tools such as Dell Boomi or Informatica helpful.\n\nVisa sponsorship is not available for this position.\n\nKudos if you have:\n\nWorking knowledge of the R programming language.\n\nExperience with geospatial analysis.\n\nExperience with reporting using SalesForce Wave Analytics\n\nWorking knowledge of graph databases.\n\nAbout the company, PatientPoint:\n\n\nIt is an exciting time to be part of the PatientPoint\u00ae team! We believe that a strong, team-oriented environment is key to the success of any endeavor. Were looking for talented team members who thrive in a fast-paced and dynamic work environment.\n\nPatientPoint\u00ae is a patient engagement solutions company passionately committed to making every doctor-patient engagement better. By harnessing the power of technology, our omnichannel platform more effectively educates and empowers patients, caregivers and staff to deliver improved health outcomes and an enhanced patient experience. For 30 years, hospitals, health systems, physician offices and sponsoring brands have trusted PatientPoint and its more than 450 team members to provide a uniquely integrated experience across care settings. Learn more at patientpoint.com.\n\nEmployer is EOE/M/F/D/V.\nTo apply to this job, click Apply Now"}, "272": {"company": "Translate Bio", "description": "Company Overview\n\nTranslate Bio is a leading mRNA therapeutics (MRT) company developing a new class of potentially transformative medicines to treat diseases caused by protein or gene dysfunction. Our MRT platform is designed to deliver mRNA carrying instructions to produce proteins for therapeutic benefit and may potentially be applicable to a broad range of diseases caused by insufficient protein production or where production of proteins can modify disease. Our lead mRNA product candidate is in development for the treatment of cystic fibrosis (CF). Beyond CF, the primary focus of our research efforts is the evaluation of targets in additional pulmonary diseases utilizing our proprietary lung delivery platform with other discovery efforts in diseases that affect the liver, eye and central nervous system.\n\nJob Summary\n\nTranslate Bio is seeking an experienced Analytical Scientist to join our CMC group. This individual in this role will contribute to the analytical development function within CMC and overall CMC strategy of drug development at Translate Bio. He/She will support the development, validation and transfer of analytical methodologies for incoming raw materials, in-process, drug substance, drug product release and stability testing. The successful individual will have expertise in pharmaceutical analytical chemistry as well as experience in authoring CMC sections of regulatory submissions.\n\nJob Responsibilities\n\nManage analytical chemistry activities both internally and at external contract laboratories\nGuide CRO to design and perform method development and validation, employing phase-appropriate approaches at different stages of development\nDevelop phase-appropriate quality control strategy for drug substance and drug product\nManage product stability study programs\nDemonstrate extensive knowledge in state-of-the-art analytical technologies\nAuthorize/review analytical method development reports, validation protocols/reports, instructions/SOP\u2019s for relevant analytical functions, and analytical sections in IND and IMPD filings\nManage internal analytical development laboratory and analytical personnel to support pipeline programs\nProvide technical advice to analytical scientists and associates to assure the highest quality of data is developed and presented\n\nRequired Skills & Qualifications\n\nPhD in analytical chemistry with 2+ years or MS with 7+ years\u2019 of analytical development experience in the pharmaceutical industry.\nExcellent scientific knowledge in analytical chemistry, strong analytical development experience for drug substance and drug product.\nFamiliarity with a full range of analytical techniques for characterization of pharmaceuticals including RP/IEX/SEC HPLC, UPLC, LCMS, Karl Fisher, solid state characterization, CE spectrophotometry.\nExperienced in CMC product development process including; cGMP manufacturing, validation, and process development.\nDemonstrated competency and hands-on experience of typical chemistry manufacturing and controls (CMC) activities.\nExperience drafting analytical sections of INDs and NDAs.\nKnowledge of GMP/ICH/FDA regulations is required.\nExperience managing CROs and CMOs.\nPrevious experience/knowledge of routine mRNA and LNP production and testing in support of Process Development and Research activities is preferable, but not required.\nReviews, interprets and communicates data cross-functionally within CMC and project teams.\nAbility to meet deadlines and demonstrate effective use of time.\nAbility to be flexible and responsive to change, be a results-driven problem solver.\n\n</br>\nTo apply to this job, click Easy Apply"}, "273": {"company": "Woodruff Sawyer", "description": "The Commercial Lines BI team at WS is a newly founded capability to enhance the organization\u2019s capacity in providing data-backed insights to its clients seeking P&C and liability insurance. The members of this team will work closely with the VP of Commercial Lines Business Intelligence and other enterprise stakeholders to develop and roll out analytics solutions. A successful candidate will apply data science methodologies, actuarial methods, knowledge of insurance, and the latest technological tools to create reusable business intelligence assets.\n\nWhat you will be doing:\n\nWith limited guidance from the leaders, managers, or project leads:\n\n\u203a Primarily collects, prepares and analyzes data from various sources.\n\n\u203a Executes formal exploratory data analysis for data science projects.\n\n\u203a Develops re-usable templates and reports for the review and feedback by other team members.\n\n\u203a Prepares analysis summaries and provides to the colleagues and leaders.\n\n\u203a Conducts data research and presents findings.\n\n\u203a Identifies areas of more in-depth analysis and builds prototypes for IT implementation.\n\nRequired Qualifications:\n\n\u203a A graduate degree in any of the quantitative disciplines, e.g., Actuarial Science, Math, Engineering, Stats, Finance, or a related discipline.\n\n\u203a Knowledge of basic data science algorithms demonstrable through internships, coursework, or a combination.\n\n\u203a 2+ years of experience in visual analysis packages such as Tableau / Power BI.\n\n\u203a 2+ years of experience in programming using Python or R.\n\n\u203a Skilled in developing presentations in PowerPoint or equivalent.\n\n\u203a 2+ years of work experience in an insurance or FINTECH environment as a data scientist or BI analyst. (4+ for an undergraduate).\n\n\u203a Knowledge of common insurance terminologies. A couple of actuarial exams is a plus.\n\nWhat you'll be getting from us:\n\n\u203a The opportunity to work with sharp, motivated co-workers in a collaborative and entrepreneurial team\n\n\u203a A flexible work schedule\n\n\u203a A fun office in vibrant downtown San Francisco\n\n\u203a Security for your future: Employee Stock Option Program (ESOP), 401K with company match and profit sharing\n\n\u203a Medical, Dental and Vision benefits for employees and families (including domestic partners)\n\n\u203a Life Insurance, short term and long-term disability benefits\n\n\u203a A Flexible work schedule\n\n\u203a Paid vacation, holiday and sick days\n\n\u203a Tuition reimbursement\n\n\u203a Access to an Employee Assistance Program\n\n\u203a Fun company and team outings\nTo apply to this job, click Apply Now"}, "274": {"company": "Allyis", "description": "Key Competencies, Knowledge & Experience\nHands-on expertise with multiple Big Data technologies\nLanguages and tools: Hadoop / Cloudera / Scala / Python / Spark / Kafka\nMachine Learning frameworks (Spark ML, H2O, Mahout, Scikit-Learn)\nNoSql (MongoDB, HBase..)\nJava Programming\nConcurrent Programming\nDWH and Big Data Architectural Patterns\nRelational Database Management System (RDBMS) including:\nWriting queries using SQL.\nKnowledge on Database constraints\nExperience working with Unix/Linux environment\nTechnical skills including understanding of software development life cycle Design, Development, Unit testing and integration testing phases.\nThe following skills will be considered a plus:\nReporting Tools:\nExperience in installing and configuring Tableau Server >= 10.4 (both on top of traditional DWH and Big Data Environment)\nExperience in reporting design and development using Tableau Desktop and Server >= 10.4\nIBM Infosphere CDC >= 11.4, IBM Infosphere Datastage >= 11.4\nDB2 Experience\nSoft Skills Must Have\nAble to communicate and influence effectively across a range of stakeholders\nStart your job application: click Apply Now"}, "275": {"company": "Just Auto Insurance", "description": "Just Auto Insurance (Just) is a young, fast-growing start-up, looking to revolutionize the auto insurance industry. Our customers will pay fair premiums, based on how they drive and what conditions they drive in, rather than how old they are or what zip code they live in.\n\nWe score how our customers drive using telematics data, gathered from our app running on their smartphones, to determine an individual price per mile for each customer. Our vision is to ingest and interpret ever-more data sources, including audio and video data, to improve driver safety, lowering the risk of accidents and the cost of insurance. Our data science platform and strategy are critical to achieving this mission. You will be a senior member of the data science team, providing this capability.\nWhat you'll do:\nSenior member of the Data Science team\nImplement data science strategy\nWork with large, complex data sets\nSolve complex, non-routine analysis problems, applying advanced analytical methods\nHelp to architect a secure, scalable and performant data warehouse and data science platform\nBuild and prototype analysis pipelines iteratively to provide insights at scale\nBuild out the technology and processes\nWhat we're looking for:\nMasters in Data Science, Computer Science or similar\n5+ years of hands-on technical experience in cross-functional Data Science roles\nExperience working with telematics datasets\nDeep understanding of statistics and experimental design\nExperience of going through an aggressive phase of growth\nStrong programming and architectural skills\nExperience in integrating models into existing systems\nSome experience with deploying on scalable cloud-based systems\nStrong standards for software engineering practices\nAbility to break down complex problems\nCreativity in sourcing datasets\nExperience in non-academic, commercial Data Science projects\nExperience in signal processing, including sensor data, time series methods and filtering\nHighly regarded but not a prerequisite:\nPhD in Data Science, Computer Science or similar.\nExperience working for a telematics-based auto insurer\nVideo or audio processing experience\nFrom a personal point of view, we're looking for someone who is innovative, collaborative and has passion for what they do. You'll be expected to roll up your sleeves and get stuck in from day one.\n\nSo that's what we need, what about what we can offer you.\n\nYou'll be joining a highly talented, focused and energetic team. Following agile principles, the data science, software engineering and stakeholders work closely and collaboratively together.\n\nAs we believe in collaborative working, we ask employees to come into the office five days a week. We start at 08:30 to align with our London, UK office a little better. Our Los Angeles office is based in trendy Brentwood with excellent access to stores, restaurants and surrounding West LA suburbs.\n\nWe believe in work-life balance, and as such, you'll get your birthday and the days between Christmas and new years off, in addition to your 20 days vacation allowance.\n\nYour remuneration is made up of salary (up to $160k), healthcare and a generous share options package.\n\nThis is an extraordinary opportunity to get in at the ground floor of a business that seeks to revolutionize a $222B industry - and that's in the US alone. If you are passionate about making a difference and have a hunger to shake up a market that is ripe for change, this is the role for you."}, "276": {"company": "Trident Technologies", "description": "Trident Technologies has an opportunity for a Sr. Data Engineer/Architect at Scott Air Force Base, IL. The ideal candidate will be experienced in establishing data processes and standards using industry best practices. business architecture.\n\nRequired Skills:\n\u2022Knowledge/familiarity with Data architecture\n\u2022Knowledge/familiarity with Data standardization and master data management\n\u2022Strong critical thinking and problem solving skills\n\u2022Ability to work with large amounts of data\n\u2022Able to define standards for data tagging into a data lake following industry best practices\n\u2022Able to communicate effectively, both orally and written, to varied levels of the organization to include technical personnel, business managers, and senior leadership\n\u2022Familiar with ETL/ELT best practices in the creation of the database\n\u2022Experience with relational SQL and NoSQL databases\n\nRequired Experience:\n5-7 years data experience\n\nEducation:\n\nBachelor\u2019s Degree (preferred Master\u2019s) in Computer Science, Information Systems, Data Analysis, Systems Engineering, Applied Mathematics/Statistics, Operation Research, or other related fields\n\nDesired:\n\n\u2022Experience in defining Data standards, Data governance and lineage, and Data migration between data base technologies\n\u2022Define Metadata standards\n\u2022Experience guiding programs related to data standardization, data stewardship and master data management\n\u2022Familiarity with establishing Master Data Management and Reference Data repositories\n\u2022Build data assessment metrics\n\u2022Working knowledge of message queuing, stream processing, and highly scalable big data stores\n\u2022Develop and drive data governance, quality and analytics initiatives are executed successfully to provide appropriate data, information & analysis to various business functions/departments\n\u2022Data architecture experience; experience including but not limited to metadata management, reference and master data management, data warehousing and business intelligence management and document and content management\n\u2022Breadth in established and emerging data technologies\n\u2022Ability to conceive and portray the big data picture\n\u2022Ability to astutely operate in the organization: well respected and influential, able to emphasize methodology, modeling, and governance, technologically and politically neutral, articulate, persuasive, and a good salesperson, and enthusiastic\n\u2022Experience with Big Data solutions\n\u2022Knowledge of commercial cloud environment; resizable, computing capacity, operations, relational database scalability. Monitor instances of volumes, balancers in real-time, and change management to data sets.\n\u2022Hands on experience working with AWS products (S3, Redshift, EC2, RDS, Aurora, Glacier), certifications recommended\n\u2022Data intelligence (i.e., data mining and profiling) Data governance to establish guidelines and processes for a data management program for the enterprise is a plus\n\u2022Data Analytics\n\u2022Knowledge/familiarity with DAMA and the Data Management Body of Knowledge\n\nMust be able to obtain and maintain a DOD SECRET clearance\n\nTrident Technologies offers a competitive salary, excellent benefits, and a professional work Environment\nTrident Technologies is an Affirmative Action, Equal Opportunity Employer\nEOE/Minorities/Females/Vet/Disabled/Gender Identity/Sexual Orientation\nApply Now: click Apply Now"}, "277": {"company": "Public Consulting Group", "description": "About Public Consulting Group\n\nPublic Consulting Group, Inc. (PCG) is a leading public sector solutions implementation and operations improvement firm that partners with health, education, and human services agencies to improve lives. Founded in 1986 and headquartered in Boston, Massachusetts, PCG has over 2,500 professionals in more than 60 offices worldwide. PCG\u2019s Health practice offers in-depth programmatic knowledge and regulatory expertise to help state and municipal health agencies respond to regulatory change, improve access to health care, maximize program revenue, improve business processes, and achieve regulatory compliance. Using industry best practices, PCG\u2019s Health team helps organizations deliver quality services with constrained resources to promote improved client outcomes. To learn more, visit http://www.publicconsultinggroup.com/health/.\n\nThe Health Data Scientist will support Public Consulting Group (PCG) colleagues, state agencies, and healthcare stakeholders in collecting, analyzing and reporting data to support analytical aspects of project engagements. The Health Data Scientist is the team steward of designated data collections, visualizations and reports, and will provide consultative guidance and training to clients and peers in the effective use of health data to help guide state leaders in health system redesign. Health data sets will primarily include Medicaid claims data and other information to be used to assess performance across indicators of healthcare quality and population health outcomes. The successful candidate will leverage strong analytical skills, technical prowess and consulting acumen to make healthcare outcome and performance data more useful to policymakers, managed care organizations and healthcare providers.\n\nThis position is located in PCG\u2019s Albany, NY office.\n\nSpecific Responsibilities:\nSupports public entities in their transition to population health management and payment reform using data analysis, coding and visualizations;\nResearches, proposes, and develops metrics and reports to monitor patient outcomes and quality of care;\nIdentifies and creates systems that lead to efficiencies and improvements in State and stakeholder data collection, and reporting;\nServes as the primary interface with State and vendor data teams operating claims and encounter systems;\nDrives and informs internal and client-facing discussions related to healthcare data systems and gathers requirements as they relate to reporting, visualizations and resultant data structures and collections;\nServes as a client facing point of contact for PCG system enhancements and development;\nResponsible for the management of data dictionaries, data flow diagrams, etc.;\nDevelops, streamlines, and actively participates in user assurance testing procedures;\nSupports and participates in the design and delivery of client and staff member training and coaching related to reporting tools and focused on specific key performance indicators in healthcare (e.g. readmissions, potentially preventable visits, follow-up to care, medication adherence);\nContributes to the firm\u2019s knowledge of the competitive environment, market opportunities, and industry trends and plays an active role in creating new markets and opportunities;\nServes as 1:1 mentor (and potentially supervises) junior staff members.\nRequired Experience/Education:\nMinimum of a bachelor\u2019s degree required;\nPrior work experience (2-3 years) in using visualization tools and applications such as Tableau, as well as statistical and database software including SQL data analytic programming;\nDemonstrated knowledge and understanding of common data warehouse structures and experience with solving analytical problems using statistical approaches;\nPreferred candidates will have experience working with Medicaid claim, encounter and recipient eligibility data;\nExperience with a Medicaid Managed Care Plan is a plus.\n#LI-SG1"}, "278": {"company": "Liberty Mutual Insurance", "description": "Advance your Career at Liberty Mutual Insurance - A Fortune 100 Company\nDescription\nThe Marketing Optimization and Data Science team within GRM US Marketing has an opening for an experienced predictive modeler with strong business sense and good communication skills to help solve challenging problems related to marketing and direct sales.\nJob Summary\nThe Marketing Optimization and Data Science team develops and applies predictive models to support all aspects of marketing and direct sales at Liberty Mutual: digital marketing, non-digital marketing, DRC sales, and Internet sales. This role will collaborate directly with analysts and business owners in these functional areas to understand their challenges and develop practical solutions.\nThis is an Individual Contributor role but will act with substantial independence in both technical model-building and stakeholder collaboration.\nResponsibilities\n\nThis role will help find practical solutions to some of the following challenges:\nWhat should our marketing budget be? How should we allocate it across marketing tactics (TV, Paid Search, Direct Mail, etc.) and across states?\nHow can machine learning help us decide, in real time, how best to follow-up with each person who quotes on our website but doesn't bind?\nWho should we send direct mail advertisements to? When is worth buying 'big' data (Acxiom, TransUnion, etc.), and when should we simply analyze results by zip code?\nCan we drive results by customizing the marketing messages individual customers see and the online quoting experiences individuals have?\nHow should we handle each call entering the DRC? When should DRC reps offer cross-sell? When should they pivot to Choice?\nQualifications\nBachelor's degree or equivalent in mathematics, statistics, computer science, economics, or other quantitative field required. PhD or FCAS preferred but not required.\nExperience in predictive analytics including real-world experience in model valuation, testing, and deployment.\nDemonstrated proficiency in R, Python, or other statistical analysis tools.\nAdept at framing business questions and practices in analytic terms and translating business requirements into relevant datasets, analyses, models, and reports.\nExperience communicating technical results to both technical and non-technical audiences.\nAbility to perform high-level work both independently and collaboratively.\n\nBenefits:\nWe value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits\n\nOverview:\n\nAt Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.\n\nWe're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.\nApply Now: click Apply Now"}, "279": {"company": "Business Wire", "description": "Business Wire, a Berkshire Hathaway company, is the global market leader in press release distribution and regulatory disclosure. We are on a mission to redefine how organizations connect with their audiences - and that\u2019s just the beginning!\n\nOrganizations, big and small, depend on us to accurately publicize market-moving news and multimedia, host online newsrooms and investor relations websites, and generate social engagements that continuously develop interactions with their target audience.\n\nThe Data Engineer is a hands-on role, responsible to help create a new model of data architecture to support business units with better access to data, drive the design and use of a new data warehouse and build automated ETL/ELT processes to connect data across the organization. The Data Engineer will help build a data practice from ground and help us drive our organization into a data-informed culture.\nThe Data Engineer will serve as the technical ambassador for our internal business units on our innovative data platform, solving problems outside the boundaries of our current system offering and providing useful feedback to inform future development. The Data Engineer will be working with multiple datasets to demonstrate value for data insights. The Data Engineer will work closely with members of our Sales, Marketing, Finance, Product, Operation and Engineering team with a constant focus of driving value for our customers.\nThe Data Engineer will be responsible to develop ETL jobs and tests to process, validate, transport, collate, aggregate and distribute data.\nWhat You'll Need\nBachelor\u2019s degree, or equivalent experience, in Computer Science, Engineering, Mathematics or a related field\n3+ years of experience of IT platform implementation in a highly technical and analytical role\nUnderstanding of Apache Spark/Hadoop and the Data Analytics ecosystem\nAbility to architect the entire data ecosystem with flows and dependencies across numerous internal systems and new cloud applications\nExperience building data pipelines with streaming and batch ETL patterns on complex datasets using Python/Docker/SQL\nExperience developing software code in one or more programming languages (Java, JavaScript, Python, etc)\nStrong SQL writing skills\n\nPreferred Skills\nHands-on experience leading large-scale global data warehousing and analytics projects\nUnderstanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, BI reporting and Dashboard development\nImplement and oversee the Data Warehousing (possibly snowflake) and ETL infrastructure\nImplement AWS services in a variety of distributed computing, enterprise environments\nIntegrate data from 3rd party services such as SFDC, Splunk, Oracle EBS/CPQ\n\n\nAt this time, Business Wire will not sponsor a new applicant for employment authorization for this position.\nBusiness Wire is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Pursuant to the San Francisco Fair Chance Ordinance and other similar state laws and local ordinances, and its internal policy, Business Wire will also consider for employment qualified applicants with arrest and conviction records.\nStart your job application: click Apply Now"}, "280": {"company": "PearlCare Search Group", "description": "The Senior Data Analyst must be experienced at gathering and interpreting large datasets. In this position, you will be responsible for the design, development, enhancement, and support of our Enterprise Data Warehouse to support various. The hiring organization is a top global law firm that is rapidly growing.\n\nResponsibilities:\n\nProvide data and application programming, under general direction, in the execution of data analysis and reporting that will contribute to and/or be part of the final project deliverables.\nGenerate data analysis/ad hoc reports and interactive dashboards/presentations, and assist management in all aspects of quality and process improvement.\nCreate efficient and reusable SQL code meant for the improvement, manipulation, and analysis of data.\nWork within and across the business in order to understand the business\u2019s functional/data requirements and KPI\u2019s.\nAdapt to shifting priorities in response to changing deadlines and the needs of the firm.\nMine and analyze both structured and unstructured data from a variety of data sets.\nMaintain and enhance existing codebases, processes and applications.\nDesign reporting solutions and visualizations.\nActively look for and assess new and emerging technologies to drive business and architecture strategy.\nRespond to information requests from all colleagues.\n\nRequirements/Qualifications:\n3+ years of relevant and progressive experience or an equivalent combination of education and experience.\nAbility and willingness to work as part of a team and with internal customers.\nMicrosoft application development stack including C# and SQL.\nStrong analytical and problem-solving skills.\nProficiency with standard business tools such as MS Office Suite or similar.\nMust have the ability to pick up new methods, programming languages, and technologies if needed.\n\nPluses:\nExperience with business reporting (BI) tools and techniques.\nKnowledge of Git, HTML, CSS, and JavaScript.\nWorking knowledge of ETL processes that include data integration, data quality, and data profiling.\nHands-on experience in SQL based analysis and development and related backend database technologies.\nExposure to dealing with unstructured, semi-structured, or big data.\nExposure to dealing with the challenges of large relational data sets, including load performance, query performance, archiving, etc.\nAbility to manage the technical aspects of data collection, cleansing, and reporting.\nAbility to coordinate application and database activities with developers and network administrators.\n\nTo apply to this job, click Easy Apply"}, "281": {"company": "DOCOMO Innovations", "description": "Responsibility\nThe ideal candidate will be responsible for real world Data Science problems, including but not limited to: Data planning/collections,\nannotation strategies and developing the state-of-the-art deep learning algorithms in the field of both computer vision/NLP to operate\non large data sets that provides robust situational assessment and predictive capabilities.\n\nPerform prototype implementation of the algorithms developed, solid engineering and classical CS knowledge is the key to success for this position.\nShare knowledge by clearly articulating ideas through papers and presentations to technical staff, management.\nQualifications\nBasic CS background (Algorithms/Data Structure) is absolutely essential, Engineering skill needs to be solid and will be tested.\nHeavy exposure computer vision/Open CV\nGood understanding of scikit-learn\nMust be professional level in Python and C++/C.\nFluency in Pytorch or Tensorflow/Keras, skills will be assessed\nMaster/Ph.D in the field of Computer Science, Computer Engineering, Electrical Engineering, Mathematics or related field"}, "282": {"company": "Echo Incorporated", "description": "For over 70 years, we have been designing and building high performance, commercial quality products. From our humble beginnings in Japan with a simple hand-held crop duster, we have grown to become a technological leader and well-respected global brand. Today the company sells its products in North America through ten distributors managing 6,600 independent dealers. An additional 24 Latin American distributors sell ECHO products through a variety of channels. ECHO products can be found in Home Depot stores in the U.S., Canada, Mexico and Puerto Rico.\n\nFor more information please visit our website atwww.echo-usa.com\n\nIf you are looking to join a dynamic information technology team that operates collectively and collaboratively then apply here!\n\nDuties/Responsibilities:\nConducting and participating in meetings with the Business Owners to understand and interpret KPI definitions, and dashboard needs.\nDeveloping and white-boarding wireframes, beta dashboards and presenting them to the business teams to see if they meet their requirements.\nDocumenting the dashboard needs, related KPIs and measures in the dataset, and the designs.\nTesting the reports for formatting and data correctness, and publishing the workbooks on the Tableau online server for scheduled refreshes.\nAttention to details in order to spot inaccuracies in coding or data.\nDefining and maintaining access control levels for different types of users in Tableau online server.\nGuide and educate best practices to business owners in building dashboards.\nEmployee must have excellent communication skills both written and verbal.\nAbility to interface with various departments throughout the organization.\nJob Experience/Skills:\n2+ years of Tableau development\nStrong oral and written communication skills\nExperience in the development of Performance Scorecards/KPI-related dashboards.\nProficient with SQL.\nKnowledge of Excel to understand and interpret end-user applications.\nEducation:\nBachelor Degree in any of the Science, Technology, Engineering, or Math related fields.\nEqual Opportunity Employment:\n\nWe're proud to be an equal opportunity employer and celebrate our employees' differences, regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or Veteran status.\n\nE-Verification:\n\nIn compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.\nTo apply to this job, click Apply Now"}, "283": {"company": "The Buffalo Group", "description": "Data Scientist\nUS Citizenship and a current TS/SCI clearance are required for the position.\n\nJob Description: Candidate will provide support to the Department of the Army Intelligence Information Services (DAIIS) Open Source Intelligence (OSINT) Team and assist in its requirement to answer enduring/ standing requirements and ad hoc Requests for Information for publicly available information that answer worldwide intelligence requirements. The intent of this program is to provide intelligence consumers access to publicly available information on the networks on which they operate so that analysts spend less time conducting searches and building queries on the internet and more time conducting all-source intelligence analysis. Candidates will provide data management functions in the form of data governance, data architecture, data warehousing, data quality management, metadata management, data security management, data development management, data operations management, data refinement, integrated data services, data transformation services, data discovery services, data tradecraft services, advanced data analytics, and technology pursuit. Candidates will continuously identify new sources of publicly available information using multiple sources including websites, databases, and email distribution lists\n\nRequired Skills:\nAbility to collect, process, analyze and report large amounts of quantitative and qualitative data, and identify trends anomalies with minimal supervision\nAbility to Evaluate performance management and formulate recommendations for senior leadership with minimal supervision\nAbility to explain mathematical formulas and statistical findings to non-technical users and decision makers\nExtract business insights from analysis of data and communicate (orally, written, or visually) those insights to business leaders\nProficiency in Microsoft Excel (e.g Pivot Tables and Pivot Charts, Multiple criteria Lookups, Nested logical/IF formulas, etc...), and Microsoft PowerPoint\nProgramming experience with Python for data analysis (e.g. Pandas, NumPy, matplotlib, etc...); particularly in processing and analysis of different sources of quantitative and qualitative data\nHoned presentation and product demo skills\nWork cross functionally\nMatch analytic solutions to business needs\nInput and manipulate data using a dashboard (e.g. Tableau, SharePoint, etc.) visualization system\nBasic programming and scripting experience with JSON is not mandatory, but is considered a plus\nBachelor\u2019s degree is required\nThe Buffalo Group is an Equal Opportunity Employer\nTo apply to this job, click Apply Now"}, "284": {"company": "Purchasing Power", "description": "Data (Decision) Scientist\nLocation\n\n\nAtlanta\n\nDepartment\n\n\nFinancial Planning and Analysis\n\nEmployment duration\n\n\nFull time\n\nApply Now\n\nPurchasing Power, Midtown Atlanta, GA\n\nData Scientist\n\nPurchasing Power is seeking a data scientist that will help us discover the information hidden in vast amounts/multiple locations of data, and help us make smarter and faster decisions to deliver better results. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems that identify areas to drive incremental revenue and predict long term performance and customer activity.\n\nWhat you\u2019ll do.\n\nThe Data Scientist supports client data integration across the company\u2019s global enterprise. Manages the retrieval, transformation, delivery, and exchange of data between both internal and external business systems across all business units and client base. Provides daily operational production support. Requires a strong understanding of discipline. Able to apply knowledge and experience to complex problems and develop recommendations. Makes decisions within broad parameters. Acts as an informal resource for others with less experience. Works with team members to provide operational support, documentation, and knowledge sharing of best practices.\n\nResponsibilities\nProvides data driven input, with insight and forward-thinking recommendations to business leaders.\nInterpret, evaluate and interrelate company and research data and develop integrated business analyses and projections for incorporation into strategic decision making\nConsistently provide proactive and prescriptive analytics\nMonitor daily/weekly/monthly metrics and alert business leaders to issues and trends\nConduct insightful, ad hoc analyses to investigate ongoing or one-time operational issues\nAnalyze business activities and present results and recommendations to enhance operational strategies both for awareness, effectiveness and overall financial benefit.\nReview business processes via analysis and involvement to develop optimization strategies the focus on value-add work.\nDevelop predictive models of customer value, behavior, and responsiveness based on various business activities related to Fraud, Fed Gov, Account Management, Account Recovery, Sales, HR, and Underwriting\nRecognizes and communicates financial implications of business decisions and strategy.\nProvides support related to data needs stored within databases, including Domo reports.\nMaintains relationship with IT and Finance teams to assure data accuracy and integrity.\nConduct and coordinate financial, product, market, operational and related research to support strategic and business planning within the departments you support\nCreates process procedures, standards, and flows for current and future state initiatives/analysis.\nCompletes special projects as assigned for various departments such as Fed Gov, Account Management, Account Recovery, Sales, HR, and Underwriting\nEnsure all deliverables adhere to department quality and delivery standards.\nMaintaining and staying up to date on the latest analytical tools and trends.\nLead meetings and develop presentations to easily explain analysis and drive actionable results.\nActively participate and partner in operational department financial related meetings.\nIncorporate proven modeling that provides future predictions on business operations and financial status.\nPreferred Competencies\nSelecting features, building and optimizing classifiers using machine learning techniques\nData mining using state-of-the-art methods\nEnhancing data collection procedures to include information that is relevant for building analytic systems\nProcessing, cleansing, and verifying the integrity of data used for analysis\nDoing ad-hoc analysis and presenting results in a clear concise manner\nCreating automated anomaly detection systems and constant tracking of its performance\nDeveloping a robust forecasting model that will predict revenue over a 18 month period based customer behavior, historical activity, and known future improvements/changes\nAssisting with the development and implementation of an EDM process\nAssist with training and coaching team members on advancing their predictive analytics skills\nQUALIFICATIONS:\nBachelor\u2019s Degree (preferably in Business, Analytics, Mathematics, or relevant field)\nMaster\u2019s Degree in Data Analytics/Data Science preferred\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\nExperience with common data science toolkits, such as R, Python, MatLab, etc. Excellence in at least one of these is highly desirable.\nExtensive experience with SAS. (Current tool primarily used)\nGreat communication skills and the ability to communicate complex concepts in simple terms\nExperience with data visualization tools, and the ability to visualize data in an executive consumption format\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\nData-oriented personality\nWhy Purchasing Power?\n\nWe are the leading specialty e-retailer offering consumer products, vacations and online education services through an easy and convenient payment plan. Our customers love us because we make paying for their purchases stress- and hassle-free. The automatic payments help them to avoid penalty fees and ballooning interest associated with other payment options. While the fixed payment duration options empower them to budget more efficiently. Ours is a revolutionary e-commerce experience that gives customers access to a better life combined with a responsible way to buy.\n\nPurchasing Power is \u2018Powering People to a Better Life\u2122\u2019 through its employee purchase program, financial literacy efforts and charitable contributions.\n\nFor more information, visit www.PurchasingPower.com\nOur people! We are very proud of our people, we \u201cPower People to a better life\u201d\n100% company paid benefits for employees\nKitchen stocked with gourmet coffee, teas and free snacks\nCasual work environment\nSummer Hours\nFlexible PTO\nTop of the line hardware\nPurchasing Power is an equal opportunity employer. At Purchasing Power, we make all employment decisions, which include hiring, promoting, transferring, demoting, evaluating, compensating and separating, without regard to sex, sexual orientation, gender identity, race, color, religion, age, national origin, pregnancy, citizenship, disability, service in the uniform services, or any other classification protected by federal, state or local law.\nStart your job application: click Apply Now"}, "285": {"company": "Orange Coast Memorial Medical Center", "description": "At\nMemorialCare Health System, we believe in providing extraordinary healthcare to\nour communities and an exceptional working environment for our employees.\nMemorial Care stands for excellence in Healthcare. Across our family of\nmedical centers, we support each one of our bright, talented employees in\nreaching the highest levels of professional development, contribution,\ncollaboration and accountability. Whatever your role and whatever\nexpertise you bring, we are dedicated to helping you achieve your full\npotential in an environment of respect, innovation and teamwork.\n\n\n\nPosition Summary\n\nThe\nClinical Laboratory Scientist will (CLS) will perform laboratory duties as\nscheduled; produce accurate and timely laboratory results in accordance with\nOrange Coast Memorial Medical Center Laboratory Services department standards\nand procedures. The Clinical Laboratory Scientist must be able to assess and\ninterpret data about the patient's status to identify each patient's age specific\nneeds and provide the care needed for that patient population.\n\nThe\nSenior Clinical Laboratory Scientist will oversee the general operation of the\nlaboratory in the absence of the Blood Bank Supervisor, assumes responsibility\nof special projects, and ensures protocols required for accreditation. The\nSenior Clinical Laboratory Scientist will assist in the development of programs\nand procedures to assure the department is aligned with community standards. In\naddition, the Senior CLS will perform work assignments as scheduled, produce\naccurate and timely results on current patient population in accordance with\nOrange Coast Memorial Medical Center Laboratory Services department standards\nand procedures\n\nEssential Functions and Responsibilities\nof the Job\nPerform\npre-analysis, analysis, and post-analysis of laboratory tests according to the\nBlood Bank department\u2019s protocols and procedures.\nOversee\nthe general operation of the laboratory in the absence of the Blood Bank\nSupervisor.\nAssume\nresponsibility of special projects and assist in the development of programs\nand procedures.\nAssist\nwith training and orientation of staff.\nFollow\nlaboratory protocol to ensure proper identification of patients and specimens.\nEvaluate\ntest results, test processes, quality control and assurance requirements where\napplicable.\nAbility\nto meet department scheduling and attendance requirements.\nRequire\neffective communication, verbally, in writing and through other means.\nConsistently\napply infection control policies and procedures.\nAttend\nand actively participate in department specific education, training,\nin-services, process improvement initiatives and staff meetings.\nParticipate\nin performance improvement projects in the laboratory.\nEnsure\nequipment and safety devices are used as intended and designed.\nEnsure\ncompliance at all times with hospital and laboratory policies and procedures.\nPerform\ndata management and documentation activities.\nPerform\nother reasonably related duties as assigned.\nAbility\nto be at work and be on time\nAbility\nto follow company policies, procedures and directives\nAbility\nto interact in a positive and constructive manner\nAbility\nto prioritize and multitask\nMinimum Requirements\nMinimum\nfive years of experience in general laboratory, including two years of\nexperience in Blood Bank.\nKnowledge\nof current information system preferred\nBachelor\u2019s\ndegree in a science discipline preferred.\nCurrently\nlicensed as a Clinical Laboratory Scientist by the state of California\nStart your job application: click Apply Now"}, "286": {"company": "TransUnion", "description": "What We'll Bring:\n\nWhat We'll Bring:\n\nAt TransUnion, we have a welcoming and energetic environment that encourages collaboration and innovation \u2013 we\u2019re consistently exploring new technologies and tools to be agile. This environment gives our people the opportunity to hone current skills and build new capabilities, while discovering their genius.\n\nCome be a part of our team \u2013 you\u2019ll work with great people, pioneering products and cutting-edge technology\n\nWhat You'll Bring:\nYou come in with 1-2 years of academic or professional analytical or modeling experience with solid knowledge of statistical methods such as GLM and machine learning techniques such as random forest, GBM, XGBoost, etc.\nAdvanced proficiency with one or more statistical programming languages such as R, Python, or H2O\nIntellectual curiosity and experience writing intermediate or advanced SQL queries for data extraction\nAbility to clearly articulate ideas to both technical and non-technical audiences\nYour strong project management and time management skills including the ability to prioritize and contribute to multiple assignments simultaneously, setting clear goals, and managing customer expectations\nYou have an advanced degree in fields of quantitative discipline such as Statistics, Analytics, or any STEM field\nWhat we love to see:\nPrior Marketing Analytics experience\nStrong data visualization skills\nExperience working with large data sets and tools such as Hive, Pig, Apache Spark, etc.\nImpact You'll Make:\n\nImpact You'll Make:\nParticipate in insurance analytics tool development projects\nCollaborate with internal and external partners to develop advanced analytical solutions for insurance marketing and retention\nContribute to projects involving descriptive, predictive, and prescriptive analysis leveraging a variety of techniques\nLead small projects and/ or work streams as a part of larger projects\nExtract insights from large data sets using languages such as R, SAS, SQL, and Python\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.\n\nTransUnion's Internal Job Title:\n\nAnalyst, Data Science and Analytics\nTo apply to this job, click Apply Now"}, "287": {"company": "Frontier Technology Inc.", "description": "FTI is currently looking for a full time Associate Data Scientist to support the Naval Safety Center in Norfolk VA. The Associate Data Scientist will be working with a diverse program team comprised of FTI team members as well as active duty and Government civilian employees to produce a series of predictive analytics models that will help diagnose and predict precursors to Naval mishaps.\n\nApply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to develop a series of predictive analytics models. Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data. Generate and test hypotheses and analyze and interpret the results of product experiments.\n\nEntry-level professional within field. Requires basic skill set and proficiency. Conducts work assignments as directed. Closely supervised with little latitude for independent judgment. Typically requires a bachelor's degree in Mathematics, Business Analytics, or Computer Science (or international equivalent) and 0-3 years of relevant experience.\nStart your job application: click Apply Now"}, "288": {"company": "Riverside Research Institute", "description": "Returning Candidate? Log back in to the Career Portal and click on 'Job Browsing/History' and find the job you're looking for.\n\n2019-045-EGR: Electromagnetics Scientist\n\nDirectorate Engineering & Support Solutions\nLocation Wright-Patterson AFB, OH\nRiverside Research has an immediate opening in the Beavercreek, Ohio area for an Electromagnetics Scientist. The candidate will perform modeling analysis of EM interactions with various materials in defined configurations.\n\nAll Riverside Research opportunities require U.S. citizenship.\n\nIND2\n\nJob Responsibilities:\n\u2022 Provide analysis of Effects for models\n\u2022 Provide support for field testing materials and sensors under high power RF and laser illumination\n\u2022 Perform and coordinate analysis with project sponsor\n\u2022 Perform modeling and simulation for RF/EM characterization and design\nJob requires 40 - 80 days of travel to include weekends and international travel\n\u2022 Other duties as assigned\n\nQualifications:\n\u2022 Masters degree in related science or engineering field or equivalent experience. PHD preferred.\n\u2022 Must currently have a Secret level security clearance. Preference will be given to those holding an active TS with SCI eligibility\n\u2022 5 years of experience with High Power Microwave (HPM)/Electromagnetic Pulse (EMP) measurements and related data interpretation\n\u2022 Experience in EM/RF modeling and simulation\n\u2022 Experience in signal analysis and composites; hands on work with aircraft and/or missile components\n\u2022 Experience with MATLAB, Microwave Studio, and/or Python. Security + certification desired\n\u2022 Ability to work as both an individual as well as a member of a team\n\u2022 Exceptional communication skills, both oral and written\n\u2022 Other duties as assigned\n\nResumes must demonstrate specialized experience that is typically in or related to the work of the position to be filled and also demonstrate particular knowledge, skills, and abilities, to successfully perform the duties of the position.\n\nDesired Qualifications:\n\u2022 Preference will be given to those holding an active TS with SCI eligibility\n\u2022 Security + certification desired\n\nRiverside Research strives to be one of America\u2019s premier providers of independent, trusted technical and scientific expertise. As we continue to add experienced, technically astute staff, we are looking for highly motivated, talented team members that can help our DoD and Intelligence Community (IC) customers continue delivery of world class programs. As a not-for-profit, technology-oriented Defense Company, we believe service to customers and support of our staff is our mission. Our goal is to serve as a destination company by providing an industry-leading, positive, and rewarding employee experience for all who join us. We aspire to be a valued partner to our customers and to earn their trust through our unwavering commitment to achieve timely, innovative, cost-effective and mission-focused solutions.\n\nAll positions at Riverside Research are subject to background investigations. Employment is contingent upon successful completion of a background investigation including criminal history and identity check.\n\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability, and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.\n\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans, and requires affirmative action by covered contractors and subcontractors to employ and advance in employment qualified protected veterans.\n\nApply Now\nTo apply to this job, click Apply Now"}, "289": {"company": "CyberSearch", "description": "Data Analyst\nStart: ASAP\nInterview: Face to Face\nOverview:\nAs a Data Analyst on the Corporate Data, Research & Reporting team, you will act as an internal consultant to the business with regards to technology based solutions. The position is responsible for full life cycle development of internally developed solutions (including requirements gathering and analysis), implementation and maintenance of vendor packages (including their integration into the overall Data/Application architecture of the firm), integration and maintenance of internal and external data sources that populate the firm\u2019s data warehouse and its various interfaces.\nRequired Skills:\nBachelor\u2019s degree (Computer Science or another technical field preferred)\n3-5 years\u2019 relevant professional software development experience\nMicrosoft Visual Studio.NET 2017 (C#) and Microsoft SQL Server (2014+)\nExperience delivering BI initiatives using the SQL Server 2014+ BI stack, including SQL Server Analysis Services and SQL Server Reporting Services\nPowerPivot/Power BI experience\nSolid understanding of Object Oriented Programming and database fundamentals\nSolid data extract, transform, and load (ETL) development experience\nHighly motivated selfstarter who takes initiative with minimal supervision in leading complex assignments.\nAbility to communicate effectively, including with nontechnical users\nCurious about new ideas and new technologies\nComfortable working through all stages of the applicationdevelopment life-cycle, including requirements gathering, development, testing, deployment, and support\nFinancial industry experience preferred\nStart your job application: click Easy Apply"}, "290": {"company": "Pindrop", "description": "The Pindrop R&D team solves tough problems and invents new ways to battle fraud using machine learning, big data and audio science in the cloud. Pindrop creates innovative products to solve global problems, and we are looking for an expert Research Scientist with in-depth Machine Learning expertise to join the Data Analytics Research team as we continue to develop ways to fight fraud and improve security in voice channels.\n\nIn this role, you will get to work in a cross functional Research team and interact with the Engineering teams and Product teams to frame the problem that are most relevant for fraud detection and authentication. You will decide which data sets are important, design sophisticated features and machine learning models to analyze the data, and present actionable results and intelligence back to internal and external clients.\n\nwhat you'll do\nPerform an in depth exploratory analysis on any given data set using machine learning and data science tools\nExplore multiple machine learning algorithms and develop improvements to existing algorithms to improve performance on a dataset\nInteract with non technical team (like Customer Success, Product) to understand customer pain points and areas of focus\nIdentify and explore different problems and datasets that are fundamental to improving Pindrop's product portfolio\nReduce most successful experiments to a working prototype that can be implemented in realtime for production customers\nCollaborate and communicate with Engineering counterparts to develop and transition the prototype solution\nWork with collaboration tools such as JIRA, Github and wikis\nRepresent the team via press conferences, internal lunch-and-learn talks, research blog posts and public presentations\nwho you are\nResearch Scientist with strong experience in machine learning and data science algorithms\nMasters degree at a minimum, PhD preferred\nStrong experience with Big Data technologies such as Spark or Hadoop\nStrong software engineering skills with experience in multiple programming languages, Python and Go preferred\nExperience with machine learning packages like scikit-learn, numpy, pandas and keras\nProven track record of providing machine learning systems that work on real world data\nKnowledge of Docker and container orchestration frameworks such as Kubernetes is ideal\nExperience with relational databases and document stores (SQL + NoSQL)\nExperience developing with AWS managed services such as S3, ElastiCache and DynamoDB\nHave the ability to deal with ambiguity in a fast-paced dynamic environment\nwhat we offer\n\n\nAs a part of Pindrop, you'll have a direct impact on our growing list of products and thus the future of security in the voice driven economy. We hire great people and take care of them. Here's a snapshot of benefits we offer:\nRecognized top employer\nAJC Top Workplaces 2017\n51 Startups to Bet Your Career On\n50 Startups That Will Boom in 2018\nHealth plans and 401k\nContinued education budget\nFlex schedules\nBest in class tools\nPaid commuter options\nFun outings to celebrate our accomplishments as a team\nAll the good karma you can rack up for fighting bad guys (our conference rooms are named after the ones we've busted)\nwho we are\n\n\nPindrop is a company founded on research and continues to innovate new ideas to market. Our solutions are leading the way to the future of voice by establishing the standard for security, identity, and trust. Pindrop products secure the future of voice, making technology more human from the call center to IoT devices.\n\nwhat we live by\n\n\nPindrop is driven by our DEPTH values. These are reflected in our goals and the base of our team's peer awards.\n\nAct with Deliberate urgency.\nCreate Evangelical customers.\nPassionate about the fight.\nPlaying for the Team.\nMake Hard easy.\n\nPindrop is an Equal Opportunity Employer.\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status; and will not be discriminated against on the basis of disability.\nStart your job application: click Apply Now"}, "291": {"company": "Travelers", "description": "Company Information\nSolid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n\nJob Summary\nThe Claim Business Intelligence & Analytics organization has an exciting opportunity for a Data Engineer. This role will be a member of an agile team who works to support our information delivery team focusing on legal analytics. Successful candidates will be able to perform analyses and complex data transformations on internal and external data sources (both structured and unstructured). You should be familiar with Linux based environments and be comfortable working with SQL and Python. Experience working with Qlikview is a plus.\n\nMarketing Description\n\nPrimary Job Duties & Responsibilities\nIndependently perform Data Acquisition\nAble to correct minor problems and implements data cleansing/quality solutions.\nApply moderate and develops basic data derivations, business transformation rules, and data requirements.\nPresent simple data visualizations to help support data exploration as needed.\nOperationalize and automate well defined simple data products independently.\nBuild, test, and implement simple analytic processes, including pilots and proof of concept. competencies - data governance, data security, data quality. Share knowledge with peer users on data or analytic products.\nMinimum Qualifications\n1 year of relevant experience with data tools, techniques, and manipulation required.\n\nEducation, Work Experience & Knowledge\nDegree in STEM related field\nKnowledge of data tools, techniques, and manipulation preferred.\nExperience with SQL, Python, and AWS (a plus)\nKnowledge of QlikView or Tableau\nJob Specific & Technical Skills & Competencies\nAbility to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.\nEffectively contributes and communicates with the immediate team.\nAble to recognize and analyze business and data issues of intermediate complexity with minimal supervision.\nAbility to foster relationships with peers to achieve objectives.\nAbility to manage time and competing priorities and provide management with accurate and timely status information.\nPhysical Requirements\nOperates standard office equipment - Continuously Sitting (Can stand at will) - Continuously Use of Keyboards, Sporadic 10-Key - Continuously\n\nEqual Employment Opportunity Statement\nTravelers is an equal opportunity employer.\nApply Now: click Apply Now"}, "292": {"company": "Samsung Semiconductor, Inc.", "description": "Deep Learning Theory Researcher/ Scientist Intern\n\nSummer 2020 internship applications are open November 2019 through January 2020. Samsung Semiconductor summer internships start in May/June 2020.\n\nJoin us for a unique 12-14 week paid internship that offers personal and professional development. You\u2019ll work with the teams that create new computing system architectures needed to support emerging machine learning applications, internet of things (IoT) and edge computing that benefit millions of users. This program will give you the opportunity work on complex solutions to that address some of the world\u2019s most complex technological challenges.\n\nOVERVIEW & IMPACT\n\nCandidate will research and develop theory and algorithms that improve state of art deep learning techniques for applications in pattern recognition, computer vision, and speech processing. Candidate should be a graduate student working towards Ph.D. Candidate will work as part of a team on the system design, implementation, and verification of algorithms for application processors and multimedia processors.\n\nJOB RESPONSIBILITIES\nUnderstand machine learning concepts, theory, and applications\nUnderstand deep learning techniques and experience with deep learning software\nDevelop theory and algorithms for deep learning, automatic speech recognition or computer vision.\nMake simulators and study the system performance.\nREQUIRED SKILLS\nStrong analytical and problem-solving skills.\nExpertise in signal processing, deep learning, and/or machine learning.\nExcellent communication and teamwork skills.\nC/C++, Python, and MATLAB coding skills, popular deep learning frameworks.\nExcellence in writing technical reports and high quality publications.\nPREFERED SKILLS\nPublications in highly ranked journals and conferences\nM.S. degree, working towards PhD.\n***********************************************************************************************************************\n\nSamsung Semiconductor Inc. (SSI), an equal opportunity employer, is a world leader in Memory, System LSI, and LCD technologies. Headquartered in San Jose, California, SSI is a wholly-owned U.S. subsidiary of Samsung Electronics Co., Ltd.- the second largest semiconductor manufacturer in the world and the industry's volume and technology leader in DRAM, NAND Flash, SSDs, mobile DRAM and graphics memory. It is one of the largest providers of system logic, imaging and LED lighting solutions, as well as providing advanced process design and manufacturing for fabless companies. Samsung Semiconductor, Inc. also has a research and innovation center with numerous labs providing product design and research in: logic, memory, image sensors, displays and mobile technologies. In addition, the company supports Samsung Display Company, the largest producer of LCD and OLED displays.\n\n***********************************************************************************************************************\n\nA day in the life Samsung Video: http://bit.ly/1saHOGu\n\nClick here to visit our Samsung Semiconductor Career Page\nStart your job application: click Apply Now"}, "293": {"company": "ATPCO", "description": "ATPCO is building the infrastructure and systems to support the next iteration of revenue management capabilities in a continuous/dynamic pricing world. This role will work within the ATPCO R&D team to help develop compelling real-world models to support the new capabilities and data points required to deliver this strategy.\nThe Strategy division defines and enables the long-term vision of the ATPCO product portfolio, creates and defines industry processes and standards to help achieve the future of ATPCO.\nAs a Data Scientist you will identify trends, patterns and value in data that would benefit internal initiatives and provide products or tools of value to our customers. You will work across functions to develop, maintain and revise views of data looking for valuable information that would support airline fare management analyses. You will work with the R&D team to solve complex business problems that require an operations research approach of large-scale data modeling and regression analysis.\nThe ideal candidate:\nExperience in airline inventory/yield management or revenue management\nBachelor\u2019s degree in mathematics or similar work experience\nHas expert knowledge of analytic business optimization\nExtensive experience in statistical modeling, experimental design, sampling, clustering, predictive modeling or other related techniques\nStrong ROI optimization, dashboard design, metric selection and definition experience\nHas extensive experience using data analysis tools to analyze and present data in a compelling manner\nAbout ATPCO:\nWhen it comes to data and content, ATPCO is the powerhouse of the airline industry, with the world's largest air price content repository. Our strength has always been in distributing that content throughout the air travel ecosystem. We lead the industry into the future by delivering all air price content via New Distribution Capability (NDC) APIs.\nATPCO is the airline industry\u2019s trusted partner in driving innovation, reducing complexity, and delivering network economics to the entire distribution ecosystem through standards, technology, and effective governance. Our Vision is to fuel the future of air travel, leading the industry into the next generation of distribution, by empowering smart connection of all content through all channels\n\nTo apply to this job, click Apply Now"}, "294": {"company": "CAQH", "description": "Position Summary:\nData is CAQH\u2019s most critical asset. You will change how we understand and work with it. CAQH is seeking a hands-on leader for our Health Data Science team. The Data Science Lead will take the prime role in analyzing and delivering results based on large health care databases \u2013 from CAQH, from health plans and third parties. They will preferably have experience in health plan performance and quality measurement and comparative effectiveness analysis. As a senior member of the Solutions team, the selected individual will contribute to business development activities and will mentor the research staff. The successful candidate can understand content area, determine what the data means, define analysis plans, select appropriate statistical methods, conduct quantitative analysis, program solutions in statistical or other programming languages, ensure an effective quality analysis plan, and communicate with clients. This is a highly technical and applied leadership position requiring experience with data science, algorithms, software development and large-scale databases.\n\nThis role is full-time exempt position and reports to the Director, Technology.\nSpecific Responsibilities:\n\u2022Set the direction and development of CAQH\u2019s research and performance measurement activities by generating research ideas, investigating data and developing data design and data structures related to the projects.\n\u2022Build, lead and mature a Data Science team to support the breadth of CAQH needs. Work within the team and across our products on the design, execution, and reporting of projects. Engage the data team to enhance their intellectual curiosity and technical skills.\n\u2022Study our data from multiple angles, determine what the data means and recommends the best possible way to analyze it. Spot trends and patterns determining what is noise and what is good data and convey that understanding to others.\n\u2022Develop analytical plans for research and analytics including: algorithm selection (data mining, machine learning etc.), advanced probability& statistics, predictive modeling, machine learning, relational database design, program design, selection of statistical methods and development of formats.\n\u2022Conduct programming tasks and statistical analyses including preparation and cleaning of data, implementation and refinement of statistical methods, preparation of results, creation of databases and other outputs, and verification of the accuracy of results. Participate in quality assurance processes.\n\u2022Lead, design, plan, and execute programming approaches to support various development projects. Code at an expert level in applications such as SAS, R, Python. Drive relational database design as well as the use of MongoDB and Hadoop/HDF.\n\u2022Present analytic results to customers, CAQH staff and other researchers incorporating descriptions of methods, relevant literature, and other background material to provide context for the results.\n\u2022Represent CAQH to technical and business audiences. Advance the company\u2019s reputation as a leading provider of quality assured provider data. Enhance CAQH reputation for scientific leadership in performance measurement through publications, conference talks, etc.\n\u2022Lead technical (econometric modeling/statistics) reviews of health-related proposals and deliverables\n\nSupervisory Responsibility:\nManage a small but growing data science team, ensuring they deliver against current commitments and can grow into our future needs.\n\nSkills:\n\u2022Strong quantitative skills, including random assignment evaluation, quasi-experimental design, and mixed method evaluation strategies. Skilled at developing and applying univariate and multivariate modeling techniques, hypothesis testing.\n\u2022Proficiency in statistical software packages strong programming skills in other languages such as Python, C# or Java required. Certifications a plus.\n\u2022Excellent ability to communicate complex technical material, both orally and in writing with the ability to explain complex models and analysis in layman terms.\n\u2022Preferably an extensive knowledge of one or more of the following areas: Medicare, Medicaid, comparative effectiveness, provider data.\n\u2022A track record of publications is a plus.\n\nExperience:\n\u2022Five+ years of experience delivering algorithm innovation into commercial software-based products.\n\u2022Three or more years of experience analyzing large datasets.\n\u2022Three or more years as a lead with experience in managing a team.\n\nEducation:\nMaster\u2019s degree (PhD preferred) in Mathematics or Computer Science with experience in health services research, applied statistics or a combination of education and experience which demonstrates the necessary skills and abilities.\n\nWHO WE ARE\nNamed one of Modern Healthcare\u2019s Best Places to Work in 2016, 2017 and 2018 CAQH, a non-profit alliance, is the leader in creating shared initiatives to streamline the business of healthcare. Through collaboration and innovation, CAQH accelerates the transformation of business processes, delivering value to providers, patients and health plans.\n\n\uf0a7COB Smart\u00ae quickly and accurately directs coordination of benefits processes.\n\uf0a7EnrollHub\u00ae reduces costly paper checks with enrollment for electronic payments and electronic remittance advice.\n\uf0a7CAQH ProView\u00ae eases the burden of provider data collection, maintenance and distribution.\n\uf0a7DirectAssure\u00ae increases the accuracy of health plan provider directories.\n\uf0a7VeriFideTM streamlines credentialing by consolidating and standardizing primary source verification.\n\uf0a7SanctionsTrack\u00ae delivers comprehensive, multi-state information on healthcare provider licensure disciplinary actions.\n\uf0a7CAQH CORE\u00ae maximizes business efficiency and savings by developing and implementing national operating rules.\n\uf0a7CAQH Index\u00ae benchmarks progress and helps optimize operations by tracking industry adoption of electronic administrative transactions.\nWHAT YOU GET\nCAQH recognizes that its most important asset is its growing team of smart, creative, collaborative, forward-thinking and passionate professionals \u2013 and that a comprehensive employee benefits package is an important factor for them in choosing where to work. CAQH offers competitive compensation along with an extensive benefits package for all full-time employees, including medical, dental and vision coverage, tuition assistance and a 401k. Our location in downtown Washington, DC is metro-accessible, has an onsite fitness center and is centrally located to allow our team to take advantage of professional networking opportunities, cultural offerings and a thriving social scene.\nApply Now: click Apply Now"}, "295": {"company": "Novartis", "description": "Two companies and one incredible alliance.\n\nNovartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop transformative medicines faster and more cost-effectively for patients worldwide.\n\nWe are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics.\n\nIn this newly formed alliance with Microsoft, you will lead Visualization analysis for Novartis .\n\nIn this newly created role, you will:\n\u2022 Conduct end-to-end Visualization analysis of large scale healthcare data sets\n\u2022 Take a hands-on role and deliver on highly visible multiple projects\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Keep ahead of latest development in the field and mentor associates\n\u2022 Inspire others on culture change\n\nWhy consider Novartis?\n\n750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\n\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data. Where you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us reimagine medicine.\n\nPosting Title\nSenior Data Scientist \u2013 Visualization, Novartis AI Innovation Lab\nStart your job application: click Apply Now"}, "296": {"company": "Pro-Sphere Tek", "description": "Overview\n\n\nProSphere is seeking an experienced Data Analyst/BI Developer to work on building, operating, and scaling next generation data platforms, BI strategy, analytics, and tools that will power data-driven capabilities end to end throughout the entire Department of Veterans Affairs (VA), spanning areas such as business intelligence and reporting, data science, and data analytics.\n\nThis is full-time position located in Austin, TX. Veterans are encouraged to apply.\n\nResponsibilities\nCreate and deliver metrics, reporting platforms and analytical models critical for tracking and managing the business\nBuild reports, dashboards, and other data representation models from scratch\nUnderstand various teams\u2019 objectives, the metrics that are the most important to them, and how they measure their performance\nTurn business requirements into technical requirements\nGuide development of dimensional models in support of a star schema architecture\nFind and understand the correct data sources for a given analysis\nParticipate in building and owning a DevOps culture\nExperience working in an Agile Project Management Methodology environment\nContinuously document your code, framework standards, and team processes\nDrive insights through rigorous analytics on business performance and cohesive, well laid out presentation of the data and recommendations\nCreate dashboards with KPIs for a variety of stakeholders\nDrive organizational change through a period of high growth, building the systems and infrastructure to support that growth\nQualifications\nBachelor's Degree in Computer Science, Engineering, Math, or related technical field involving coding, or equivalent practical experience (8 years of additional experience can be substituted for education)\n5+ years' relevant experience\nStrong Communication, Presentation and Facilitation Skills. Must be able to explain data quality issues and impacts to a non-technical audience\nExperience in Business Intelligence Tools such as SSMS, PowerBI and Excel\nExperience with front end development\nExperience working in an environment using Agile methodology\nExperience in Analytical concepts such as dimensional modeling, data visualization, analytical mindset\nPhysical Demands\nTypical office environment. Ability to sit and stand for extended periods of time\nAbility to lift 5-20 lbs.\nProSphere offers full-time employees a comprehensive and competitive benefits package including paid vacation, sick leave, holidays, health insurance, life insurance, military leave, training, tuition reimbursement, a wellness program, short- and long-term disability, 401(k) retirement plan with company matches/immediate vesting, commuter benefits, and more.\n\nIt is ProSphere\u2019s policy to promote equal employment opportunities. All personnel decisions, including, but not limited to, recruiting, hiring, training, promotion, compensation, benefits and termination, are made without regard to race, creed, color, religion, national origin, sex, age, marital status, sexual orientation, gender identity, citizenship status, veteran status, disability or any other characteristic protected by applicable federal, state or local law.\nTo apply to this job, click Apply Now"}, "297": {"company": "Memorial Health System", "description": "Responsible for engineering, testing and maintaining the functionality and integrity of data pipelines and other data assets in order to make data accessible and useful for data analytics consumers throughout Memorial Health System.\n\nEducation:\nBachelor\u2019s degree in computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field is required. Master\u2019s degree in these fields is preferred.\nSeven Years of Applied Data Engineering experience required in lieu of educational requirements.\nLicensure/Certification/Registry:\nCertifications in SQL or Data Engineering (such as those offered by Microsoft or Google) preferred\nExperience:\nAt least three years or more of work experience in data management disciplines including data integration, report writing, data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.\nAt least five years of experience working in cross-functional teams and collaborating with business stakeholders.\nOther Knowledge/Skills/Abilities:\nIs a practitioner of handling large and diverse datasets, parsing and understanding the data, and then building, managing and operationalizing data pipelines. Must be able to provision datasets quickly across multiple, distributed and often diverse datasets within and outside the organizational boundaries. Has a demonstrable understanding of how to expose data from systems (for example, through APIs), link data from multiple systems and deliver streaming services. Ensures risks associated with deployment are adequately understood and documented.\nIs a practitioner of a range of coding tools and languages. Specifically must be well versed in SQL Management Studio, TSQL, Oracle SQL Developer, PL-SQL, and Postgres SQL. Must also be able to identify the applicability of, and appropriate utilize these various coding and programming. Is well versed in security, accessibility and version control.\nWill work side by side with domain experts in business groups and with data scientists and analysts to frame the business problem, integrate the needed data, and determine the best way to provision that data on demand. Will often be the primary analytics representative in cross functional value stream teams throughout the organization.\nWorking experience with cloud technologies is not required, but is preferred.\nIs able to communicate effectively across organizational and technical boundaries, making complex and technical information and language simple and accessible for non-technical audiences.\nIs aware of and keeps up to date with advances in digital analytics tools and data manipulation products.\nHas working knowledge of the process and or team resources available to logs, analyze and manage problems in order to identify and implement the appropriate solution. Will execute proper escalation of critical service calls to ensure timely and appropriate resolution to system issues Ensures that the problem is fixed.\nHave an awareness of the skills and concepts required to build, populate and manage visualization and/or reporting assets. Tableau experience is preferred.\nDemonstrated problem solving skills and ability to consistently exercise sound judgment and initiative in all circumstances, including very stressful situations.\nMust be able to effectively manage competing priorities.\nDemonstrated skills in developing and maintaining good interpersonal relationships.\nDemonstrated effective written and verbal communication in performing assigned duties.\nDemonstrated ability to communicate effectively with all levels of staff both in and outside of IT essential.\nDemonstrated dedication to a positive attitude, strong customer service support and commitment to the achievement of Memorial\u2019s strategic goals is essential.\nDemonstrated ability to achieve results as well as a strong sense of personal accountability for results is essential to success in this position. Must be dedicated to continue learning and investigation of relevant technology improvements.\n\nDesigning, Building, managing and optimizing data pipelines and then moving these data pipelines effectively into production.\nCollects, collates, cleanses and synthesizes data to derive meaningful and actionable insights.\nIntegrates and separates data feeds in order to map, produce, transform and test new data assets.\nDevelops fit for purpose, resilient, scalable and future-proof data services to meet user needs.\nDesigns, writes and iterates code from prototype to production-ready.\nDesigns, writes and deploys data visualization and data reporting assets.\nTroubleshoots problems and tunes for performance.\nDevelops and manages data asset documentation.\nParticipates in development opportunities including but not limited to quality and leadership classes as determined by manager and employee. (MHS, vendor, or scholastic provider; member of professional society).\nPerforms other related work as required or requested.\nThe intent of this job description is to provide a representative summary of the major duties and responsibilities performed by incumbents of this job. Incumbents may be requested to perform tasks other than those specifically presented in this description.\nStart your job application: click Apply Now"}, "298": {"company": "7Park Data", "description": "7Park Data, a Vista Equity portfolio company, is the leading data intelligence provider to businesses around the world. The Data Acquisition Analyst will join an extremely passionate team, who share a common interest in using complex, unstructured data to answer real world questions. Our technologies and data power the insights for financial services and corporations.\n\nIdeal candidates are those who are excited by big data challenges and enjoy using new technologies to make large data sets feel small.\n\nResponsibilities:\n\u2022 Assess high value data from both data and non-data companies across the Alternative Data.\n\u2022 Manage delivery of data sets from existing partners, while seeking to improve and expand coverage.\n\u2022 Identify the needs of customers through user research, stakeholder collaboration, and analysis of data\n\u2022 Collaborate with partners, analysts, data scientists and engineers to create new data products\n\u2022 Become the subject matter expert for alternative data vendors.\n\u2022 Troubleshoot potential data issues\n\u2022 Create and implement internal documentation and workflow tools to improve evaluation and identification of data sources.\n\u2022 Experience with Equity and Macro-economic analysis is a plus\nRequirements:\n\u2022 3-5 years of experience in procurement, technical account management or data analyst preferably within finance.\n\u2022 An interest in understanding how customers use data.\n\u2022 High-level understanding of the investment research market and institutional investing processes\n\u2022 Strong experience in creating analytics from data for better decision making\n\u2022 Ability to articulate technical concepts, how they map to product features, and how the features can solve client business problems to both technical and non-technical end users\n\u2022 Possession of excellent communication skills, as the ability to listen, communicate verbally and through written documentation is essential.\n\u2022 Willingness to meet time sensitive deadlines\nStart your job application: click Apply Now"}, "299": {"company": "Novartis", "description": "Two companies and one incredible alliance. Novartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop transformative medicines faster and more cost-effectively for patients worldwide.\n\nWe are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics.\n\nIn this newly formed alliance with Microsoft, you will lead Causal & Predictive analysis for Novartis .\n\nIn this newly created role, you will:\n\n\u2022 Conduct end-to-end Causal & Predictive analysis of large scale healthcare data sets.\n\u2022 Take a hands-on role and deliver on highly visible multiple projects\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Keep ahead of latest development in the field and mentor associates\n\u2022 Inspire others on culture change\n\nWhy consider Novartis?\n\n750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\n\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data.\nWhere you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us reimagine medicine.\n\nPosting Title\nSenior Data Scientist: Causal & Predictive analytics AI Innovation Lab\nStart your job application: click Apply Now"}, "300": {"company": "LendingHome", "description": "LendingHome is re-imagining the mortgage process from the ground up by combining innovative technology with an experienced team. Our goal is to create a seamless, transparent process that transforms the mortgage process from end to end.\n\nThe Team\n\nWith our built-from-scratch technology that covers every stage of the loan process, LendingHome has opened access and simplified a way for people to get financing and generate wealth through real estate. Since 2013, LendingHome has funded over $3.5 billion dollars worth of loans across 15,000+ projects, making it the largest fix and flip lender in the country. Combining the best technology and the most knowledgeable people, LendingHome has raised $167MM in venture capital, has grown to a team of over 300, and has been featured on the Forbes Fintech 50 list for two years running. LendingHome is uniquely positioned to become the next great financial services brand powered by the most advanced mortgage platform in the world.\n\nThe Role\n\nLendingHome is seeking a highly analytical and innovative Data Scientist to join our Data team. Data drives every area of LendingHome including marketing, sales, operations, and credit, and you will be collaborating closely with all of these groups to tackle the highest priority strategic questions and to enable excellent, robust data-driven decision making.\n\nResponsibilities\nDefine, create, and improve metrics and dashboards that precisely and accurately measure the pulse of the business\nProactively initiate in-depth, rigorous analysis to derive meaningful insights the business can clearly act upon\nDrive improvements in business outcomes by testing new and different strategies through systematic planning and execution of experiments\nContinually explore and iterate statistical models and features to advance our understanding of key underlying business drivers\nBuild production grade machine learning pipelines and data products that solve critical, complex problems and deliver business value\nIdentify, research, and analyze new data sources that complement and enrich the quality of the data platform\nSupport ad hoc analysis requests\nQualifications\nA graduate degree in Computer Science, Statistics, Math, or related quantitative discipline\nExcellent grasp of fundamentals in statistics and probability\nExpertise in SQL and proven comfort and an intellectual curiosity for working with large sets of data\nProficiency in coding and software engineering concepts. Fluency in Python/R preferred\nExperience with basic classes of machine learning techniques and algorithms (e.g. regression, classification, boosting, clustering, time series, NLP)\nAbility to partner, collaborate, and communicate well with a diverse set of colleagues, both technical and non-technical, at all levels\nA resourceful and pragmatic approach to problem solving and recognition that the best solutions are sometimes the simplest\nExperience in Hadoop/Spark or other distributed parallel computing paradigms is a plus\nAbility to transform technical analysis into easily digestible visualization is a plus\nLendingHome in the News\nWinner: Forbes Fintech 50\nLendingHome Passes $3 Billion in Mortgage News\nHow Wall Street, Silicon Valley Institutionalized Home Flipping\nA Tour of LendingHome's New San Francisco Headquarters\nRiding the House Flipping Boom, Mortgage Lender Adding More Jobs on North Side\nBenefits and Perks\nCareer Growth: We foster an environment that encourages opportunities to use your voice, make an impact, and move towards your long-term goals.\nLunch & Snacks: Hungry? We have you covered! Enjoy catered lunches and Bagel Wednesdays\u2014and don't forget to take your pick of healthy snacks and drinks daily from our fully stocked kitchen.\nWork-life Balance: With our flexible time off policy, you can enjoy a well-rounded lifestyle while easily balancing work, travel, loved ones, and passions.\nFamily Matters: We know your role here might not be the only one you have. Enjoy your job as a parent and welcoming your new bundle of joy with our competitive parental leave policy.\nCommuter Benefits: Travel from A to B without the stress. We help you save money on your commute to work with pre-tax deductions and a monthly stipend.\nProduct Ownership: We recognize your hand in making our business great. With offered equity, you can claim your stake in our growth.\nHealth Insurance: Your well-being is important to us. Our comprehensive medical, dental, and vision plans ensure that your mind and body are in good keeping.\nIf you'd like to see more about what LendingHome has to offer or explore additional opportunities, visit us at LendingHome.com/Careers.\n\n\nLendingHome is an Equal Opportunity Employer\nSan Francisco Fair Chance Ordinance Police Code, Article 49\nTo apply to this job, click Easy Apply"}, "301": {"company": "Clickfox", "description": "Overview\n\nBryterCX is seeking a Data Engineer to work with our Denver, CO office. Our ideal candidate has experience and working knowledge of RDBMS and distributed database technologies. Experience with some combination of analytics, time series data, and creating pipelines for analytics tools and data science is required.\n\nKey Responsibilities\nParticipate in a scrum-based agile delivery team.\nCreate and support production quality application code and database structures and code.\nImplement software patterns for data retrieval and persistence to support complex analytical queries and storage needs.\nAssist in data modeling and query optimization for RDBMS technologies.\nSupport RDBMS and MPP RDBMS design, creation, and implementations.\nCreate and implement ETL improvements to automate, validate and audit data ingestion.\nContribute to architecture and design of performant analytical software systems.\nQualifications\nBachelor's degree in Computer Science or equivalent\nExperience with RDBMS systems, particularly Postgres is required.\nExperience in query optimization is required.\nExperience with data extraction & transformation is required\nStrong communication and time management skills are required.\nExperience in data modeling is preferred.\nExperience with time series data, and/or data visualization and analytics is preferred.\nExperience in any of these technologies is desirable: Postgres, Greenplum, Hive, Impala, Map Reduce, Java, Spark.\nKnowledge and experience in these technologies is a plus: Cloud Services, microservices, Java API tuning, MapReduce tuning, Python, Scala.\nExperience in creating technical Proof of Concepts is a bonus.\nCompany Overview:\n\nBryterCX pioneered and remains the industry leader in providing the premier Journey Analytics (Fox) solution for optimizing self-service information systems. BryterCX unique software modeling solutions enable its customers to translate complex customer interactions across multiple self-service channels, including Interactive Voice Response, Web/Intranet, Email, Chat, Agent Desktop, Routing, and other enterprise applications. Through ongoing application of the ClickFox Customer Behavior Intelligence system, companies can dramatically reduce operational costs, improve customer satisfaction and revenue generation and enhance the overall interactive customer experience.\nTo apply to this job, click Easy Apply"}, "302": {"company": "UFG Insurance", "description": "UFG offers you an award-winning workplace and a trustworthy, financially stable company. While we\u2019ve always known our commitment to employees and financial stewardship, it is good to have others recognize our dedicated efforts. We've been named an Iowa Top Workplace by the Des Moines Register for four consecutive years, and included on Forbes\u2019 \u201cAmerica\u2019s Most Trustworthy Financial Companies\u201d every year since 2014. Additionally, UFG is a super-regional property and casualty insurer rated \u201cA\u201d (Excellent) by A.M. Best Company.\nThe UFG Enterprise Analytics Department is focused on delivering strategically-impactful results by building analytically based solutions that integrate a wide range of internal and external data assets. The ultimate objective of the Enterprise Analytics organization is to help UFG gain and maintain a competitive advantage in how it prices risk and identifies potential loss.\nWe are seeking an Associate Data Scientist to facilitate the development of Analytics solutions in support of UFG\u2019s strategic plan. This individual will work closely with business units throughout the organization to develop and implement strategies that leverage data to enable enhanced decision making. The ideal candidate will possess strong technical and communication skills, as well as proven experience in predictive modeling, change management, and the insurance industry in general.\n\nWork with management to prioritize modeling needs\nSupport research and development efforts in a diverse set of challenges as we rapidly prototype and build new models\nExtensive experience analyzing data and a broad understanding of core statistical and ML techniques\nDesign, build, and deploy Machine Learning (ML) systems aligning to business objectives\nTranslate and champion ML capabilities for non-technical audiences\nStay current with modeling techniques/technologies\nMaintain positive, professional business acumen and relationships with cross-functional teams and external customers\nTrain end users on new models\nResearch opportunities for data acquisition and new uses for existing data\nCollaborate with data architects, analysts and IT team members on project goals\n\nEducation:\nCompetencies typically acquired through a Ph.D. (in Statistics, Computer Science, Mathematics, or other scientific field of study)\nExperience:\n1-3 years of relevant commercial P&C modeling experience\nExtensive experience analyzing data and a broad understanding of core statistical and ML techniques\nPast experience implementing complex data-driven solutions is preferred.\nDeep experience with GLMs as well as modern machine learning methods.\nDemonstrated experience in handling large datasets, structured and semi-structured data formats\nKnowledge, skills & abilities:\nThis role will require the candidate to be extremely hands on with building models and data driven tools.\nAdvanced Python skills. Should be familiar with Python\u2019s scientific computing ecosystem.\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.\nAbility to translate technical concepts into non-technical, lay terms.\nUnderstanding of star/snowflake schemas as general data warehousing methodologies (i.e. Kimball).\nStrong written and verbal communication skills.\nAbility to deliver incremental value via an Agile Development Methodology.\nAbility to thrive in a fast-paced environment with significant uncertainty\nApply Now: click Apply Now"}, "303": {"company": "SpringML", "description": "SpringML is seeking an Analytics Consultant to augment our Salesforce delivery practice. You will play a critical role in our client engagements using the Tableau and the Salesforce Analytics Cloud platform (Einstein Analytics, Einstein Discovery, and the Einstein Platform). You will design and implement highly customized solutions for our customer's business problems, typically across multiple functions of a customer's organization through data integration, visualization, and analysis.\n\nRESPONSIBILITIES\nAbility to work as a member of a team assigned to design and implement solutions for our customers.\nData analysis skills to conduct analysis and deliver recommendations to the team and customer.\nDashboard and Dataset development develop dashboards and datasets that meet and exceed customer requirements.\nPresentation skills demonstrated ability to simplify complex situations and ideas and distill them into compelling and effective written and oral presentations.\nLearn quickly ability to understand and rapidly comprehend new areas, functional and technical, and apply detailed and critical thinking to customer solutions.\nQUALIFICATIONS\nB.S. or equivalent degree in computer science, statistics, mathematics or other relevant fields.\n0 3 years of experience in business analytics, data science, or consulting in these fields.\n1+ year experience with Salesforce or Tableau preferred.\nPrevious experience using Salesforce Einstein Analytics or Einstein Discovery a plus.\nCandidates holding certifications in either Tableau or Salesforce Analytics will receive priority consideration.\nExperience or equivalent coursework using statistics for data analysis with an understanding of, at a minimum, multivariate regression.\nStrong understanding of query languages and basic understanding of programming languages; experience with Python, R, Java, or Apex a plus.\nStart your job application: click Easy Apply"}, "304": {"company": "SpringML", "description": "Data Engineer\n\nTHE ORGANIZATION\n\nJUST Capital is an independent nonprofit working to build a more just marketplace that better meets the needs of all Americans. We embrace markets and data to drive change on the issues Americans care about most income inequality, job creation, reducing environmental impacts, supporting local communities, and more. We believe business can and must be a greater force for good and that our technology supported rankings, data-driven tools and insights will help all market participants corporations, investors, policymakers, nonprofits, and the general public build a more just marketplace. Core to our mission success is our technology platform and data management infrastructure.\n\nThe successful candidate will join our technology and products team and has strong, advanced technology and data management skills along with stellar interpersonal relationship skills and experiences. Inspired by this unique opportunity to make a difference, this person will not only demonstrate intellectual curiosity and thought leadership in their area of expertise but also contribute to the overall strategic work of JUST Capital.\n\nKEY RESPONSIBILITIES [include but not limited to]:\nProvide technical guidance, direction and leadership on unusual or complex technology and data problems.\nRequirements gathering, design, implement, and support Data Models and ETLs that provide structured, timely access to large datasets.\nBuild fault tolerant, self-healing, adaptive and highly accurate ETL platforms.\nDevelop and maintain programs on source systems, ETL applications, data cleansing functions, system management functions, including load automation, data acquisition functions and others.\nDevelop the data model(s) for the data warehouse\nResponsible for data administration and tuning for the Database and ETL process.\nRefine the logical design with the outcome that it can be translated into a specific data model.\nSolve challenging technological and analytical problems associated with our research model\nDevelop, institutionalize and drive best practice and data architectural awareness\nPROFESSIONAL EXPERIENCE/QUALIFICATIONS\n\nProfessional Skills\nA commitment to and passion for the JUST Capital mission.\nProven project management, time management and multi-tasking abilities while maintaining excellent attention to detail.\nStrong, persuasive communication skills, including an ability to articulate progress, define and overcome challenges, and provide recommendations or solutions relevant to our data platform and research\nAble to adapt communication style and approach to varying audiences and stakeholders and possess a proven ability to present complex work and insights to non-technology audiences.\nOperate at the highest level of integrity and ethical standards.\nStrong Technical Skills\nGraduate degree in Math, Statistics, Computer Science, or other quantitative discipline\n1+ years of experience in enterprise and open source ETL tools such as Informatica and Pentaho PDI platform\n2+ year experience in SQL with focus on Business Intelligence and Data warehousing\n5+ years of Java and/or Python development experience\nWorking knowledge of and experience in designing & orchestrating Pentaho kettle transformations and job flows\nProven skills and experience of data architecture and data modeling, developing and implementing metadata and master data strategies in data warehouse and mart environments\nThorough understanding of relational and dimensional database modeling\nExperience in ODS design, data warehouse and mart design methodologies such as Star-schema. Snowflake, designing slowly changing dimensions and fact tables\nExperience in extracting data from disparate and heterogeneous data sources like mysql, flat files, ftp, web services, XML and weblogs into target ODS and data warehouse\nWorking knowledge with Amazon workflow services\nCollaborative, Creative Approach\nAbility to bring vision and strategic thinking and insights to the work.\nA positive, entrepreneurial attitude, openness and willingness to learn from others, strong interpersonal skills and a passion to make an impact.\nDemonstrated experience as a strong team player, with the ability to work effectively as part of a positive, highly collaborative group that shares tasks and responsibilities.\nBENEFITS & WORK ENVIRONMENT\n\nThe compensation and benefits package at JUST Capital has been thoughtfully designed to ensure we model what we measure when it comes to just business behaviors. Benefits include:\nFair, equitable, and competitive pay.\nBest-in-class health, vision and dental care benefits for you and your family including membership in One Medical Group for on-demand primary care and access to Health Advocate, the nation's leading healthcare advocacy & assistance company.\nRespect for work-life-balance, including a flexible work from home policy.\n5 paid sick days plus 20 personal time off days, as well as 14 holidays a year and we encourage you to take them!\nOther paid time off when the office generally closes the last week of the year.\nFully paid parental leave of up to 12 weeks and backup childcare.\n401(k) retirement plan, with employer matching of 100% up to 4% of salary.\nSubsidized gym memberships, Citi Bike membership, and pre-tax commuter benefits.\nJUST Capital is a small organization staff-wise and operates with a nimble, entrepreneurial mindset. As such, in addition to the key responsibilities, candidates should have professional work approaches, be self-starters and possess well developed organizational skills honed to allow him/her to be effective and resourceful in a fast-paced workplace. Further, adaptability, good colleagueship, working with cross-functional teams to deliver projects on tight deadlines, and internal community building are important attributes of the JUST Capital culture.\n\nTO APPLY\n\nDue to the pace of this search, candidates are strongly encouraged to apply as soon as possible. Applications must include a thoughtful cover letter describing your interest in working for a nonprofit and this role in particular and how your qualifications match those specified, along with your resume. This role is located in New York City. Please note that candidates must be authorized to work in the United States; we are not able to support eligibility to work visa transfers.\n\nPlease submit your resume and cover letter to: https://justcapital.com/careers. Resumes without a thoughtful cover letter that addresses your interest in working for a nonprofit and how your skills match those in the job description will not be considered. Due to volume, only those candidates considered for an interview will be contacted.\n\nJUST Capital is an Equal Opportunity Employer people with disabilities are encouraged to apply\nApply Now: click Easy Apply"}, "305": {"company": "Press Ganey", "description": "Data Scientist\nLocation\n\n\nIL - Chicago\n\nFunctional Area\n\n\nResearch & Analytics\n\nEmployment Status\n\n\nRegular\n\nApply Now\n\nAbout Press Ganey\n\nPress Ganey pioneered the health care performance improvement movement more than 30 years ago. Today, Press Ganey offers an integrated suite of solutions that enable enterprise transformation across the patient journey. Delivered through a cutting-edge digital platform built on a foundation of data security, Press Ganey solutions address safety, clinical excellence, patient experience and workforce engagement. The company works with more than 33,000 health care facilities in its mission to reduce patient suffering and enhance caregiver resilience to improve the overall safety, quality and experience of care.\n\nJob Overview\n\nPress Ganey is looking for an energetic, creative and curious data scientist to join its Data Science team! We have an opening for a data geek (statistician, data scientist, economist, etc.) interested in producing novel \u2013 and impactful - data-driven insights, and developing world-class analytic products, from our database of over 1 billion patient experience and employee engagement results, representing over 20 thousand healthcare facilities. Positions are available for our Boston, Chicago, Charlotte, or Baltimore office.\n\nDuties & Responsibilities:\nFunction as technical lead, in collaboration with other business partners serving the analytic client, to develop deliverables requirements\nIndependently write programs in appropriate language (e.g. R, SQL, Python), to develop data (sets), from multiple databases, needed to support deliverables\nIndependently produce analysis (e.g. basic data analysis, statistical test, statistical modeling) or analytics (e.g. a dashboard), with appropriate tools (e.g. Excel, R, Python, HTML, Tableau)\nDocument work\nProduce written reports, for internal constituents, which summarize analytic deliverable; including methods, interpretations, and business implications\nProvide ad-hoc analytic support to internal clients (e.g. sales, account management, advisory services, product management, and consulting), including answering data and methodology questions, interpretation of results and\nStay abreast of contemporary analytics, such as big data technologies (e.g. Azure, AWS, Hadoop, OLAP tools), analytic technologies (e.g. SAS, R, Python, Tableau, etc.), and statistical (including data-mining) methods\nIn collaboration with business partners (e.g. Knowledge Management, Engineering, Product Management, and Custom Reporting), develop prototypes of scalable, novel analytic solutions that address important business questions\nDevelop and prototype novel data sets that integrate existing PG or external data, for the purpose of developing novel analytic solutions\nStay abreast of healthcare industry issues affecting PG clients (e.g. value based reimbursement programs, meaningful use, \u201cPopulation Health\u201d)\nDevelop internal network of colleagues, and a corresponding reputation for collaboration, that removes barriers to analytic production and enables problem solving\nQualifications:\nIntermediate to advanced proficiency with SQL, SAS, R, STATA or other high level data programming language\nBasic proficiency with Python, PHP, Perl, VB, JavaScript, C++ or other programming language\nFormal training or extensive applied experience with advanced statistical methods such as regression-type modeling and data-mining methods (e.g. classification trees)\nProficiency with data visualization\n2+ years developing data that merges relational tables, either within a relational database or related \u201cbig data\u201d environments (e.g. SQL Server, Hadoop)\n2+ years of data and statistical analysis\n1-2 years project management experience, including demonstrated success with cross-functional collaboration\n1-2 years implementing novel analytics with minimal supervision\nMinimum Education:\nBachelors or higher in Mathematics, Statistics, Engineering, Economics, or other quantitative discipline.\nAll positions at Press Ganey require an applicant who has accepted an offer to undergo a background check. The specific checks are based on the nature of the position. Background checks may include some or all of the following: SSN/SIN validation, education verification, employment verification, criminal check, search against global sanctions and government watch lists, fingerprint verification, credit check, and/or drug test. By applying for a position with Press Ganey, you understand that you will be required to undergo a background check should you be made an offer. You also understand that the offer is contingent upon successful completion of the background check and results consistent with Press Ganey's employment policies. You will be notified during the hiring process which checks are required for the position.\n\nFor more information about Press Ganey, visit our web site at pressganey.com .\n\nPress Ganey Associates, Inc. is an Equal Employment Opportunity/Affirmative Action employer and well committed to a diverse workforce. We do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, veteran status, and basis of disability or any other federal, state or local protected class.\n\nPay Transparency Non-Discrimination Notice \u2013 Press Ganey will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information.\nTo apply to this job, click Apply Now"}, "306": {"company": "BOLD", "description": "Since 2005, BOLD has established itself as a job seeker's ally. Unlike our competitors that specialize in posting jobs for employers, BOLD's focus steadfastly remains on the job seeker. Our top-rated tools offer job seekers of every walk of life the help they need to get the jobs they want.\n\nA profitable, mature startup, BOLD walks with the job seeker through every phase of the job search process. Our award-winning resume and cover letter builders have helped millions of job seekers in more than 180 countries create the application materials they need to succeed.\n\nBold's brands have a presence across the globe and Bold is continuing to build its international offerings and serve millions of job seeker.\n\nDepartment Summary:\n\nThis role is on our Analytics team. This team partners with Product, Marketing, and Finance to produce world-class analysis and provide recommendations that improve our products and increase customer engagement.\n\nPosition Summary:\n\nBOLD is looking for an enthusiastic PRODUCT DATA ANALYST to join our team. You will provide critical insights to business partners and strategic support to the executive team. You will also have your fingers on the pulse of the business and develop metrics and reporting to keep the organization informed. Through your high-quality analysis and attention to detail, you will be the go-to person for product performance and insights. The ideal candidate is highly motivated and will use their technical skills and business acumen to quickly make an impact!\n\nPosition Responsibilities:\nConduct in-depth analysis to uncover opportunities for improving our products.\nWork closely with business partners to extract meaningful insights using a variety of data sources: relational databases, front-end analytics tools, clickstream data, etc.\nPresent insights and recommendations to executive leadership using high quality visualizations and concise messaging.\nDesign and analyze A/B tests to drive KPI improvements.\nBuild models to predict customer behavior and better understand the drivers of customer engagement and retention.\nDevelop dashboards to inform business decisions with an emphasis on automation and scalability.\nCollaborate with Engineering to advance data infrastructure and governance.\nRequired Qualifications:\n2-5+ years of professional, post-academic relevant experience as an individual contributor performing quantitative analysis, preferably for an internet or technology company.\nBachelors or Masters degree in Math, Engineering, Statistics or other quantitative field, with a track record of academic excellence.\nSelf-starter with a desire to learn and the ability to rapidly understand the business and its drivers.\nAbility to handle multiple projects and meet deadlines in a fast-paced environment.\nAbility to write complex SQL queries to extract data from a variety of internal sources.\nSolid understanding of Statistics with ability to explain statistical concepts to non-technical audiences.\nProficiency with BI tools such as Tableau, Looker, or equivalent.\nDesired Qualifications:\nKnowledge of programming languages such as Python/R preferred.\nExperience with Google Analytics, MixPanel or other front-end analytical platforms a plus.\nAbout BOLD:\n\nBOLD is a fast-paced, innovative company full of smart, committed people who are passionate about our products and love helping people find the career of their dreams. We balance work and fun while continuing to build a successful, fast-growing company that is changing the way people get jobs.\n\nOur vision is to revolutionize the online career world by creating transformational products that help people find the careers they love and reach their full potential.\n\nBOLD is an equal opportunity employer. All persons will receive consideration for employment without regard to race, color, religion, gender, pregnancy, national origin, ancestry, citizenship, age, legally protected physical or mental disability, covered veteran status, status in the U.S. uniformed services, sexual orientation, gender identity or expression, marital status, genetic information or membership in any other legally protected category.\n\nQualified applicants with arrest and conviction records will be considered for the position in accordance with San Francisco's Fair Chance Ordinance.\nStart your job application: click Easy Apply"}, "307": {"company": "Systems Evolution Inc.", "description": "WHO WE LOOK FOR\n\nAn SEI Consultant is a master communicator and active listener who understands how to navigate an audience. Self-aware, almost to a fault, SEI consultants keenly understand how to adjust their approach based on the situation. Following a logical, fact-based approach, our consultants possess the superior ability to see correlations others may not, ask the right questions and drive solutions.\n\nAs super-connectors, our consultants connect not only people, but data, trends and experiences. Mature, humble, and genuine, SEI Consultants frequently go above and beyond for both their clients and their colleagues. SEI Consultants are ethical and trustworthy individuals who do what they say. SEI Consultants have an insatiable curiosity and love to learn. These individuals are commonly tech savvy and early adopters. Their passion for learning is infectious and excites others.\n\nAs every project is different, an SEI Consultant must be adaptable and comfortable with unexpected situations. An SEI Consultant must be at ease with ambiguity because although a client knows that a problem exists \u2013 they need SEI to figure it out and drive a solution. SEI Consultants define ambition differently. SEI Consultants are authentic, low-maintenance individuals who like to hang out with colleagues outside of work. Whether it be cooking, traveling, hiking, or volunteering, SEI Consultants enjoy working with genuine, thoughtful folks who want to steer clear of the traditional grind and share the joy of day-to-day life and activities with colleagues, friends and family.\n\nWHAT WE DO\n\nOur consultants work with clients at all levels of the organization, from the C-suite to the shop floor, helping them to deliver on their most strategic initiatives. We\u2019re known for making realistic, data-driven decisions that deliver value in tangible ways to our clients. Our clients ask for us on projects that require a superior combination of technical and business capabilities, people and management skills, and a collaborative mindset. We excel in understanding complex programs and strategic initiatives and breaking them into actionable pieces.\n\nWe are actively looking for professionals in the following areas:\nData Strategy and Governance\nDatabase Architecture and Development\nData Analysis\nReporting and Data Visualization\nThe ideal candidate will:\nHave experience understanding and solving real business problems\nSolid writing and speaking skills to support data storytelling\nIdeal candidates may call themselves Data Engineers, Data Scientists and Analysts and Data Governance professionals. Experience may include but is not limited to the following:\nExperience with statistical and mathematical modeling, artificial intelligence and machine learning software and methods\nSpecialization in architecting enterprise solutions with visualizations and data-discovery tools such as Tableau, QlikView, Spotfire, Amazon Web Services, Cloud, Salesforce\nTechnical capabilities that include designing scalable data architectures, solution performance tuning, and hardware sizing\nExperience and knowledge of programming and scripting languages, such as , Python, Java, C#, PL/SQL, R and SAS\nExperience and knowledge of relational and dimensional database structures, theories, principles, and practice used in data warehousing and analytics solutions\nExperience managing, populating, and querying database technologies including RDBMS, NOSQL, and big data platforms and experience working with these technologies' ecosystems\nQUALIFICATIONS\n\nRequired\nDemonstrated business and technology acumen\nProven track record of delivering results\nExperience working with and/or leading a team\nAbility to work independently\nAbility to work across industries, roles, functions & technologies\nPositive can-do attitude\nA curiosity for new technology\nAuthorization for permanent employment in the United States (this position is not eligible for immigration sponsorship)\nPreferred\nBachelor\u2019s degree (Mathematics, Computer Science, or related field preferred)\n8+ years professional experience\nConsulting experience\nExperience across our service offerings\nTo apply to this job, click Apply Now"}, "308": {"company": "Billy Casper Golf", "description": "Billy Casper Golf is one of the largest privately owned golf course management companies in the U.S. that prides itself on being an industry leader in advancing the marketing science of the industry. This position will be a key member of the analytics team developing capabilities leveraging the CRM and a suite of marketing technologies to drive conversion and grow revenue for clients. The ideal candidate will have strong ability across the full data lifecycle: from data extraction via queries and API integration through model development, implementation, and measurement. This role will require close collaboration with both marketing and IT team members.\n\nQualifications:\nA degree in Computer Science, Physics, Mathematics, Electrical Engineering, or related discipline.\n3+ years of experience as a Data Scientist.\nExpertise in Python and R with proficiency using PyCharm, Jupyter Notebook, and RStudio environments.\nAdvanced SQL knowledge.\nExperience with cloud storage and computing, preferably Amazon Web Services.\nDemonstrated ability to use predictive modeling and machine learning algorithms to solve business problems.\nCapability with business intelligence and data visualization tools such as Shiny, Tableau, or Domo.\nFamiliarity with Java and/or C++ a plus.\nAbility to convey analysis and results in a clear manner.\nResponsibilities:\nWrite software that extracts and transforms data across disparate sources into unified and centralized systems.\nBuild and deploy algorithmic solutions across various marketing technologies and applications that improve the customer experience and result in increased engagement.\nDevelop and implement models for pricing optimization by channel.\nGenerate methods to evaluate and measure the true business value of marketing tactics.\nPropose reporting formats to effectively communicate meaningful data trends and relationships.\nPresent complex analysis across various organizational levels and external clients.\nStart your job application: click Apply Now"}, "309": {"company": "CopperPoint Insurance Companies", "description": "Founded in 1925, CopperPoint Insurance Companies is a leading provider of workers\u2019 compensation and commercial insurance solutions. With an expanded line of insurance products and a growing six-state footprint in the southwestern United States, CopperPoint embodies stability for policyholders in Arizona, California, Colorado, Nevada, New Mexico and Utah. CopperPoint Mutual Insurance Holding Company is the corporate parent of Arizona-based CopperPoint Insurance Companies, California-based Pacific Compensation Insurance Company and other CopperPoint Insurance Entities.\nThis newly defined role will be part of a core team that is focused on building out an enterprise data warehouse for our rapidly growing commercial insurance company. The person in this role will have the opportunity to engage with colleagues in numerous other departments in the company to understand sources of data as well as the wide variety of uses of data, including financial reporting and data-driven analytics.\n\nPerform data profiling and analysis on internal and external data sets in order to inform requirements, perform testing, and support production processing.\nCreate business requirements to define capabilities for data selection, transformation, collection and distribution.\nDevelop test scenarios for validating the quality of data capabilities.\nPerform testing necessary to validate that developed solutions align with defined business requirements.\nContribute toward root cause analysis of data related defects.\nCollaborate with colleagues in areas sourcing data and consuming data to align expectations as part of developing requirements, creating and executing test plans and to effectively support production processing.\nCollaborate with IT partners on solution design within assigned tasks.\nDevelop a deep understanding of data required for operational, analytic and reporting functions of a property & casualty insurance company.\nComplete special projects as assigned by manager and perform other duties as requested.\n\nStrong analytical, problem solving and strategic thinking skills\nUnderstanding of Analytical and Statistical methods, some experience with analytical software (R, Python, SAS, etc.)\nProgramming skills in Python/ R / Java or equivalent\nInsurance industry experience, especially P&C or workers\u2019 compensation, preferred but not required\nSome actuarial experience, exposure or understanding preferred but not required\nAbility to operate in fast paced environment\nExcellent communication skills both verbally and in written form.\nBachelor\u2019s Degree in Information Systems, Mathematics, Finance or another quantitative subject.\nProficient in Microsoft Office including Outlook, Word, Excel and Access.\nFamiliarity and experience with querying tools (e.g. Cognos, SAS, SQL)\nCopperPoint\u2019s culture of compassion extends to the community through employee volunteerism, corporate matching, Board service, program sponsorships and in-kind contributions. We empower employees by providing 12-hours of paid volunteer time annually and matching their personal contribution to the charities of their choice up to $500 per year. In 2018, CopperPoint employees reported 3,500 volunteer hours.\nCopperPoint offers a competitive compensation package and comprehensive benefits package including major medical, dental, vision and a wide range of competitive benefits programs, generous matching contributions to your 401(k) plan, generous paid time off, tuition reimbursement and other education benefits and business casual dress. CopperPoint is an equal employment opportunity employer. All qualified applicants will receive consideration without regard to race, color, sex, religion, age, national origin, disability, veteran status, sexual orientation, gender identity or expression, marital status, ancestry or citizenship status, genetic information, pregnancy status or any other characteristic protected by state, federal or local law. CopperPoint maintains a drug-free workplace.\nTo apply to this job, click Apply Now"}, "310": {"company": "Practice Fusion", "description": "Overview\n\n\nWelcome to Allscripts! Our Mission is to be the most trusted provider of innovative solutions that empower all stakeholders across the healthcare continuum to deliver world-class outcomes. Our Vision is a Connected Community of Health that spans continents and borders. With the largest community of clients in healthcare, Allscripts is able to deliver an integrated platform of clinical, financial, connectivity and information solutions to facilitate enhanced collaboration and exchange of critical patient information.\n\nThe primary purpose of this role is responsibility for normalizing data, structuring data for predictive analytics, building framework in Azure to facilitate analytics, machine learning, data extraction from structured and unstructured data utilizing NLP, predictive model development for embedment into Allscripts Products.\n\nResponsibilities\n\n\nBusiness Requirements\nWorks with stakeholders to identify business requirements and expected outcomes\nModels and frames business scenarios that impact critical business processes/decisions\nData Requirements\nIdentifies relevant and available data including internal and external data sources\nCollaborates with SMEs to select relevant sources of information\nWorks with teams to support data collection, integration and retention requirements incorporating business knowledge and best practices\nAnalysis\nSolves client analytic problems and communicates results and methodologies\nWorks in iterative processes with the client and validates findings\nDevelops experimental design approaches to validate findings and test hypotheses\nValidates analysis by comparing appropriate samples\nQualification and Assurance\nAssesses expected qualification and assurance of information\nDefines validity of the information and how long the information is meaningful\nAccess Management and Control\nWorks to ensure information is used in compliance with regulatory and security policies\nPerformance\nProvides on-going tracking and monitoring of performance decision systems and statistical models\nSupport\nTroubleshoots and implements enhancements as needed\nQualifications\n\n\nAcademic and Professional Qualifications:\nBS Degree in Computer Science, Mathematics, Statistics or related field\nMasters in mathematics, statistics or computer science or related field\nExperience:\n3-5 years experience of relevant quantitative and qualitative research and analytics experience\nSolid knowledge of statistical techniques\nStrong programming skills (such as Hadoop, Hive, Spark)\nStrong skills and experience with Big Data, Cloud-based computing, neural networks\nStrong proficiency in statistical analysis, quantitative analysis, and predictive analytics\nExperience using machine learning algorithms\nHigh proficiency in use of statistical packages\nIn depth industry/business knowledge\nTravel Requirements:\nNo usual travel\nTravel to educational conferences as needed\nWorking Arrangements:\nWork is performed in a standard office environment with minimal exposure to health or safety hazards\nAt Allscripts, our greatest strength comes from bringing together talented people with diverse perspectives to support the technology needs of 180,000 physicians, 1,500 hospitals and 10,000 post-acute organizations across the globe. Allscripts offers a comprehensive compensation and benefits package, including holidays, vacation, medical, dental, and vision insurance, company paid life insurance and retirement savings.\n\nAllscripts policy is to provide equal employment opportunity and affirmative action in all of its employment practices without regard to race, color, religion, sex, national origin, ancestry, marital status, protected veteran status, age, individuals with disabilities, sexual orientation or gender identity or expression or any other legally protected category. Applicants for North American based positions with Allscripts must be legally authorized to work in the United States or Canada. Verification of employment eligibility will be required as a condition of hire.\n\nFrom a \"VEVRAA Federal Contractor\" We request Priority Referral of Protected Veterans\nStart your job application: click Apply Now"}, "311": {"company": "Novartis", "description": "To continue to add even greater value for the business we need to have the right people with the right capabilities in the right location.\nNovartis has recently signed off a partnership with Microsoft to use AI in drug development and is now looking for talented and passionate professionals to join our NBS IT team and help us #ReimagineMedicine\nIn exchange, Novartis offers this extraordinary work experience, dealing with latest technologies and evolving scenarios, with a real opportunity to develop in a highly fast-paced technology-driven environment where collaboration and innovation are at the heart of who we are and what we do.\n\nPosition Purpose:\n\u2022Create and maintain optimal data pipeline architecture on Azure platform\n\u2022Develop batch processing solutions by using Data Factory and Azure Databricks\n\u2022Design for real-time processing by using Stream Analytics and Azure Databricks\n\u2022Ingest data using Polybase\n\u2022Implement Azure Databricks clusters, notebooks, jobs, and autoscaling\n\u2022Assemble large, complex data sets that meet functional / non-functional business requirements.\n\u2022Design relational and non-relational data stores on Azure\n\u2022Design security for source data access. Chose the appropriate authentication mechanism, such as access keys, shared access signatures (SAS), and Azure Active Directory (Azure AD)\n\u2022Design for data encryption for data at rest and in transit\n\u2022Design for data auditing and data masking\n\u2022Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n\u2022Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources\n\u2022Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\n\u2022Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\n\nNovartis Business Services IT (NBS IT) is working to support Novartis to deliver better patient outcomes through innovative use of information and technology. As technology is reshaping the healthcare industry, IT will be a differentiator for our businesses, inspiring new ideas and enabling Novartis to reimagine medicine.\n\nMajor Accountabilities:\n\u2022Ensure that system designs adhere to solution architecture design (i.e. high level conceptual design) and are traceable to functional as well as non-functional requirements in projects/enhancements\n\u2022Ensure designs produced adhere to architectural roadmap and support the development, execution and operations of solutions\n\u2022Ensure system design standards are defined to improve and sustain standardization of solutions\n\u2022Ensure that solutions meet requirements outlined in the architecture handbook\n\u2022Support scoping, fit-gap workshops for projects/enhancements, propose solutions for key gaps, provide effort estimations and alignment with business teams\n\u2022Ensure that project/enhancements work is delivered to agreed time, cost and quality constraints following the release calendars\n\u2022Ensure that developed solutions are peer reviewed, formally documented and signed off by business\n\u2022Ensure that solution testing is performed to meet quality standards\n\u2022Establish standardized design and development processes to enable cost effective delivery\n\u2022Ensure the overall user experience is taken into account when designing new solutions and services\n\u2022Perform scoping, fit-gap workshops for projects/enhancements, proposes solutions for key gaps, provide effort estimations and align with business teams\n\u2022Follow standardized design and development processes to enable cost effective delivery\n\u2022Ensure adherence with Security and Compliance policies and procedures within Solution Design scope\n\u2022Directly contribute in the design, implementation and rollout of Data Engineering solution on Novartis Big Data platforms, including code management and review, (automated) testing, configuration and performance tuning.\n\nAbout Novartis:\nNovartis provides innovative healthcare solutions that address the evolving needs of patients and societies. Headquartered in Basel, Switzerland, Novartis offers a diversified portfolio to best meet these needs: innovative medicines, cost-saving generic and biosimilar pharmaceuticals and eye care. Novartis has leading positions globally in each of these areas. In 2016, the Group achieved net sales of USD 48.5 billion, while R&D throughout the Group amounted to approximately USD 9.0 billion. Novartis Group companies employ approximately 121,000 full-time-equivalent associates. Novartis products are sold in approximately 155 countries around the world. For more information, please visit http://www.novartis.com\n\nPosting Title\nAzure Data Engineer\nApply Now: click Apply Now"}, "312": {"company": "Novartis", "description": "750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\n\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data. Where you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us re-imagine medicine.\n\nTwo companies and one incredible alliance. Novartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop trans-formative medicines faster and more cost-effectively for patients worldwide. We are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics. In this newly formed alliance with Microsoft, you will lead analysis of large image data sets for Novartis.\nYour responsibilities:\nIn this newly created role, you will:\n\u2022 Lead independently end-to-end analysis of image data sets\n\u2022 Take a hands-on role and deliver on multiple highly visible data science projects\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Keep ahead of latest development in the field and mentor associates\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Inspire others on culture change\n\nPosting Title\nSenior Data Scientist \u2013 Image Analytics, Novartis AI Innovation Lab\nApply Now: click Apply Now"}, "313": {"company": "Wells Fargo", "description": "Job Description\n\nImportant Note: During the application process, ensure your contact information (email and phone number) is up to date and upload your current resume when submitting your application for consideration. To participate in some selection activities you will need to respond to an invitation. The invitation can be sent by both email and text message. In order to receive text message invitations, your profile must include a mobile phone number designated as Personal Cell or Cellular in the contact information of your application.\n\nAt Wells Fargo, we want to satisfy our customers financial needs and help them succeed financially. Were looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where youll feel valued and inspired to contribute your unique skills and experience.\n\nHelp us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.\n\nConsumer Banking is an industry leader in supporting homeowners and consumers, in addition to operating one of the most extensive banking franchises in the country. We serve mass market, affluent, and small business customers; as well as provide home and personal lending. Our focus is on delivering an exceptional experience for our customers through financial advice and guidance coupled with providing the products and services that will help them realize their financial hopes and dreams. Weve built our team of top professionals by rewarding their accomplishments and ensuring they have what's needed to succeed.\n\nAs part of the Wells Fargo Auto Data Services Team the Analytics Consultant 5 will be part of the Data Services Team within Wells Fargo Auto. The Data Services team serves as a strategic partner for WFA by providing data management for the line of business, offering best in class insight, analysis, and governance while fostering strong relationships throughout the organization to help build innovative solutions and protect our businesses and clients. Our Data Services team promotes a strong risk culture and provides strategic/operational leadership. May travel occasionally to meet with stakeholders.\n\nPlease note that this posting may be taken down early due to job seeker volume.\n\nPrimary responsibilities include:\nPerform data validations for SHRPs, regulatory MRAs, and internally identified issues. Evaluate and test business requirements, programs written by the LOB to run control reports, and output from those programs. Validate the output of those programs against the data warehouse.\nProvide advice the LOB on the design and execution of control reports to address issues found by regulators and internal resources.\nUse advanced programming skills in SAS and SQL to write, modify, and test data extraction and analytics programs in a Unix environment.\nProvide data validation and code review for reports and applications written by other teams within Wells Fargo Auto.\nReview documentation of control processes as implemented by the LOB.\nCollaborate with users to design, implement, automate and manage data acquisition and load processes.\nTranslate business needs and objectives into technical requirements and data solutions.\nPerform data discovery and investigation to ensure that the data meets the business objectives.\nBuild and maintain the necessary and mandated controls and procedures to ensure data accuracy and business functionality.\nSpecific duties and responsibilities of the role include, but may not be limited to:\nHave strong business sense and communication skills to interact seamlessly with Wells Fargo Auto business partners and serve as a liaison with Credit Risk, Corporate Controllers, and Corporate Credit and COE stakeholders to improve efficiencies and enhance the data quality.\nSupport enterprise and LOB data initiatives associated with regulatory and risk reporting.\nDevelop in-depth knowledge and expertise regarding WFA data.\nStrive for an exceedingly high level of accuracy.\nDevelop an innate understanding of the data and respond to data/production questions/issues by performing analysis of findings and trends using SAS and SQL.\nEnsure adherence to data management regulations and policies.\nConsult with business partners to identify new data elements and understand the process in how the data elements have been originated. Deep dive in data warehouses to understand and clarify the data elements.\nProvide leadership to other Data Services consultants.\nRequired Qualifications\n8+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 5+ years of experience in one or a combination of the following: reporting, analytics, or modeling\nDesired Qualifications\nExtensive knowledge and understanding of research and analysis\nStrong analytical skills with high attention to detail and accuracy\nExcellent verbal, written, and interpersonal communication skills\nAbility to execute in a fast paced, high demand, environment while balancing multiple priorities\nAdvanced Microsoft Office (Word, Excel, Outlook and PowerPoint) skills\nAbility to prioritize work, meet deadlines, achieve goals, and work under pressure in a dynamic and complex environment\nAbility to develop partnerships and collaborate with other business and functional areas\nExperience in gathering, analyzing and interpreting large datasets\nAbility to work effectively in virtual environment where key team members and partners are in various time zones and locations\nAbility to work effectively in a team environment and across all organizational levels, where flexibility, collaboration, and adaptability are important\nAbility to influence, partner, and negotiate with senior business leaders to gain commitment to accomplish business goals\nStrong analytical skills with ability to turn findings into executable plans to meet business objectives\nOther Desired Qualifications\n8+ years of SAS and/or SQL programming experience.\nExperience with Wells Fargo Auto data and business systems.\nJob Expectations\nAbility to travel up to 10% of the time\nStreet Address\n\nNC-Raleigh: 1100 Corporate Center Dr - Raleigh, NC\nAZ-Chandler: 2501 S Price Rd - Chandler, AZ\nTX-Irving: 250 E John Carpenter Freeway - Irving, TX\nIA-West Des Moines: 7001 Westown Pkwy - West Des Moines, IA\nNC-Charlotte: 1525 W Wt Harris Blvd - Charlotte, NC\nMN-Minneapolis: 550 South 4th St - Minneapolis, MN\n\nDisclaimer\nAll offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.\n\nRelevant military experience is considered for veterans and transitioning service men and women.\nWells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.\nCONSUMER BNKG\nApply Now: click Apply Now"}, "314": {"company": "Novartis", "description": "750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\n\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data. Where you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us re-imagine medicine.\n\nTwo companies and one incredible alliance. Novartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop trans-formative medicines faster and more cost-effectively for patients worldwide. We are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics. In this newly formed alliance with Microsoft, you will lead Biochemistry / Pharmaceutical Chemistry data science efforts.\n\nYour responsibilities:\nIn this newly created role, you will:\n\u2022 Lead data science efforts to develop novel compound suggestions to Novartis\u2019 medicinal chemistry teams\n\u2022 Take a hands-on role to deliver on multiple highly visible data science projects\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Keep ahead of latest development in the field and mentor associates\n\u2022 Inspire others on culture change\n\n\nPosting Title\nSenior Data Scientist \u2013 Gen Chem, Novartis AI Innovation Lab\nApply Now: click Apply Now"}, "315": {"company": "Alector", "description": "At Alector, our mission is to develop therapies that empower the immune system to cure neurodegeneration. Our team is solely focused on developing cures for some of the most challenging diseases facing our society. We are supported in this mission by experienced and accomplished scientists and board members, leading healthcare investors and some of the most innovative pharma companies.\nUse your cutting-edge analytical skills and biological insights to help us achieve our mission of saving lives by curing neurodegenerative diseases and cancer.\n\nAs a Scientist for the bioinformatics team, you will play an important role in every aspect of Alector scientific mission, from target discovery to pre-clinical and clinical phases. You will work closely with - and under the mentorship of - our scientists to discover and develop novel drugs targeting neurodegenerative disorders and cancer. As part of a talented and multi-disciplinary bioinformatics team you have a transversal role and interact closely with scientists from different fields. You will carry out valuable analyses which will further Alector\u2019s collective scientific understanding. You will apply your existing technical skills, and learn new skills. As an early hire, you\u2019ll be influential in championing and developing Alector\u2019s culture.\n\nDuring the first year, your goals will include:\nClosely collaborate with research and clinical scientists to develop informatics analysis approaches and independently execute bioinformatics analyses that support discovery and pre-clinical studies such as new target identification and biomarker development\nIdentify relevant internal and external data and knowledge resources and execute integrated data mining analyses\nKeep track of the current analytical methodologies and introduce them when appropriate\nCommunicate analytical analysis verbally and in writing to teammates\nWe'd love to hear from you if:\nYou take pride in being persistent, self-motivated, and efficient\nYou thrive in an environment where we work independently and on teams\nYou demonstrate a track record of learning new things and troubleshooting independently\nYou are fluent in scientific scripting languages such as R, Perl/Python, and very adept at working in both linux and windows environments\nYou have hands-on experience in genomics and genetic databases, in data analyses using existing and custom pipelines\nYou have an in-depth knowledge of current technologies for genetic, transcriptomic and proteomic data generation and analysis, including single-cell RNAseq, in silico deconvolution or eQTL analysis.\nYou have experience in performing statistical analysis\nYou are familiar with human genetics concepts and analytics\nYou have a solid background in immunology, oncology or neurodegenerative disorders\nYour academic background includes a PhD in bioinformatics, immunology, neuroscience, biology or a related scientific field\nYou have a point of view but are low ego\nYou have excellent communication skills\nAt Alector, we believe that high-performing teams include people from a wide variety of backgrounds and experiences who can challenge each other\u2019s assumptions with fresh perspectives and bring creative ideas to the table. We are committed to building an open, diverse, and inclusive environment for all employees. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, sexual orientation, age, marital status, veteran status, or disability status, or any other characteristics protected under applicable federal, state, or local laws.\nAlector is a phenomenal place to learn and experiment. If you excel in a dynamic environment where everyone is committed to finding a cure, where you\u2019ll drive growth, this is the role for you. There is no limit to how far you can go with us.\n\nBenefits\nWhile we\u2019ve focused on what to look forward to during the first year and beyond, Day One is great, too: committed and driven colleagues, a bold and important company goal, state-of-the-art brand-new brightly-lit offices in the heart of the biotech area, competitive compensation and benefits. But these matter only if you\u2019re excited to build and own something great, and tackle these challenges with us. Come join us.\nTo apply to this job, click Apply Now"}, "316": {"company": "Alector", "description": "750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\n\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data. Where you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us re-imagine medicine.\n\nTwo companies and one incredible alliance. Novartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop trans-formative medicines faster and more cost-effectively for patients worldwide. We are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics. In this newly formed alliance with Microsoft, you will lead NLP analytics capabilities for Novartis.\n\nYour responsibilities:\nIn this newly created role, you will:\n\u2022 Build Novartis\u2019 NLP center of excellence to make it a team of international reputation\n\u2022 Take a hands-on role and coach data science teams to deliver on multiple high visibility projects\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Coach and mentor associates\n\u2022 Inspire others on culture change\n\nPosting Title\nHead Data Scientist \u2013 NLP lead, Novartis AI Innovation Lab\nApply Now: click Apply Now"}, "317": {"company": "Novartis", "description": "Why consider Novartis?\n750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data. Where you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us re-imagine medicine.\n\nTwo companies and one incredible alliance. Novartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop trans-formative medicines faster and more cost-effectively for patients worldwide. We are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics. In this newly formed alliance with Microsoft, you will lead image analytics capabilities for Novartis.\n\nYour responsibilities:\nIn this newly created role, you will:\n\u2022 Build Novartis\u2019 image analytics center of excellence to make it a team of international reputation\n\u2022 Take a hands-on role and coach data science teams to deliver on multiple high visibility projects\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Coach and mentor associates\n\u2022 Inspire others on culture change\n\nPosting Title\nHead Data Scientist \u2013 Image Analytics lead, Novartis AI Innovation Lab\nStart your job application: click Apply Now"}, "318": {"company": "Ecolab", "description": "With annual sales of $15 billion, Ecolab (ECL) is the global leader in water, hygiene and energy technologies and services that protect people and vital resources. Our 49,000 associates help make the world cleaner, safer and healthier by delivering critical insights and innovative solutions to help our customers achieve clean water, safe food, abundant energy and healthy environments at nearly three million customer locations in more than 170 countries.\n\nOur innovative products and services touch virtually every aspect of daily life and are used in hospitals, hotels, restaurants, schools, manufacturing plants, refineries and other locations throughout the world. Many of the worlds most recognizable brands rely on Ecolab to help ensure operational efficiencies, product integrity and brand reputation.\n\nWhen you come to work at Ecolab, you get to take on some of the worlds most meaningful challenges and have the opportunity to learn and grow, shape your career, make an impact and quickly see the importance of your work.\n\nFor more Ecolab news and information, visit www.ecolab.com. Follow us on Twitter @ecolab, Facebook at facebook.com/ecolab, LinkedIn at Ecolab or Instagram at Ecolab Inc.\n\nEcolabs Nalco Water division is seeking a business focused Data Scientist to unlock the value in data assets while creating new and unique offerings for customers in the industrial segment. In this role, you will work with the business innovation teams, marketing, sales and customers along with expertise from Ecolabs Center for Advanced Analytics, to help develop the data strategy and advanced analytics pipeline for the business.\n\nWhat you will do\nActively engage with internal business teams to understand industrial challenges and deliver robust, data driven solutions.\nWork alongside global counterparts to solve data-intensive problems using standard analytical frameworks and tools.\nBe encouraged and expected to innovate and be creative in your data analysis, problem solving and presentation of solutions.\nNetwork and collaborate with a broad range of internal business units to define and deliver joint solutions.\nWork alongside customers to leverage cutting edge technology (machine learning, streaming analytics and real big data) to creatively solve problems and disrupt existing business models.\nWhats in it for you\nA problem-solving mindset with the ability to understand business challenges and how to apply your analytics expertise to solve them.\nThe unique person who can present complex mathematical solutions in a simple manner that most will understand including customers.\nAn individual excited by innovation and new technology and eager to finds ways to employ these innovations in practice.\nA team mentality empowered by the ability to work with a diverse set of individuals.\nMinimum Qualifications\nA Bachelors degree in Data Science, Math, Statistics, Computer Science or related field with an emphasis on analytics.\n6+ Years professional experience in a data scientist/analyst role\nProficiency in your statistics/analytics/visualization tool of choice, but preferably in the Microsoft Azure Suite, including Azure ML Studio and PowerBI as well as Python and SQL.\nPreferred Qualifications\nExcellent communication, organizational transformation, and leadership skills\nDemonstrated excellence in Data Science, Business Analytics and Engineering\nOur Commitment to Diversity and Inclusion\n\nAt Ecolab, we believe the best teams are diverse and inclusive, and we are on a journey to create a workplace where every associate can grow and achieve their best. We are committed to fair and equal treatment of associates and applicants. We recruit, hire, promote, transfer and provide opportunities for advancement on the basis of individual qualifications and job performance. In all matters affecting employment, compensation, benefits, working conditions, and opportunities for advancement, we will not discriminate against any associate or applicant for employment because of race, religion, color, creed, national origin, citizenship status, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran.\n\nIn addition, we are committed to furthering the principles of Equal Employment Opportunity (EEO) through Affirmative Action (AA). Our goal is to fully utilize minority, female, disabled and covered veteran individuals at all levels of the workforce. Ecolab is a place where you can grow your career, own your future and impact what matters.\n\nWe will consider for employment all qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles Fair Chance Initiative for Hiring Ordinance and the San Francisco Fair Chance Ordinance.\nApply Now: click Apply Now"}, "319": {"company": "ExtraHop Networks, Inc.", "description": "Would you like to be part of a company where the machine learning is at the core of its product offerings? Do you want to build (not analyze, support or A/B test) machine learning based product features from scratch? Are you interested in applying machine learning to a dataset that no other company in the world has? Can you innovate in a greenfield machine learning application environment that has rarely been researched in academia? Then come and join a collaborative team that builds solutions which provide deep performance insights, behavioral security analyses, and drives business analytics.\n\nAre you looking to make an impact? Do you love seeing your work implemented and hearing how your contributions have made a difference? ExtraHop offers an exciting, high energy, and versatile environment in which people are encouraged and supported to collaborate on industry-leading technology while they develop and enrich their individual growth. And we're doing it with creativity, intellectual curiosity, and a sense of humor (it's required here, seriously).\n\nThe ExtraHop platform is a novel approach to processing vast amounts of wire data in real-time. It provides unparalleled visibility into every transaction and behavior for every single entity within an enterprise network. This complete visibility allows our customers to proactively detect and remediate IT performance issues and cyber attacks in real time. As part of the data science team, you will be responsible for end-to-end delivery and operation of all machine learning capabilities across ExtraHop products.\n\nThe Role\nInnovate and build new attack detection and analytic capabilities using machine learning on the ExtraHop platform\nCollaborate with software engineers and own the end-to-end development of machine learning features and capabilities (from ideation to productionization)\nIdentify and engineer new features with our networking subject matter experts\nInspire and educate our user interaction designers to incorporate model results and analysis into user workflows\nLearn from threat researchers and become an expert in network attack scenarios and encode domain expertise into algorithms and models\nTypical successful candidates have;\nBachelor\u2019s, Master\u2019s or Phd degree or equivalent experience in computer science, engineering, mathematics/statistics or other quantitative fields\nFive or more years of professional experience and/or equivalent combination of education and experience\nProficient at programming in Python or other high level languages\nKnowledge of basic computer science data structures and algorithms\nA deep understanding of the theory behind machine learning models such as generalized linear models, classification, clustering, ensemble learning, time series analysis, graphical analysis, neural networks, etc.\nWillingness to learn complex topics in cyberattacks and network monitoring\nYou make the bonus round if you have:\nExperience in applying machine learning or statistical modeling to solve real world problems\nExperience in building end-to-end machine learning systems\nAn understanding of network protocols including IP, TCP, UDP, DNS, and HTTP\nKnowledge of building scalable and high-performance systems\nAn understanding of various product-development life cycles\nABOUT EXTRAHOP\n\nExtraHop is an enterprise cyber analytics and performance monitoring company helping the world\u2019s leading organizations understand and secure their entire environment from core to edge to cloud. Our breakthrough approach to analytics and machine learning helps our customers investigate threats, ensure the delivery of critical applications, and secure their investment in the cloud, resulting in 95% faster threat detection and reducing unplanned downtime by 86% while providing the best possible customer experience.\n\nExtraHop is recognized by leading organizations for both its innovation in the market and its commitment to building a world-class team. We\u2019ve been named to Wealthfront\u2019s Career-Launching Companies list for the last four years, and JMP Securities put ExtraHop on its 2018 Super 70 List as one of the most strategically positioned private companies in the cybersecurity industry. Credit Suisse recognized ExtraHop as a member of its inaugural Disruptive Technology Recognition Program, and SC Media named ExtraHop a 2019 Industry Innovator for enterprise network traffic analysis.\n\nWith well over $100 million in bookings in 2018, and 10x growth in security, the opportunity with ExtraHop has never been greater. Are you ready to rise above the noise?\n\nExtraHop is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, disability, military status, or national origin or any other characteristic protected under federal, state, or applicable local law.\n#LI-BKW\nApply Now: click Apply Now"}, "320": {"company": "Alector", "description": "At Alector, our mission is to develop therapies that empower the immune system to cure neurodegeneration. Our team is solely focused on developing cures for some of the most challenging diseases facing our society. We are supported in this mission by experienced and accomplished scientists and board members, leading healthcare investors and some of the most innovative pharma companies.\nAs Associate Scientist for the immuno-oncology team, you\u2019ll work closely with scientists in Research to advance our drug discovery programs. You will be able to contribute across a variety of programs and have broad involvement in work central to Alector\u2019s strategic goals. You will apply your existing technical skills, learn new skills, and play a key role in nonclinical development of the programs and help grow the company and guide its direction. As an early hire, you\u2019ll be influential in championing and developing Alector\u2019s culture.\nDuring your first year, your goals will include:\nPerforming cell line-based and primary immune cell-based functional assays for in vitro target validation and antibody characterization\nCollaborating with scientists to develop syngeneic tumor models for in vivo efficacy studies of lead antibodies\nProcessing and phenotyping human and/or mouse tumor samples for marker expression and immune cell infiltration\nRecording experiments and results, including analyzing, interpreting, and presenting data to the rest of the company\nWe'd love to hear from you if:\nYou take pride in being persistent, self-motivated, and efficient\nYou thrive in an environment where we work independently and on teams\nYou have experience in isolating immune cell populations and performing immune assays (including, but not limited to flow cytometry, proliferation assays, cytokine release assays - ELISA, Luminex, or MSD)\nYou demonstrate a track record of learning new skills and troubleshooting independently\nYou have a Bachelor\u2019s with minimum 8 years experience or Master\u2019s Degree with minimum 4 years of experience in the lab for Associate Scientist\nYou have a point of view but are low ego\nAt Alector, we believe that high-performing teams include people from a wide variety of backgrounds and experiences who can challenge each other\u2019s assumptions with fresh perspectives and bring creative ideas to the table. We are committed to building an open, diverse, and inclusive environment for all employees. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, sexual orientation, age, marital status, veteran status, or disability status, or any other characteristics protected under applicable federal, state, or local laws.\n\nAlector is a phenomenal place to learn and experiment. If you excel in a dynamic environment where everyone is committed to finding a cure, where you\u2019ll drive growth, this is the role for you. There is no limit to how far you can go with us.\n\nBenefits\nWhile we\u2019ve focused on what to look forward to during the first year and beyond, Day One is great, too: committed and driven colleagues, a bold and important company goal, state-of-the-art brand-new brightly-lit offices in the heart of the biotech area, competitive compensation and benefits. But these matter only if you\u2019re excited to build and own something great, and tackle these challenges with us. Come join us.\nApply Now: click Apply Now"}, "321": {"company": "Novartis", "description": "Two companies and one incredible alliance. Novartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop transformative medicines faster and more cost-effectively for patients worldwide.\n\nWe are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics.\n\nIn this newly formed alliance with Microsoft, you will lead Causal & Predictive analytics capabilities for Novartis .\n\nIn this newly created role, you will:\n\n\u2022 Build Novartis\u2019 Causal & Predictive center of excellence to make it a team of international reputation.\n\n\u2022 Take a hands-on role and coach data science teams to deliver on highly visible multiple projects.\n\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions.\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Coach and mentor associates\n\u2022 Inspire others on culture change\n\nWhy consider Novartis?\n750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\n\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data. Where you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us reimagine medicine.\n\nPosting Title\nHead Data Scientist, Predictive Analytics Lead AI Innovation Lab\nTo apply to this job, click Apply Now"}, "322": {"company": "eSolutions, Inc.", "description": "eSolutions is a healthcare technology company working to strengthen providers' revenue health so they can focus on what really matters \u2013 their patients. Since 1999, we've delivered the best RCM tools and improved billing outcomes for our clients, who include physicians and providers in the hospital, home health, hospice, health center, skilled nursing/long-term care and durable medical equipment markets.\n\nWe are seeking a dynamic Data Analyst to analyze, prepare, and process complex datasets to be consumed for direct insights for internal and external clients. The candidate will be expected to work on various data and integration projects simultaneously. Project work will include a variety of data analysis, data modeling, database development, ETL, and system integration efforts.\n\nThe Data Analyst role has responsibility for analyzing complex datasets and designing data models for use by:\nData warehouse and database administrators who create the physical objects in the target data stores based on the data models\nDevelopers who create the code that references the data in the data model\nThis position works closely with domain experts, developers, data stewards, business stakeholders, product owners, and 3rd party entities to design and build data models.\n\nResponsibilities\nDesign, develop and maintain enterprise and departmental data models for data marts, data warehouses, databases and reporting\nInterpret data and analyze results using statistical techniques and provide ongoing reports\nDevelop and maintain metadata for items in the data models\nServe as subject matter expert in multiple analytic disciplines and data domains\nResearch business problems and create models that help analyze these business problems\nIdentify, analyze, and interpret trends or patterns in complex datasets\nWork with internal teams to establish ETL and data cleansing processes\nDevelop and implement interactive analytic dashboards and data visualizations\nProvide technical, analytical, and business knowledge support to the team\nConduct sophisticated statistical testing and exploratory data analysis\nEnsure effective communication between internal team members and between teams on data process flow\nDevelop routines and procedures to educate and facilitate best practices and use of analytic tools and processes\nQualifications\n3+ years related experience with data analysis and analytics\nExcellent knowledge of data modeling, database design / development, data mining and segmentation techniques\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\nDemonstrated ability to write complex SQL to query OLTP and OLAP databases\nExperience in report writing, analytics, logical, and physical database design\nExcellent verbal and written communication skills\nA drive to succeed and work independently and on a team, with the ability to multi-task and deliver quality results\nBachelor's degree in IT, Statistics/Analytics, Software Engineering, or related major\nPreferred Qualifications\nExperience in one or more Data Modeling and Business Intelligence tools\nExperience with Data Visualization tools such as Tableau or Power BI\nExperience developing business analytics in the Microsoft stack (SQL Server)\nExperience in Data Mining using R, SAS, or other analytics software\nKnowledge of a data lake ecosystem, such Hadoop, Spark, MPP databases\nHands on experience with AWS or Azure cloud data analytics services\nKnowledge of Revenue Cycle process and claims datasets\nBenefits\nMedical, dental and vision insurance\nEmployer paid life insurance coverage\nEmployer paid short and long-term disability\n401K with strong matching program\nPre-tax flexible spending account\n15 PTO days on year one and 20 PTO days on year two\n9 company paid holidays per year\n8 hours of community service paid time off per year\nPerks\nEligibility for annual bonus\nCasual dress code\nDiscounted gym membership\nCompany sponsored events to gather and socialize with family and co-workers\nCompany kitchen and Foodsby\nSummer Fridays\nSecurity roles and responsibilities shall include the following requirements\nImplement and act in accordance with the organization's information security policies\nProtect assets from unauthorized access, disclosure, modification, destruction or interference\nExecute security processes or activities\nEnsure responsibility is assigned to the individual for actions taken\nReport security event or potential events or other security risks to the organization\neSolutions, Inc. has created an excellent work environment, one designed to help you reach your full potential by providing you with all the tools and support needed to succeed.\n\neSolutions is an Equal Opportunity Employer.\nStart your job application: click Easy Apply"}, "323": {"company": "Rally Health", "description": "Rally Health\u2122 is all about putting health in the hands of the individual. It's our mission, and it drives everything we do, which is to empower people with easy-to-use online and mobile tools that help them take charge of their health and health care, from improving their diet and fitness to selecting health benefits, and choosing the right doctor at the right price for their needs.\n\nOur culture is built on a deep and sincere dedication to helping people live healthier lives. To do this, we are committed to innovating continuously at every level. We know that some of the things we do are not going to work, and that's okay. We're not trying to build something that is churn and burn. We're building something that supports people over their lifetime. Every day, we get to work with amazing people on something that directly impacts the lives of millions of people for the better.\n\nAt Rally Health, we believe that two heads truly are better than one. Rallyers understand the importance of communication and collaboration, ensuring that we work we produce is the best that it can be. Every opinion is valid and valued, and we share ideas that elevate the way we work. We know that the big picture and the small details are tied together, and we keep both in mind. Everything we do is executed with our users in mind, so we make sure that all of our work has a human touch. Here at Rally, we take advantage of the opportunity to build strong relationships with each other, because it makes us better.\n\nAbout the Team: The Data Sciences team is seeking a senior data scientist to support our Find and Price Care product, which enables and rewards consumers to find, price, schedule, and pay for the care they need. We work with diverse data to generate insights and develop strategies that help our products evolve to better serve our customers and users, informing them about their healthcare options and engaging them in their own healthcare.\n\nYour day to day:\nYou'll bring your knowledge of health data and machine learning algorithms to understand how our users search for Care and make recommendations on personalizing the search experience.\nYou'll closely collaborate with product leaders, leveraging data and strategies to measure and improve our search offerings through algorithms that optimize search results, metric development and instrumentation, data investigations, designing and interpreting experiments, exploratory research, and impact evaluation.\nYou'll be empowered to mine our data which includes user interactions, activity, and achievements in our wellness product; lifestyle and health status from our comprehensive health assessment survey; search terms when seeking care; and direct health information such as biometrics, health risk, and medical claims.\nYour core responsibilities:\nBuild robust and interpretable models that predict how digital search engagement leads to real-world health outcomes.\nWork with Product and Engineering to find new opportunities for predictive modeling and to improve our search infrastructure.\nDevelop replicable analyses and a reusable code base for understanding and enhancing search performance.\nSharpen our data science capacity by mentoring team members in areas of your expertise whether it's NLP, network analysis, search algorithms, or personalization.\nAbout you:\nDegree in a quantitative field with 5+ years of experience as a data scientist supporting product development using machine learning, Natural Language Processing, Network Analysis, or ElasticSearch to power high impact customer-facing features.\nEffective communicator, with and without data, paired with a dedication to understanding user problems and technical challenges.\nExperience building and evaluating machine learning-powered search applications.\nHistory of successfully driving analytic projects and investigations independently, owning them from design to delivery of results with a strong focus on quality and analytic integrity.\nDemonstrated experience with data-driven personalized product development (A/B testing, time series analysis, propensity modeling, etc).\nPreferred:\nHealthcare or wellness specific business knowledge and/or experience with behavioral and claims data\nExperience implementing machine learning models in consumer-facing applications\nExperience working with a variety of data environments, e.g., Hadoop, HDFS, SQL, Mongo, DataBricks, ElasticSearch, etc.\nPhD degree in NLP or Network Science\nWhy join Rally? On top of an innovative work atmosphere and a chance to help people change their lives, we offer competitive pay, daily catered lunches, and an extensive benefits package for all full-time employees (including medical, dental, vision and 401(k)). In addition, we offer the ability to grow, while truly making an impact in the healthcare system.\n\nRally knows that we are strongest when our employee population reflects the diversity of the world around us, and we are a place where all voices are valued. A diverse workforce will enrich us with the talent, energy, perspective and inspiration we need to achieve our mission. Rally Health believes in a policy of equal employment and opportunity for all people. It is our policy to recruit, hire, train, and promote individuals in all job titles, and administer all programs, without regard to race, color, religion, national origin or ancestry, citizenship, sex, age, marital status, pregnancy, childbirth or related medical conditions, personal appearance, sexual orientation, gender identity or expression, family responsibilities, genetic information, disability, matriculation, political affiliation, veteran status, union affiliation, or any other category protected by applicable federal, state or local laws.\n\nIndividuals with disabilities and veterans are encouraged to apply. Applicants who require an accommodation related to the application and/or review process should notify Talent Acquisition (recruiting@rallyhealth.com).\nTo apply to this job, click Easy Apply"}, "324": {"company": "NetImpact Strategies", "description": "JOB SUMMARY\nTitle: Data Scientist\nClearance Requirement: Active Top Secret\nRequisition Number: 1909-1202\nLocation: Vienna, VA\nRemote Flexibility: 100% on client site\nJob Type: Full-Time, Salaried\nSUMMARY\n\nWe are looking for a Data Scientist who will support our customer with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\nRESPONSIBILITIES\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nDevelop company A/B testing framework and test model quality.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nREQUIRED SKILLS\n5-7 years of experience manipulating data sets and building statistical models,\nMaster's or Ph.D. in Statistics, Mathematics, Computer Science\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\nCoding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.\nKnowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.\nExperience querying databases and using statistical computer languages: R, Python, SLQ, etc.\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience visualizing/presenting data for stakeholders using: Hue or Kibana\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams.\nA drive to learn and master new technologies and techniques.\nWORKING AT NETIMPACT STRATEGIES, INC.\n\nNetImpact Strategies specializes in Strategy and Business Transformation, IT Modernization, Data-Driven Intelligence, Cloud Services, and Cybersecurity. We are a team of skilled Consultants who listen to our clients' needs. We design and implement comprehensive, tailored solutions which are both mindful of the client culture and organizational dynamics. As mission needs change, new priorities emerge, technologies advance, and methodologies evolve; NetImpact stands out as a trusted advisor that can solve the challenges of today while looking for the opportunities of tomorrow. Our professionals stay abreast of these changes to provide agile, outcome-focused results for federal agency strategic and tactical needs. Approaching engagements as a partner, we provide solutions which empower our clients to achieve results that align with their mission and strategic vision.\n\nINCLUSION & EQUAL OPPORTUNITY EMPLOYMENT\n\nNetImpact Strategies, Inc. is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other basis prohibited by applicable law. Recruitment, training and development, transferring and promotion practices are performed without regard to the above-listed items.\n\nON THE JOB\n\nIn compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\n\nWork Environment: All employees are responsible for their own safety, as well as that of others in the workplace. To help us maintain a safe workplace, everyone must be safety-conscious at all times. This position is performed in a typical office environment. The noise level in the work environment is usually quiet to moderate.\n\nPhysical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\n\nWhile performing the duties of this job, the employee is regularly required to talk or hear. The employee frequently is required to stand; walk; use hands to finger, handle or feel; and reach with hands and arms.\n\nDisability Specifications: NetImpact Strategies will make reasonable accommodations in compliance with the Americans with Disabilities Act of 1990.\nApply Now: click Easy Apply"}, "325": {"company": "Reliant Funding", "description": "Established in 2008, Reliant provides short term working capital for small and mid-sized businesses nationwide. Reliant has been named to the Inc. 500/5000 for 7 consecutive years and San Diego Business Journal\u2019s 100 Fastest Growing Private Companies the past 7 years. Reliant is a leading alternative source for Small Business Funding, the 28th fastest growing Financial Services company in the United States.\n\nWe are currently seeking a Data Analyst with a finance or operations background in a services industry. The ideal candidate should have a knack for synthesizing information from multiple sources, developing assumptions, and using data analysis to draw conclusions. The Data Analyst requires strong communications skills to succeed as part of a dynamic cross-functional team.\nEssential Duties and Responsibilities\nDevelop and create reports and presentations to communicate business insights for internal customers\nMine and analyze internal data sets and reports to help stakeholders develop action plans and / or draw conclusions\nBuild prototypes for demonstration and illustration purposes for peer groups, Business partners, or senior leaders\nEnhance and automate queries from data sources such as relational databases and flat files\nCreate and manage reports & dashboards in Tableau\nDevelop new and better analytics approaches to solve questions in a creative way\nDeliver key insights with interpretation and recommendation, contributes to the development of hypotheses and actions, and presents them to management team\nEducation and Experience\nBachelor\u2019s Degree preferred in Business Administration, Finance, or similar field\n2+ Years in a finance, business analyst, or business intelligence experience required\nExperience in preparation executive reporting, finance, and operational reports\nRequired Skills and Abilities\nExtensive experience with Excel\nExperience with Tableau, PowerBI, or related data analysis tools to aggregate and analyze data collected from various sources\nExperience with Salesforce.com a plus\nTrusted to work independently with stakeholders at all levels\nAbility to communicate information to senior executives for decision making purposes\nAbility to execute projects and tasks with minimal guidance and supervision\nExcellent oral and written communication skills\nStrong research and creative problem-solving skills\nExcellent data gathering, analytical, and problem-solving skills\n\n\nQualifications\nTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\nPhysical Demands\nThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Essential functions of this role include sitting and standing for long periods of time, typing, data entry, reading on a computer, and communicating face to face and on telephone.\nWork Environment\nThe work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. This is an office environment which is open from 6 AM - 6 PM.\nWe Offer\n\u2022 Medical, Vision and Dental Benefits\n\u2022 Group Life, LTD and AD&D (Employer paid)\n\u2022 401K with match\n\u2022 Group team building events\n\u2022 Free onsite gym\n\u2022 Paid sick, vacation and holidays\n\u2022 Fun work environment\n\u2022 Casual dress code\nReliant Funding is an Equal Opportunity Employer (EOE) and takes great pride in building a diverse work environment. Qualified applicants are considered for employment without regard to age, race, religion, gender, national origin, sexual orientation, disability or veteran status.\nTo apply to this job, click Apply Now"}, "326": {"company": "Wealthfront", "description": "We are seeking a Principal Machine Learning Scientist to join the Data Science team at Wealthfront. The primary responsibility of the role is to build machine learning models to facilitate improvements in Financial Planning and Advice with the goal of improving financial outcomes for customers, not merely providing the best advice. Your focus will span topics related to personalization and recommendations. Successful candidates will combine an ability to derive and apply quantitative models to the empirical analysis of financial and client data. Code and models are the way we express insights and analysis, thus you need to be comfortable working with large datasets and writing significant amounts of product-ready code.\nResponsibilities\nBuild machine learning models for financial planning product\nCurate and collect data to train machine learning models, measure, report and compare the performance with baselines\nBe able to drive a research agenda that is well aligned with business needs\nMaintain a current understanding of industry and technology trends in the area of research\nImprove and accelerate technology with science, machine learning (including deep learning), statistical modeling, algorithm design, and prototyping\nInvestigate, identify, and acquire internal / external datasets\nCollaborate with other teams (engineering, product, design, marketing, and compliance) to commercialize new products and ongoing enhancements to existing products\nRequirements\nPhD (or equivalent experience) in Computer Science/Statistics plus 4+ years of data product experience with web-scale data. Candidates from related disciplines with a strong focus on machine learning (e.g. operations research, engineering) are also encouraged to apply\nStrong Computer Science fundamentals in data structures, algorithm design and complexity analysis\nStrong fundamentals in applied statistics and probability\nTechnically deep in the principles of building large-scale machine learning systems\nProgramming competency in Python and Spark\nStrong presentation skills and ability to communicate technical content to an audience with varied backgrounds\n\n\nEveryone across the financial spectrum deserves to live secure and rewarding lives. In order to successfully serve clients across the United States, the Wealthfront team is focused on hiring team members with a diverse range of backgrounds, experiences and perspectives. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\n\nAbout Wealthfront\n\nWealthfront is a nextgen banking service. We help you manage your money for both your short-term and long-term goals by providing a cash account with a top-of-market APY, best-in-class automated investment management, and free financial advice, anytime you want it. We entered into the banking space in a big way this year with the launch of our cash account that offers an interest rate 23x greater than the national average. We\u2019ve been overwhelmed by the response and have grown nearly 100% this year already to manage nearly $20 billion in total client assets.\n\nOur ultimate vision is to optimize and automate all of our clients\u2019 finances and build what we call Self-Driving Money\u2122\ufe0f. We want clients to be able to automatically deposit their paycheck into their Wealthfront account, and let us take care of the rest \u2014 paying their bills, topping off their emergency fund or 401(k), and investing the rest based on their specific goals and lifestyle. To get there, we\u2019ll be focusing the bulk of our 2019 efforts on creating a better alternative to what the banking industry provides. Join us so you can help us turn this industry on its head and build a service that our clients don't just like, they love.\nTo apply to this job, click Apply Now"}, "327": {"company": "Alector", "description": "At Alector, our mission is to develop therapies that empower the immune system to cure neurodegeneration. Our team is solely focused on developing cures for some of the most challenging diseases facing our society. We are supported in this mission by experienced and accomplished scientists and board members, leading healthcare investors and some of the most innovative pharma companies.\nAs an investigator in our Genomics team, you will play a key role in Alector's efforts to understand the biology of brain disorders and translate phenomenal science into exceptional drugs. You will work closely with other scientists to validate original targets and develop innovative drugs targeting the immune cells to treat neurodegenerative disorders and cancer. You will apply your existing technical skills to carry out analyses central to Alector\u2019s scientific discovery effort - and learn new skills along the way. As an early hire, you\u2019ll be influential in championing and developing Alector\u2019s culture and discovery strategy.\n\nDuring your first year, your goals will include:\nClosely collaborate with research scientists to develop cell models to evaluate new potential target genes\nKeep track of cutting-edge methods and introduce them when appropriate\nCommunicate analytical analyses verbally and in writing to teammates\nWe'd love to hear from you if:\nYou have expertise in induced pluripotent stem cells manipulation and differentiation, ideally towards myeloid cell types\nYou have experience in cell culture and lentiviral transduction, ideally with CRISPRi/CRISPRa systems\nYou take pride in being persistent, self-motivated, and efficient\nYou thrive in an environment where we work independently and on teams\nYou demonstrate a track record of learning new things and troubleshooting independently\nYou have a working knowledge of current technologies for genomic data generation, such as RNAseq\nYou have a PhD with at least 3 years of postdoc or equivalent experience in industry in immunology, neuroscience or cell biology.\nYou have a point of view but are low ego\nAt Alector, we believe that high-performing teams include people from a wide variety of backgrounds and experiences who can challenge each other\u2019s assumptions with fresh perspectives and bring creative ideas to the table. We are committed to building an open, diverse, and inclusive environment for all employees. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, sexual orientation, age, marital status, veteran status, or disability status, or any other characteristics protected under applicable federal, state, or local laws.\nAlector is a phenomenal place to learn and experiment. If you excel in a dynamic environment where everyone is committed to finding a cure, where you\u2019ll drive growth, this is the role for you. There is no limit to how far you can go with us.\n\nBenefits\nWhile we\u2019ve focused on what to look forward to during the first year and beyond, Day One is great, too: committed and driven colleagues, a bold and important company goal, state-of-the-art brand-new brightly-lit offices in the heart of the biotech area, competitive compensation and benefits. But these matter only if you\u2019re excited to build and own something great, and tackle these challenges with us. Come join us.APPLY FOR THIS JOB\nTo apply to this job, click Apply Now"}, "328": {"company": "Publicis Sapient", "description": "The ideal candidate will be intricately involved in rapid prototyping, building analytical models, applying modern application building principles, examining data sources, running analytical experiments in a methodical manner, and translating theoretical concepts into concrete solutions making a difference for our clients. This is the perfect opportunity to become a part of an innovative and energetic team that is building products and solutions focused on creating strong ROI.\n\nComing from a quantitative science discipline, you will be driven by curiosity and will have an appreciation for qualitative inputs. You\u2019ll enjoy using your statistical experience to uncover meaning from the data, as well as making data science models solving client challenges.\n\nYou will work closely with the interdisciplinary Agile DevOps team and will be responsible for transforming data into information, and information into insights and recommendations. You will utilize your analytical, statistical, and programming skills to collect, analyze, and interpret (large) data sets in order to develop data-driven solutions to difficult business challenges. This role will require collaboration within an agile team comprised of technologists, interactive designers, business analysts and architects to produce viable data science models/solutions for our clients\u2019 needs. You will also utilize understanding of data integration and big data design principles in creating solutions, which can operate effectively in production environments. You will drive data science work to insure the necessary health of the overall solution.\n\nResponsibilities:\nUtilize data science techniques to build models and solutions for our clients including AI, machine learning and natural language processing\nIntegrate data science models into client applications\nLeverage advanced analytics and statistical tools to explore and analyze data from multiple sources\nCreate visualizations and/or compelling presentations to communicate data and metrics\nEstablishing efficient, automated processes for model development, validation, implementation, and large-scale data analysis\nCollaborate with product managers, engineers, designers and others to understand requirements and develop solutions\nKeep up-to-date with latest technology trends\nImplement new statistical or other mathematical methodologies as needed for specific models or analysis\nAssess the effectiveness and accuracy of data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nApplying statistics to understand the significance of different attributes\nDocument all processes and research\nBuild new algorithms and model training\nExecute projects involving analytics\nIdentify data patterns and trends\nPerform graphical model analysis\nProduce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets.\nApply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement.\nGenerate and test hypotheses and analyze and interpret the results of product experiments.\nWork with product engineers to translate prototypes into new products, services, and features and provide guidelines for large-scale implementation.\nAnalyze data to develop predictive models including anomaly detection and running diagnostics\nMay provide work leadership to junior level employees.\nMust Haves:\nMust be a US Citizen\nBachelor\u2019s degree in computer science, data science, statistics, math or similar disciplines\nMore than 3 + Years of Experience in building data science models including developing machine learning algorithms\nExcellent critical thinking with sharp focus on business results\nHumble and willing to learn, teach, and share ideas\nExperience with Python, R and Jupyter Notebook\nAbility to work in a fast paced-environment and being able to promptly recognize emerging problems and identify potential solutions while delivering high-quality results on time\nUnderstanding of unit testing, Agile, DevOps and CI/CD pipeline\nAbility to manage and manipulate large data sets, develop data science approaches, and manage data science tasks\nExcellent written and verbal communications skills; the ability to translate complex analyses into well-structured and simple to understand concepts, recommendations or reports\nSelf-starter, with a keen interest in technology and highly motivated towards success\nExtensive background in data mining and statistical analysis\nExcellent pattern recognition and predictive modeling skills\nAble to understand various data structures and common methods in data transformation\nKnowledge of Natural Language Processing (NLP) modeling\nKnowledge of a variety of machine learning techniques (e.g. clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (e.g. GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nExperience with data visualization tools\nNice to Haves:\nExperience working with Mongo DB and/or other NoSQL DBs\nExperience with deep learning paradigms and frameworks\nExperience with manipulating data and extract, transform, and load (ETL) in parallel processing and distributed compute environments\nUnit testing with Pytest or similar frameworks\nExperience in working in cloud environment (AWS)\nUser knowledge of Jenkins, Sonar and similar DevOps tools\nCoding knowledge and experience with other languages such as Java and JavaScript\nExperience with data querying languages\nExperienced in computation frameworks like Spark, Storm, Flink using Java/Scala\nHands-on experience with the Hadoop (stack)\nLI-GSNA\nGD-POST\n\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\n\nAs part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hiring@publicissapient.com or you may call us at +1-617-621-0200.\n\nApply Now\nTo apply to this job, click Apply Now"}, "329": {"company": "Clarity Insights", "description": "Do YOU love working with Data in machine learning, real-time analytics, or Big Data in a Cloud environment? Do you find that you want to choose other technologies but work for a vendor that limits the options that you can recommend? We are looking for a Data Nerd to help us help our clients evaluate and implement big data and advanced analytics solutions in the Cloud. At Clarity Insights, we only provide Data & Analytics expertise. It\u2019s all we\u2019ve ever done and we love specializing in it and working on hard problems.\n\nClarity Insights is the largest independent professional services firm focused exclusively data analytics solutions. Our Data Science service line has one vision: to drive better business outcomes through data and analytics. We provide data analytics advisory and solution delivery consulting services. We believe that nothing sells like great delivery, and are committed to our people and client delivery excellence. With continuing, aggressive growth plans for the next five years, Clarity is seeking outstanding data analytics leaders to successfully qualify, propose, close and lead client solution delivery.\n\nAs a Data Scientist at Clarity Insights you will fully understand the requirements of our client and will be working with various data sources which may include big data and advanced Machine Learning techniques. You'll be part of a team environment and interact with various other roles such as architects, senior data scientists and leads on scoping customer facing projects. You will assist in identifying and positioning follow-on work at customers and with stakeholders. The Data Scientist should enjoy solving analytical problems. They should be able to understand the business problem to be solved and should be skilled at extracting, transforming, and analyzing data using a variety of common analytical tools and statistical techniques. The Data Scientist should be able to present findings in compelling manner to business and non-technical audience. The position requires a team player that seeks to supplement their skills through the use of project experience, self-study, and ongoing training.\nBasic Qualifications\n3+ years of professional work experience working with data integration, data science or data visualization\n3+ years recent hands-on experience working with data mining tools like SAS, SPSS, R or Python\nSolid SQL Skills working with RDBMS's such as Oracle, DB2, Greenplum, or TeradataExperience with data cleansing, tidying and wrangling from multiple sources\n1-2 years of professional work experience implementing solutions using Regression modeling techniques (logistic and linear) is required. Experience with R packages/functions such as LM, GLM, LME4, LMER & Python NumPy, SciPy, Pandas & SciKit-Learn\n1-2 years of professional work experience implementing solutions using tree based learning (classification). Experience with R packages/functions such as CARET, RandomForest, GLMNET & Python NumPy, SciPy, Pandas & SciKit-Learn\nExperience working with 1 or more data visualization tools like Tableau, PowerBI, Rshiny, GGPlot, Qlik, Alteryx, Flask, or D3 used to tell the \u201cdata\u201d story\nExcellent written and oral communication skills; must be capable of effectively articulating technical concepts to non-technical audiences\nMust have an undergraduate (BS) or postgraduate (MS) degree in Statistics, Mathematics, Physics, Econometrics, Operations Research, Industrial Engineering or equivalent work experience\nNational travel to the client on a weekly basis is expected. Normal schedule is M-Th weekly travel to client location\nPreferred Qualifications\nIndividuals with past management consulting experience working with both Strategy and Full-Lifecycle implementations for nationally based clients\nWhy Clarity Insights, Why Consulting and Why Now?\n\nWe don\u2019t try to be everything to everybody all the time. We specialize in Data & Analytics and will remain a platform and tool agnostic company so you can grow technically throughout your career. It sounds ridiculous but you actually need to be 100% technical and 100% business with strategy because we don\u2019t hire non-communicative robots who have a one size fits all approach. We often could speak to a CFO or Head of Underwriting about a business or finance problem, and based on the need for real-time and affordable scalability, we can outline \u2013 in terms they can understand \u2013 why they should think about a cloud solution for big data and analytics. If we step across to the DevOps lab, we can easily pick up on a conversation about Apache committers, OSF, full stack development, microservices, containers \u2013 you know \u2013 GEEK OUT. We\u2019re not trying to boil the ocean. We want to grow from 400 people to 1700 people in 4 years to take the market an accessible set of consulting skills. We have a lot of fun together. Most people join here and stay here for the people. That said, we are popular so we do rack up some travel miles. I have a million things to share about why that may change and why that must stay the same for now, but here\u2019s a suggestion \u2013 if you LOVE Cloud Computing for Big Data and/or Advanced Analytics, Machine Learning, etc we should talk.\n\n\nClarity Insights is an Equal Employment Opportunity Employer. We believe in treating each employee and applicant for employment fairly and with dignity.\n\n#LI-NT1\nGLDR\nTo apply to this job, click Apply Now"}, "330": {"company": "Keen360, Inc.", "description": "Keen360 is recruiting for a Senior Data Analyst who will work within our client's oncology marketing team to utilize internal and external data sources in providing integration support, and analytical insight to the brand team. Support and liason between Marketing and Technical team. He/she will work under supervision of the Marketing Director and Data Senior Manager.\n\nResponsibilities include but are not limited to:\nOnboard new data sets from Data Suppliers such as IQVIA, SHS, ION and McKesson.\nAnalysis and integration of physician level sales data to provide insights for the Marketing Team.\nConduct gap and trend analysis and incorporate Marketing Mix analysis\nFacilitate and manage various reporting assets and collaborate with brand-specific stakeholders to identify and prioritize KPIs where necessary.\nCollaborate with marketing and business functions to develop business rules and coordinate with IT for execution\nThe execution and management of ad hoc requests for analytical purposes adhering to the relevant business rules.\nCoordination across multiple systems, teams and data providers\nDevelop and improve standardized templates for brand-specific home office based marketing and executive teams.\nPrepare informative and insightful PowerPoint slides, as required.\nEngage with both onshore and offshore vendors to execute on various brand related projects, both collaborating and managing responsibilities.\nReview and do quality checks on the reports from offshore team.\nRequirements\nMust have experience working with Pharmaceutical Sales Data: Sub-national and National level Retail and Non-Retail Data.\n3 - 5 years of experience in pharmaceutical data analytics, reporting role.\nPharmaceutical industry experience required. Oncology disease area experience is highly desirable.\nStrong SQL skills and working knowledge of Tableau, Alteryx, and AWS Technologies\nExpertise in MS Excel including Pivots.\nAbility to communicate data insights to marketing team utilizing PowerPoint and/or Tableau\nIndividual contributor role with flexibility to work and as part of a team.\nDetail oriented and quick learner.\nExcellent written and oral communication skills.\nExperience in requirement gathering and project management is a Plus.\nBenefits\n\nKeen360 is a Management Consulting firm that specializes in advising organizations to design Business strategies, develop operational efficiencies and deliver innovative solutions to achieve measurable results. Our projects range from pure design and development topics to more transverse transformation involving multiple business lines or regions.\n\n]]>"}, "331": {"company": "Quotient Technology Inc.", "description": "Quotient Technology Inc. is currently seeking an Engineer for the Data Platform & Architecture Team to drive high quality data products and services to the market. This person will be responsible for design, develop and support products and services on top of our big data platform. This candidate demonstrates architecture, data and analytics quality as his/her passion, does not shy away from challenges. His/Her experience is filled with taking initiatives, patience, thoroughness, hands on working experience, willing to negotiate and work in a diverse, distributed data culture. Possesses strong technical skills and prior experience in working with highly talented engineers is expected.\n\nPosition Responsibilities\nIndividual contributor\nDesign and implement frameworks for future needs in Hadoop, Snowflake, Data Bricks and Cloud\nManaging the quality of big data platform(s) such that end users have trust and confidence in data\nForward looking, strategic thinker and executes with impeccable results\nDevelopment must support data completeness, data transformation and data quality\nWork with diverse teams to make complex architecture decisions\nWork with multiple teams to manage goals, objectives and measure the results\nLearn, evaluate and adapt new tools/technologies to meet business and technical objectives\n\nQualifications\n4+ years of experience in Big Data & Data Warehousing technologies\nStrong cloud and non-cloud data management experience\nStrong experience with big data tool sets in UNIX environment\nGood knowledge in Snowflake or MPP, Azure, GCP and AWS preferred\nStrong experience developing in programming languages such as Java, Python or Scala\nExperience with advertising, media data platforms in large scale preferred\nExperience working with data science engineering, advanced data insights engineering preferred\nStrong quality proponent and thrives to impress with his/her work\nStrong problem solving skills and ability to navigate complicated database relationships\nGood written and verbal communication skills\nDemonstrated ability to work with product management and/or business users to understand their needs\nSelf-starter, able to work in a fast-paced, deadline driven environment with multiple priorities\nAbout Quotient Technology:\n\nQuotient Technology Inc. (NYSE: QUOT) is a leading digital promotions, media and analytics company that delivers personalized digital coupons and ads\u2014informed by proprietary shopper and online engagement data\u2014to millions of shoppers daily. Founded in 1998, Quotient is based in Mountain View, California, and has offices across the U.S., in Bangalore, India; Paris and London. Learn more at Quotient.com, and follow us on Twitter @Quotient\nStart your job application: click Apply Now"}, "332": {"company": "Liberty Mutual Insurance", "description": "Help bring Liberty Mutual into the future with state-of-the-art reproducible machine learning!\n\n**Please Note: Flexibility to hire a Director II, Data Science or Senior Director I, Data science based on qualifications and experience.\n\nJob Summary:\n\nAs a leader in the Office of Data Science (ODS) Enablement & Collaboration unit you will lead a team of data science and machine learning experts solving Liberty's most challenging data science problems. The ODS was approved in order to provide additional centralized support and expertise to data science (DS) teams across various business units.\n\nYour team will be responsible for leading centralized research and development in various areas of DS such as machine learning, computer vision, and natural language processing. You will also help improve DS and machine learning (ML) development across Liberty by (1) guiding increased adoption of reproducible research methods, (2) helping improve Liberty DS infrastructure, and (3) guiding teams developing common DS tools used across the business.\n\nFinally, you will advise on Liberty's MIT Quest investment. including guiding Liberty researchers from ODS or business teams working in collaboration with MIT researchers.\n\nResponsibilities:\n\n1. Responsible for the management, technical oversight and development a team of data scientists.\n\n2. Leads cross-functional R&D teams including ODS and possibly BU researchers doing hands on ML research in areas such as computer vision and natural language processing\n\n3. Leads cross-Liberty efforts to increase the adoption of reproducible research methods and other DS best practices\n\n4. Works with product owners and business units across Liberty to identify new opportunities where the ODS can help on researching and development of DS and ML tools\n\n5. Guides and/or personally conducts training on advanced data science techniques possibly including advanced coding, reproducible research, and advanced machine learning.\n\n6. Advise on Liberty's MIT quest investment. including guiding Liberty researchers from ODS or BU teams working in collaboration with MIT researchers\n\n7. Advise and support the development of Liberty data science infrastructure including guiding teams developing common DS tools used across business.\nQualifications:\n\n1. Expert knowledge of Python and/or R\n\n2. Expert knowledge of machine learning (deep learning, tree ensembles, reinforcement learning, SVMs, etc.)\n\n3. Expert knowledge of data science and machine learning current best practices\n\n4. Experience in distributed computing using technologies such as AWS, Hadoop, and Spark\n\n5. Experience modeling unstructured data including computer vision and/or natural language processing\n\n6. Proven ability to lead and drive projects and assignments to completion through others.\n\n7. Advanced degree and 8+ years of relevant experience.\nBenefits:\nWe value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits\nOverview:\nAt Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.\nWe're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.\nTo apply to this job, click Apply Now"}, "333": {"company": "GSN Games", "description": "GSN Games is looking for a Director of Data Engineering to be part of our team in San Francisco.\nAbout the Data Team\nThe GSN Data team provides the data, analytics, and algorithms necessary to make GSN Games a fun and rich experience for players. We are building a next generation data platform and analytics suite to support the billions of records a day coming from our portfolio of gaming apps, databases, supporting web services, third party APIs, and everything in between. Our team supports key data platform, analytics and Machine Learning initiatives across the company.\nWhat You\u2019ll Do:\n\u00b7 Provide technical leadership to the GSN Data Engineering team (based in San Francisco) on key data initiatives for the company. This includes all aspects of data delivery, from ingestion, pipelining, data infrastructure, ETL and Machine Learning support\n\u00b7 Participate in design, implementation and deploying of full pipelines utilizing modern cloud data technologies (AWS Kinesis/Lambdas, Google Dataflow etc.)\n\u00b7 Participate in strategic data initiatives across all studios\n\u00b7 Coordinate production and 24x7 support for all data products, with the support of a highly talented, international team of Data Scientists, Engineers and Analysts\nAbout You:\n\u00b7 7+ years of experience in Software Engineering, including several years in data\n\u00b7 Experience with managing Engineering teams of 5+ personnel, including mentoring, roadmapping, strategic planning and execution\n\u00b7 Experience with relational databases, NoSQL databases and end-to-end data pipeline architectures from ingestion through infrastructure, ETL and reporting/analytics layers\n\u00b7 RESTful service design and implementation\n\u00b7 Strong experience with SQL, key DB Admin/ETL concepts\n\u00b7 Strong familiarity (developing/supporting production level code) with at least two general purpose programming languages such as Python, Java, Scala, or C++\n\u00b7 Commitment to high quality software through automated tests and continuous integration\n\u00b7 Experience working in agile environment\n\u00b7 BS/MS in Computer Science or similar\nBonus Points:\n\u00b7 Experience with Vertica a plus\n\u00b7 Experience with Google platform/tools such as BigQuery, Cloud Dataflow & Pub/Sub\n\u00b7 Experience in the gaming industry a plus\nStart your job application: click Apply Now"}, "334": {"company": "Recursion Pharmaceuticals", "description": "At Recursion, we combine experimental biology, automation and artificial intelligence to quickly and efficiently identify treatments for human diseases. The Principal Data Scientist (Computational Chemistry) will identify and use computational chemistry methods, integrating them with machine learning and data science approaches to augment our AI platform, accelerate our current drug discovery programs, and lead towards the discovery of high value medicines.\n\nTHE PROBLEMS YOU'LL SOLVE\n\nThis is an individual contributor position reporting to the Director, Data Science, in which you'll help lead the expansion of Recursion's capabilities downstream of our high-throughput image-based phenotypic discovery platform. Specifically, you will collaborate with teams spanning data science, chemistry, and biology to apply ligand-based drug design techniques in the context of therapeutic project teams, and help guide methods development efforts in this area to complement a phenotypic-discovery-oriented process.\n\nIn this role you will:\nBuild. You will advance chemistry related R&D processes across Recursion's small molecule discovery programs by identifying and building computational tools to accelerate and automate them. You will apply the methods in hit to lead and lead optimization programs. In collaboration with chemistry, you will actively identify opportunities to contribute to Recursion's chemical space strategy, e.g. in evolving the screening library.\nGuide, Create, and Question. Just because something has been done one way for decades doesn't mean it's optimal. You will bring new methods to bear while staying thoughtful about the value that exists from many tried and true approaches, and guide your peers in the implementation of a creative vision for computational chemistry in drug discovery.\nCode. You are both a chemist and technologist at heart and won't be happy unless you are also writing code to be used throughout the organization.\nTHE EXPERIENCE YOU'LL NEED\nAdvanced degree in Computational Chemistry, Physical Organic Chemistry, Computer Science, Machine Learning, or relevant fields.\nExperience in shaping and executing programs in computational medicinal chemistry and pharmacology as part of multidisciplinary teams.\nDemonstrated contributions that changed the course of both active therapeutic candidate projects and longer-term research and development programs.\n3+ years experience in developing ligand-based drug design methods, including pharmacophore modeling, QSAR, 3D-QSAR, and conformational analysis.\nExperience in developing novel predictive models for DMPK/Tox in the context of active candidate programs is desirable.\nExperience developing new methods and products in computational chemistry for virtual library assembly and screening\nExperience in machine learning applied to chemistry, including both classical (e.g., matched-pairs and substructure analysis) and recent (e.g., representation learning and graph convolutional) methods.\nExpertise programming in thePython data stack, including ML packages such as Scikit-Learn,PyTorch, and Tensorflow/Keras, in a Linux environment.\nTHE PERKS YOU'LL ENJOY\nCoverage of health, vision, and dental insurance premiums (in most cases 100%)\n401(k) with generous matching (immediate vesting)\nStock option grants\nTwo one-week paid company closures (summer and winter) in addition to flexible, generous vacation/sick leave\nCommuter benefit and vehicle parking to ease your commute\nComplimentary chef-prepared lunches and well-stocked snack bars\nGenerous paid parental leave (including adoptive)\nFully-paid gym membership to Metro Fitness, located just feet away from our new headquarters\nGleaming new 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking\nWHAT WE DO\n\nRecursion is reinventing the pharmaceutical industry's approach to drug discovery. Our unique platform combines the most advanced biology, high-throughput automation, and artificial intelligence to rapidly discover treatments for rare diseases, diverse immune and inflammatory diseases and new indications in the future.\n\nRecursion is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. Recursion strictly prohibits and does not tolerate discrimination against applicants because of race, color, religion, creed, national origin or ancestry, ethnicity, sex, pregnancy, gender (including gender nonconformity and status as a transgender individual), age, physical or mental disability, citizenship, past, current, or prospective service in the uniformed services, or any other characteristic protected under applicable federal, state, or local law.\n\nCheck out what it is like to work at Recursion: https://www.youtube.com/watch?v=UpOENLieOd8\nApply Now: click Apply Now"}, "335": {"company": "Tecolote Research", "description": "Data Analyst\nLocation: Arlington, VA\nEducation Required: Bachelor\u2019s degree required, preferably in math, engineering, business, or the sciences.\nSkills Required:\n\nWe are seeking highly motivated individuals to support a range of critical and exciting Department of Homeland Security (DHS) and Department of Defense (DoD) projects at our office sites in Arlington, VA and Washington, DC. Ideal candidates will possess a Bachelor\u2019s degree in business, engineering, or related fields and 3+ years of experience, or a Master\u2019s degree in a related field and at least one year of experience.\n\nSuccessful candidates will also possess the following qualifications:\n24 semester hours of quantitative course work (mathematics, statistics, engineering, physics, chemistry, etc.)\nExperience obtaining, integrating, analyzing, and reporting client data, esp. acquisition data\nAbility to apply analytic techniques to define project objectives and strategic direction, resolving complex problems using an in-depth knowledge of analytic methodologies and principles\nStrong researching, data gathering, and technical reviews needed to produce written deliverables to include reports, spreadsheets, databases, formal process mapping, and technical designs\nMicrosoft Access experience\nAbility to obtain and maintain a security clearance\nResponsibilities:\nAssess requirements, determine necessary resources to accomplish task, hypothesize solutions, develop solution, and report findings to various levels of government leadership\nDevelop algorithms for data analysis\nPlan and conducts work requiring judgment in the evaluation, selection, and adaptation and/or modification of methodologies and tools\nConsult with senior consultants or functional specialists on unusual or complex problems\nAssess requirements, determine necessary resources to accomplish task, hypothesize solutions, develop solution, and report findings\nBenefits:\nWe offer competitive salaries commensurate with education and experience. We have an excellent benefits package that includes:\nComprehensive health, dental, life, long and short term disability insurance\n100% Company funded Retirement Plans\nGenerous vacation, holiday and sick pay plans\nTuition assistance\n\nTecolote Research is a private, employee-owned corporation where people are our primary resource. Our investments in technology and training give our employees the tools to ensure our clients are provided the solutions they need, and our very high employee retention rate and stable workforce is an added value to our customers. Apply now to connect with a company that invests in you.\nApply Now: click Apply Now"}, "336": {"company": "Qualys", "description": "We are looking for a Senior Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\n\nResponsibilities:\nDesigning and deploying deep learning algorithms and predictive models\nDevelop custom data models and algorithms to apply to data sets\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\nDevelop processes and tools to monitor and analyze model performance and data accuracy\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\nQualifications:\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\nAbility to drive a project and work both independently and in a team\nTo apply to this job, click Apply Now"}, "337": {"company": "First Tech Federal Credit Union", "description": "Our Data Warehouse team is looking to add a Senior Data Engineer to their team. A qualified applicant will have 5-7 years of experience in a Data Engineer position; as well as a background in supporting data transformation, data structures, metadata, dependency, and workload management. Expert experience with Talend and SQL is highly desired.\n\nHere's what you can expect from the job and what you need to be successful:\n\nJob Duties\nCreate and maintain optimal data pipeline architecture\nAssemble large and complex data sets to meet functional/non-functional business requirements\nBuild a data pipeline infrastructure for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, cloud based relational, and/or non-relational databases employing Talend and/or scripting languages like Perl/Python\nIdentify, design, and implement internal process improvements, including automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability\nWork with key stakeholders, including members of the executive, product, data and design teams to assist with data-related technical issues and support data infrastructure needs\nCreate data tools for analytics and data scientist team members that assist in building and optimizing data integration platform to serve credit union business data needs\nPartner with data and analytics experts to ensure greater functionality of data integration platform\nFollow established configuration/change control processes\nIdentify options for ETL, data, and data warehouse potential solutions and assess for technical and business suitability\nEssential Skills\n5-7 years of experience in a Data Engineer or similar position\nMinimum 3 years of developing ETL processes using Talend, including the processing of NoSQL and JSON formats\nAdvanced working knowledge in employing Talend tool to build robust data pipelines. Talend certification is preferred\nAdvanced working knowledge in scripting languages, including Perl/Shell& Python\nAdvanced working SQL knowledge and experience working with relational/non-relational databases, query authoring (SQL), and excellent SQL troubleshooting skills\nExperience performing root cause analysis on internal and external data and processes to respond to specific business questions and identify opportunities for improvement\nExperience in building processes to support data transformation, data structures, metadata, dependency, and workload management\nExperience in working with an agile project management environment\nExposure to basic issues in working within a Cloud (Azure/AWS ) environment\nExperience in building data pipelines in a Big Data environment\nExcellent problem solving and critical thinking skills with the ability to carry out assigned tasks with limited oversight\nSuperb verbal and written communication skills\nBachelor\u2019s degree in Business Administration, Computer Science or other related fields of study or equivalent work experience. Experience in financial services industry is preferred\nLocation: San Jose, CA 95134\n\nFirst Tech is not currently offering Visa sponsorship or transfers for this position\n\nHP123\nStart your job application: click Apply Now"}, "338": {"company": "Grid Dynamics", "description": "As part of the Enterprise Data team, the Data Scientist supports the development of next-generation data platforms by employing data analytics and various data science capabilities (i.e. machine learning). Incumbents will be part of an innovative and energetic team that develops capabilities which will influence our business model and help our customer build the next generation data platform. The Data Scientist will have access to the vast amount of data stored in heterogeneous formats. This person is supposed to handle complex problems independently and demonstrate analytical thinking. Data Scientist should be able to make judgments and recommendations based on the analysis and interpretation of data.\n\nResponsibilities:\nInvestigate and analyze business and technical problems (application architecture), requirements for a new solution\nDrive the collection, cleaning, processing and analysis of new and existing data sources\nDesign a new solution architecture for manufacturing, sales\nCollaborate with development, testing, release engineering teams\nPlan phases of R&D towards the final architecture state\nSupport decision making on process layout through the data analyzing\nRequirements:\nStrong practical knowledge of analytical techniques and methodologies such as machine learning(supervised and unsupervised techniques), segmentation, time series modeling, response modeling, lift modeling\nExperience in manufacturing, marketing & sales, pricing, demand forecasting\nTechnologies: Python, Pytorch/Tensorflow, Keras, Spark\nEnglish level Intermediate and higher\nWe offer:\nOpportunity to work on bleeding-edge projects\nWork with a highly motivated and dedicated team\nCompetitive salary\nFlexible schedule\nMedical insurance\nBenefits program\nCorporate social events\nProfessional development opportunities\nNB:\nPlacement and Staffing Agencies need not apply. We do not work with C2C at this time.\nAt this moment, we are not able to process H1B transfers. Applicants with CPT and OPT visas are welcome to apply.\n\nAbout us:\nGrid Dynamics is the engineering services company known for transformative, mission-critical cloud solutions for retail, finance and technology sectors. We architected some of the busiest e-commerce services on the Internet and have never had an outage during the peak season. Founded in 2006 and headquartered in San Ramon, California with offices throughout the US and Eastern Europe, we focus on big data analytics, scalable omnichannel services, DevOps, and cloud enablement.\nStart your job application: click Apply Now"}, "339": {"company": "MITRE", "description": "MITRE is a trusted operator of federally funded research and\ndevelopment centers and we\u2019re on a mission to make the world a safer place\u2014for\nall of humanity, today and in the future. To deliver on our mission, we need\nthe world\u2019s best talent and leaders\u2014groundbreakers and partnership-builders on\na global scale in areas like healthcare, artificial intelligence, critical\ninfrastructure resiliency, pandemic management, and cybersecurity. In return,\nwe have the privilege of backing you with thousands of technical experts in\ndiverse fields, a culture of innovation and knowledge sharing, access to data\nand resources uniquely available to MITRE through our wide-ranging partnerships\nacross government, industry and academia.\n\nThe A&T mission\nis to advance the safety, security, effectiveness and efficiency of aerospace\nand transportation in the U.S. and around the globe. We drive mission-critical operational\nchanges which address current issues and prepare for tomorrow\u2019s challenges.\n\nThe scope of the\nA&T organization is a recognition of continued commitment as the FAA\u2019s\nFFRDC (CAASD) to address the critical challenges facing the national airspace\nsystem, while also acknowledging the opportunity to apply our skills and\ncapabilities to other important transportation missions.\n\nA&T\u2019s strategic approach is to drive mission-critical operational\nchanges which address current issues and prepare for tomorrow\u2019s challenges\n\nMITRE\nperforms leading-edge research and development toward transformational\nsolutions to our world\u2019s most challenging problems . Our Center for Advanced Aviation\nSystems Development is a Federally-Funded Research and Development Center\n(FFRDC) established to serve as strategic partners to the federal government\nand various aviation groups around the world. Our engineers, analysts,\ntechnical and operational experts team to solve problems in the public interest\nthat improve the safety and efficiency of the airspace system in the U.S. and\nabroad.\n\nThe Aviation Safety & Analysis\ndepartment is seeking a highly qualified Lead Artificial Intelligence Engineer/Machine\nLearning Data Scientist that will support our aviation safety work programs in\nthe following ways:\nImprove\nidentification of systemic aviation vulnerabilities\nIncrease\nquality of vulnerability discovery, and;\nIncrease\nefficiency of aviation analysis\nWe are seeking a highly skilled individual with a\npassion for artificial intelligence, experience and proficiency with\nalgorithmic design and development in one or more of the following domain\nareas: machine learning, deep learning, text mining, big data and software/application\ndevelopment.\n\nThe candidate will\nwork with the FAA and international customers, leveraging one of the largest repositories\nof aviation data to improve the capabilities, safety, and efficiency of the\naviation system.\n\nThe candidate will\nbe responsible for:\nLeveraging AI/ML techniques and solutions to\nidentify complex patterns for predicting safety hazards\nIncreasing\nthe efficiency and quality of the vulnerability discovery process by tightly\nintegrating automated processes, AI/ML techniques and human SME/analyst\nexpertise\nCollaborating\nwith government organizations, academia, and industry to encourage innovation\nin aviation safety analysis\nSupport\nsharing of data and tools for broader AI community to focus on aviation safety\nproblems\nDevelop and\nprototype AI algorithms and software tools.\nAdapting\ncurrent research and work in the AI/ML industry for application to the aviation\nsafety problem space.\nEnhancing\nand maintaining current analysis tools, including automation of current\nprocesses using AI/ML algorithms.\nConducti\nDeveloping techniques that make use of both digital flight data, text-based safety reporting, and a variety of other aviation data sets both in a silo and in a fused environment to identify potential safety vulnerabilities\nng quantitative\ndata analysis using a variety of datasets, including developing\nretrieval, processing, fusion, analysis, and visualization of various datasets\nMaintaining\nknowledge of advances of AI capabilities in industry and academia\nBasic Qualifications:\nBachelor\u2019s\nDegree in Artificial Intelligence or related field\n5 years of\nexperience in defining, developing, and deploying AI solutions\nProven\nability to work independently to learn new technologies, techniques, processes,\nlanguages, platforms, systems\nStrong\nwritten and verbal communication skills\nAbility to\nwork both independently and with a team\nExperience\nwith programming languages such as Python, Java, or other languages for prototyping/testing\nalgorithms\nExperience\nin AI-relevant fields, such as machine learning, deep learning, and data\nscience\n\nPreferred\nQualifications:\nAdvanced\ndegree in related field of study\nAbility to\narticulate AI-specific challenges, discuss critical issues, and identify gaps\nAbility to\nfoster relationship with sponsors\nTo apply to this job, click Apply Now"}, "340": {"company": "SharpSpring", "description": "Data Engineer\nGainesville, FL\nSite Reliability \u2013 Data Engineering\nFull-Time\nApply for this job\nSharpSpring is seeking a talented Data Engineer to join our Data Engineering team on-site in Gainesville, FL. As a Data Engineer, you will be responsible for the code and processes required to load data into our data lake and transform it for use by our Data Analysts and Software Engineers. You should possess knowledge of schema design, concurrency, API design, distributed processing, and aggregation. This role represents an opportunity to directly shape and impact a newly-created team within our business and bring fresh ideas to the table regarding our long-term data strategy.\nAs a key member of our Data Engineering team, you\u2019ll work across departments to assist with the provisioning, analysis, and interpretation of business intelligence data as it relates to the adoption of our flagship SaaS platform. You will also work alongside our development team to provide centralized access to our customers\u2019 data which we use for realtime reporting inside of our application.\nYou\u2019ll also be responsible for evaluating the available ecosystem of Big Data tools and for advising our senior technical staff members regarding which tools best fit the needs of our organization. You\u2019ll assist with the implementation and deployment of the solutions we collectively decide upon.\nThe Responsibilities\nExtract data from multiple data sources, such as SQL, MongoDB, Google Analytics, and other platform APIs, and load them into a centralized data lake to facilitate unified reporting.\nAssist with the creation of dataflow pipelines in Apache Airflow or similar tools, to regularly aggregate and summarize data sets for consumption by our application and other business intelligence tools.\nWork alongside other departments such as Finance, Customer Success, and Marketing, to understand trends and key performance indicators affecting the health of our business and the available data to measure them.\nAssist our product and development teams with data needs as they relate to our reporting functionality in the SharpSpring application.\nMaintain data feeds for ad hoc reporting tools.\nProvide consultation regarding Big Data toolsets and storage solutions.\nAssist in maintaining the company data model and documentation.\nAdminister and maintain our data infrastructure.\nThe Person\nDegree in Computer Sciences, Mathematics, Statistics, or similar discipline (or significant industry experience).\n3+ years of professional, industry experience as a Software Engineer. Please provide source code samples.\nExperience with the design and operation of large distributed systems.\nExpert in a programming language such as Python or Golang, and their respective standard data processing libraries.\nStrong working knowledge of relational databases and SQL.\nExperience with at least one queueing system, such as ActiveMQ, SQS, etc.\nRigor in high code quality, automated testing, and other Software Engineering best practices.\nHigh level of comfortability with command-line tools and data pipeline processing from a terminal.\nKnowledge of build systems and version control systems such as Git.\nBasic business acumen, customer empathy, and a team-player attitude.\nExcellent spoken and written communication skills.\nEnjoys a fast-paced work environment and the challenges it brings.\nSelf-starter with the ability to work independently, take initiative, and learn new skills.\nFind Out What It's Like to Work at SharpSpring\n\nSharpSpringers are dedicated, diverse individuals working to provide the best product and service possible to our customers. SharpSpring (NASDAQ: SHSP) provides excellent benefits, an engaging workplace, and talented, friendly coworkers. Join our team!\nApply for this job\nApply Now: click Apply Now"}, "341": {"company": "Pivotal Software", "description": "About Us VIDEO\n\nFounded in 2013, Pivotal Software, Inc. combines our leading cloud-native platform, tools, and methodology to empower the world's largest organizations to adapt to change and build great software. Our technology unleashes developer productivity, while fulfilling our mission to transform how the world builds software.\n\nYou\n\nAs a data scientist on Pivotal's Data Science team, you'll be working on a wide variety of data problems for a diverse range of clients. You will often be asked to learn new technologies and domains on the fly. You should be comfortable working under deadlines and making tough decisions. Consequently, you will frequently have to balance achieving an immediate goal with scalability and productionalizability.\n\nThe role offers room for personal and professional growth, and you won't be working in isolation. Data Science at Pivotal is an encouraging and supportive team, where ideas and challenges are addressed collaboratively. We're looking for the kind of person who will try and solve a problem on their own first, but isn't afraid to ask for help or say \"I don't know.\"\n\nUs\n\nThe Data Science team at Pivotal is primarily a consulting practice; we are tool agnostic, working with our customers to solve real world problems. Our customers, like us, are cross-disciplinary. We service engagements with use cases running from customer churn to optimization to detecting fraud and misconduct. We are not just doers, we are also educators and enablers.\n\nYour Day\n\nWhile there is no such thing as a \"typical day\", these are activities we frequently find ourselves doing:\nWorking with clients to uncover and frame new opportunities for data science. Clients often come to us without a clear understanding of what we can do, so this is our chance to open their eyes to new possibilities for their businesses.\nExploring client datasets, looking for actionable insights we can present.\nEngineering features, training models, tuning hyperparameters and evaluating the results. We emphasize rigor, because data science done right at this stage leads to models that shine in production.\nTaking the models we build into production. This is an exciting stage for anyone who likes collaborating with engineering teams and seeing their model become real when users interact with it.\nHelping our clients develop their internal data science practices, from hiring and recruiting to data capturing, so that they can be successful when we hand off the project.\nRequired Skills / Experiences\nClear and empathetic communicator. You'll be the one sharing your insights with clients and stakeholders at check-ins, documenting your work, and even explaining your model to client data teams as part of a handoff. As such, communication and empathy are essential parts of your toolkit.\nAdvanced knowledge of statistical modeling and/or machine learning methods. These are the tools we need to go from analysis to prediction.\nStrong programming skills. Left to our own devices most of us work in Python, but learning the client's tech stack is an important part of the job.\nStrong exploratory data analysis skills. Every engagement starts with an investigation of the data, and thorough EDA saves us a lot of headaches in the long run.\nSome travel is expected, depending on location and skillset. We mostly work out of the Pivotal office closest to the client, but sometimes we have to be on site for an extended period of time.\nAt least a bachelor's degree in an analytical or technical field. This could be applied mathematics, statistics, computer science, operations research, economics, etc. Higher education welcome and encouraged.\n\nThis role will support US government clients that require US citizenship. Given this, US citizenship is required for you to apply.\nDesired Skills / Experiences\n2+ years of work in a data-centric field (data science or data engineering).\nExperience with relational databases.\nExposure and experience working in a Linux environment.\nYou have a specialization in an area like NLP, optimization, or image processing.\nHands-on experience working in a distributed computing environment or proven theoretical understanding of parallelism.\nPivotal is an Equal Employment Opportunity employer that will consider all qualified applicants, regardless of race, color, religion, gender, sexual orientation, marital status, gender identity or expression, national origin, genetics, age, disability status, protected veteran status, or any other characteristic protected by applicable law.\nStart your job application: click Apply Now"}, "342": {"company": "Coffee Meets Bagel", "description": "Coffee Meets Bagel\n\nCoffee Meets Bagel's mission is to inspire singles to share and connect authentically. The app curates quality matches with fuller profiles that result in real conversations. Globally, CMB has generated millions of real dates and thousands of lasting relationships. Coffee Meets Bagel was named one of the Top 10 Dating apps by Time Magazine and the Best Dating App for Women by Refinery29. It has also been voted the #1 recommended dating app for singles looking for relationships.\n\nJob description\n\nEach day, our users visit our app with the hope of connecting authentically with someone. These interactions generates millions of data points that can be used to help us better understand our customers\u2019 experiences. We need you to ask and answer the questions that will transform this data into a better understanding of what our customers find delightful and what they find painful so that you can help drive changes that further our vision of helping singles form meaningful connections with other amazing singles!\n\nThe Senior Product Analyst will be responsible for partnering with our product and growth teams to provide the facts needed to make better decisions and a well thought point of view to help push our products and services to better serve our customers. You will be responsible for building a strong understand of our ecosystem, working with the product team to determine which projects are the most important, and being willing to use the right tool (a scripted model, a dashboard, a presentation) to find and explain the relevant and timely findings that help us operate better.\n\n\nResponsibilities\nWork cross-functionally with product, design, finance, and engineering teams to provide data-driven insights that will help define the product & marketing roadmap and drive significant increase in core business KPIs (growth, revenue, engagement)\nCreate internal dashboards to monitor the health of the product and business KPIs (growth, revenue, engagement).\nDeliver ad-hoc analyses and reports to support business needs, investigate, triage and resolve metrics-based issues without heavy guidance\nAssist in feature development from ideation to execution, including helping with user research, designing and analyzing A/B tests, and running deep analysis of feature performance post launch\nCreate and share compelling presentations that motivates and inspires the team to build with conviction\nWhen necessary, build models in R, Python, or other systems that help us better measure and understand the results of experiments or user flows.\nQualifications\nBachelors and 5+ years post-collegiate work experience within tech, finance, consulting or related industry\n3+ years working as a product analyst working with a team to understand and sharpen a product\nExperience working in a fast-paced environment such as startup\nExpert level in SQL & business intelligence tools (e.g., Mode, Tableau, etc)\nCompetency in R, Python, or another scripting language\nStrong analytical skills, with experience solving ambiguous problems using data\nAbility to analyze data and condense data to tell a persuasive story\nProven ability to effectively communicate with cross functional teams\nSelf-starter, with ability to thrive in a dynamic, fast-paced environment, drive change through influence, and collaborate effectively with a variety of cross-functional stakeholders. Excited and hungry to try new tools and processes to achieve results.\nPassionate about building delightful products for our customers.\nTo apply to this job, click Apply Now"}, "343": {"company": "Genesis Research", "description": "Genesis Research is an international healthcare consultancy providing end-to-end evidence development, optimization and communication services for Life Sciences groups. Our RWE-S team has seen exceptional growth and success in providing holistic and comprehensive support to Life Science organizations. We are looking for an experienced Real World Evidence (RWE) Scientist to join our research team.\nLocation: Hoboken, New Jersey.\nResponsibilities:\nConceptualize the scope of projects and work with the team from project initiation through completion of client deliverables\nWork with project teams to identify data needs, sources, and structure to support client issues problem solving\nUnderstand the strengths and limitations of Real-World Data (RWD) sources\nGenerate Evidence and Analyze large and complex healthcare data (Claims, EMR, and Registry Data) using R, SQL, Python\nParticipate in the production and presentation of deliverables\nDevelop creative solutions for complex problems\nKey Requirements:\nBachelor\u2019s degree in a technical or quantitative field from an accredited college or university (e.g., statistics/ biostatistics, epidemiology, bioinformatics, health economics, mathematics, outcomes research, public health, biology, medicine); Masters, MPH or PhD degree preferred\n3+ years relevant work experience (less with PhD)\nDemonstrated knowledge of R/SQL and statistical methods\nExperience developing and implementing statistical analysis plans utilizing RWD or clinical trials\nDemonstrated thorough aptitude for conducting quantitative and qualitative analyses\nWillingness to provide superior customer service through first-rate work product\nAbility to work independently and collaboratively\nStrong communication skills with the ability to explain technical data analysis results to business people, as well as communicate quantitative challenges and issues to technical people\nKnowledge Preferred:\nSignificant experience working with analytical models and visualization techniques and tools\nAdvanced analytics techniques (regression, simulation, etc.)\nIdentifying and addressing client needs, building relationships with clients, developing requests for proposals\nCreative and innovative problem solving skills\nAbility to work under tight deadlines in a highly dynamic environment.\nExperience developing scientific communications (Abstracts, Posters, Reports)\nCompensation:\nCompetitive salary, 401K, performance-related bonus and health insurance benefits.\nGenesis Research is an equal opportunities employer.\nStart your job application: click Easy Apply"}, "344": {"company": "CopperPoint Insurance Companies", "description": "Founded in 1925, CopperPoint Insurance Companies is a leading provider of workers\u2019 compensation and commercial insurance solutions. With an expanded line of insurance products and a growing six-state footprint in the southwestern United States, CopperPoint embodies stability for policyholders in Arizona, California, Colorado, Nevada, New Mexico and Utah. CopperPoint Mutual Insurance Holding Company is the corporate parent of Arizona-based CopperPoint Insurance Companies, California-based Pacific Compensation Insurance Company and other CopperPoint Insurance Entities.\nThis newly defined role will be part of a core team that is focused on building out an enterprise data warehouse for our rapidly growing commercial insurance company. The person in this role will have the opportunity to engage with colleagues in numerous other departments in the company to understand sources of data as well as the wide variety of uses of data, including financial reporting and data-driven analytics.\n\nPerform data profiling and analysis on internal and external data sets in order to inform requirements, perform testing, and support production processing.\nCreate business requirements to define capabilities for data selection, transformation, collection and distribution.\nDevelop test scenarios for validating the quality of data capabilities.\nPerform testing necessary to validate that developed solutions align with defined business requirements.\nContribute toward root cause analysis of data related defects.\nCollaborate with colleagues in areas sourcing data and consuming data to align expectations as part of developing requirements, creating and executing test plans and to effectively support production processing.\nCollaborate with IT partners on solution design within assigned tasks.\nDevelop a deep understanding of data required for operational, analytic and reporting functions of a property & casualty insurance company.\nComplete special projects as assigned by manager and perform other duties as requested.\n\nStrong analytical, problem solving and strategic thinking skills\nUnderstanding of Analytical and Statistical methods, some experience with analytical software (R, Python, SAS, etc.)\nProgramming skills in Python/ R / Java or equivalent\nInsurance industry experience, especially P&C or workers\u2019 compensation, preferred but not required\nSome actuarial experience, exposure or understanding preferred but not required\nAbility to operate in fast paced environment\nExcellent communication skills both verbally and in written form.\nBachelor\u2019s Degree in Information Systems, Mathematics, Finance or another quantitative subject.\nProficient in Microsoft Office including Outlook, Word, Excel and Access.\nFamiliarity and experience with querying tools (e.g. Cognos, SAS, SQL)\nCopperPoint\u2019s culture of compassion extends to the community through employee volunteerism, corporate matching, Board service, program sponsorships and in-kind contributions. We empower employees by providing 12-hours of paid volunteer time annually and matching their personal contribution to the charities of their choice up to $500 per year. In 2018, CopperPoint employees reported 3,500 volunteer hours.\nCopperPoint offers a competitive compensation package and comprehensive benefits package including major medical, dental, vision and a wide range of competitive benefits programs, generous matching contributions to your 401(k) plan, generous paid time off, tuition reimbursement and other education benefits and business casual dress. CopperPoint is an equal employment opportunity employer. All qualified applicants will receive consideration without regard to race, color, sex, religion, age, national origin, disability, veteran status, sexual orientation, gender identity or expression, marital status, ancestry or citizenship status, genetic information, pregnancy status or any other characteristic protected by state, federal or local law. CopperPoint maintains a drug-free workplace.\nApply Now: click Apply Now"}, "345": {"company": "Sandia National Laboratories", "description": ":\n\nWe are seeking a Software Systems Engineer to participate on a strategic Sandia project that requires development and deployment of legacy application functionality into a new Microsoft Cloud environment. This front-end Software Systems Engineer will participate in the analysis of software system requirements that will enable IT systems to be put in place to support this project. This position will focus on front-end IT solutions that integrate with back-end software and COTS/SaaS tools, in addition to performing front-end development on Data Science tools/capabilities being built for Sandia data Scientists and/or customers. You will be working on the IT systems being implemented in external Microsoft Azure and O365 Cloud environments and on Data Science solutions being deployed at Sandia. All these efforts are managed from the Sandia Data Sciences Department via oversight from the Departments Manager and an IT Project Manager.\n\nOn any given day you may be called on to:\nParticipate in the analysis of software system requirements that will enable IT systems to be put in place to support both the cloud project and Data Science tools.\nFocus on front-end IT solutions that integrate with back-end software and COTS/SaaS tools.\nPerform front-end development on Data Science tools/capabilities being built for Sandia Data Scientists and/or customers.\nAre you ready for your next challenge? Join us and achieve your dreams while making a difference.\n\nRequired:\nBachelors degree in Computer Science; Information Systems, Software Engineering, or relevant discipline\nPlus, five or more years of experience, or equivalent: experience and/or achievements that demonstrate the knowledge, skills and ability to perform the duties of the job\nExperience with SDLC:\n\nsuch as: planning, defining, designing, building, testing, and deployment of applications/tools, or data-related products in a production environment\nAbility to obtain and maintain a DOE Q-level Security Clearance\nDesired:\n\nExperience in the following:\n\nSoftware engineering in Microsoft Azure or O365, or other cloud vendor environments\nAngular front-end development, React, or vue\nClaim-based authentication OAUTH\nnpm, yarn, or another package management solution\nCode repository use and agile lifecycle tools and technique\nREST, SOAP, RPC, AJAX, WebSockets, etc.\nWorking knowledge of Systems Engineering, ITIL standard methodologies, and Scrum/Agile delivery\nProven ability to perform requirements gap analysis against out-of-the-box application/system functionality and suggest standard methodology solutions\nDepartment Description:\n\nThe primary mission of the Data Sciences Department is to increase the value that Sandia obtains from information assets. To accomplish this mission, the Department focuses on streamlining data access with governance, integrating and federating data, data quality issues, data virtualization, and the creation of a scalable analytic service architecture. Data Sciences provides data analytics and visualization services, and software engineering of applications in support of analytic tools. The goal is to enable Sandia to obtain actionable insights from data and make high-confidence decisions. We are dedicated to creating quality data and analytics products that have positive mission/corporate impact. New data delivery and analytics technologies and methods are persistently evaluated for inclusion within the portfolio of Data Science services the Department offers..\n\nAbout Sandia:\n\nSandia National Laboratories is the nations premier science and engineering lab for national security and technology innovation, with teams of specialists focused on cutting-edge work in a broad array of areas. Some of the main reasons we love our jobs:\nChallenging work withamazingimpact that contributes to security, peace, and freedom worldwide\nExtraordinary co-workers\nSome of the best tools, equipment, and research facilities in the world\nCareer advancement and enrichment opportunities\nFlexible schedules, generous vacations,strongmedical and other benefits, competitive 401k, learning opportunities, relocation assistance and amenities aimed at creating a solid work/life balance\\\nWorld-changing technologies. Life-changing careers._ Learn more about Sandia at: http://www.sandia.gov\n\n*These benefits vary by job classification.\n\nSecurity Clearance:\n\nSandia is required by DOE to conduct a pre-employment drug test and background review that includes checks of personal references, credit, law enforcement records, and employment/education verifications. Applicants for employment need to be able to obtain and maintain a DOE Q-level security clearance, which requires U.S. citizenship. If you hold more than one citizenship (i.e., of the U.S. and another country), your ability to obtain a security clearance may be impacted.\n\nApplicants offered employment with Sandia are subject to a federal background investigation to meet the requirements for access to classified information or matter if the duties of the position require a DOE security clearance. Substance abuse or illegal drug use, falsification of information, criminal activity, serious misconduct or other indicators of untrustworthiness can cause a clearance to be denied or terminated by DOE, resulting in the inability to perform the duties assigned and subsequent termination of employment.\n\nEEO Statement:\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.\nTo apply to this job, click Apply Now"}, "346": {"company": "Glassdoor", "description": "Looking for your next challenge? How about helping us disrupt a $90B+ talent acquisition market! At Glassdoor, we have more than 63+ million unique users and thousands of business customers that together we are revolutionizing the way phenomenal employees find great jobs and companies they love.\n\nWe are looking for a hardworking Sr. Data Engineer to join our growing Data Engineering team. You will have significant experience in building scalable data platforms that enable business intelligence, analytics, data science and data products. You have strong, hands-on technical expertise in a variety of the newest technologies and the proven ability to fashion robust, scalable solutions. You will work on Glassdoor's next generation products. You have a passion for continuous quality improvement and will be energized by working in a highly energized environment. We work on fun data problems, partner with other engineering teams, data scientists and business stakeholders to deliver end to end solutions.\n\nResponsibilities\nDesign and develop big data applications using different technologies.\nDevelop logical and physical data models for big data platforms.\nAutomate workflows using Apache Airflow.\nWrite data pipelines using Apache Hive, Apache Spark, Apache Kafka.\nCreate solutions on AWS using services such as Lambda and API Gateway.\nProvide ongoing maintenance and enhancements to existing systems, and participate in rotational on-call support.\nLearn our business domain and technology infrastructure quickly and share your knowledge freely and actively with others in the team.\nKey Qualifications\n5+ years of hands-on experience with developing data warehouse solutions and data products.\n2+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive or Spark, Airflow or a workflow orchestration solution are required\n2+ years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms.\nExperience with programming languages: Python, Java, Scala, etc.\nExperience with scripting languages: Perl, Shell, etc.\nPractice working with, processing, and managing large data sets (multi TB/PB scale).\nExposure to test driven development and automated testing frameworks.\nBackground in Scrum/Agile development methodologies.\nCapable of delivering on multiple challenging priorities with little supervision.\nExcellent verbal and written communication skills.\nBachelor's Degree in computer science or equivalent experience.\nNice To Have\nExperience building machine learning pipelines or data products.\nFamiliarity with AWS or GCS technologies.\nBe passionate about or have contributed to open sourced engineering projects in the past.\nWhy Glassdoor?\nWork with purpose join us in creating transparency for job seekers everywhere\nGlassdoor gives back! Glassdoor is a Pledge 1% member; all employees receive 3 paid volunteer days per year\n100% company paid medical/dental/vision/life coverage, with 80% dependent coverage\nLong Term Incentive Plan\n401(k) Plan with a Company Match to prepare for your future\nConveniently located office in the heart of downtown San Francisco (Embarcadero)\nNo gender pay gap; we're committed to equal pay with our annual pay gap 'checkup'\nFully-stocked break rooms with complimentary food and drinks\nPaid holidays and flexible paid time off\nYour choice between Mac or PC\nGlassdoor is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, age, veteran or military status, or any other category protected under the law. Glassdoor is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.\nStart your job application: click Easy Apply"}, "347": {"company": "Glassdoor", "description": "PRIMARY RESPONSIBILITIES\nResponsible for the preclinical strategy to incorporate PK/PD-related endpoints for assessing pharmacodynamics, biodistribution and immunogenicity in preclinical studies.\nResponsible for providing interpretation of relevant preclinical pharmacology studies, including PD studies, analysis of data using PK/PD modelling and simulation methodologies adapted for gene therapy, development and delivery of regulatory strategy (e.g. IND and BLA) and data analysis.\nFunction as the primary point of contact for PK/PD-related activities on preclinical and early clinical development programs, and influence team strategy using modelling expertise.\nInvolved in assessing and managing analyses of PK/PD data, integrating preclinical study simulation strategies and disseminating the relevant risk/benefit implications to the Company's Translational Strategy Teams (TST).\nInteract closely with bioanalytical sciences team to ensure seamless and timely transfer of bioanalytical data to the Preclinical team.\nInteract within the preclinical and bioanalytical sciences team and regulatory in the creation of preclinical PK/TK written and tabulated summaries for IND and BLA applications, as well as IBs, annual updates and other regulatory activities.\nHelp design and conduct translational PK/PD modelling and simulation to support gene therapy design goals, designs of PK/PD and safety assessment studies, and dosing justifications for first-in-human clinical studies\nCollaborate within preclinical development on the design and reporting of nonclinical safety studies; prepare subreports; comply with good laboratory practice (GLP) regulations for GLP studies.\nComply with all pertinent SOPs and GLP regulations.\nPerform PD, biodistribution and immunogenicity analyses for GLP studies, record data and analysis results in GLP-compliant manner, ensure timely and clear communication with GLP SD/PI on GLP studies, contribute to GLP study reports.\nSupervise, assist, and mentor contributing scientists on gene therapy pharmacokinetic analysis, data interpretation, and report writing.\nSKILLS, KNOWLEDGE AND ABILITIES REQUIRED\n2+ years of experience with a PhD in pharmacokinetics or a biological or related discipline (e.g. pharmacology, toxicology, biology. biochemistry, pharmaceutical science) Equivalent experience may be accepted.\nExperience in contributing to pharmacokinetic summaries for regulatory documents successfully submitted to regulatory agencies.\nAdvanced scientific writing skills.\nMaintains a compliant work environment by staying current with SOPs and being up-to-date with existing GLP guidelines.\nGood communication and scientific writing skills, and ability to independently work in a matrix environment.\nTECHNICAL SKILLS\nExpertise in assays for pharmacodynamics, biodistribution (PCR) and immunogenicity included in pharmacology and toxicology studies.\nExpertise with PK software and have an understanding of non-compartment& multi-compartment modeling.\nExperience in animal PK/TK studies, including protocol design& study conduct.\nExperience in formulating hypothesis testing for early clinical studies and executing on that using in vitro and in vivo preclinical studies as well as patient samples.\nTo apply to this job, click Apply Now"}, "348": {"company": "brightfield strategies", "description": "Data Analyst\n\n\nPosition DescriptionWe seek a self-motivated entry- or mid-level data analyst responsible for the validation, standardization, and organization of contingent workforce data during new customers engagements. This is a hands-on data management role requiring a high degree of organization, attention to detail, and independent analysis & decision-making. We seek a team player eager to dig into the data, gain new technical skills, and learn about human capital analytics.\nResponsibilities:\nReview and validate customer data requirements and large datasets from multiple data sources to ensure completeness, accuracy, and conformity\nFollow established data management procedures and ensure timely completion of all steps\nMap disparate data to standardized values using a structured taxonomy\nValidate automated mappings for accuracy and revise mappings as needed\nCreate and maintain client-specific data dictionaries\nMap Brightfield\u2019s standard data fields to client-specific data fields\nAudit inbound and outbound data for conformity to documented requirements\nTroubleshoot data issues and work with clients to identify root causes and solutions\nSupport TDX implementation projects as data management lead\nProvide status reports, audit summaries, and results of analysis\nIdentify, analyze, and interpret trends or patterns in complex data sets\nAnswer key questions from stakeholders\nAggregate and summarize data to create executive reports and dashboards with rich interactive visualizations\nIdentify opportunities to automate steps and data validation techniques\nSupport Brightfield\u2019s Advisory team by analyzing job title taxonomies and associated rates\nParticipate in reviewing data analysis with clients\nQualifications:\nMust have at least two years of practical work experience in a similar role\nHighly proficient with Excel is critical (i.e., pivots, vlookups, etc.)\nAbility to manage multiple projects with various priorities and deadlines\nStrong analytical and problem-solving skills\nSelf-motivated, driven, independent\nStrong communication skills\nA Bachelor\u2019s Degree in a quantitative discipline preferred\nUnderstanding of relational data models and database structure\nData management experience\nInterest in and ability to learn new technical skills quickly\nExperience with SQL a plus\nTableau experience a plus\nProgramming ability is a plus\nWilling to travel to visit customers on-site\nWork Location:\n\nNew York, NY and Washington, D.C.\n\u200d\nQualified candidates should email a cover letter and resume to jobs@brightfield.com\nStart your job application: click Easy Apply"}, "349": {"company": "Gigster", "description": "What We Do At Gigster and Why\n\nGigster accelerates the delivery of digital transformation applications, giving companies the agility to thrive in a software-defined world. Simply put: we build applications that matter, at startup speed. We're a series B, Andreessen Horowitz backed company on track to hit $50MM in revenue by the end of 2019. Other investors include Redpoint Ventures and Greylock Partners.\n\nWhether from our office in downtown San Francisco, which features stunning views of the Bay, or from remote home offices, our team works together to disrupt systems integrators like Accenture by offering customers fixed-price projects. We employ a unique talent model, powered by a technology platform and a proven development methodology that enables virtual teams to deliver high-impact software applications quickly and consistently.\n\nGigster's unique business model creates many opportunities for personal and career growth. We partner with several world renowned companies like Google and Dentsu and drive digital transformation for global businesses and brand leaders like Canon, Clorox, GlaxoSmithKline, Harley Davidson, Prudential, and Staples, AND we empower the workforce of the future - top global talent in our Gigster Talent Network. We enable these talented individuals to work on projects that matter and that matter to them (at competitive rates and with ultimate flexibility and independence) and to belong and thrive in the Gig Economy regardless of where they call home.\n\nWe are intentional about a diverse and inclusive culture. We care about being \"whole humans\" and about bringing all of ourselves to work - humans first, professionals second.\n\nLike most fast-growing start-ups in the tech industry, we have a constantly changing environment. We value passionate and resourceful team members with a growth mindset who enjoy working collaboratively to solve hard problems.\n\nAbout the Role\n\nFor the first time, it is now possible to measure team performance as well as the end-to-end process of developing software and truly understand how teams and software ultimately drive business impact. After delivering over 1000 software projects for both large enterprises and startups, Gigster has amassed a one of a kind data set about software teams, productivity, and business impact. We invite you to come and drive industry-leading thought leadership based on this data set with answers to age-old questions in software and management science as well as product related questions around what truly drives business impact. What investments should be made to engage customers? What makes software teams productive? How does remote work impact outcomes? What aspects of the software process can be automated? What is quality and how can it be incentivized?\n\nYou will work closely with Sales, Marketing and delivery and have access to Gigster's data from software projects, teams, and real-time collaboration tools. You will be crucial to unearthing and communicating insights. You will work directly with the Co-founder & CTO and have end-to-end autonomy. Your findings will drive Gigster's ability to communicate value to clients in a data-driven way as well continuously improve its software development platform. Your work will have visibility across the company as well as outside of it via thought leadership articles and conferences.\n\nCore Responsibilities\nCommunicate data-driven insights about how to build impactful software via articles and physical events\nPerform analyses to understand key drivers of customer outcomes as well as pointers for streamlining tools and processes\nCarry out specific investigations to uncover insightful correlations and patterns\nDrive sessions with key customers\nQualifications\n5+ years experience in lead product, engineering or data roles\nStrong oral and written communication skills\nSound statistical intuition and analytical skills\nExtensive experience using data to influence business outcomes\nExperience with Python, R, Julia or similar\nExperience with relational databases\nSolid grasp of modern technologies and experience using them to drive enterprise scale business outcomes\nAn undergraduate degree in Engineering, Computer Science, or Mathematics\nScrappiness and ability to work autonomously.\nHighly Preferred Competency\nMachine learning expertise\nExperience with non-relational databases\nAn MS or PhD in a quantitative field\nTOTAL REWARDS\n\nYou should not have to spend any time worrying about whether you are paid more than fairly for what you contribute to our team (and to the world!). We offer competitive cash and equity compensation. We frequently review whether our compensation is competitive to market and to ensure internal parity and we make thoughtful and discretionary adjustments accordingly and during frequently scheduled reviews and cycles.\n\nCURRENT BENEFITS & PERKS\n\nIn addition to competitive compensation, we offer:\nCompetitive health, dental, and vision coverage\nWellness and fitness stipend(s)\nFlexible time off - work hard, but take time away when you need it for moments that matter in your life that require you to disconnect from work\n401K Plan - invest in your future\nCommuter Contributions - we all rely on different ways to commute\nShared experiences and meaningful offsites vs. meaningless perks\nAt HQ:\nHealthy drinks and snacks for whenever you need sustenance\nCatered meals daily\nLife-changing work you'll want to brag about - solving real, challenging problems in partnership with exceptional and unique colleagues\nOUR COMMITMENT TO EQUAL OPPORTUNITY\n\nWe are excited to work with and welcome applications from anyone who shares our values and who are qualified for the role that they apply for regardless of: race, color, national origin, citizenship, ancestry, familial pedigree, education, religion, gender, sexual orientation, age, marital status, disability, or veteran status.\nTo apply to this job, click Apply Now"}, "350": {"company": "Northrop Grumman", "description": "Are you ready to leverage your security clearance, knowledge and technical experience in a new role?\n\nAdversaries, cybercriminals and cyber terrorists, are working every hour of every day to develop new means to compromise networks, to seize valuable intellectual property and personal data, and to gain an advantage on the digital battlefield. At Northrop Grumman, our mission is to see to it that they fail. Speed, stealth and precision keys to controlling the physical domains of land, sea, air and space are imperatives in controlling the cyber domain. Our talented employees make advances every day based on these imperatives and are committed to providing the most advanced protection for our customers against the rapidly evolving cyber threat spectrum. Our company is trusted with securing some of the most high-risk systems and continues to be the trusted provider of mission-enabled solutions for the security or our nation and allies. This is without a doubt one of the most exciting times to join our team. So come join us and experience the value of performance.\n\nNorthrop Grumman Mission Systems is seeking multiple Data Scientists to support fast-paced cutting edge programs ensuring national security and defense. The positions are located in the Annapolis Junction, MD greater area.\n\nThis position represents immediate opportunities across multiple programs. Though each program has specific labor categories which must be met prior to placement, all candidates must minimally meet the knowledge, skills and abilities listed below.\n\nNGCIMSMD\n\nBasic Qualifications:\n\nBachelor's Degree in related technical discipline (including but not limited to computer science, data science, information systems, science, engineering, math, economics, or aerospace) from an accredited college or university is required. Four (4) years of additional systems engineering/architecture experience on projects with similar software processes may be substituted for a bachelor's degree.\n\n2+ years of Experience with data analysis and applications, that address a business issue or provide a competitive advantage for an organization. (2 Years with Bachelors in Science; 0 Years with Masters)\nFamiliarity with creating data mining architectures/models/protocols, statistical reporting, and data analysis methodologies to identify trends in large data sets.\nStatistical or data visualization skills.\nUS Citizen with Active TS/SCI w/Polygraph clearance\n\nPreferred Qualifications:\n\nBachelor's degree in a STEM discipline (Science, Technology, Engineering, or Math) along with 2 or more years of data science experience.\nKnowledge of statistical datasets and implementation techniques and tools for the most efficient metrics, including present and future capacity requirements.\nExperience with Tableau, SAS, Apache Spark, BigML, D3, MATLAB, or other data science tools.\nExperience taking big data and turning it into metrics or prediction information for decision making.\nStrong statistical and data visualization skills.\n\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\nTo apply to this job, click Apply Now"}, "351": {"company": "Northrop Grumman", "description": "Northrop Grumman's products support the front lines, securing our democracy and future. Our Manufacturing team's work on these cutting-edge products support the users, our military, to complete their missions and get home safely.\n\nWe are looking for a Data Scientist who will support our product development, production and leadership teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. Must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\nResponsibilities for Data Scientist\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine existing databases, create databases, tabulate and analyze data from company databases to drive optimization to manufacturing processes, product development and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to optimize current processes and improve corrective action timeliness.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\n\nMSRMM\n\nMANUMS\n\nRocktober\n\nBasic Qualifications:\n\nData Scientist\n\nBachelor's degree in Computer Science, Statistics, Mathematics, or another quantitative field with 2 years' experience in various software toolsor a Masters degree in Computer Science, Statistics, Mathematics or another quantitative field.\n\nPrincipal Data Scientist\n\nBachelor's degree in Computer Science, Statistics, Mathematics, or another quantitative field with 5 years' experience in various software tools or a Master's degree in Computer Science, Statistics, Mathematics, or another quantitative field with3 years' experience in various software tools\n\nFor Both Levels:\nExperience with C, C++, or equivalent.\nExperience creating User interfaces.\nExperience with Tableau or SAP Lumira.\nExperience with querying databases\n\nStrong problem solving skills with an emphasis on production environments\nExperience working with and creating data architectures\nExperience using statistical computer languages (Minitab, Tableau, Python, SQL, etc.) to manipulate data and draw insights from large data sets\nProven ability to learn and master new software tools, technologies and techniques\nAbility to obtain a security clearance and US Citizenship\n\nPreferred Qualifications:\n\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\n\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.\n\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\nApply Now: click Apply Now"}, "352": {"company": "C2G Partners", "description": "Data Scientist\n\nJob Title\n\nData Scientist\n\nJob\nID\n\n27066981\n\nDuration\n\nLocation\n\nColumbia,\n\nMD\n\nOther Location\n\nBoston, MA\n\nDescription\n\nDynamic, Entrepreneurial Consulting Company seeking Data Scientists! If you\u2019ve got entrepreneurial spirit and passion, are driven by results, and want to be a part of significant growth, we\u2019re looking for you!\n\nBLEND360 is recognized as an award-winning consulting firm and has provided services to some of the world\u2019s best known and most respected organizations. While BLEND360 has worked primarily with clients that are Fortune 500 and mid-sized companies, we also extend services to smaller businesses and non-profits.\n\nBLEND360 is a marketing and analytic consulting company that places consultants in highly strategic marketing and analytic roles, and one of the fastest growing Inc 5000 companies.\n\nIf you are ready to embrace the challenge and would like to join our team as one of our Data Scientists, please keep reading!\n\nAs Data Scientists, we work with business leaders to solve clients\u2019 business challenges and improve clients\u2019 business results using advanced analytics techniques. We contribute our Advanced Data Science subject matter expertise to the recommendations and solutions delivered to our clients.\n\nWe spend most of our time on getting data into proper shape, performing statistical analyses, developing predictive models and machine learning algorithms to solve clients\u2019 business problems. We evaluate different sources of data, discover patterns hidden within raw data, create insightful variables, and develop competing models with different machine learning algorithms. We validate and cross validate our recommendations to make sure our recommendations will perform well over time.\n\nMain Responsibilities\nWork with practice leaders and clients to understand clients\u2019 business problem, industry context, data sources, potential risk and constraints\nProblem solve with practice leaders to translate the business program into a solvable Data Science problem, formulate different approaches, outline pros and cons for each approach\nWork with practice leaders to get client feedback, get alignment on approaches, deliverables, and overall timeline\nDevelop a project plan including key milestones, timeline, and contingency plan\nGather data from client and external data vendors\nPerform data cleaning/hygiene, data QC, and integrate data from both client internal and external data sources on Advanced Data Science Platform\nConduct statistical data analysis, including exploratory data analysis, data mining, and document key insights and findings\nCreate insightful and/or predictive summary variables from granular-level data\nDevelop, validate, and cross-validate predictive models and/or machine learning algorithms using Advanced Data Science techniques and tools\nDocument predictive models / machine learning results that can be incorporated into client-deliverable documentation\nDocument key insights, recommend actions client could take, and quantify business impact\nAssist client to turn models and algorithms into implementable production codes\nQualifications:\nMS or PhD degree in Statistics, Math, Operation Research, Economics, Advanced Analytics, Computer Sciences, Engineering\n2-10 years\u2019 professional experience in Advanced Data Science, such as predictive modeling, statistical analysis, machine learning, Neural Nets, text mining, geo-spatial analytics, time series forecasting, optimization\nExperience with one or more Advanced Data Science software languages (R, Python, Matlab, SAS, Perl, Java, PHP)\nExperience with structured or un-structured data analysis and tools (SQL, Hadoop, Spark, NoSQL, MySQL, MariaDB, Hive, Pig, etc)\nComfortable with cloud-based platforms (AWS, Azure, Google)\nExperience with Google Analytics, Adobe Analytics, Optimizely a plus\nExperience in digital marketing a plus\n**This role will require 30-40% travel.\n\nTo apply to this job, click Apply Now"}, "353": {"company": "Master Electronics", "description": "Master Electronics has exciting opportunities for several ProcessAnalyst/Data Scientist Internships that will report to the Vice President of Data Science in Phoenix, AZ. As a member of theMaster Electronics Data Science Team, you will be a process analyst intern that will partner with our business teams, documenting and influencing key process decisions that will optimize theMaster Electronics' customer journey.\n\nThe intern program is aten-week assignment, led by theMaster Electronics Data Science team, where each intern works in a specific project. Each project leverages the intern's supply chain management, analytics, academic, and student project work skills to solve a business problem. Interns will have access to on-the-job training opportunities, networking, social opportunities, and exposure to the improvement of decision-making workflow processes with senior leadership atMaster Electronics.\n\nTo be considered for the position, candidates must possess the minimum qualifications stated below. Preferred qualifications are in addition to the minimum qualification requirements, which are considered a plus factor in identifying top candidates.\n\nTheAnalyst/Data Scientist Internship is an entry-level position with a corresponding compensation. The internship projects are specific toMaster Electronics business needs and may vary in size, complexity, and business domain.\n\nA successful candidate will demonstrate:\nAbility to independently model changes in process outcomes using mathematical, statistical, or Python techniques\nStrong ability to document and improve supply chain and business processes that optimize process outcomes\nAbility to work in a dynamic, results and team-oriented environment\nStrong written and verbal communication skills\nExcellent problem-solving and business analysis skills\n\nMinimum Qualifications\nStudents pursuing a:\nBachelor's degree in data science, supply chain management, computer science, mathematics/physics, machine learning, operations research, applied to business decision making\nSkills and experience in supply chain and business process creation using:\nUnified Modeling Language (UML) and\nBusiness Process Model and Notation (BPMN 2) frameworks\nWorkflow process diagraming experience using Draw.io, Gliffy, and Microsoft Visio\nBusiness and process modeling analytical skills using Microsoft Excel and Power Pivots\nExperience creating balanced scorecards using Microsoft Power BI and Microsoft Excel\n\nPreferred Qualifications\nStudents pursuing a:\nGraduate degree in data science, supply chain management, computer science, mathematics/physics, machine learning, operations research, applied to business decision making with a GPA of 3.5 (out of 4 points) or higher\nSkills and experience in supply chain and business process creation using:\nObservation and engagement of audiences in requirements gathering sessions to extract and prioritize user needs\nVisualization of as-is and to-be business processes (process mapping) to model performance improvements\nQuantitative modeling of as-is and to-be business processes using statistics, simulation algorithms, and Python 3\nExperience with User Acceptance Testing and Change Management processes\n\nWhy Master Electronics?\n\nMaster Electronics has a fast-paced and entrepreneurial environment, which requires a professional, flexible self-starter attitude.\n\nHeadquartered in Phoenix, AZ, Master Electronics is a leading global authorized distributor of electronic components. For more than half a century, our family-owned company has remained focused on strong relationships, responsive service and added value. This is howMaster Electronics has grown to serve hundreds of thousands of customers in partnership with hundreds of world-class suppliers.\n\nMaster Electronics, a leading global authorized distributor of electronic components, is committed to providing equal employment opportunities for all applicants and employees. The Company does not unlawfully discriminate on the basis of race, color, creed, pregnancy, religion, sex, national origin, age, disability, veteran, marital, or any other protected status. The Company also makes reasonable accommodations for disabled employees. Finally,Master Electronics prohibits the harassment of any individual based on their protected status. This policy applies to all areas of employment, including recruitment, hiring, training, promotion, compensation, benefits, transfer, and social and recreational programs.\nTo apply to this job, click Apply Now"}, "354": {"company": "Meltwater", "description": "About Meltwater\n\nFounded in Oslo in 2001 before moving our headquarters to San Francisco in 2006, Meltwater is the global leader in media intelligence, with over 2,000 employees globally and 30,000 corporate clients. Our innovative products help businesses extract insights from billions of online conversations and articles we call it Outside Insight.\n\nUnique Culture\n\nFor over fifteen years, Meltwater has maintained a very unique culture, based on a foundation and belief in people and the potential they possess, regardless of experience. Like many entrepreneurially focused companies, Meltwater employees embody the work-hard, play-hard spirit. Whether you meet an employee from San Diego or Hong Kong, you will likely discover many similarities in terms of their achievements, focus and superior communication skills.\n\nOur office spaces are collaborative, open working environments in which teamwork, learning, and fun are the day-to-day norms. Each office consists of a number of small teams, ensuring that all of our employees have easy and frequent exposure to their managers and can quickly learn from those around them.\n\nEqual Opportunity\n\nMeltwater is firmly committed to affording equal employment opportunities to all candidates and employees alike without regard to race, color, religion, age, national origin, gender, sexual orientation, gender identity or gender expression, marital status disability, veteran status and we treat each individual with respect and dignity.\n\nThe EEO is the Law poster is available at: http://bit.ly/2KBm9Ei\n\nAnd EEO is the Law Supplement poster is available at: http://bit.ly/2Kmxnxd\n\nOn-Line Accessibility Directive: If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us here for assistance.\nStart your job application: click Apply Now"}, "355": {"company": "Stratagem Group", "description": "Data Scientist\nValley Forge, PAApply Now\nAre you interested in supporting the ever-changing technology needs of the U.S. Government by providing services that support defense initiatives? Come look at Stratagem, where we help the U.S. Government solve some of the most difficult and fun problems in the world.\n\nStratagem is hiring motivated, creative, and technically-minded individuals with a passion and skill for building the state-of-the-art in emerging technologies. We understand that candidates may not be able to check the boxes for all desired qualifications, but what is most important to us at Stratagem is that candidates have exceptional problem-solving skills, creative out-of-the-box thinking, and comfort with quickly learning, evaluating, and deploying new technologies. Successful employees are self-starters, excellent communicators and positive individuals with a passion for delivering uncompromising quality products.\n\n** TS \u2013 SSBI Required **\n\nThis is a data scientist position in Valley Forge, PA, and we are not hiring your average Java Joe\u2019s. We\u2019re looking for the Americano with a double pump. You will be given substantial feature ownership, and we'll expect you to contribute product ideas as well as occasional code. Your ideas will help shape the future of Stratagem.\n\nResponsibilities & Skills\nOur ideal candidate is a data scientist with a love for learning, the ability to pivot directions quickly, and someone with a conceptual understanding application development. You should love manipulating data, running statistical analysis, and getting your hands dirty by working in a multitude of environments.\nAs a data scientist, your responsibilities include:\nIntegrating with a diverse team to deliver in an agile-like manner\nUsing statistics tools to analyze data\nUnderstanding and modeling the relationship between different metrics to identity key insights\nIdentifying opportunities for data science products\nConsulting with developers to run tests and algorithms\nYour core skills/experience include:\nExpertise in one of the following: R, Python, Java, or Scala\nWorking in a software development environment\nExpertise at data mining and analysis for structured and unstructured data\nAbility to produce data visualizations on findings\n3-15 years experience\nYou are the proud owner of a TS/SCI SSBI clearance or you can be granted one\nBonus points if you have experience in any of the following:\nExperience with systems like Hadoop and Spark\nBachelor Degree in Data Science, Statistics, Mathematics, Computer Science, or related discipline or equivalent business experience in a professional service related to Big Data\nDevOps experience\nMission Management\nSIGINT experience\nAbout you\nYou are an exceptional problem solver, a quick learner, and a creative out-of-the-box thinker who values team work. You are comfortable with the pace and ever-changing requirements of a small development company while maintaining a healthy work life balance.\n\nWho is Stratagem\nStratagem is a small and fast-growing technology company built around the idea that we can make a lasting impact for our customers and employees. We believe in a culture of innovation, fun, empowerment, and family. We want you to learn new skills so you can become more fulfilled in both your personal and professional life.\n\nAt Stratagem, our goal is to make our company the last company you work for!\nStart your job application: click Apply Now"}, "356": {"company": "Target", "description": "Description:\n\nTarget is an iconic brand, a Fortune50 company and one of Americas leading retailers. Behind one of the worlds best-loved brands is a uniquely capable and brilliant team of data scientists, engineers and analysts.\n\nJoin Targets Data Science and Analytics team where your goal will be to accelerate omni-channel experimentation to foster a culture of continuous innovation at Target. We believe that continuous innovation is critical to delivering and exceeding our brand promise of Expect More Pay Less to Targets guests irrespective of their preferred channel of engagement and commerce. You will enable continuous innovation and drive business performance via testing and measurement (experimentation). We play a key role in identifying the test-and-measure or A/B test opportunities that continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.\n\nA role with Data Science and Analytics is a chance to help develop our in-house strength for getting the maximum value from Targets many data assets. We see data as a product and an opportunity to experiment and refine our approach to new guest experiences. This is how we bring to life what wasnt possible yesterday, and generate new revenue sources for Target in the process. Our purpose is to accelerate omni-channel A/B testing to fuel the continuous innovation that we believe is the key to exceeding guest expectations in our stores and digital channels. Together, we positively impact changes to various initiatives, processes and interdependencies that require exceptional data collection, measurement and analysisultimately leading to quicker and more meaningful decision-making at Target. This is a role for someone passionate about data, feature experimentation and business strategy.\n\nAssortment strategy and segmentation involves in-depth analysis and understanding of guest shopping behaviors at the individual store location level, and analytically determining an optimal framework for clustering stores by those guest shopping behaviors. Assortment strategy and segmentation is a vital part of Targets business initiative to improve satisfaction and relevance to our guests.\n\nAs a Senior Data Scientist in Data Science & Analytics, youll:\nServe as an advocate of our data-driven culture, work closely with Product, Business and Engineering, helping them use insights that will direct their efforts towards initiatives with the highest impact.\nDevelop statistical models to drive lean and efficient analysis practices, providing metrics on model performance\nExecute solutions to business problems using data analysis, data mining, forecasting, optimization tools, and machine learning techniques and statistics\nAnalyze and explore data in our Hadoop ecosystem, work with the product manager to design in-product experiments, analyze the results, and provide strategic recommendations.\nSynthesize analysis and results in compelling storylines and communicate to key stakeholders. You should have the ability to tell a story around the problem, the solution and the impact and value of implementing a solution\nPartner closely with our Product Managers and/or business partners to identify gaps in product offering by conducting comprehensive data analysis, and accelerating the analytics maturity (predictive & prescriptive) in key product areas\nDefine data to be collected for measuring the success of new product features or business strategies, define KPIs, and work with engineering on tracking and instrumentation of data.\nStrive for query optimization problems on large data sets.\nDesign and build self-service dashboards using a mixture of analytical and visualization techniques to derive actionable insight from data to influences business and product decisions\nDemocratize data and insights as you strive to deliver self-service tools to your partners and enable them to make better decisions quicker.\nAbout You/Requirements:\nMasters degree with strong academic performance in a quantitative field; or strong equivalent experience\n3+ years of work experience in data science/analytics, consulting, product, or engineering\nProfessional work experience in a technology company, start-up, or other analytical roles, including: digital and brick and mortar A/B and multivariate testing (design, execution and analysis), and predictive modeling\nIntermediate to advanced SQL experience writing complex queries\nPassion for problem solving and building ideal solutions\nExperience working with product managers and business leaders to develop product roadmaps and feature development\nSupport conclusions with analytical evidence using descriptive statistics, basic inferential statistics, and data visualizations\nAbility to identify and succinctly summarize roadblocks, constraints, and trade-offs, propose potential solutions, and drive toward resolution\nIntellectually curious, high energy and possess a strong work ethic\nCollaborate with your peers for finding solutions to complex problems.\nExceptional oral and written communication skills\nStrong experience in multiple analytics tools such as: SQL, Excel, R, Python, Hadoop/Hive, DOMO, spark, etc. or equivalent technologies\nJob duties may change at any time due to business needs.\n\nLevel:\n\n5\n\nAmericans with Disabilities Act (ADA)\n\nTarget will provide reasonable accommodations (such as a qualified sign language interpreter or other personal assistance) with the application process upon your request as required to comply with applicable laws. If you have a disability and require assistance in this application process, please visit your nearest Target store or Distribution Center or reach out to Guest Services at 1-800-440-0680 for additional information.\n\nQualifications:\nStart your job application: click Apply Now"}, "357": {"company": "Better.com", "description": "About Better.com:\n\nWe're one of the fastest growing homeownership companies in America. Why? Because we're making homeownership simpler, faster \u2014 and most importantly, more accessible for all Americans.\n\nBy combining smarter technology with a desire to not just change one piece of the journey but the entire makeup of what it's like to buy and own a home in this country, we're building things that don't exist yet.\n\nBetter.com by the numbers:\nWe fund $600 million in home loans per month\nNearly $5 billion in loans funded since our inception in 2016\n2 years running, we're one of Crain's \"Best Places to work\"\nWe're #11 on Fortune's Best Places to Work in NYC\nAnd #964 on Inc.'s 2019 \"5000 Fastest-Growing Companies\"\nWe've secured over $254 million from our investors to date\n...and counting\nWe continue to outpace the industry at every turn. Our backers have helped build some of the most transformative tech and finance companies in history. Kleiner Perkins, Goldman Sachs, IA Ventures, Ally Bank, American Express, Citigroup, Activant Capital, and others have all invested in our vision of redefining the entire home buying journey.\n\nA Better opportunity:\n\nHelp us hack a thirteen trillion dollar industry by building a product that will allow more people than the status quo to own a home and build wealth rather than rent for life. Our tech team is small, and you will be a big part of defining the technical direction and culture. We encourage proposals for projects off the beaten path, experimentation with different frameworks and libraries, and doing as you see fit to solve problems. We also offer above-market compensation and equity, as well as full benefits.\n\nSome projects you could be working on:\nWork extremely closely with our product team to understand user behavior and come up with product ideas\nPresent conclusions to the executive team that can impact the strategic direction of the company\nBuild a lead scoring model to help our customer support team prioritize\nModel the time-lag of conversions using fun math like Gamma distributions\nDesign experiments to understand causal impact\nBuild web scrapers to track price data for competitors\nBuild scalable infrastructure to deploy machine learning models and serve predictions\nBuild infrastructure for ingesting data into our data warehouse continuously and as close to real-time as possible\nWho you are:\nYou have at least 4 years experience writing Python, not limited to small scripts, but also working on larger codebases\nYou have a few years experience with SQL\nYou have experience working with open-ended questions and have a track record of turning fuzzy problems into actionable data\nYou are business-driven, and care about getting to the bottom of how to make a startup successful\nYou have an interest in statistics and machine learning\nBetter Technology:\nWe do continuous deployment and we ship code 50-100 times every day\nThe data stack is all in Python 3.7\nWe use TypeScript and Python for services\nRedshift for our data warehouse, Postgres for the production databases\nKubernetes, for deployment and devops\nAWS for infrastructure, leveraging EC2, S3, Redshift, CloudFront, Route53, and much more\nBetter Team:\nThe tech team is currently 50 engineers but growing quickly\nThe data team is 5 people but with the plan to grow it to 25 in the next year\nErik Bernhardsson (CTO) used to run the data team and the music recommendation team at Spotify. He is the open source author of a few popular projects like Annoy and Luigi and writes a blog about (mostly) data\nThings we value:\nCuriosity. Why? How? Repeat.\nNerdiness. Financial news and trends are fascinating. Seriously.\nRelentlessness. No one here gives up. We try. We fail. We try again.\nPassion. If you don't get excited about homeownership, mortgages, and real estate, it simply won't work.\nSmarts: book and street. We have to use all the tools at our disposal to build Better.\nEmpathy and Compassion. You understand that people's biggest dreams are in your hands.\nCommunication. Can you ask for help or put your hand up when you don't understand?\nApply Now: click Easy Apply"}, "358": {"company": "Purchasing Power", "description": "Senior Data Decision Scientist - Merchandising\nLocation\n\n\nAtlanta\n\nDepartment\n\n\nFinancial Planning and Analysis\n\nEmployment duration\n\n\nFull time\n\nApply Now\n\nPurchasing Power, Midtown Atlanta, GA\n\nData Decision Scientist - Merchandising\n\nAt Purchasing Power the merchandising team is about driving demand and increasing profitability by new concept development, strategizing, planning, modeling, testing, and validation of the initiatives, including pricing, inventory, brand affinity, and promotions as related to customer behavioral patterns.\n\nAre your talents ready to make a real and measurable difference in the life-time-value of customers?\n\nPurchasing Power needs your creative, predictive, and quantitative \u201cWOW skills to surface the hidden insights.\u201d You discovery efforts are an integral component of our team's ultimate goals of increasing sales efficiency and effectiveness, by targeting the right promotion to the right customer with personal relevancy, enabling forecasting inventory to reduce overstocking and associated cost of effective advertising strategies, and expanding our competitive advantage in today\u2019s marketplace.\n\nResponsibilities\n\nPricing, Branding Affinity, and Inventory / Assortment Optimization\nResearching, designing, and implementing analytical models and algorithms that will be utilized for pricing across promotion, product, shipping sensitivities, and optimization.\nAnalyzing & distilling loyalty insights from diverse data sets (member, segment & program level)\nEnabling best in class offer generation (customer targeting & offer assignment) & optimization based on all the available data, scores & model outputs including dynamic attributes.\nUse time-based demand forecasting to augment cross-sectional binary classification\nProvides in-depth and sophisticated analytic capabilities to support retail business problems by understanding business challenges\nCollects, cleans, transforms, and restructures data for statistical analysis; performs statistical summaries and tests for relevant business questions\nCreates analytic solutions by exploring innovative data and techniques; conducts exploratory data analysis and modeling\nBuilds predictive and prescriptive models supporting a vast array of customer and business scenarios; performs statistical tests to enhance the predictability of deployed models\nCommunicates insights to leaders by summarizing conclusions and solutions; translates analytics and statistics into clear, understandable themes for business leaders; identifies specific analytic results that drive actionable insights\nMaintains consistency in analytic practices by brainstorming and partnering with other areas within the Data Analytics and Consumer Insights COE\nResponsible for continuously learning and sharing analytic methodology and techniques new to Purchasing Power\u2019s Decision Science Team\nDevelops robust hypotheses, in collaboration with business partners, on how value can be created; builds analytical models to validate/disprove these hypotheses and develops actionable recommendations for the business\nQualifications\nBachelor\u2019s or Master\u2019s degree in Statistics, Econometrics, Information Sciences, Applied Quantitative equivalent combination of education and experience or related field.\nMinimum of 3 years of directly related experience and strong proficiency of predictive modeling techniques, test/learn, base, shipping, and promotional lift and price optimization, affinity modeling, and inventory stock and assortment market basket analysis.\nExperience working with analytic tools/software (e.g., Base SAS, SAS Enterprise Miner, R, Python) and performing advanced data modeling, data mining and exploratory data analysis (e.g., logistic regression, Hyndman Package \u2018forecast\u2019, Affinity Analysis, MNL, NL, LC, ED, Sentiment scoring, NLP, Heuristics, DP, IP)\nSuccessful track record of applying sophisticated analytics techniques in a retail company, eCommerce, or consumer brand.\nStrongly motivated to be a player in a team which is constantly working to improve themselves through discovering new analytics techniques and software tools to improve the quality of our work.\nSuperior research, statistical, analytical, processing, and mathematical skills with the ability to structure and conduct analyses.\nStrong verbal and written communication skills; ability to present complex information in an easy-to-understand manner with clear recommendations based on data insight.\nAdaptability and the capability of multi-tasking and strong time management.\nThrive in a fast\u2010paced, entrepreneurial environment.\nWhy Purchasing Power?\n\nWe are the leading specialty e-retailer offering consumer products, vacations and online education services through an easy and convenient payment plan. Our customers love us because we make paying for their purchases stress- and hassle-free. The automatic payments help them to avoid penalty fees and ballooning interest associated with other payment options. While the fixed payment duration options empower them to budget more efficiently. Ours is a revolutionary e-commerce experience that gives customers access to a better life combined with a responsible way to buy.\n\nPurchasing Power is \u2018Powering People to a Better Life\u2122\u2019 through its employee purchase program, financial literacy efforts and charitable contributions.\n\nFor more information, visit www.PurchasingPower.com\nOur people! We are very proud of our people, we \u201cPower People to a better life\u201d\n100% company paid benefits for employees\nKitchen stocked with gourmet coffee, teas and free snacks\nCasual work environment\nSummer Hours\nFlexible PTO\nTop of the line hardware\n\nApply Now: click Apply Now"}, "359": {"company": "Orange Coast Memorial Medical Center", "description": "At MemorialCare Health System, we believe in providing extraordinary healthcare to our communities and an exceptional working environment for our employees. Memorial Care stands for excellence in Healthcare. Across our family of medical centers, we support each one of our bright, talented employees in reaching the highest levels of professional development, contribution, collaboration and accountability. Whatever your role and whatever expertise you bring, we are dedicated to helping you achieve your full potential in an environment of respect, innovation and teamwork.\n\nPosition Summary\n\n\n\nThis position requires the full understanding and active participation in fulfilling the mission of Orange Coast Memorial Medical Center. It is expected that the employee demonstrate behavior consistent with our core values, support Orange Coast Memorial Medical Center\u2019s strategic plan and participate in and advocate performance improvement/patient safety activities.\n\nThe Clinical Laboratory Scientist will (CLS) will perform laboratory duties as scheduled; produce accurate and timely laboratory results in accordance with Orange Coast Memorial Medical Center Laboratory Services department standards and procedures. The Clinical Laboratory Scientist must be able to assess and interpret data about the patient's status in order to identify each patient's age specific needs and provide the care needed for that patient population. CLS will be able to perform pre-analysis, analysis and post-analysis procedures for clinical laboratory testing in the Blood Bank section.\n\nMinimum Requirements\nMinimum three years of experience in general laboratory, including two years of experience in Blood Bank.\nKnowledge of current information system preferred.\nBachelor\u2019s degree in a science discipline preferred.\nCurrently licensed as a Clinical Laboratory Scientist by the state of California.\nTo apply to this job, click Apply Now"}, "360": {"company": "Marin Software", "description": "Software Engineer, Data Science (Optimization)\n\nat Marin Software\n\nSan Francisco, CA\n\nMarin is the Advertising Management Platform of choice for global brands such as General Motors, American Express, Macy's, REI, Sephora, Salesforce.com, and 500 other top consumer and B2B companies.\n\nOptimizing ad targeting and performance starts with having the right data, and the Big Data engineering team makes it happen. Combining thousands of reports from Google, Facebook, Bing, and other publishers, over 100M click events per day from our in house performance tracking system and customer reporting systems, and 5+ billion advertising campaign objects, we power our proprietary bidding systems and financial models to maximize value and return for our customers.\n\nMarin is rapidly building out our Big Data infrastructure. We've already built out a 100+ node, petabyte size cluster, and now is a great opportunity to join as a key member of the team and be at the center of the action. We are in an active search for a Data Science Engineer, Bidding to bring real world experience of data analysis and machine learning techniques on vast datasets. We enjoy intense mathematics and computer science challenges and approach these problems with creativity and teamwork. We believe Marin's explosive growth should not compromise its agility in responding to market trends. We are a company that believes in building a product for the long-term, and creating a company that can grow as the market matures.\n\nResponsibilities\nChallenging Machine Learning problems in Bid Prediction in the search advertising space.\nAnalyze large datasets on Spark. Contribute to open source, work on mlib & Presto!\nWork on convex portfolio optimization techniques in the display advertising space.\nMatrix Factorization methods at scale comparable to the Netflix Challenge, to identify target audiences for product segments\nRequirements\n2+ years relevant work experience\nExperience with Scala, Spark, functional programming.\nStatistical Programming (Matlab, R, Python)\nIndustry experience with data analytics projects involving machine learning/optimization in production\nIndustry experience working with or developing distributed systems, especially distributed data stores a plus (Spark, HBase, Presto)\nBS/MS/Ph.D. in Computer Science/Mathematics/Statistics or other quantitative discipline\nCompensation\n\nThis is an on-site, full time salaried position located in our San Francisco world headquarters office. Marin Software provides Equity participation, best in class comprehensive health plans including medical, vision and dental, in addition to flex time off and reimburses 50% of monthly commuting costs for parking and/or mass transit up to the IRS limitations. Marin Software's world headquarters is located in the financial district of San Francisco, with remote offices in Chicago, New York, Austin, and Portland. European headquarters are located in London, with additional offices in Singapore, Paris, Hamburg, Sydney and Tokyo.\n\nAbout Marin Software\n\nMarin Software Incorporated's (NYSE: MRIN) mission is to give advertisers the power to drive higher efficiency, effectiveness, and transparency in their paid marketing programs that run on the world's largest publishers. Marin provides industry leading enterprise marketing software for advertisers and agencies to measure, manage, and optimize more than $7.8 billion in annualized ad spend across the web and mobile devices. Offering an integrated SaaS ad management platform for search, social, and display advertising, Marin helps digital marketers improve financial performance, save time, and make better decisions. Advertisers use Marin to create, target, and convert precise audiences based on recent buying signals from users' search, social, and display interactions. Headquartered in San Francisco, with offices in eight countries, Marin's technology powers marketing campaigns around the globe. For more information about Marin Software, please visit: marinsoftware.com.\n\nMarin Software embraces diversity and is proud to be an equal opportunity employer. As part of our commitment to diversifying our workforce, we do not discriminate on the basis of age, race, sex, gender, gender identity, color, religion, national origin, sexual orientation, marital status, citizenship, veteran status, or disability status, and we operate in compliance with the San Francisco Fair Chance Ordinance.\nStart your job application: click Easy Apply"}, "361": {"company": "Elysium Health", "description": "Bioinformatics Data Scientist\n\nDescription\nElysium is seeking a Bioinformatics Data Scientist. In this position, you will be an essential member of our team and support new product development. You will work with multidisciplinary teams to perform and analyze complex genomic data analysis.\n\nAt Elysium, our mission and goal is to solve the most challenging aspects of health. Join our team of exceptional scientists, doctors and researchers focused on solving the most challenging and important aspects of health.\nResponsibilities\nApply statistical modeling and/or machine learning approaches to analyzing biological data\nImplement and develop innovative analytical approaches with translational impact for biological data\nAdvise and contribute to efficient study design and statistical analysis plans\nReview, synthesize, interpret, and report on analysis results\nPerform assessment of quality control metrics\nStay up-to-date with available bioinformatics tools through literature review and computational experiments\nContribute to a team of translational researchers committed to improving health\nPlace a priority on getting results with an emphasis on high quality outcomes\nDisplay a willingness to challenge the status quo and take risks\nPossess a strong sense of urgency that drives performance beyond expectations\n\nRequirements\n\nPhD or MS in Statistics, Bioinformatics, Computational Biology, Biostatistics, Genetics, Computer Science, or a related field\nFamiliarity with fundamental concepts in genomics, statistics, and bioinformatics\nProficiency with R and Bioconductor packages, one or more programming languages (Python, Perl, etc)\nFamiliarity with high-performance computing environments and cloud services/management systems\nExcellent collaboration and communication skills, both verbal and written\n\n\nHow you are benefited\n\nCompetitive Salary\nHigh quality health insurance: As an employee at Elysium you\u2019ll be able to pick between several medical, dental, and vision plans. All choices include healthcare support, on-demand primary care, and virtual support.\nFlexible vacation: Hard work requires time off to rest and recharge. Elysium employees take vacation at their discretion (in consultation with their managers)\nMonthly wellness reimbursement credit: Can be used towards gym memberships, therapy, massages, yoga, etc.\nProfessional Development: Team members are granted a stipend per year for continuing education expenses.\nKitchen fully stocked with snack options.\nCatered lunches on Fridays\nTeam Outings\nDog Friendly Office\n\n\n\nTo apply to this job, click Apply Now"}, "362": {"company": "Avalere Health", "description": "Job Title: Healthcare Data Scientist\nPractice: Health Plans Practice\nGeneral Summary\nAvalere Health is a strategic advisory company whose core purpose is to create innovative solutions to complex healthcare problems. Based in Washington, D.C., the firm delivers actionable insights, business intelligence tools, and custom analytics for leaders in healthcare business and policy. Avalere's experts span 230 staff drawn from Fortune 500 healthcare companies, the federal government (e.g., CMS, OMB, CBO, and the Congress), top consultancies, academia and nonprofits. The firm offers deep substance on the full range of healthcare business issues affecting the Fortune 500 healthcare companies. As an Inovalon company (NASDAQ: INOV), Avalere\u2019s focus on strategy is supported by outstanding data analytics that generate unique insights and meaningful business improvement. Through events, publications, and interactive programs, Avalere insights are accessible to a broad range of customers. For more information, visit avalere.com, or follow us on Twitter @avalerehealth.\nThe Healthcare Data Scientist will work with large healthcare datasets to provide complex data extracts, programming, and analytical modeling capabilities in support of the team\u2019s services to internal and external clients. The team consists of staff with specialized experience, such as research scientists, health service researchers, health economists, clinicians, and project managers, who conceptualize, execute, and deliver qualitative, analytical, and strategy-based work products for clients. We also work closely with other practices, applying the full scope of the firm\u2019s knowledge base to the development of multi-disciplinary, creative solutions on behalf of our clients.\nPrincipal Duties and Responsibilities:\nWork collaboratively with teams of health services researchers and business analysts to draw insight and intelligence from large administrative claims datasets, electronic medical records and various healthcare registry datasets;\nIdentify and develop solutions to key strategic business problems using high-level modeling and statistical analyses techniques;\nUtilize SQL to perform advanced-level data extraction, transformation and data management; fully document and manage library of source code and algorithms for future use;\nDevelop and test hypotheses in support of research and product offerings, and communicate findings in a clear, precise, and actionable manner to our clients;\nRespond to operational data requests and create ad-hoc queries to support research projects;\nWork closely with Inovalon\u2019s Enterprise Data Management, Data Integration, MORE2 Registry\u00ae, and iPORT+\u2122 teams to identify, understand, and resolve data issues and improve the efficiency, productivity and scalability of Avalere and Inovalon Product and production data processes;\nTroubleshoot production-related issues and coordinate successful resolution;\nAssist with the evaluation of data analytic vendors and tools;\nMaintain compliance with Inovalon\u2019s policies, procedures and mission statement;\nAdhere to all confidentiality and HIPAA requirements as outlined within Inovalon\u2019s Operating Policies and Procedures in all ways and at all times with respect to any aspect of the data handled or services rendered in the undertaking of the position; and\nFulfill those responsibilities and/or duties that may be reasonably provided by Inovalon for the purpose of achieving operational and financial success of the Company.\nSkills, Experience, and Other Job-Related Requirements:\n3+ years of professional experience in healthcare or pharmaceutical industries working with administrative claims data and big data;\nStrong SQL programming skills in addition to working knowledge and experience using statistical analysis tools such as SAS, R, SPSS, Stata, and/or MatLab;\nDemonstrated problem solving, analytical reasoning and decision-making skills;\nStrong understanding and experience in researching and resolving data issues with a logical, instinctive, and problem-solving mentality working with large, complex and incomplete sources;\nBusiness analytical skills (process flows, procedures, spreadsheets, modeling, etc.) and good understanding of design and architecture principles;\nExhibit strong project management skills, with an ability to work independently on multiple projects with competing priorities and a strong commitment to meeting goals and deadlines;\nUnderstanding of database management tools (e.g., Hadoop, Hive or MapReduce);\nExcellent analytical skills and ability to understand and interpret results based on advanced statistical techniques;\nStrong written and verbal communication skills in IT and business environments; ability to communicate to technical and non-technical audiences;\nAbility to work under minimal supervision in a fast-paced multidisciplinary environment;\nAdvanced knowledge of health care, health policy, pharmaceutical, medical device, and related issues;\nSuperior customer service in the form of first-rate work product and project management;\nStrong ability to manage challenging client situations;\nStrong ability to troubleshoot and recommend solutions; and\nStrong ability to translate complex information for a wide range of clients.\nHow to Apply:\nAll applications should be submitted through the Careers section of our website at www.avalere.com/careers. Please submit copies of the following application materials:\nCover letter\nResume\nWriting sample (could include published abstract, manuscript, or presentation)\nCandidates should be prepared to complete an interview exercise as part of the in-person interview process.\nAvalere Health is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, or protected veteran status.\nTo apply to this job, click Apply Now"}, "363": {"company": "ACI Worldwide", "description": "DETAILS: ACI Worldwide is looking to fill one Data Scientist\nposition to be based out of its Waltham, Massachusetts office located at 880\nWinter Street, Suite 110, Waltham, MA 02451.\nPosition responsible for the following:\nDesigns, develops, and programs methods, processes, and systems to\nconsolidate and analyze unstructured, diverse big data sources to generate\nactionable insights and solutions for client services and product enhancement.\nInteracts with product and service teams to identify questions and issues for\ndata analysis and experiments. Develops and codes software programs, algorithms\nand automated processes to cleanse, integrate, and evaluate large datasets from\nmultiple disparate sources. Identifies meaningful insights from large data and\nmetadata sources; interprets and communicates insights and findings from\nanalysis and experiments to product, service, and business managers. Job Responsibilities: Develops predictive models for customers\nutilizing a variety of statistical and machine learning algorithms. Holds\nresponsibility for projects of a moderate degree of complexity. Executes all\nstages of model development and delivery including data definition, sampling,\npreprocessing, feature selection, model generation, and validation and support\nor production model release. Validates and prepares data for model development,\nperforms exploratory data analysis and data cleaning on large datasets and\nqueries and visualizes data with a variety of tools. Works with a team of\nscientists and engineers responsible for the development and deployment of the\nstate-of-the-art predictive models for a variety of financial applications.\nThis includes the design, development, and deployment of statistical predictive\nmodels. Understand and adhere to all corporate policies to include but not\nlimited to ACI Worldwide Code of Ethics and Global Information Security.\nPerform other duties as assigned.\n\nMINIMUM REQUIREMENTS: Bachelor\u2019s Degree (foreign\nequivalent accepted) in Bioinformatics, Computer Science, Electrical\nEngineering, Applied Statistical Mathematics, Physics, Computational Chemistry\nor related field plus 3 years\u2019 experience in the specialty or an IT-related\noccupation. Experience must include 3\nyears\u2019 experience with Predictive Modelling and Data Analysis (Hadoop, Pig,\nHive, SQL, and Oracle); 3 years\u2019 experience with ETL Procedures and Tools\n(Oracle Di, Sqoop, and SSIS); 3 years\u2019 experience with Business Analytics\n(HADOOP, Hive, and Oracle); 3 years\u2019 experience with Data Modelling (Hive and\nPig); and 2 years\u2019 experience with developing standards and best practices.\n\n*Current employees eligible\nfor referral bonus as per company policy with regard to this position.\nApply online at www.aciworldwide.com; AutoReqID 19003066.\n\nACI Worldwide is an AA/EEO\nemployer in the United States, which includes providing equal opportunity for\nprotected veterans and individuals with disabilities, and an EEO employer\nglobally.\n\nVEVRAA Federal Contractor\n\nRequest Priority Protected Veteran Referrals\nEOE \u2013 Veteran/Disabled/Minority/AA/F/M/SO\n#LI-DNI\nStart your job application: click Apply Now"}, "364": {"company": "EF Educational Tours", "description": "EF Tours helps students gain new perspectives and build skills for the future through experiential learning. As an accredited institution, we partner with educators across the world to create global education programs that blend classroom, digital, and experiential learning for students.\n\nThe Tours Engineering team @ EF Tours is the group of engineering and creative professionals empowering EF to send groups of students and educators on guided educational tours across the world. We power every step of our customer\u2019s journey \u2013 from showcasing our tour offerings, to creating personalized itineraries, and collecting their feedback after the tour. Over the course of your career with Tours Engineering, you\u2019ll have the opportunity to build beautiful front-end interactions for our customers, solve large scale data optimization problems, and get your hands on everything in between.\n\nWhat you\u2019ll do:\n\nYou will be part of a cross-functional, autonomous data team, collaborating closely with analysts, data scientists, engineers and executive stakeholders. You will be deeply involved in building out a data lake that will serve as the new source of truth for our business. As part of that effort, you will leverage your mastery of Spark and ETL to transition work loads from our legacy relational data warehouse into modern, open-source data processing platforms.\n\nWho you are:\n\nTo succeed in this role, you\u2019ll need excellent problem-solving skills, strong attention to detail, and the technical know-how to independently build solutions from start to finish. We are looking for a true data expert, someone who is comfortable working with and shaping datasets of varying latencies, size, and format.\n\nWe ask that you have:\n5+ years of hands-on industry experience with Python and AWS\n2+ years of proven ability developing ETL in Spark (PySpark preferred)\nAdvanced SQL (ANSI SQL or Transact-SQL)\nWorking knowledge of Data Lake patterns: partitioning, multi-step transformations, data cataloging\nWorking knowledge of self-describing, compressed data file formats: Parquet, Avro\nWorking knowledge of event streaming platforms: Kinesis, Kafka, Flink\nWorking knowledge of Domain Driven Design (DDD) and event storming\nExperience with AWS data processing services: EMR, Athena, Redshift\nExperience with AWS serverless infrastructure: API Gateway, Lambda, DynamoDB, S3\nExperience with NoSQL/non-relational databases, especially document stores\nExperience building data models intended for data visualization solutions\nDemonstrable experience implementing business logic into well structured data models that have been successfully applied to BI\nExcellent verbal and written skills in order to effectively communicate business concepts to partner analysts and teams\nA drive to learn the intricacies of the business, with a versatile and dynamic understanding of businesses you\u2019ve worked with in the past\nOther useful skills include:\nExperience coding in Java or Scala\nDocker or other containerization tooling\nCI/CD exposure using git based deployment automation.\nInfrastructure-as-code: Terraform, CloudFormation\nExperience working on a SCRUM Team\nExperience using global data catalogs for either end user reference or data automation\nExperience with relational modeling, star schemas and Kimball Data Warehousing\nLet\u2019s talk about the Perks:\n\nWe believe that happy people do great work. What makes us happy? Things like:\nThe opportunity to travel internationally\nDiscounts on travel\nThree weeks paid vacation for your first year and then four weeks after your first year\nFree language classes, taught in-house\nAccess to a brand-new fitness center and rock-climbing wall on the EF campus\nA restaurant and bar located in 2 of our EF campus buildings\nMarket-leading benefits package including top of the line health coverage, 401k with company match, tuition reimbursement, and more\u2026\nEF is the world\u2019s largest international education company \u2013 providing life-changing educational experiences to create global citizens. We offer millions of people the opportunity to learn a language, travel abroad, experience another culture or earn an academic degree. Since 1965, EF\u2019s mission has been opening the world through education. Our 52,000 employees have a worldwide presence in over 600 schools and offices within 50 countries.\n\nFor more information about our career opportunities, visit www.careers.ef.com\nStart your job application: click Apply Now"}, "365": {"company": "Expedition Technology, Inc.", "description": "Machine Learning Engineer\n\nUS Citizenship is required due to security clearance requirements.\n\nAre you a motivated engineer who is passionate about embracing new challenges and solving the hardest technical problems in a team-oriented environment? Every day, the engineers at Expedition Technology work together to solve our Nation's defense and intelligence challenges by using Machine Learning and Deep Learning to demystify data obtained from signals and images.\n\nOur applied research and development mindset afford our people the opportunity to work on the most cutting-edge methods of optimizing deep learning networks, developing state-of-the-art algorithms and ultimately producing software products that are critical to our nation's defense infrastructure.\n\nThe success we have already achieved has made Expedition Technology one of the top Machine Learning/Deep Learning research organizations in the Defense and Intelligence communities and we need additional intelligent, passionate, creative people to join our team.\n\nWhen you join our team, you'll have the opportunity to:\nDive directly into the latest computer vision and signal processing research to replicate new techniques published in academia and find ways to make those ideas work on a larger scale\nUse your strong Python coding skills to research, design, develop and expand upon algorithms that will train neural networks to deliver actionable intelligence faster and more effectively\nDevelop deep-learning software prototypes that demonstrate potential usefulness to our customers\nAnalyze data from disparate sources including images, video, radar, signals and more\nBrainstorm solutions to the toughest problems alongside a team of smart, creative, passionate engineers\nParticipate in machine learning brownbag sessions and other forms of collaborative learning to keep abreast of the constant changes in Machine and Deep Learning\nRequired skills:\nStrong problem-solving skills combined with deep intellectual curiosity and the desire to push technical boundaries\nStrong coding skills- preferably in Python, C/C++, Julia or other object-oriented language in a Linux environment\nSoftware development skills and the desire to work on cutting edge development in a Cloud environment\nDeep understanding of data structures and algorithms\nKnowledge of computer vision and/or signal processing including techniques for classification and feature extraction\nExcellent oral, written, presentation and communication skills\nBachelor's degree in Computer Science, Computer Engineering, Electrical Engineering or related field. Advance degrees welcome\nUS Citizenship- Must be a US Citizen eligible to maintain a US Government security clearance\nDesired skills:\nExperience with deep learning frameworks like Tensorflow, PyTorch, Caffe or Keras\nAbout Expedition Technology\n\nAt Expedition Technology, we push the boundaries of what is possible every day. Our engineers work on the most challenging problems in Computer Vision, Digital Signal Processing and Software Engineering from a Machine Learning/Deep Learning perspective and collaborate to find the answers. We are a research-focused company whose mission it is to solve our customer's most pressing needs in a creative, novel manner.\n\nExpedition Technology offers self-directed, company-paid Medical, Dental and Vision benefits and the freedom to allow you to select which benefits matter most. We offer a 401k with a generous company match, a student loan repayment program, equity shares, paid holidays, paid time off and an education reimbursement allowance. Most importantly, we offer an environment where we are encouraged to push boundaries, take risks and enjoy the rewards.\n\nInterested in joining our team? Let's explore together.\n\nEXP is proud to be an Equal Opportunity Employer that believes a diverse range of talent creates an environment that fuels creativity and innovation. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, disability, national origin, genetic information or protected veteran status.\nApply Now: click Easy Apply"}, "366": {"company": "NAVIS", "description": "NAVIS is excited to be hiring a Data Engineer! This is a NEW position due to growth in this area.\n\nBe a critical element of what sets NAVIS apart from everyone else! Join the power behind the best-in-class Hospitality CRM software and services that unifies hotel reservations and marketing teams around their guest data to drive more bookings and revenue.\n\nOur Guest Experience Platform team is seeking an experienced Data Engineer to play a lead role in the building and running of our modern big data and machine learning platform that powers our products and services. In this role, you will responsible for building the analytical data pipeline, data lake, and real-time data streaming services. You should be passionate about technology and complex big data business challenges.\n\nYou can have a huge impact on everything from the functionality we deliver for our clients, to the architecture of our systems, to the technologies that we are adopting.\n\nYou should be highly curious with a passion for building things!\n\nClick here for a peek inside our Engineering Team\n\nDUTIES & RESPONSIBILITIES:\nDesign and develop business-critical data pipelines and related back-end services\nIdentification of and participation in simplifying and addressing scalability issues for enterprise level data pipeline\nDesign and build big data infrastructure to support our data lake\nQUALIFICATIONS:\n2+ years of extensive experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, HBase, Parquet)\nExperience with building, breaking, and fixing production data pipelines\nHands-on SQL skills and background in other data stores like SQL-Server, Postgres, and MongoDB\nExperience with continuous delivery and automated deployments (Terraform)\nETL experience\nAble to identify and participate in addressing scalability issues for enterprise level data\nPython programming experience\nDESIRED, BUT NOT REQUIRED SKILLS:\nExperience with machine learning libraries like scikit-learn, Tensorflow, etc., or an interest in picking it up\nExperience with R to mine structured and unstructured data and/or building statistical models\nExperience with Elasticsearch\nExperience with AWS services like Glue, S3, SQS, Lambda, Fargate, EC2, Athena, Kinesis, Step Functions, DynamoDB, CloudFormation and CloudWatch will be a huge plus\nPOSITION LOCATION:\n\nThere are 3 options for the location of this position:\nCan work remotely in the continental US with occasional travel to Bend, Oregon\nBased at a shared office space in the heart of downtown Portland, Oregon\nBased at our offices in Bend, Oregon (relocation assistance package available)\nCheck out this video to learn more about the Tech scene in Bend, Oregon\n\nNAVIS OFFERS:\nAn inclusive, fun, values-driven company culture we've won awards for it\nA growing tech company in Bend, Oregon\nWork / Life balance - what a concept!\nExcellent benefits package with a Medical Expense Reimbursement Program that helps keep our medical deductibles LOW for our Team Members\n401(k) with generous matching component\nGenerous time off plus a VTO day to use working at your favorite charity\nCompetitive pay + annual bonus program\nFREE TURKEYS (or pies) for every Team Member for Thanksgiving (hey, it's a tradition around here)\nYour work makes a difference here, and we make a huge impact to our clients' profits\nTransparency regular All-Team meetings, so you can stay in-the-know with what's going on in all areas our business\nABOUT NAVIS:\nNAVIS is the only Unified CRM solution for hotels and vacation rental management companies that brings their data and their reservations sales, marketing, and revenue teams together to drive more direct bookings and revenue. Because we believe technology should make you money, not cost you money, we developed our game-changing Revenue Performance Platform to transform teams into revenue makers, enabling them to drive, capture and convert more direct bookings. We deliver actionable guest insights so departments can seamlessly sell and market together. The result is always a dramatic increase in direct sales and profit. We guarantee it.\n\nFounded in 1987, NAVIS is a privately held company with headquarters in Bend, Oregon, and growing locations in Orlando, Florida and Reno, Nevada.\n\nWe have been named on multiple \"Top Workplaces\" lists for NINE years running!\n\nNAVIS is honored and humbled to have been recognized as a \"Top Workplace\" by \"The Oregonian\" for several years (and again in 2019).\n\nAt NAVIS, our Core Values are:\nGolden Rule: I treat others as I want to be treated\nIntegrity: I am a person of my word and highly trusted\nInnovation: I create solutions for difficult business problems\nPerformance: I am part of an ambitious team and my results matter\nAttitude: I am a positive influence, I love my team and the work we do\n\n\nNAVIS is an Equal Opportunity Employer (EOE).\n\nTo apply to this job, click Easy Apply"}, "367": {"company": "Clearlink", "description": "Job Posting Title:\n\nData Engineer\n\nJob Description:\n\nWho We're Looking For\n\nData Engineer - Salt Lake City\n\nWe understand the power of (quality) data. It elevates the user experience, reveals patterns, and provides valuable insights that have a direct impact on our bottom line.\n\nAnd that's why we're looking to increase data's role in our current strategy.\n\nIf sifting through analytics and breaking down complex information is your idea of fun, there's a whole mess of adventure and excitement headed your way.\n\nAs a Data Engineer at Clearlink, you'll work directly with our Information Management team, responsible for managing, optimizing, and monitoring data retrieval, storage, and distribution throughout the organization.\n\nYou'll find trends. Track inconsistencies. Communicate your findings to a broader audience. And help various department leaders turn those complicated stats and algorithms into effective marketing strategies.\n\nSound good?\n\nLet's crunch some numbers.\n\nBreaking Down Your Day-to-Day\nOptimize data (both underlying data structure and delivery method) for use by reporting platforms\nDefine and implement data structures across RDMS, graph, and object data stores\nLearn and assist with our Extract Transform and Load (ETL) process for bringing data into /*and out of*/ the warehouse in order to turn it into usable information\nStand-up API endpoints and other delivery mechanisms along with their underlying integrations for use with our internal and external IT partners\nProvide architectural solutions and assist in evolving our data platform\nPartner with various users company wide to build a strong data driven culture through the use of information-based decision making\nHelp users access and understand the data and metrics in the data warehouse\nDevelop appropriate new metrics to be used across the business\nBuild ad hoc reports for various stakeholders\nWhat You Need\nBachelor's Degree in a related field\n2 years of SQL query experience\nPython and/or PHP experience\nExperience with Object Oriented/Programmatic ETL/Data Integration Workflow Management Services (e.g., Airflow, AWS Step Functions, and other similar solutions)\nFamiliarity with AWS Service Architecture (FaaS, IaaS, IaC, CI/CD, Analytical/DB services, DevOps, etc.)\nClickstream web analytics data management experience\nIn-depth quality assurance expertise\nComplex problem-solving skills\nStrong communication skills, both written and verbal; ability to translate complex technical language to easily understood messages for\nHigh degree of independent judgement and love for solving complex problems\nComfortability with auditing data to verify integrity and identify discrepancies\nKnowledge in web design - BI and Analytical dashboards\nWhat We Offer\nCompetitive pay\nAward-winning healthcare coverage and wellness programming, including onsite massage therapists, yoga classes, and personalized nutrition and fitness coaching\n401(k) matching\nInvestment in your personal development: tuition reimbursement, leadership programming, opportunities for industry conferences and influence\nGenerous PTO and work / life integration\nMore About Clearlink\n\nClearlink, a SYKES company, is an award-winning digital marketing and sales company headquartered in Salt Lake City, Utah. Clearlink's leading-edge technology and 2,000 digital marketing, sales, and data science experts are the reason it's been a trusted partner for Fortune 500 companies since 2003. Clearlink's people-focused culture has been recognized internationally for strong leadership, business growth, innovative employee initiatives, and corporate social responsibility. As the global leader in Intelligent CX, Clearlink is committed to providing intuitive, connected, and engaging experiences throughout the customer journey.\n\nAnd in the past year alone, Clearlink and our people have been honored with over a dozen awards, including:\nUtah Business Magazine's SAMY Awards\nUtah Business Magazine's 40 Under 40 Awards\nUtah Business Magazine's 30 Women to Watch Awards\nUtah Business Magazine's 20 in Their 20s Awards\nUtah Business Magazine's Fast 50 Awards\nSearch Engine Land Awards, Best In-house SEO Team Finalist\nPR Daily Digital PR Awards, Viral Campaign Award\nPR Daily Digital PR Awards, Media Relations Campaign Award\nUtah Diversity Connection, Large Business Diversity Award\nThe Stevie Awards, Achievements in Health and Wellness\nThe Stevie Awards, Achievements in Developing and Promoting Women in Business\nThe Stevie Awards, People-focused CEO of the Year\nUtah Business Magazine's CEO of the Year\nAchievers 50 Most Engaged Workplaces Award\nWomen Tech Council's Shatter List\nLocation:\n\nSalt Lake City\nStart your job application: click Apply Now"}, "368": {"company": "Qualys", "description": "We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.\n\nResponsibilities:\nDesigning and deploying deep learning algorithms and predictive models\nDevelop custom data models and algorithms to apply to data sets\nAssess the effectiveness and accuracy of new data sources and data gathering techniques\nDevelop processes and tools to monitor and analyze model performance and data accuracy\nCollaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions\nQualifications:\n7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred\nExperience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nExperience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nApplied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.\nFamiliarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those\nExperience with data cleansing, data quality assessment, and using analytics for data assessment\nExcellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.\nExperience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.\nAbility to drive a project and work both independently and in a team\nTo apply to this job, click Apply Now"}, "369": {"company": "MatrixCare", "description": "In this Lead Data Scientist role, you will be responsible for the design, development, implementation and delivery of the organization's Machine Learning Products, including the components required to support it and the integration with the corporate and business architecture and applications.\n\nAs our Lead Data Scientist, you will:\nOversee Machine Learning Projects across the company from end-to-end including marketing optimization and product innovation\nLead a team of Data Scientists, Data Administrators, and Data Engineers and collaborate with cross-functional teams to build products\nDevelop and use advanced software programs, algorithms, query techniques, models to solve complex business problems, and automate processes end-to-end\nProcess, filter and present large quantities (Terabytes) of data using Natural Language Process (NLP), Artificial Intelligence (AI), and Machine Learning (ML)\nDesigns and develops methods, processes, and systems to consolidate and analyze structured and unstructured, diverse sources including\"big data\" sources\nCoordinate with software developers and database developers to implement data architecture standards and practices. Help select the right technologies to maintain flexibility and deliver high business value and results\nDemonstrate up-to-date expertise in Machine Learning and apply to the development, execution, and improvement of action plans. Incorporate software and system architecture (e.g., infrastructure, network) into designs and standards.\nReview designs to ensure scalability and applicability\nImplementation of software best practices that lead to high-quality software related to test coverage, code reviews, and continuous integration and continuous delivery\nMaximize professional development, personal contribution, and performance of team.\nReview the work of others\nMentoring and training of software developers and database developers in areas pertaining to data\nMaintain knowledge of current domains and strategic roadmaps\nGood working knowledge of current application/system infrastructure\nEnsure alignment of solutions with business and IT goals/objectives\nSkills and Experience needed for this position:\nMS or PhD in Statistics, Data Science, Physics, Mathematics, or a similar quantitative field\nUnderstanding of healthcare data and healthcare opportunities\nA proven and successful track record of leading teams through the successful delivery of advanced machine learning and statistical modeling that positively impact business performance\nUnderstanding of probability and statistics, data science, machine learning, data management, and visualization technique\nExperience with leading development in programming languages commonly used for data analysis, including R, Python, and Web development, such as Python, JavaScript, CSS and HTML\nExperience with machine learning APIs and computational packages (TensorFlow, Theano, PyTorch, Keras, Scikit-Learn, NumPy, SciPy, Pandas, statsmodels)\nVery strong knowledge and experience with ETL tools, preferable SSIS\nVery strong knowledge and experience with SQL, preferably Transact SQL\nKnowledge and experience in DBMS performance and tuning\nOur ideal candidate may also have:\n10+ years of hands-on work experience in R, Python implementing statistical models and machine learning models (anomaly detection, classification, clustering, time series prediction, regression models, etc.)\n10+ years of experience with large scale computing systems like Hadoop, MapReduce, Spark, and/or similar systems preferred\nIT development experience with expertise with both transactional and data warehousing systems.\nProficient with AWS or Azure cloud computing environments.\nExperience leading technical projects and/or teams and a desire to be both a technical and people leader\nKnowledge and professional experience in data warehousing related infrastructure\nProficiency and experience with SQL relational databases, database concepts, dimensional modeling and database design.\nProficiency in MS Office (Word, Excel, PowerPoint, Outlook)\nProficiency with MS Visio\nHealthcare Industry experience\nWhy MatrixCare?Change the way technology is used to deliver healthcare. Build amazing products. Create ways to provide better care for the nation\u2019s aging population. Tackle complex questions to ensure optimal customer service. See your work improve healthcare each and every day.\n\nAbout MatrixCareMatrixCare, a wholly owned subsidiary of ResMed (NYSE, RMD, ASX: RMD), is the complete solution for growing organizations that need to successfully manage risk in care delivery outside of a hospital. Current and multi-time winner of the prestigious Best in KLAS for Long-Term Care Software award, MatrixCare solutions are trusted by more than 15,000 organizations across the spectrum of out-of-hospital care. ACOs, skilled nursing facilities, senior living organizations, life plan communities (CCRCs), and home care, home health and hospice organizations depend on MatrixCare to help them connect, collaborate and prosper as we migrate to a fee-for-value healthcare system. In addition to purpose-built EHR components for any long-term, post-acute care setting, MatrixCare also includes solutions to systematically increase clinical quality: Enterprise Analytics, robust Clinical Decision Support and the industry\u2019s first Care Coordination platform to create a true, person-centric, e-longitudinal health record and enable providers to efficiently manage the populations under their care. Visit www.matrixcare.com for more information. MatrixCare is a registered trademark of MatrixCare.\nApply Now: click Apply Now"}, "370": {"company": "NJF Global Holdings", "description": "Our client is a leading hedge fund looking to hire a Data Engineer for their Macro Strategies business unit.\n\nResponsibilities:\nDriving innovation through product and platform development\nHelping to facilitate bespoke custom basket trades for clients in a scalable infrastructure\nDeveloping infrastructure and tools to administer basket rebalances for external clients and internal trading teams\nAutomation of corporate action adjustments and improvement of work-flow\nProviding metrics for basket trades, to drive sales and trading decisions and to grow the business\nBoth independent and collaborative work, involving several sales/strat/trading teams globally\n\nRequirements:\nExpertise in Python\nStrong SQL skills\nWeb scraping experience\nExperience with Linux and Windows platform\nStrong communication skills, both written and verbal\nExposure to non-relational databases\nExposure to web UI technologies\nData Warehousing and Modeling expertise\nFinancial knowledge\n\n\nIf you would like to be considered for the position of Data Engineer or wish to discuss the role further then please leave your details below. Your resume will be held in confidence until you connect with a member of our team\nEmail: info@njfsearch.com or call London (0207 604 4444,) New York (212 400 4845) or Chicago (312 204 72176) to speak to a member of our team. Thank you"}, "371": {"company": "CORPORATE", "description": "Title\n\nMachine Learning Engineer\n\nThe Impact\n\nThe Machine Learning Engineer is an integral member of S&P Globals AI Engineering group who partners with data scientists to design, build, deploy, and support AI-powered applications that transform S&P Global's products and operations using machine learning and related techniques. Our machine learning engineers take a modern, full-stack approach to prototyping, developing, deploying, and operating advanced analytics applications and infrastructure in production environments. Working in an organization for which data is the primary raw material, finished product, and core asset provides an unusually rich environment for a machine learning engineer to make an impact.\n\nResponsibilities\nPartner with data scientists to identify, prototype, develop, deploy, and operate AI-powered applications in production settings\nManage and support the organization's cloud-based data and computing platforms and infrastructure for AI applications\nHelp drive the organization's initiatives and vision around data pipelines, DevOps, and cloud architecture\nWork with a machine-learning-first mindset\nBasic qualifications\nUniversity degree in engineering or a related field\nExperience releasing and supporting a production software deployment in a cloud environment\nDemonstrated expertise in some full-stack combination of:\nData Engineering\nData Science\nData Architecture\nWeb UI / UX\nSoftware Engineering\nCloud Architecture\nDevOps, Docker, Kubernetes\nEntrepreneurial spirit\nPreferred qualifications\nGraduate degree in a technical field\nExperience operationalizing machine learning applications in a production setting\nDeep Python and or React expertise\nExperience with applied machine learning tools e.g. Scikit-Learn, TensorFlow, PyTorch\nApplied experience with text extraction and information retrieval\nDemonstrated UI and UX expertise in delivering end-to-end intuitive web UI experiences\nFine Print\nThe AI Engineering group is based in Charlottesville, VA\nThe full application process requires completing a take-home data engineering challenge. If this sounds like a fun opportunity, youre in the right place.\nPositions are available at all levels"}, "372": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking a Data Scientist who wants to develop innovative solutions for customers and internal product teams. We look to rapidly prototype solutions and deploy the most promising of them. We identify and leverage the latest techniques (fast.ai is a team favorite) so that our customers can stay one step ahead. On every project you'll learn something new (and likely teach us something as well). If that sounds appealing to you - we'd love to chat.\n\nResponsibilities include:\nDevelop solutions spanning multiple subject areas, from NLP to Image and Video.\nMaintain awareness of state-of-the-art machine learning and techniques, methods and platforms, including commercial and open source.\nImplement, configure and test machine learning and deep learning libraries and platforms (e.g. fast.ai, TensorFlow, Keras, XGBoost, LightGBM).\nTest solutions on AWS using services such as SageMaker, EC2, and Snowball Edge.\nWrite blog posts and presentations that clearly communicate complex machine learning concepts to both technical and non-technical audiences.\nContribute to visually-appealing, web-enabled prototype applications that illustrate relevant machine learning capabilities.\nBasic Qualifications:\nExperience with Python\nExperience with machine learning or statistics\nAbility to work both independently and collaboratively.\nHigh levels of curiosity, creativity, and problem-solving capabilities.\nStrong written and verbal communication skills.\nComfortable navigating the command line.\nDesired Skills:\nResearch experience in Machine Learning specific to Natural Language Processing, Computer Vision, or deep learning.\nExperience with managing data and creating algorithms using AWS.\nExperience with R, Java, or other programming languages.\nSecurity Clearance:\nMust be eligible to obtain and maintain a TS/SCI with Poly clearance\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nTo apply to this job, click Apply Now"}, "373": {"company": "Age of Learning", "description": "Company Overview:\nAge of Learning is a leading education technology innovator based in Glendale, California, with a talented team of 500+ individuals comprised of nationally-renowned educators, curriculum experts, designers, animators, engineers, and more. We develop engaging, effective digital learning technology and content to help children build a strong academic foundation for lifelong success.\n\nOur flagship product ABCmouse.com Early Learning Academy\u00ae is a comprehensive online curriculum and the #1 learning app and website for children ages 2 through 8. More than 20 million children worldwide have completed over 5 billion learning activities on ABCmouse. We recently launched Adventure Academy, the first educational massively multiplayer online (MMO) game, serving elementary and middle school children with thousands of learning activities in a fun and safe virtual world. Other programs include an immersive English language learning product for children in China; ReadingIQ, a world-class digital library with thousands of curated books; and a groundbreaking adaptive learning system that personalizes math instruction for every learner.\n\nWe are committed to helping all children succeed. Through our Education Access Initiatives, we make ABCmouse available at no cost to millions of children through schools, libraries, Head Start programs, and community centers\u2014including public housing authorities and after-school programs.\n\nAs we expand our global reach and increase the educational impact of our programs, we\u2019re looking for passionate, ambitious, and collaborative leaders to become a part of our growing team!\n\nSummary:\nAge of Learning is looking for a data scientist to work on our Mastery products that teach math and reading to elementary school children.\nIn this position, you will define and analyze data sets that enable the company to answer important product questions easily and effectively. You will work with questions from game designers, curriculum specialists, product owners, and learning analytics; translate analytical specifications, work with data engineers to produce data sets, and then mine them for insights. You will be directly responsible for mining data, cleaning it, creating reproducible visualizations, insights and inferences, and communicating them effectively.\nNote that this is an \u201con-site\u201d position\u2014you will be an integral part of the Mastery team, and will interface with product teams and executives, and you will be required to be located at the corporate campus.\nResponsibilities:\nWork closely with game designers, curriculum experts, and learning analysts to understand important product questions that can be answered by data. Be the go-to person for data questions for this product\nTranslate game design questions, usage questions, and learning science questions into meaningful insights, whether via A/B testing or reproducible dashboards\nWork with data engineers to design ideal data schemas and documentation\nHelp to build a reusable library of data schemas and reports that enable quick reproduction and reuse of analytical tools and ideas on other games and products\nWork closely with other analysts to share knowledge and build a repository of data analysis processes\nRequired Skills and Qualifications:\nDegree in Computer Science or a related field (statistics, economics, mathematics)\n3-5 years of experience in a data science role\nExperience in a statistical programming language (Python or R) for data cleaning, munging, analysis, and visualization\nDeep knowledge of the standard basket of machine learning algorithms (linear regression, logistic regression, random forests, regularization techniques, cross-validation) and proficiency with using machine learning algorithms in either Python or R\nStatistical fluency. You don\u2019t need to have a degree in statistics, but you should understand why ANOVA is really just linear regression and be comfortable with figuring out which goodness-of-fit tests make sense in a particular scenario\nExperience writing SQL queries and data transforms against large-scale column-oriented databases (Vertica, Redshift, Snowflake)\nStrong desire to explain what you\u2019ve learned from the data to the rest of the company using visualization frameworks including ggplot and (occasionally) Tableau dashboards\nA willingness to roll up your sleeves and do what it takes\nPreferred Skills and Qualifications:\nKnowledge of git and standard engineering processes (everything you do will be peer-reviewed and version-controlled in the company git)\nGood knowledge of classical statistics\nFamiliarity with adaptive educational technology and psychometric algorithms such as IRT (you will be creating and tuning algorithms for adaptive applications)\nExperience with standard metrics in gaming or in education\nFamiliarity with adaptive educational technology and psychometric algorithms such as IRT (you will be creating and tuning algorithms for adaptive applications)\nExperience in custom ETL design, implementation, and maintenance\nExperience with data quality frameworks and data validation and verification\nProficiency with Python and AWS Services (e.g. Lambdas, Redshift, and S3)\nProficiency with H2O and ggplot and other common R libraries; has created new R libraries before\nExperience with a Python data science framework such as scikit-learn\nExperience building reuseable dashboards and tools\nExperience writing SQL queries and data transforms against large-scale column-oriented databases (Vertica, Redshift, Snowflake, etcetera)\nIn-depth knowledge of how to write and optimize SQL statements\nKnowledge of Docker, and prior experience with using Docker containers (it\u2019s how we deploy adaptive layers in production)\nVideo game and educational gaming experience\nWe Provide:\nMedical, Dental, Vision + 401k\nHighly competitive PTO policy\nCasual Dress Code\nSnacks + Drinks (Coca Cola Freestyle Machine)\nGaming room including an Arcade (2,000+ games)\nFrequent team and company outings\nLimitless opportunities for professional growth!\n\nApply Now: click Apply Now"}, "374": {"company": "Daugherty Business Solutions", "description": "Overview\n\n\nAt a lot of organizations, it is hard to stand out. Everyone is working on the same projects; creating and testing as fast and efficiently as humanly possible. Don\u2019t get lost in the crowd. Team Daugherty offers the opportunity to work on something different. With every project comes the unique opportunity to showcase your skills.\n\nTeam Daugherty is looking to grow the Data and Analytic space here in Atlanta. Potential roles could include: Informational Architect, Information Analyst, Data Engineer, Data Scientist, or Big Data Developer. Ideal candidates for these positons are problem solvers with the ability to utilize insights, creativity, and perspective to drive business success for our clients. In these roles, you could have the opportunity to work with analysts, technical team leads, and software engineers on business intelligence related architectural issues and best practices. You may also assess organizational readiness, plan and execute a proof of concept, and lead an implementation plan to success.\n\nNow, imagine yourself:\nAssisting in the design and development of reports and dashboards for varying levels of the organization (operational through executive management).\nAssembling large, complex data sets that meet functional/non-functional business requirements.\nCollaborating with clients to design information management and business intelligence solutions.\nAnalyzing application specifications and technology approaches to ensure business requirements are met and are scalable for future product releases.\nCreating custom software components and employing a variety of languages and tools.\nWorking with business analyst and management to recommend future application solutions.\nInterest in joining our crew? Here are a few things that we look for:\nAbility to pick up new languages and technologies quickly.\nInterest in working with tools and technologies such as: Hadoop, Informatica, Vertica, Business Objects, Cassandra, Kafka, Postgres, BigTable, Oracle, Teredata, MarkLogic, MongoDB, MatLab, HBase, Hive, CouchDB, Sklearn, Azure, PostGIS, Redshift, SAS, Memcache, Redis, Pandas, Accumulo, NumPy, TensorFlow, Python, BASH, Scala, Julia, Spark, Map Reduce, Elastic Search, AWS, Splunk, Sqoop, Kibana, Spark Streaming, Solr, DynamoDB, SoftLayer, DigitalOcean, Google Cloud, Ansible, Jenkins, Crystal Reports, Qlik, Docker, Chef, Zoomdata, SPSS, AMOS, LISREL, Theanos, t-tests, power analysis, ANOVA, ANCOVA, linear regression, logistic regression, ARIMA, factor analysis, principal components, decision trees, Na\u00efve Bayes, K-Nearest Neighbors, Neural Networks, Random Forest, K-means clustering, Gaussian Mixture Models, GPFS, Kudu, Impala, Kinesis, GCP, Salt, Puppet, Pentaho, Jaspersoft, Talend, SSIS, SSAS, SSRS, Domo, Looker, Nifi, Spotfire, D3, PowerPivot, Power BI, Actian Vector, StremSets, REST, GraphQL, Kubernetes, GIS, Airflow, Oozie, Node Red, Mic\nTo apply to this job, click Easy Apply"}, "375": {"company": "Whitney, Bradley and Brown", "description": "JOB TITLE: Data Analyst (Navy Budget and Readiness Modeling) OPNAV N83\n\nPROJECT OVERVIEW:\n\nThis project provides analytical and IT technical support and life cycle management for a portfolio of cloud-based performance pricing models. These models and services assist the Navy to develop, price, and compare readiness alternatives in key ship, aircraft and expeditionary domains.\n\nJOB DESCRIPTION AND RESPONSIBILITIES:\n\nProvide data analytics support for IT team supporting Navy readiness model operation, development, integration and accreditation/re-accreditation efforts. Duties would include data analysis and presentation of collected data; development of requirements for future software upgrades, group and deskside training, testing, process development, and other responsibilities associated with software development life cycle.\n\nREQUIRED SKILLS AND QUALIFICATIONS:\n\nSecurity Clearance: Secret\nSecret Clearance\nBachelors degree in a science or business intensive discipline. Five (5) years of additional relevant experience can be substituted for a bachelors degree.\nAt least 3 years of relevant experience in data analysis and/or computer modeling\nProficient in MS Excel, PowerPoint and Word\nDESIRED SKILLS AND QUALIFICATIONS:\nExperience with the DOD Planning, Programming, Budgeting and Execution (PPBE) and the Program Objective Memorandum (POM) processes.\nAbility to translate functional model requirements to programming staff and ability to functionally test model results.\nFormer Navy, DOD or government service experience\nProficiency in data analytics using Business Intelligence software applications\nExperience with Business Intelligence tools (e.g. Qlik, Tableau, PowerBI, etc.)\nWORK LOCATION: Reston, VA\n\nTRAVEL: None\n\nKEY WORDS: Operations Research Analyst, Operation analysis, Data analytics, Business Intelligent software, Navy, Program and Budget Information System (PBIS), Program Objective Memorandum (POM), Performance feedback systems, Functional testing cloud-based models\n\nWBB is a technical and management consulting company that provides innovative products and services that solve government and commercial customers toughest problems. For more than 30 years, WBB has set the standard for excellence in consulting services, while providing its employees with an outstanding work environment with ample opportunities for growth and success. WBB continues to enjoy impressive growth, which is directly attributed to the companys hiring practice of always hiring the very best professionals from government, military and industry.\n\nWe are proud of our diverse environment and are an Equal Opportunity Employer. WBB is committed to a policy of equal employment opportunity. WBB participates in E-Verify.\n\nWBB does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of WBB and WBB will not be obligated to pay a placement fee.\nStart your job application: click Easy Apply"}, "376": {"company": "Gilead Sciences", "description": "For Current Gilead Employees and Contractors:\n\n\nPlease log onto your Internal Career Site to apply for this job.\n\nJob Description\n\n\nSpecific Responsibilities:\n\nThe Department of Bioinformatics at Gilead is seeking a highly motivated clinical data scientist to lead clinical data analysis. The successful candidate will have the opportunity to work in a fast-paced and highly collaborative environment to support clinical development programs with a focus on developing predictive models on complex high-dimensional clinical data to support clinical development programs in various disease areas, including liver disease, virology, inflammatory disease, and oncology.\n\nEssential Functions:\n\n\u2022 Working with internal colleagues to design and execute data analysis plans, and to summarize the actionable findings to support both exploratory research and new drug application activities.\n\n\u2022 Curate and analyze complex clinical data, including but not limited to genomic data, protein assay data, cytokine, and chemokine data from patient samples, and develop novel predictive models using statistical techniques and machine learning to support patient stratification and biomarker selection in clinical trials.\n\n\u2022 Develop and validate the analysis workflow, software applications, and data warehouse to improve visualization, integration, and accessibility of complex clinical data.\n\n\u2022 Serve as an internal expert in machine learning, predictive modeling, and quantitative data analysis.\n\nKnowledge, Experience & Skills:\n\n\u2022 Ph.D. in statistics, mathematics, bioinformatics, genomics, computer science or a related field with strong hands-on experience in machine learning, predictive modeling or a master degree with 3+ years of work experience in the related field.\n\n\u2022 Proficient in at least one of following programming languages: Python, R, SAS, Matlab, JavaScript or SQL.\n\u2022 Extensive experience in machine learning, predictive modeling or deep learning is required.\n\n\u2022 Strategic thinker and outstanding team player with strong interpersonal and communication skills.\n\n\u2022 Knowledge of biology in virology, liver disease, inflammation disease, and oncology is a plus.\n\nMeet the team:\n\nhttp://biometrics-careers.gilead.com/\n\nAbout Gilead:\n\nGilead Sciences, Inc. is a research-based biopharmaceutical company that discovers, develops and commercializes innovative medicines in areas of unmet medical need. With each new discovery and investigational drug candidate, we seek to improve the care of patients living with life-threatening diseases around the world. Gilead\u2019s therapeutic areas of focus include HIV/AIDS, liver diseases, cancer and inflammation, and serious respiratory and cardiovascular conditions.\n\n#LI-RA1\n\n\nFor jobs in the United States:\n\n\nAs an equal opportunity employer, Gilead Sciences Inc. is committed to a diverse workforce. Employment decisions regarding recruitment and selection will be made without discrimination based on race, color, religion, national origin, gender, age, sexual orientation, physical or mental disability, genetic information or characteristic, gender identity and expression, veteran status, or other non-job related characteristics or other prohibited grounds specified in applicable federal, state and local laws. In order to ensure reasonable accommodation for individuals protected by Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veterans' Readjustment Act of 1974, and Title I of the Americans with Disabilities Act of 1990, applicants who require accommodation in the job application process may contact careers@gilead.com for assistance.\n\nFor more information about equal employment opportunity protections, please view the \u2018EEO is the Law\u2019 poster.\n\nNOTICE: EMPLOYEE POLYGRAPH PROTECTION ACT\nYOUR RIGHTS UNDER THE FAMILY AND MEDICAL LEAVE ACT\nPAY TRANSPARENCY NONDISCRIMINATION PROVISION\n\nOur environment respects individual differences and recognizes each employee as an integral member of our company. Our workforce reflects these values and celebrates the individuals who make up our growing team.\n\nGilead provides a work environment free of harassment and prohibited conduct. We promote and support individual differences and diversity of thoughts and opinion.\n\n\nFor Current Gilead Employees and Contractors:\n\n\nPlease log onto your Internal Career Site to apply for this job.\nApply Now: click Apply Now"}, "377": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta has an exciting opportunity for people interested in Data Science and/or Software Engineering to join our new team in Tampa, FL. This is a paid internship and each participant will be nominated for a full TS/SCI clearance. This is a rare opportunity to start a career in the US Intelligence Community and get paid to learn alongside experts in the field. The Department of Defense is shifting investment into the future of machine learning and artificial intelligence across the Defense Intelligence Enterprise to reimagine and revolutionize the intelligence process. This is your opportunity to participate in a paradigmatic shift in National Security.\n\nNovetta is seeking to build an intern cell of students interested in Data Science and Software Engineering with a wide variety of backgrounds. Our interns will work with a Department of Defense Research and Development center, exploring big data analytic techniques and advanced visualizations. As part of our team you will have the opportunity to work on all aspects of solving difficult National Security problems; from problem definition, data exploration to model implementation to the delivery of production quality Data Science solutions. You will work as part of a multidisciplinary team and will impact multiple real-world projects concurrently.\n\nWork will be conducted on the customer's unclassified on-premise virtual environment and cloud based systems. This internship is an opportunity to:\nLearn from senior Technologists delivering production ready solutions.\nWork independently on projects to deliver a demonstrable product to the customer. Projects will be customized based on each intern's interest and skill level and is only limited by your imagination.\nBecome versed in cutting edge National Security and US Intelligence Community problems and projects.\nOur interns are expected to contribute new and novel ideas and are active members of our team. Ideal candidates will:\nIdentify important and interesting questions surrounding our customer's challenges, then translate those questions into concrete analytical tasks.\nDevelop strategies to extract, resolve, and unify information of various types from numerous data sources.\nOrganize and mine massive data sets of both structured and unstructured data;\nProvide thought-leadership in the areas of machine learning, artificial intelligence, analytics and data science.\nWork with a diverse team of engineers, computer scientists, data scientists, and intelligence analysts.\nBasic Qualifications:\nPursuit of an academic degree in a relevant field (e.g., Computer Science, Engineering, Mathematics, Statistics, Operations Research, Physics, Economics, Geography, etc.) and the following:\nCuriosity\nA keen interest in using novel techniques and state of the art technologies to help solve the most pressing issues in National Security\nExcellent communication and interpersonal skills\nPositive attitude, motivation to self-start and work independently\nFamiliarity in one or more programming languages (e.g. Python, Java, JavaScript, R etc.)\nThe ability to obtain a DoD Clearance (US Citizen with a clear background)\nDesired Skills:\nFamiliarity or interest in machine vision, network analysis, natural language processing or artificial intelligence\nInterest or experience with Big Data, and associated technologies (Spark, ElasticSearch & Kibana, etc.)\nInterest or experience with web application development.\nInterest or experience with open source frameworks for Neural Network architectures such as Keras, TensorFlow, PyTorch, or Caffe.\nInterest or experience with cloud services such as AWS or MS Azure.\nInterest or experience with software containerization & orchestration (Docker, Kubernetes).\nSecurity Clearance:\nMust be a US Citizen with the ability to obtain a Government Security Clearance\n\nThe requirements listed above are not all-inclusive. Anyone with an interest in using advanced technology to solve complex problems should feel free to apply. We will work within all successful candidates' schedules. This is a unique opportunity to shape the future of analytics while supporting our Nation's security in a fast paced, non-traditional, paid internship.\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nStart your job application: click Apply Now"}, "378": {"company": "Turo", "description": "Senior Data Analyst, Product\n\nTuro is seeking a Senior Data Analyst to join our growing SF team and turbo-charge Turo's growth in the US. The Senior Data Analyst will have the opportunity to liaise with many cross-functional teams and executives across the entire company to drive growth and product initiatives. The ideal person for this role is passionate about data, growth, product and marketplaces and will be able to leverage all of our data to help product managers make the best possible decisions.\n\nResponsibilities\nDevelop a keen understanding of our business with a specific focus on product experience (product journey)\nDrive ongoing analysis of business performance trends and KPIs across key parts of the business (marketplace metrics, supply, etc.) in close partnership with Product Management and other leaders\nLead ad-hoc analytical projects based on Turo strategic priorities\nDesign and build new dashboards to monitor performance metrics; maintain existing dashboards for accuracy and incorporate changes in the business\nBuild a strong relationship with the data science team to develop impactful data products\nPresent your research and insights to all levels of the company and work with cross-functional teams to rapidly execute and iterate\nRequirements\n3-5 years of using analytics to drive strategic business decisions; examples include product analytics, business intelligence, strategy consulting firm or investment banking; experience in consumer tech, marketplaces or e-commerce a strong plus\nTop notch quantitative skills; strong proficiency in conducting detailed data analysis and using metrics to drive business results\nExtensive experience with SQL; additional experience with BI & visualization tools is a strong plus (i.e. DOMO, Looker, Tableau)\nExperience transforming data into presentations that \"tell the story\" behind the data\nVery strong communication skills and ability to work collaboratively with cross-functional teams and at senior executive level\nComfortable working with MS Excel and MS PowerPoint\nMust be intellectually curious, eager to learn, self-motivated, detail oriented, and able to multitask\nPositive mental attitude, high energy, high integrity, strong work ethic, enthusiasm, sense of humor, and a commitment to our mission\nAbility to thrive in a dynamic startup environment; you'll have guidance when you need it, but you're also goal oriented and can execute without close supervision\nBenefits\nCompetitive salary and equity for all full-time employees\nEmployer paid medical, dental, and vision insurance\nGenerous paid time off, paid holidays, paid volunteer time off, and paid parental leave\nWeekly catered lunch with a fully-stocked kitchen\nCompany-sponsored happy hours and team events\nTuro host matching and vehicle reimbursement program\nTuro travel credit every month\nAbout Turo\n\nTuro is the world's largest peer-to-peer car sharing marketplace where you can book any car you want, wherever you want it, from a vibrant community of trusted hosts across the US, Canada, the UK, and Germany. Guests choose from a totally unique selection of nearby cars, while hosts earn extra money to offset the costs of car ownership. A pioneer of the sharing economy and the travel industry, Turo is a safe, supportive community where the car you book is part of a story, not a fleet. Discover Turo at https://turo.com, the App Store, and Google Play, and check out our blog, Field Notes.\n\nTuro has raised $450M to date from top-tier investors, including IAC, Daimler AG, Kleiner Perkins, GV, Canaan Partners, August Capital, and Shasta Ventures.\n\nTuro cultivates a tight-knit team of smart, critical thinkers who care about their work and their colleagues. Our recruiting team is always on the lookout for supportive, down-to-earth, pioneering, and efficient candidates to grow our team's talent and enrich our culture.\n\nRead more about the Turo culture according to Turo CEO, Andre Haddad.\n\nWe're an equal opportunity employer and value diversity at our company. We don't discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status. When in doubt, please apply!\nStart your job application: click Easy Apply"}, "379": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta has an immediate opportunity for Data Analysts/ Junior Data Scientist to provide support to a major federal client. This organization provides services that analyze and produce enhanced cyber security and threat intelligence information to include threats and potential threats to the customer's personnel, information, and information systems; provides timely and relevant intelligence to assist with mitigating cyber threats confronting the Department; supports evaluation, implementation, and operations of tools/technologies used in advanced data analysis.\n\nThe Data Analyst will support the customer's overall cyber threat analysis efforts. In addition, they will be responsible for applying advanced analytics and data science techniques, including statistical analysis, event correlation, anomaly detection, data visualization and dashboards, and predictive modeling in solving cyber security problems or helping others to automate their research and analysis.\n\nBasic Qualifications:\nBachelor's degree in computer science, information systems, cybersecurity, or other related technical discipline, plus 4 years of experience in technical data analysis with increasing responsibilities.\nAlternatively, a Master's degree with 1 year of experience.\nGood working knowledge of statistical data analysis techniques, including sampling, descriptive statistics, regression.\nExperience with data analysis tools and languages, such as SQL, SPSS, SAS, R, advanced Excel, or similar.\nExperience with data cleaning and preparation.\nExperience with visualization and dashboard techniques and tools, such as Power BI, Tableau, or similar.\nBasic understanding of supervised and unsupervised machine learning algorithms.\nKnowledge of computer networking concepts and protocols (e.g., Transmission Control Protocol [TCP] and Internet Protocol [IP], Open System Interconnection Model [OSI], Domain Name System [DNS]), and network security principles.\nKnowledge of cybersecurity and cyber defense principles (e.g. cyber threats and vulnerabilities, adversarial tactics, cyber attack stages).\nHighly self-motivated and capable of completing ad hoc and time-sensitive assignments.\nStrong analytical skills and the ability to effectively research, write, communicate and brief to varying levels of audiences to include at the executive level.\nDesired Skills:\nTwo years of experience in intelligence or technical analysis with a focus on cyber threat analysis and threat modeling, to include preparing and presenting results.\nExperience analyzing data sets from real-world problems.\nSoftware development experience in Python/Pandas/Scikit-learn, experience with Rapidminer or similar tools.\nExperience in natural language processing.\nExperience in Splunk or similar log storage/retrieval systems.\nPrevious experience working within cross functional and interdisciplinary project teams.\nProven experience effectively prioritizing workload to meet deadlines and work objectives\nSecurity Clearance:\nActive Secret clearance or ability to obtain a Secret clearance\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nTo apply to this job, click Apply Now"}, "380": {"company": "Radius Bank", "description": "Return to Job List\nGENERAL RESPONSIBILITIES:\n\nThe Data Analyst is a key member of Analytics team that provides data and analytical support to Virtual Bank business lines including Direct-to-Consumer, Direct-to-Business, and Partnership. Essential job functions span from analytics infrastructure, system administration, data operations, measurement, testing, data mining, data exploration and visualization, to in-depth analysis and modeling.\n\nESSENTIAL DUTIES:\nComprehend full eco-system of customer data across Bank\u2019s systems, including Account Opening Platforms, MISER, CRM, OLB/Mobile App, Autopilot (email marketing), Marketplace, in conjunction with other external resources (such as marketing channels)\nExercise sound analytical capabilities to interpret data within business context; provide actionable recommendations.\nDeliver essential data needed for marketing operations, programs and other business areas. This includes generating marketing lists and reporting\nWork with business line owners to develop requirements, define success metrics, manage & execute analytical projects, and evaluate results\nManage analytics infrastructure such as Analytics database schemas, campaign tracking systems and data source automation\nConduct regular data mining and exploratory analyses across analytics spectrum to ensure data quality & integrity and to produce data insights\nDevelop dashboards to illustrate data insight 8. Perform AB tests and preliminary data modeling\nREQUIRED KNOWLEDGE SKILLS AND ABILITIES:\n\u2022 Bachelor\u2019s degree from a leading university in computer science, physics, economics, math, statistics, engineering or other quantitative fields\n\u2022 1- 4 years of experience in an analytical capacity or equivalent graduate degree. Direct exposure to customer analytics, ecommerce or digital marketing is preferred. Banking experience is not required\n\u2022 Strong curiosity in data. Understand data\u2019s potential and limits\n\u2022 High proficiency in SQL and knowledgeable in data management and database\n\u2022 Hands-on experience in Tableau\n\u2022 R, Python or other programming languages a plus\n\u2022 Strong project management skills; ability to prioritize and meet deadlines\n\u2022 Self-motivated, enthusiastic and ability to maintain a healthy atmosphere in the team\n\u2022 Excellent written and oral communication skills\n\nCOMPETENCIES:\n\u2022 Embraces and creates change\n\u2022Customer Focus\n\u2022 Integrity/Trust\n\u2022 Results and Quality Focus\n\u2022 Attention to Detail\n\u2022 Quick learner\n\u2022 Ability to multitask\n\nStart your job application: click Easy Apply"}, "381": {"company": "Code42", "description": "WHAT YOU\u2019LL BE DOING:\n\nCode42 is looking for a Senior Software Engineer to join our growing team! We're looking for people with a passion for world-class software development who understand the importance of maintainable code and comprehensive tests, and who will help Code42 protect and secure our customers' data. As an engineer at Code42 you'll be working on challenging problems focusing on data engineering. We're looking for a self-motivated engineer who has a passion for resilient and scalable systems, and experience working within the Amazon Web Services stack. Technologies include API Gateway, Kinesis, Lambda, S3, EMR (Hadoop and Spark), Elasticsearch, etc. You might be a good fit if you enjoy participating in or leading design sessions in front of a whiteboard, implementing a pragmatic solution to a sticky problem, or optimizing an ETL flow. We have a casual and collaborative work atmosphere where everyone\u2019s opinions and ideas are valued.\n\nYOU\u2019LL BE RESPONSIBLE FOR:\nDesigning and implementing code for assigned projects, both independently and with teammates, taking into account needs for monitoring, supportability, and testability.\nWorking with data science and product management to implement data-driven features and productionize machine learning systems.\nDesigning and developing high-volume data pipelines within AWS.\nProviding recommendations and strategies to manage scalability, tuning and other configurations within the data infrastructure.\nIdentifying and making available data to support Code42 products, internal development initiatives and answering product-centric business questions.\nImplementing systems to track data quality and consistency.\nYou will also be contributing to the development of our proprietary analytics product, repository of solutions, and helping engineering teams leverage analytics to aid with better consumption of data.\nWriting unit and integration tests for your team's code.\nTesting, debugging, and troubleshooting all across the Code42 technology stack.\nDocumenting code and design, and reviewing code and design docs from others.\nDemoing progress on team deliverables.\nParticipating in story mapping and sizing sessions for small to medium-size product features.\nSynthesizing requirements into cohesive designs, identifying gaps and contradictions.\nHelping to estimate and prioritize product backlog.\nHelping to mentor and guide more junior staff.\nCollaborating with teammates across the product development organization.\nContributing to process improvement efforts within engineering.\nLeading team design discussions and code reviews, asking questions, contributing and accepting feedback.\nLearning about new things and sharing that with the team.\nSKILLS AND REQUIREMENTS:\nBachelor\u2019s degree and 5+ years professional experience, or can convincingly demonstrate this level of skill.\nAdvanced in the primary languages of the team (typically a combination of Java and/or Scala, Kotlin, JavaScript).\nAdvanced understanding of object-oriented development concepts and practical application.\nExperienced with testing frameworks used by the team (jUnit, Mockito, or similar).\nExperienced with databases and using SQL.\nBackground with AWS data pipeline technologies such as Kinesis, Lambda, S3, Elasticsearch and EMR (Hadoop or Spark).\nExperience with statistical computer languages such as R or Python.\nExperienced with agile/lean development processes.\nPractical experience on public cloud platforms (AWS, Azure or Google Cloud).\nFamiliar with continuous integration and DevOps concepts.\nComfortable taking ownership of deliverables as part of a team.\nComfortable working in a collaborative environment, both offering and asking for help when it's needed.\nClearly able to communicate technical ideas to peers in written and verbal form.\nCan articulate business impact of technical decisions to non-technical staff.\nPREFERRED:\nExperience with SaaS and On-Prem software products.\nExperience with ETL tools and processes.\nBasic understanding of statistical analysis and machine learning.\nComfortable with build tools (gradle, Jenkins, Concourse).\nFamiliar with cloud deployment tools (Terraform, CloudFormation, Serverless).\nExperience developing Java and/or Scala applications.\nActive in the local tech community.\nContributor to open-source software.\nApply Now: click Apply Now"}, "382": {"company": "Oden Technologies", "description": "About Oden:\n\n\nWe are on the brink of the fourth industrial revolution.\n\nManufacturing has long been an analog world, but this is rapidly changing. There is a staggering opportunity for improving the efficiency of current manufacturing processes, and enabling the next generation of manufacturing through the effective gathering, analysis, and productionization of data and insights. Oden is driving this revolution.\n\nWe have combined industrial hardware, wireless connectivity, large-scale data processing architectures, and advanced machine learning algorithms within the Oden platform so all manufacturers can monitor, analyze and optimize their production, across their diverse set of processes. Our goal is to democratize efficiency, sustainability, and competitiveness in the manufacturing domain.\n\nWhy We Do It:\n\n\nWe like to enable those who make things - to make more, to waste less, to serve their customers, and to thrive in a competitive world. Help enough makers, and the world can give us all the abundance we want for less cost and environmental impact. We\u2019re on the verge of a 4th industrial revolution for everyone who makes things.\n\nYou:\nCare about the purpose of the product and company.\nAre never satisfied with the way things are, but excited about the way things could be.\nTinker. You embrace data and different technologies and want to see how they can work together.\nEmpathize with customer needs and enjoy novel ways of posing and solving their problems.\nLive by transparent and scientific thinking. You put in the work to find the best ideas with those around you.\nAre happy to put on steel toe boots and hit the factory floor to work with the production manager.\nThe Role:\n\n\nAs a Data Scientist on the Engineering Team you will be responsible for building statistical and machine learning models that improve the efficiency of manufacturing using telemetry collected from Oden\u2019s factory cloud. This includes real-time metrics that capture various properties of the manufacturing process, context about these metrics provided from external systems and human input, and offline measurements that describe the quality of the resulting products. Problems of interest range from diagnostic to predictive, eventually leading up to closed loop process control.\n\nYou will be working closely with Oden\u2019s data and product engineers to address customer needs. You will push the envelope on how machine learning can provide value to process engineers, operators and materials scientists. This is a crucial role for Oden, and requires someone who will uphold the highest standards of quality, accountability, and attention to detail.\n\nResponsibilities:\nInteracting with customers to understand and pose relevant data analysis problems.\nDeveloping and validating models and methods that address these problems, and working with the engineering team to deploy these as solutions\nGeneralizing solutions and innovating to create the next generation of product features\nEngaging with the technical community to present results externally, keep up to date on recent advances, and advance the state of the art\nMinimum Qualifications:\n\n\n5 years professional experience as a Data Scientist or advanced degrees (M.S. or PhD. in Statistics, Data Science, Computer Science with ML focus, or related fields)\nExperience with Python and SQL\nExperience with designing, building and deploying performant statistical models on large data sets (bonus: experience with time series data, and with real-time data analysis)\nFamiliarity with process improvement and exploratory techniques (e.g. design of experiments and optimization)\nEnthusiasm to own projects end-to-end; from experimentation to customer delivery\nExperience predictive modeling or machine learning on large datasets\nBonus:\n\n\nMaterials Science, Chemistry, or a related physical science expertise\nWhat We Offer You:\n\n\nMeasurable impact to the world and the chance to help real people - family businesses, entrepreneurs, engineers.\nExposure to many tech disciplines, most of which are rapidly evolving.\nA bridge between the physical and cloud worlds of tech. Our platform unites big data visualizations with sensors, M2M tech, and heavy industrial equipment.\nA platform that has the potential to evolve beyond what we have envisioned now.\nScientific and transparent thinking, for everyone involved.\nWe have backing by world leaders of both industry and tech that will ensure long term growth and development for us.\nWe\u2019re an equal opportunity employer (EOE).\n\nDiversity at Oden means building a team that is rich across all boundaries of race, ethnicity, gender identification, sexual orientation, disability, religion, age and thinking style. We welcome all backgrounds, life experiences, and worldviews as this is the catalyst for the rapid evolution of our product and our organization. Diversity allows us to tackle new challenges, embrace change, make well-informed decisions, and ultimately Make Things Better. In alignment with our \u201cPeople First\u201d company value, Oden has a passionate internal team dedicated to the promotion of diversity and inclusion initiatives as a core component of our culture.\n\nOur diversity initiatives apply to our practices and policies on recruiting, compensation and benefits; professional development; promotions; social activities and the ongoing development of a psychologically safe work environment.\nStart your job application: click Easy Apply"}, "383": {"company": "Mars", "description": "JOB CATEGORY:\n\nInformation Services\n\nREQUISITION NUMBER:\n\n251340\n\nData Scientist\n\nA BIT ABOUT OUR DATA SCIENCE & ANALYTICS TEAM\n\nKinship\u2019s Data Science & Analytics team is core to our strategy. We\u2019re using digital, data and customer insights to transform our business by finding answers to problems that we\u2019ve often never asked ourselves before. Our vast data assets are being combined to build a 360\u00b0 view of Pets and Pet Owners to not only power Kinship\u2019s businesses but also influence the next great ideas in the Petcare space. This role will be key in helping us understand the power of our data, and how this translates into value for our company, Pets, and Pet Owners. Frequently the projects will be ambiguous, but that\u2019s part of the fun; you will determine the best way to leverage our data to tell the right story for any given audience.\n\nHOW YOU\u2019LL CREATE A BETTER WORLD FOR PETS\nApply data science approaches to understand and predict pet and pet owner behaviors\nUse machine learning techniques, visualizations, & statistical analysis to gain insight into various data sets \u2013 some readily available, and some you create and curate yourself\nCollaborate with internal and external teams to ensure we focus on pet-centric product and service recommendations\nSupport new pet technology businesses and partners by generating actionable insights from our data assets\nDevelop compelling stories that provide insight into the drivers of business performance and Pet/Pet Owner behavior\nWHO WE NEED TO CHART THE FUTURE OF PET CARE\n\nWe strive to hire people who are passionate about our mission: creating a better world for pets. For all of our Kinship roles, we look for candidates who exemplify our attributes through consistent behaviors. We believe what we do is just as important as how we do it, and we aim to hire people who are:\nOptimistic. Those who\u2019s boundlessly energy and enthusiasm for what\u2019s next shines through in everything they do. We seek to work with people who are intrinsically happy, and who will drive our vision and purpose while managing the complexities of our businesses.\nPurposefully Inquisitive. Those who are courageous and use their deep business insights to cultivate innovation. We want the trailblazers in tech. Those who are entrepreneurs at heart, ask the tough questions, adapt quickly to new situations, and analyze data in new ways to push our big ideas forward.\nOpen to All. Those who are inclusive leaders, committed to learning, and leveraging our differences as strengths. We hire people who are naturally collaborative and thrive in a flat and flexible organization. Those who are thoughtful communicators, and seek to foster meaningful relationships across our community of diverse partners.\n\n\nAnd for this role, we hope you have the following skills we require to round out our team:\n\nExceptional written & verbal communication, coupled with critial thinking skills.\nTruly inspired by, and want to live, our purpose of creating a better world for pets.\n1+ years\u2019 experience in a data science role handling varied and complex data\nProficiency in machine learning modeling and statistical thinking (random forest, decision trees, supervised and unsupervised modeling, etc.)\nHands-on experience with Python is required; Familiarity with PySpark is also desirable\nComfortable with ambiguity, with a passion for collaboration to achieve objectives\nA Bachelor\u2019s degree in quantitative field (economics, statistics, business, computer science) or equivalent experience\n\n\nIf you also had these experiences, you\u2019d knock it out of the dog park:\n\nPassion for growing and strengthening a business using data driven approaches\nFamiliarity with cloud-based computing services e.g. AWS, Databricks, etc.\nEnjoys explaining how models and systems work to both non-technical and technical stakeholders.\nWe want to understand what you're passionate about, the work you've done, and why you'd specifically like to work for Kinship. In order to be considered for this role, you must submit a cover letter and resume to Katelyn@Kinship.co. Candidates without a cover letter will not be considered.\n\nWHY JOIN US?\n\nWe offer our associates a unique opportunity to have a completely customizable career within pet care. Through Kinship you will work with and learn from a community of industry executives, pet partners, entrepreneurs, and fellow associates across our startup investment companies, outside partners, and in Mars Petcare. Our nimble and flexible approach to work allows you to make an immediate impact across businesses, while learning new skills at every stage. The diversity of our work opens doors to big opportunities and unlocks enormous potential for countless career experiences in pet care. Join us in our mission to chart the future of pet care, alongside the industry\u2019s brightest minds.\n\nKinship\u2019s offices are global, and so are our associates. We are located in NYC, San Francisco, Portland, London, Helsinki, Shanghi, and in Moscow. Many of us flex between our dog-friendly hubs and our home offices. Today, Kinship offers exceptional benefits for you, your family, and your pets, generous paid time off, exponential opportunities to build a career within pet care, and progressive reward packages. Interested? Let\u2019s take big strides, together.\n\nData Scientist\n\nJob Segment:\nDatabase, Scientific, Computer Science, Cloud, Statistics, Technology, Engineering, Data\n\nApply now \u00bb\n\nTo apply to this job, click Apply Now"}, "384": {"company": "ADP", "description": "Principal Data Scientist\n\nLocation: 71 Hanover Road, Florham Park, NJ 07932\n\nPosition Summary:\n\nThe SBS Principal Data Scientist will be responsible for the design, planning and execution of major data science and analytics initiatives which span the enterprise and drive measurable business outcomes.\n\nTheir focus will on development, validation and business adoption of statistical and machine learning models to identify trends within structured, semi-structured and time-series data; all heavily leveraging our existing big data infrastructure, making use of leading edge analytical approaches.\n\nThis individual will be a senior member of the SBS Data Insight team, a highly collaborative team, which provides data science and deep analytics expertise to solve the most challenging business problems here at SBS ADP.\nUnlock Your Career Potential: Technology at ADP. Do you enjoy exploring, identifying and inspiring the future of the workplace and the lives of millions of people? At ADP, the world's largest B2B cloud company, our Technology team is comprised of brilliant engineers, architects, data scientists, infrastructure experts, and more. We were first in our industry to offer a SaaS solution and continue to push the envelope utilizing the latest operating platforms to deliver the highly automated, intelligent and predictive solutions that are redefining what is possible. Named one of Forbes' \"Most Innovative Companies\" and one of Computerworld's \"100 Best Places to Work in IT\", we are committed to leading the way in product development and research, empowering you to bring to life the latest innovations that will forever change the way businesses manage their most vital asset, employees.\n\nWe strive for every interaction to be driven by our CORE values: Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility.\nQualifications:\nEducation & Certification: An advanced degree in computer science or equivalent subject, PhD preferred.\nTrack record in designing and delivering useful, consumer-oriented big data and machine learning applications\nTrack record in top-tier publications (e.g., NIPS, ICML, T-PAMI, ACL, ICDM, AAAI, etc.)\nFoundational knowledge about statistics and computational probability.\nStrong foundational knowledge and experience with Machine Learning and Data Mining such as\nKernel machines, ensemble learning, deep learning, regularization theory\nActive and semi-supervised learning\nTransfer learning\nClustering\nFeature selection and dimension reduction\nStatistical analysis and hypothesis tests\nStrong knowledge and experience with NLP such as POS tagging, chunking, named entity recognition, parsing, sentiment analysis, topic detection, etc.\nStrong knowledge and experience with recommendation such as learning to rank, collaborative filter, etc.\nSolid knowledge on numeric computation and scientific optimization including linear programming, convex programming, dynamic programming, etc.\nExperience with OO and functional languages (e.g. Scala, Python, etc.)\nExperience with big data framework (e.g., Hadoop, Spark, etc.)\nExperience with scientific computing packages and machine/deep learning libraries (e.g., scikit-learn, tensorflow, pytorch, deeplearning4j, h2o.ai, spark ML, etc.)\nExperience with data visualizations\nExperience with NLP libraries (e.g., nltk, corenlp, etc.)\nEssential Duties and Responsibilities:\nDefine how analytics solution will be constructed: which existing will be integrated, how they will be integrated and what gaps in capability need to be filled.\nServes as design authority at a project level by understanding the business goals and technology constraints and designing appropriate solutions that create measurable impact to business.\nExtract, merge, clean and normalize large-scale data from disparate sources in preparation for exploratory data analysis, model building and validation -- within a big data environment.\nDevelop, validate ML classification, regression models using Python or similar in order to directly answer business needs, and to positively impact business operations.\nPrepare appropriate data visualizations and presentations to highlight findings and recommendations for both a technical and executive audience.\nPromote a unified approach leveraging existing data sets and efforts while also ensuring collaboration throughout the organization to ensure adoption and common standard approach\nEstablish credibility as a trusted advisor to key stakeholders across the enterprise in order to drive business actions and outcomes based on results of your analysis.\nApply good business and financial acumen to create and assess business cases.\nImplement appropriate mechanisms to track, measure the business impact of your work.\n\n________________\nreq 186040\n#LITECH\n</P>\n\nWe're designing a better way to work, so you can achieve what you're working for. Consistently named one of the 'Most Admired Companies' by FORTUNE\u00ae Magazine, and recognized by DiversityInc\u00ae as one of the 'Top 50 Companies for Diversity,' ADP works with more than 740,000 organizations across the globe to help their people work smarter, embrace new challenges, and unleash their talent. \"Always Designing for People\" means we're creating platforms that will transform how great work gets done, so together we can unlock a world of opportunity.\n\nAt ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.\nStart your job application: click Apply Now"}, "385": {"company": "Entertainment Benefits Group", "description": "Entertainment Benefits Group (EBG) is one of the fastest growing e-commerce companies in the country that specializes in live entertainment and travel. EBG generates millions of transactions annually by merchandising thousands of attractions and activities, live entertainment, hotel rooms, and other products and services through private, membership-based programs and other direct distribution channels.\n\nEBG powers a robust portfolio of technology solutions and operates a network of membership-based websites reaching a captive audience, providing leading brands with incremental distribution opportunities. EBG owns and operates the largest travel and entertainment benefits program in the country\u2014serving over 40,000 corporate clients and reaching more than 50 million employees through its Corporate Perks Programs. We are proud to be the largest sales partner for many of the major theme parks, attractions, entertainment producers, and other travel organizations in the country.\n\nEBG is headquartered in Aventura FL (Miami area), with offices in New York, Las Vegas, Orlando, Connecticut, and Los Angeles.\n\nWe are looking for a savvy Data Engineer to join our growing team of analytics experts. He/She will be in charge to designing, building, integrating data from various sources, and managing big data in the cloud. Run ETL (Extract, Transform and Load) on top of big datasets and create data warehouses that can be used for reporting or analysis by the Analytics team. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.\n\nThey must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing and/or re-designing our company\u2019s data architecture to support our next generation of products and data initiatives.\n\nJob Description:\nAlign data architecture with business requirements\nDevelop, construct, test and maintain optimal data pipeline architecture\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AZURE.\nAssemble large, complex data sets that meet functional / non-functional business requirements.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nPrepare data for predictive and prescriptive modeling.\nUse data to discover tasks that can be automated\nDeliver updates to stakeholders\nWork with stakeholders including the marketing and email teams to assist with data-related technical issues and support their data infrastructure needs.\nWork with data and analytics experts to strive for greater functionality in our data systems.\nSkills:\nAdvanced working SQL knowledge and experience working with relational databases, as well as working familiarity with a variety of databases.\nExperience building (or redesigning) and optimizing \u2018big data\u2019 data pipelines, architectures and data sets.\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management.\nProven success supporting and working with cross-functional teams in a dynamic environment.\nWe are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:\nExperience with big data tools: Hadoop, Spark, Kafka, etc.\nAdvanced proficiency with relational MS SQL databases\nAdvanced proficiency with Azure cloud services\nExperience with stream-processing systems: Storm, Spark-Streaming, etc.\nExperience with object-oriented/object function scripting languages: Python,R, Java, C++, Scala, etc.\nExperience supporting e-commerce and/or travel and entertainment business a plus\nOther Information\n\nThe statements contained herein reflect general details as necessary to describe the principal functions of this job, the level of knowledge and skill typically required, and the scope of responsibility but should not be considered an all-inclusive listing of work requirements.\n\nStart your job application: click Easy Apply"}, "386": {"company": "MeridianLink", "description": "Job Overview\n\nWe are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. The right candidate will be excited by the prospect of optimizing or even re-designing our company\u2019s data architecture to support our next generation of products and data initiatives.\n\nResponsibilities for Data Engineer\n\n\u00b7Create and maintain optimal data pipeline architecture,\n\n\u00b7Assemble large, complex data sets that meet functional / non-functional business requirements.\n\n\u00b7Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n\n\u00b7Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Microsoft, Open Source, and Google technologies.\n\n\u00b7Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\n\n\u00b7Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\n\n\u00b7Work with data and analytics experts to strive for greater functionality in our data systems.\n\nQualifications for Data Engineer\n\n\u00b7Working Knowledge or familiarity with the following: GO, Docker, Kubernetes, Big Query, Azure, SQL, Python, ETL, as well as working familiarity with a variety of databases.\n\n\u00b7Experience building and optimizing \u2018big data\u2019 data pipelines, architectures and data sets.\n\n\u00b7Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\n\n\u00b7Strong analytic skills related to working with unstructured datasets.\n\n\u00b7Build processes supporting data transformation, data structures, metadata, dependency and workload management.\n\n\u00b7A successful history of manipulating, processing and extracting value from large disconnected datasets.\n\n\u00b7Working knowledge of message queuing, stream processing, and highly scalable \u2018big data\u2019 data stores.\n\n\u00b7The ideal candidate will have 3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience/familiarity using/withthe following software/tools:\n\n\u00b7Experience with big data tools: Hadoop, Spark, Kafka, etc.\n\n\u00b7Experience with relational SQL and NoSQL databases.\n\n\u00b7Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\n\n\u00b7Experience with Google Cloud (Big Query), Azure, etc.\n\n\u00b7Experience with stream-processing systems: Storm, Spark-Streaming, etc.\n\n\u00b7Experience with object-oriented/object function scripting languages: GO, Python, Java, C++, Scala, etc.\nApply Now: click Easy Apply"}, "387": {"company": "Agios Pharmaceuticals", "description": "Associate Scientist/Scientist, Metabolism\nLocation\n\n\nAgios Pharmaceuticals HQ\n\nJob Code\n\n1097\n\n# of openings\n\n1\n\nApply Now\n\nAssociate Scientist/Scientist, Metabolism\n\nAgios (agios.com) is a biopharmaceutical company committed to applying our scientific leadership in cellular metabolism to transform the lives of patients with cancer and rare genetic diseases. We are growing rapidly with an active research and discovery pipeline across both therapeutic areas. Agios has two approved oncology precision medicine and multiple first-in-class investigational therapies in clinical and/or preclinical development.\n\nAgios Pharmaceuticals is searching for a dynamic Associate Scientist/Scientist to join our growing Metabolism and Proteomics team. You will be responsible for the design and execution of metabolomics and targeted LCMS experiments to support drug discovery efforts in cancer metabolism, immuno-oncology, and rare genetic disorders. You will have the ability to work cross-functionally as a contribution member to our pre-clinical project teams.\n\nThe Cell Metabolism department focuses on quantitatively understanding cellular metabolism, relying on state-of-the-art mass spectrometry methods for proteomics, lipidomics, metabolomics and isotopic labeling studies. Our work includes characterization of tumor and immune metabolism as well understanding the metabolic effects of rare genetic disorders. The successful candidate will leverage their understanding of metabolism to support drug discovery across the portfolio.\n\nKey Responsibilities\nDesign and execute metabolomic assays to assess perturbations in cellular metabolism in a variety of disease settings, including cancer metabolism, immunology, and rare genetic diseases.\nImprove and troubleshoot established LCMS metabolomics methods, from sample processing to data analysis.\nDesign and validate new LCMS methods supporting metabolomics analysis\nAnalyze data using commercial, open-source, and proprietary computational techniques for understanding target pathways, discovering biomarkers, and analyzing metabolic flux data.\nCollaborate with internal groups, such as Cell Biology, Bioinformatics, Biochemistry, Pharmacology and Clinical, as well as external groups from academia and CROs.\nCommunicate data to project reps, scientific teams, senior management, and the external community through scientific journals and conferences. Have responsibility for sharing results with program teams and publishing.\nMinimum Requirements\nPhD/Postdoc with relevant metabolomics experience in disease metabolism, DMPK, bioanalysis, natural products, or biomarker research\nProven track record of using mass spectrometry to solve complex biological problems in a discovery research environment, including publications that demonstrate analytics supporting biology or clinical research\nExperience with liquid chromatography and mass spectrometry methods for small molecule analysis\nBasic understanding of cellular metabolism in relation to disease progression\nSelf-motivated and able to work independently or in a small team with minimal supervision.\nExcellent communication and organizational skills.\nExcellent problem-solving skills and ability to multi-task.\nPreferred Qualifications\nGCMS experience a plus\nMammalian cell culture experience a plus\nVariety of analytical chemistry experience applied to the analysis of biomolecules\nCompetencies:\nKnow & Show your Stuff: Possesses technical or professional expertise and is able to apply it at Agios to create value/impact.\nCollaborates: Work in and with teams to achieve outcomes that individuals would not have been able to achieve alone.\nDemonstrates critical and creative thinking to solve problems\nTalks straight: Open and authentic in conversations; cultivates trust in interactions.\nExecutes and Operates to a High Standard in delivering results to project teams.\nImproves Continuously: Takes an approach to continuous improvement; anticipates and addresses capability gaps to prepare for future challenges.\nBuilds networks internally to establish an effective collaborative environment\n\nApply Now: click Apply Now"}, "388": {"company": "Whitney, Bradley and Brown", "description": "JOB TITLE: Data Analyst/Visualization Specialist\n\nPROJECT OVERVIEW:\n\nLeverage analytical experience to execute project tasks for Marine Corps client. Apply expertise in quantitative and qualitative analysis, process improvement, data extraction, and visualization. Enable improved decision-making concerning Marine Corps manpower issues and challenges by creating impactful visualizations and dashboards.\n\nJOB DESCRIPTION AND RESPONSIBILITIES:\nProvide information management, presentation preparation, report generation, and methodology development in support of briefings for senior level leadership.\nCollect, complete, organize and interpret operational, technical data.\nCommunicate complex quantitative analysis in a clear, precise, and actionable manner.\nDiscover and develop quantitative and qualitative data to define, analyze, and execute data driven decisions.\nDesign and document visualization dashboards.\nManage multiple projects and stakeholder interests with timeliness, accuracy, and quality.\nREQUIRED SKILLS AND QUALIFICATIONS:\n\nSecurity Clearance: Secret\nActive Secret Security Clearance\nBachelors degree in math, statistics, operations research, or a related technical discipline\nMust have clear and indepth understanding of Marine Corps organizational structure\nExperience using business intelligence tools i.e. Tableau, power BI, Qlik to help decision-makers visualize actionable data\nExperience with data analytic methodologies\nKnowledge of Extraction Transformation and Loading (ETL) processes and activities\nExperience with statistical software packages (e.g., SAS, SPSS, R, RStudio, others.)\nUnderstanding of Structured Query Language (SQL)\nExperience in developing and maintaining databases, document types and structure of open source data\nExperience mining and extracting data on patterns and correlations from large datasets\nApply statistical and mathematical analysis to identify trends, conflicts, opportunities, solve complex analytic problems, and optimize data interoperability\nA working knowledge of the Microsoft Office Suite.\nDESIRED SKILLS AND QUALIFICATIONS:\nAbility to operate in a dynamic environment\nKeen problem-solving skills; and strong interpersonal skills to work internally with different stakeholders\nWORK LOCATION: Quantico, VA\n\nTRAVEL: 5%\n\nKEY WORDS:Data Scientist, Tableau, R, SAS, Programming, Data Analyst, Decision Analytics\n\nWBB is a technical and management consulting company that provides innovative products and services that solve government and commercial customers toughest problems. For more than 30 years, WBB has set the standard for excellence in consulting services, while providing its employees with an outstanding work environment with ample opportunities for growth and success. WBB continues to enjoy impressive growth, which is directly attributed to the companys hiring practice of always hiring the very best professionals from government, military and industry.\n\nWe are proud of our diverse environment and are an Equal Opportunity Employer. WBB is committed to a policy of equal employment opportunity. WBB participates in E-Verify.\n\nWBB does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of WBB and WBB will not be obligated to pay a placement fee.\nStart your job application: click Easy Apply"}, "389": {"company": "InfoTrust", "description": "Lead Analytics Consultant\n\n\n\nJob description\n\n\u201cI didn\u2019t know analytics could do that\u201d\n\n\u201cWow, you have a great grasp on our goals\u201d\n\n\u201cThe strong analytics implementation you did really set us up for success\u201d\n\n\u201cI received a promotion after using your digital analytics architecture\u201d\n\nAre these things you have heard from your clients? Are you an experienced analytics professional who seeks to drive impact and grow your successful career even further? If so, then this role might be a great fit for you!\n\nInfoTrust is seeking an experienced Lead Digital Analytics Consultant to join our team. We are looking for someone that has worked in advanced implementation and measurement projects with Google Analytics and/or Adobe Analytics, and feels confident they can help drive value to large enterprise clients due to their expert level knowledge, technical prowess, and client relationship skills.\n\nOur company was started with one principle \u2013 we are going to provide the best workplace for the best people and as long as we keep our eyes on this #1 goal, all other things will fall into place. This strategy has been extremely successful and we are thrilled to be #1 Employer in Ohio, #1 for Cincinnati, and ranked on national lists such as Ad Age's Best Places to Work and Inc 5000 Fast Growing Companies (4 years strong).\n\nThe Lead Digital Analytics Consultant role will be responsible for client management, advanced implementations of Google Analytics and/or Adobe Analytics, auditing and troubleshooting existing configurations, reporting, dashboards and education to improve clients\u2019 digital marketing initiatives. Lead Digital Analytics Consultants have worked with measurement end to end, from KPI planning and measurement design, to implementation/testing/validation, to reporting and driving insights\n\nThings you will be doing as the Lead Analytics Consultant:\nIdentify client objectives, develop KPI framework and map suitable analytics solutions to ensure that all required performance data can be reliably tracked and reported\nProduce analytics audit reports for corrective or advanced tracking and data collection architectures\nTroubleshooting, testing and validating analytics implementations and tracking through various testing tools. Deliver testing results and work with client engineering teams to fix or enhance data collection practices\nDeliver reports and findings to clients in-person or via conference calls\nEducate clients on the importance of online measurement & provide best practice guidance for technical aspects of analytics.\nProvide instruction on campaign tagging and additional on-site tracking\nProvide guidance to data analysts to produce marketing dashboards via Google Docs, Excel and various APIs (e.g. Google Analytics)\nTrain clients on Suite 360 products such as Google Analytics, Google Tag Manager and Google Data Studio\nAssist the product team with Tag Governance and other technical products\nWork with some of the largest brands in the CPG, Retail, and News & Media Industries.\nJoin InfoTrust and find out why it is so exciting to join a fast-growing technology company.\n\n\nRequirements\n\nThe successful Lead Digital Analytics Consultant will have the following background & skills:\nYou have experience (4+ years preferred) utilizing and implementing Google Analytics AND/OR Adobe Analytics -- We can only consider you if have experience with at least one of these platforms\nTech Savvy: you pick up new technology quickly and have experience with web technologies such as, but not limited to javascript, tag management, tag governance, web design etc\nYou are a great communicator, with the ability to talk with clients and other partners\nReal passion for helping clients solve complex business and marketing questions\nYou can work independently and prioritize multiple projects\nProject Management experience - you know what it is like creating raving fans\nYou are a self-starter that seeks knowledge and expertise in digital analytics\nOther than an awesome culture, and free lunch, we also offer: Free Health, Dental and Vision Insurance (seriously), Unlimited PTO, Flexible Work Schedule, a generous Parental Leave policy, 401K with match, Tuition Reimbursement, Gym reimbursement and much, much more.\n\nInfoTrust is committed to a diverse workforce and we are an equal opportunity employer. We evaluate applicants regardless of an individual\u2019s age, race, color, gender, religion, national origin, sexual orientation, disability, or veteran status.\n\n** We are open to both full-time and part-time people for this role. As well, for the the experienced person will consider a remote role. If you have any questions about this, or the benefits of being PT, contact the Talent Acquisition Manger - Lisa Wilms. **\n\nStart your job application: click Easy Apply"}, "390": {"company": "Robin Powered", "description": "At some point you\u2019ve probably attended or scheduled a meeting -- maybe it was in a room, on video or over the phone -- then your meeting room gets stolen, you don't have the right resources, or you can't find where you need to be. Finding space and time to communicate can be painful. The problem is easy to understand but difficult to solve. That's where Robin comes in. We build software that coordinates meeting spaces, people and things in your workplace so you can get back to doing your best work.\n\nBased in Boston, the DNA of our eclectic team shapes our culture in a way that means we can show up to work as our whole selves. Our values guide the way we treat our customers, our coworkers, and our candidates. We are intentional with our words and actions. We\u2019re helpful. And at the end of the day, we're all united by the mission of modernizing the open office so that businesses (like HubSpot, Twitter, Bumble and Kayak) are more enjoyable places to walk into each day, including our own.\n\nWe are looking for a Data Analyst to partner with engineering and product to support the development of customer-facing workplace analytics. If you consider yourself smart, have a drive for results, proven track record and are not shy to challenge the status quo -- we want you!\nWork you\u2019ll be responsible for:\nQuery databases (Postgres/MySQL) to gather large amounts of complex calendar data. Identify trends, patterns, gaps and insights using descriptive analytics and data visualizations to further business insights.\nLeverage best in class analytical programming tools, such as Jupyter notebooks, and create well documented and repeatable analytical processes.\nPerform complex ad-hoc analyses in Excel to solve important business problems and formulate robust, actionable recommendations for leadership that support the product team in creating a data-driven company.\nContribute to the development of data strategy tools such as a data dictionary and assist with the creation of team onboarding materials.\n\nYou are:\nAnalytical. You\u2019re passionate about using and understanding data to problem-solve.\nCollaborative. You enjoy partnering with various teams to drive analytics on business trends through multiple systems. You are able clearly distill the essence of your technical work to audiences of all levels and across multiple functional areas.\nAdaptable. You are able to work on multiple projects, meet deadlines and love a fast-paced environment.\nCuriosity: You\u2019re driven to learn the latest and greatest of an industry. You enjoy problem-solving and know-how to ask strategic questions rather than just talking about implementation details.\nArticulate. You are able to communicate and simplify complex data into sensible business solutions. Experience articulating product questions and using statistics to arrive at an answer.\nExperience you already have:\n2-4 years of experience on a data or analytics team\nKnowledge and experience applying statistical techniques to real business data\nA Bachelors degree in a quantitative field such as Statistics, Computer Science, Engineering, Mathematics, Data Sciences or equivalent experience\n2 or more years of experience working with Microsoft Excel\n2 or more years of experience working with Python (preferable) / R\nCompetency with relational databases, writing SQL scripts and working with large sets of data\nFamiliar with Git\nPlus if you are interested in learning Go or Java\nWe\u2019re creating the smart office of the future. We\u2019d love to have you be a part of it.\n\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We are ADA compliant and handicap accessible.\nTo apply to this job, click Apply Now"}, "391": {"company": "SpringML", "description": "About SpringML\n\nAt SpringML, we are all about empowering the doers in companies to make smarter decisions with their data. Our predictive analytics products and solutions apply machine learning to todays most pressing business problems so customers get insights they can trust to drive business growth.\n\nWe are a tight knit, friendly team of passionate and driven people who are dedicated to learning, get excited to solve tough problems and like seeing results, fast. Our core values include putting our customers first, empathy and transparency, and innovation. We are a team with a focus on individual responsibility, rapid personal growth and execution. If you share similar traits, we want you on our team.\n\nWhats the opportunity?\n\nSpringML is looking to hire a topnotch Data Engineer who is passionate about working with data and using latest distributed framework to process large dataset.\n\nAs a Data Engineer, your primary role will be to design and build data pipelines. You will be focused on helping client projects on data integration, data prep and implementing machine learning on datasets. In this role, you will work on some of the latest technologies, collaborate with partners on early win, consultative approach with clients, interact daily with executive leadership, and help build a great company.\n\nChosen team member will be part of the core team and play a critical role in scaling up our emerging practice.\n\nResponsibilities\nAbility to work as a member of a team assigned to design and implement data integration solutions.\nBuild Data pipelines using standard frameworks in Hadoop, Apache Beam and other open source solutions.\nLearn quickly ability to understand and rapidly comprehend new areas functional and technical and apply detailed and critical thinking to customer solutions.\nPropose design solutions and recommend best practices for large scale data analysis\nDesired Skills and Experience\nB.S. or equivalent degree in computer science, mathematics or other relevant fields.\n5-10 years of experience in ETL, Datawarehouse, Visualization and building data pipelines.\nStrong Programming skills experience and expertise in one of the following: Java, Python, Scala, C.\nProficient in big data/distributed computing frameworks such as Apache Spark, Kafka,\nExperience with Agile implementation methodologies.\nApply Now: click Easy Apply"}, "392": {"company": "Brighthouse Financial", "description": "Brighthouse Financial is on a mission to help people achieve financial security. As one of the largest providers of annuities and life insurance in the U.S., we specialize in products designed to help people protect what they\u2019ve earned and ensure it lasts. We are built on a foundation of experience and knowledge, which allows us to keep our promises and provide the value they deserve.\n\nAt Brighthouse Financial, we\u2019re fostering a culture where diverse backgrounds and experiences are celebrated, and different ideas are heard and respected. We believe that by creating an inclusive workplace, we\u2019re better able to attract and retain our talent, provide valuable solutions that meet the needs of our advisors and their clients, and deliver on our mission of helping more people achieve financial security. We\u2019re seeking passionate, high-performing team member to join us. Sound like you? Read on.\n\nHow This Role Contributes to Brighthouse Financial:\n\nData Scientists in Brighthouse Financial\u2019s Data Science organization work closely with cross-\u00adfunctional teams in marketing, distribution, actuarial, product and other functions, leveraging Brighthouse Financial\u2019s rich datasets to develop and deliver propensity models and data-\u00addriven insights, and ultimately drive Brighthouse Financial\u2019s top line growth. A successful candidate will be passionate about finding insights in data and using quantitative analysis to answer complex questions, with a collaborative and resourceful style.\n\nKey Responsibilities:\nConduct data analytics with the relevant programming / statistical package (such as R or Python) for large-scale problem solving\nWork independently and possesses exceptional technical ability.\nUnderstand complex business challenges, develop hypotheses, convert into the right analytical hypothesis, and communicate the results back to the partner teams with limited or no analytical background to drive the business strategy\nAnalyze internal / external, online / offline, and structured / unstructured data such as speech analytics, digital footprints, financial information, proprietary market research and secondary sources to identify insights\nCreate innovative solutions to business problems.\nPartner with other operational areas to identify opportunities for new projects.\nBuild strong working relationships and improve workflow and organizational issues.\nBuild complex advanced-level machine learning and advanced analytics models.\nHandle and resolve questions and issues referred by junior staff members.\nMay propose, evaluate and implement process improvements to increase efficiency and effectiveness.\nPerform other duties as required or assigned.\nEssential Business Experience and Technical Skills:\nDoctoral degree in a technical field and two plus years of related work experience, or a Master\u2019s degree in a technical field and at least 3-4 years of related work experience, or a Bachelor\u2019s degree in a technical field and at least 6-8 years of related work experience.\nSignificant professional experience required applying quantitative analysis and modeling to solving real-world business problems including experience in model validation, testing and deployment\nDemonstrated proficiency in Python/PySpark required\nDemonstrated ability to perform high quality work independently\nExcellent oral and written communication skills, including the ability to explain complicated quantitative concepts to non-\u00adtechnical stakeholders using effective story telling techniques and visualization\nAbility to translate business requirements into detailed analysis plans.\nAbility to prioritize requests to meet the most important and urgent business needs\nWorking knowledge of insurance industry is a plus\nPrior exposure to financial services or insurance industry preferred\nTravel:\n\nLess than 5%\nStart your job application: click Apply Now"}, "393": {"company": "Riverside Research Institute", "description": "Returning Candidate? Log back in to the Career Portal and click on 'Job Browsing/History' and find the job you're looking for.\n\n2019-126-INT: Machine Learning Engineer\n\nDirectorate Intelligence & Defense Solutions\nLocation Wright-Patterson AFB, OH\nRiverside Research\u2019s Intelligence and Defense Solutions Directorate is seeking a full-time Machine Learning Engineer to support a cross-functional team of artificial intelligence/machine learning (AI/ML) practitioner\u2019s prototyping and implementing solutions for enduring customer challenges at the National Air and Space Intelligence Center (NASIC) Wright-Patterson AFB, Ohio.\n\nAll Riverside Research opportunities require U.S. citizenship.\n\nJob Responsibilities:\n\u2022 Assess customer systems and processes for application of machine learning / artificial intelligence technologies to support their needs\n\u2022 Create and prototype machine learning approaches to demonstrate efficacy\n\u2022 Coordinate with external agencies and research partners on emerging methods and technologies for the application of AI/ML\n\u2022 Communicate advanced AI/ML concepts to senior leadership to facilitate decision making\n\u2022 Perform basic and applied research in applying ML solutions to complex problems and datasets; document and present research results and the status of ongoing or emerging projects\n\u2022 Participate in a multi-disciplinary, experienced, energetic team on a rapid development schedule\n\u2022 Other duties as assigned\n\nQualifications:\n\u2022 Bachelor\u2019s degree in computer science, engineering, or related technical field with specialization in artificial intelligence and/or machine learning with 5 years relevant experience\n\u2022 Top Secret clearance\n\u2022 High degree of proficiency with programming languages and software packages related to the development of artificial intelligence and machine learning algorithms\n\u2022 Strong communication skills (written and verbal)\n\u2022 Self-motivated, independent, detail oriented, responsible team player\n\nDesired Qualifications:\n\u2022 Doctorate or Master\u2019s degree in computer science, engineering, or related technical field with specialization in artificial intelligence/machine learning or other technical related field\n\u2022 Experience working with or in support of Department of Defense (DoD) or intelligence community (IC) organizations\n\u2022 Software development experience with AI/ML applications to include design, develops, test, and deploy.\n\u2022 Experience with one or more of the following: GPU/parallel processing (i.e. CUDA), classification, pattern recognition, anomaly detection, pose estimation, or similar.\nRiverside Research strives to be one of America\u2019s premier providers of independent, trusted technical and scientific expertise. As we continue to add experienced, technically astute staff, we are looking for highly motivated, talented team members that can help our DoD and Intelligence Community (IC) customers continue delivery of world class programs. As a not-for-profit, technology-oriented Defense Company, we believe service to customers and support of our staff is our mission. Our goal is to serve as a destination company by providing an industry-leading, positive, and rewarding employee experience for all who join us. We aspire to be a valued partner to our customers and to earn their trust through our unwavering commitment to achieve timely, innovative, cost-effective and mission-focused solutions.\n\nAll positions at Riverside Research are subject to background investigations. Employment is contingent upon successful completion of a background investigation including criminal history and identity check.\n\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability, and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.\n\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans, and requires affirmative action by covered contractors and subcontractors to employ and advance in employment qualified protected veterans.\n\nApply Now\nApply Now: click Apply Now"}, "394": {"company": "DeepMind", "description": "DeepMind is active within the wider research community through publications and partners with many of the world's top academics and academic institutions. We have built a hardworking and engaging culture, combining the best of academia with product led environments, providing an ambitious balance of structure and flexibility.\n\nOur approach encourages collaboration across all groups within the Research team, leading to ambitious creativity and the scope for innovative breakthroughs at the forefront of research.\n\nThe DeepMind for Google (DMG) Research team focuses on using the best available technologies to address some of the most pressing and complex challenges. Collaborating with Google teams, we apply our groundbreaking research to products used by millions of people around the world. These real world applications of AI technology help us work towards one of DeepMind's purposes - to use intelligence to make the world a better place.\n\nOur ambitious team works in close collaboration with Google product teams to deploy machine learning algorithms to help improve Google products and services. Right now, for example, we are working on collaborations with Google's Data Centre Operations team, Google Play, Google Ads Quality, and Google Text to Speech, among others. DMG is made up of Research Scientists and Software Engineers, all of whom work very collaboratively together.\n\nOur Research Scientists connect fundamental research and applications by integrating research into applied projects and working on research inspired by applications. To this end, we are looking to hire top quality Research Scientists that are passionate about contributing to both the applied and academic sides of research.\n\nVisit https://deepmind.com/applied/deepmind-google/ to see more details on the projects we're currently working on.\n\nThe role:\nPerform research to make machine learning more applicable to impactful issues in the real world.\nProvide research input on Google products: determine scope of the problem, the best place to apply machine learning, and evaluate different approaches.\nBridge the gap between the research and products by integrating new fundamental research into applied projects and identifying interesting real world problems to research.\nCollaborate with Software Engineers to design and run experiments, including designing and evaluating new algorithms as well as implementing known algorithms.\nReport and present experimental results and research findings clearly and efficiently, both internally and externally.\nBe active members of the applied research community, by validating and contributing to advances in ML.\nMinimum qualifications:\nPh.D. in computer science or a related discipline.\nPublication track record in machine learning conferences and/or journals.\nSolid software engineering skills for prototyping.\nExperience with implementing numerical methods and data visualization.\nGood knowledge of algorithm design.\nPreferred qualifications:\nExperience in applying ML to real world problems.\nStrong expertise in reinforcement learning and/or deep learning.\nCompetent in one or more of the Google supported languages (C++, Java, Python) with a desire to learn more.\nA real passion for AI\nThe work you will do will significantly move the needle within a Product Area that has high strategic importance to Google - which could be one of our existing collaborations or one of the new ones we will start up.\n\nThe role will suit those who enjoy metrics-driven work, building momentum through successive experiments and launches anywhere from Ads to Search to Android, and who wish to immerse themselves in some of the most ground breaking ML and AI research.\n\nDeepMind welcomes applications from all sections of society. We are committed to equal employment opportunity regardless of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity or any other basis as protected by applicable law. If you have a disability or additional need that requires accommodation, please do not hesitate to let us know.\nTo apply to this job, click Easy Apply"}, "395": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking a Data Scientist (Senior)) in the role of the Maritime Safety Office.This position is to provide both digital and hardcopy maritime products, services, and data to support worldwide Safety of Navigation. Without accurate and up-to-date nautical products, military platforms are at increased risk when they conduct operations, transport personnel and deliver material. The U.S. Navy has made it clear to NGA that it will continue to require both digital and hard copy maritime products for the foreseeable future. Services procured under this contract will primarily support the production and maintenance of Maritime GEOINT at NCE facilities.\n\nResponsibilities include:\nStrong data management skills, including SQL, NoSQL (MongoDB), and triplestore/graph\ndatabases\nExperience createing and managing ETL processes using Ni-Fi or similar software using both\nstructured and unstructured data\nAWS experience, particularly with EC2, S3, Cloudwatch, RDS\nExperience with data visualization tools\nExperience with or working knowledge of ElasticSearch or similar\nPerform ad-hoc analysis and present results in a clear manner\nConduct undirected research and frame open-ended industry / customer questions\nRecommend cost-effective changes to existing procedures and strategies\nCreate / maintain tools to extract features from a variety of sources including raster to vector,\nvector to vector, text to vector, and text to database.\nWrite / maintain Python Scripts in ARCGIS to improve efficiency of the production process.\nSupport Business Processing Re-Engineering\nPerform Data Conversion/migration\nPerform Business Analytics\nWork with the Government on new production capabilities / services\nStrong data management skills, including SQL, NoSQL (MongoDB), and RDF\n(triplestore/graph) databases\nLinux experience\nBasic Qualifications:\nStrong data management skills, including SQL, NoSQL (MongoDB), and triplestore/graph databases\nExperience createing and managing ETL processes using Ni-Fi or similar software using both structured and\nunstructured data\nAWS experience, particularly with EC2, S3, Cloudwatch, RDS\nExperience with data visualization tools\nExperience with or working knowledge of ElasticSearch or similar\nPerform ad-hoc analysis and present results in a clear manner\nDesired Skills:\nExperience with combining digital cartography, computer technology, GIS, cartographic and geospatial\nproduction techniques, remote sensing, photogrammetry, and digital data formats.\nAbility to clean / prune data to discard irrelevant information\nAbility to examine data from a variety of angles to determine hidden value, weaknesses, trends, and / or\nopportunities\nAdvanced knowledge of ESRI ArcGIS and ArcServer.\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nStart your job application: click Apply Now"}, "396": {"company": "Tradeweb Markets LLC", "description": "Working as a data scientist, you will be part of the Data Solutions and Analytics team within Market Data at Tradeweb. With live and extensive historical data across the Institutional, Wholesale, and Retail fixed income markets globally, you will have the unique opportunity to produce models to advance the fixed income marketplace. Working in partnership with platform business heads, product managers, and the market data team, you will develop models that will improve executions and generate ideas for our clients. Your models will produce live data both within our trading platforms as well as generate independent commercial data products. You are comfortable working in a results-driven environment and want to be part of an innovative team that is forging new ground and redefining the world of investment and trading in fixed income securities.\n\nJob Responsibilities:\nCreate predictive models using current and emerging methodologies in data science. Candidates will possess a deep understanding of statistics, machine learning, causal predictive modeling, and ideally optimization.\nCollaborate across the organization to drive projects from beginning to end: frame business questions, collect and analyze data, research, prototype, build pipelines, and share insights.\nWork with technology to ensure robust translation to production environments and create solutions that operate effectively live and at scale.\nQualifications\n7+ years of experience in applying statistical and machine learning techniques such as regression and classification models, cluster analysis, neural networks, ensembles, random forests.\nAdvanced degree (MS or PhD) in a quantitative field such as Statistics, Computer Science, Mathematics, Physics, Engineering, Economics, or similar.\nExpert programming skills for data analysis and machine learning. Experience using version control and general software development best practices for contributing to a collaborative code base.\nStrong communication and collaboration skills. Ability to communicate technical modeling concepts and relevant aspects of modeling platforms to non-technical audiences.\nWillingness to learn fixed income and improve across all technical skill areas.\nAbility to work in a start-up environment that is fast paced and maintain a focus on rapid prototyping of capabilities.\nDemonstrated leadership and self-direction.\nEnjoys teaching and collaborating with others.\nExperience using the python data science stack a plus, e.g. Pandas, Jupyter notebooks, scikit-learn, Tensorflow, Anaconda etc.\nAbout Tradeweb:\n\nTradeweb Markets Inc. (NASDAQ: TW) is a leading, global operator of electronic marketplaces for rates, credit, equities and money markets. Founded in 1996, Tradeweb provides access to markets, data and analytics, electronic trading, straight-through-processing and reporting for clients in the institutional, wholesale and retail markets. Advanced technologies developed by Tradeweb enhance price discovery, order execution and trade workflows while allowing for greater scale and helping to reduce risks in client trading operations. For more information, please go to www.tradeweb.com .\n\nTradeweb Markets LLC (\"Tradeweb\") is proud to be an EEO Minorities/Females/Protected Veterans/Disabled/Affirmative Action Employer.\n\nhttps://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf\nStart your job application: click Apply Now"}, "397": {"company": "Atara Biotherapeutics, Inc.", "description": "The Principal/Senior Scientist-CAR-T Platform Development Lead is an integral member of the Preclinical Sciences Laboratory Group and brings extensive engineered T cell product development expertise. This principal role oversees the allogeneic, off-the-shelf CAR-T development laboratory team tasked with developing new product candidates for our expanding pipeline. The candidate must have an established record of leadership in an academic or industry setting with extensive laboratory-based CAR-T cell expertise.\nReports to Sr. Director of Preclinical & Translational Science\nLocation Thousand Oaks (northwest Los Angeles area), CA\n\nPosition Responsibilities\nApplies expert knowledge in the field of CAR-T Therapy to lead laboratory team designing and generating new CAR-T product candidates using Atara Bio\u2019s novel allogeneic engineered T cell therapeutics platform.\nCoordinates multiple programs to validate targets, optimize CAR construct design and CAR-T cell generation, and explore therapeutic potential of resulting CAR-T lead candidates.\nMentors a group of diverse scientists and research associates to facilitate new CAR-T programs and oversee IND-enabling in vitro. Independently designs and executes studies to facilitate preclinical proof-of-concept activity for efficacy and safety.\nCoordinates reports, summaries, and presentations supporting experimental results.\nOversees continued growth and recruitment activities to expand CAR-T laboratory research group.\nDevelops and leads strong collaborative relationships with internal and external groups.\nManages activity of direct reports and preclinical development project teams.\nRole model for Atara\u2019s Values of patients first, innovation teamwork, community and mindset.\n\n\nTravel Travel may be required (up to 10%).\n\nPhysical Requirements:\nSubject to extended periods of sitting and/or standing, vision to monitor and moderate noise levels. Work is generally performed in an office, laboratory, or manufacturing environment. Car and airplane (see above) travel is an essential part of the job\n\nPosition Requirements\nPh.D. with at least 8 years of experience in a Cellular/Molecular Immunology and immuno-oncology field, with industry experience required.\nExpertise and broad functional, laboratory-based CAR-T and/or T cell engineering expertise.\nMust possess extensive working knowledge of CAR-T design, T-cell biology, immunotherapies, retroviral, and gene-editing technologies, including CRISPR/CAS9 system.\nExpertise with current landscape of engineered T cell platforms and approaches to modulate the tumor/immune microenvironment.\nRecord of productivity and innovation in the engineered T cell space as evidenced by publications and/or patents.\nProficient with flow cytometry-based applications.\nAbility to Independently propose, design, execute, and report research projects.\nExperience leading a small group of scientists capable of handling tight timelines and delivery of quality data.\nEvidence of independent thinking and leadership skills are vital.\n\nWe launched Atara Biotherapeutics in August 2012 to help patients with serious diseases and few therapeutic options. We\u2019re named after Atara Ciechanover who suffered from cancer before passing away. We are considered a leading off-the-shelf T-cell immunotherapy company (Nasdaq ATRA) developing novel treatments for patients with cancer, autoimmune and viral diseases.\nWe\u2019re proud of our team of 350+ Atarians co-located by design in South San Francisco (corporate headquarters) and Southern California (R&D and manufacturing headquarters in the northwest Los Angeles area) with a newly-established European headquarters in Zug, Switzerland. Atara also has a R&D site in the Denver, Colorado area and an office in New York City. Our Southern California hub is anchored by a new 90,000 sq. ft., state-of-the-art Atara T-Cell Operations and Manufacturing (ATOM) facility in Thousand Oaks, California.\n\nOur mission \u2013 \u201cTransform the lives of patients with serious medical conditions through pioneering science, teamwork and expertise.\u201d\nVisit www.atarabio.com to learn more.\n\nAtara Bio is an equal opportunity employer and makes employment decisions on the basis of merit and other lawful factors. In accordance with applicable law, the Company prohibits discrimination based on race, color, religion, creed, sex, gender (including pregnancy, childbirth or medical condition related to pregnancy or childbirth), gender identity, expression or dysphoria, marital status, age, national origin or ancestry, physical or mental disability, medical condition, genetic information, veteran status, caregiver status, sexual orientation, transgender status or any other classification protected by federal, state or local laws or because of the individual\u2019s association with a member of a protected group or connection to an organization or group related to a protected group.\n\nWe comply with all applicable national, state and local laws governing nondiscrimination in employment as well as employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must have authorization to work for Atara Bio in the United States.\nTo apply to this job, click Apply Now"}, "398": {"company": "Gilead Sciences", "description": "For Current Gilead Employees and Contractors:\n\n\nPlease log onto your Internal Career Site to apply for this job.\n\nJob Description\n\n\nAssociate Director, R & D Information Systems - Data Science\n\nSpecific Responsibilities:\nLead a Data Science team of full-time and contract technical professionals to support Pharmaceutical Development & Manufacturing (PDM) science and operations.\nWork with senior management to establish a data model to organize chemistry, manufacturing and control information derived from pharmaceutical process, formulation and analytical development, quality control and commercial manufacturing operations. Work closely with business process owners, data stewards and IT to establish a data management process with the appropriate governance to sustain the accuracy and completeness of data. Apply data sciences techniques to build knowledge management, predictive analytics, and identifying trends in scientific and operational datasets.\nWork with senior management to develop a comprehensive data sciences strategy and framework that builds out a core PDM data sciences capability and knowledge management platform. Partner with Enterprise IT to establish a sustainable data governance process with defined and roles and responsibilities. Examples include identifying and capturing data sets needed to solve complex issues and questions, data cataloguing, storage, compute, processing, analysis, search, use of business intelligence tools and visualizations for reporting, dashboards, and self-service.\nBuild and execute on an approach to mature the data sciences capability including assessments, process, value targeting and proposition, business case, technology solutions and proof of value. Use oral and written communication skills to summarize, present results, and influence direction.\nManage and maintain existing analytics reporting platforms which include providing web and Oracle Business Intelligence Enterprise Edition (OBIEE) reporting; as well as data visualization tools such as Tableau and Spotfire. These operations provide a set of targeted value-added reports, dashboards, metrics, monitoring, and tools throughout the PDM community such as analytical operations, clinical supply chain management, chemical development, and pharmaceutical quality assurance\nAnticipate data needs from sources by iterating to find and fill gaps through collaboration with data providers and data consumers.\nEstablish key performance indicators and metrics that measure the effectiveness, value and success of delivered solutions. This includes quality of deliverables, quality of service, effective of change management, measure of adoption and captured efficiencies\nKey Responsibilities:\nActively engage, partner with, and form alliances both internal and external between business, IT, and vendor stakeholders to cultivate a network of data partners and to identify pressing data analysis questions and develop data structures as well as visualizations tailored to PDM interests, business processes and needs.\nCreate and align on data sciences methodology and technologies through frequent communications and change management.\nBe able to develop analytical methods to apply to business problems involving large quantities of data, choosing the right algorithms, appropriate optimization techniques, and models\nDevelop security and access models so that data is controlled but meets a broad range of needs and provides agility and velocity. This include balancing autonomy with access controls, and segregation of environments.\nSupport building a data-driven culture and data-driven organization, conducive to data-driven decision making, quantitative analysis, identifying appropriate talent, and creating an environment conducive to effective data sciences and allowing for data-driven experiments\nStay current with modern and emerging big data, cloud, analytics, and visualization technologies as well as practical approaches to utilize such tools. Examples include big data in the cloud, data streaming and real-time analytics, automation, artificial intelligence, machine learning, interactive visualization, and batch processing techniques\nResponsible for implementation, development and management of business information systems against strategy and to meet business objectives.\nActs as a consultant to the Business in his/her area. Liaises with Global IT. Assigns objectives for team.\nLiaises with IT to schedule changes and updates for Business Systems.\nManages specific projects under direction from Senior Management.\nWorks as a project lead.\nContributes to the development of systems strategy.\nActs as technical spokesperson to the business on area of expertise.\nMay contributes to setting and achieving budget. Manages the team to ensure they meet the full requirements of their role.\nConducts professional appraisals for team members and effectively manages performance.\nProvides guidance to subordinates based on organizational goals and company policy. Work is reviewed in terms of meeting the organization\u2019s objectives and schedules\nEstablishes operating policies and procedures that affect subordinate organizational units. Interprets, executes, and recommends modifications to organizational policies.\nKnowledge, Experience & Skills\n\nMinimum Qualifications:\nA Bachelor\u2019s Degree with a minimum of ten (10) years of relevant experience OR and Master\u2019s Degree with a minimum of eight (8) years of relevant experience OR a PhD with a minimum of four (4) years of relevant experience.\nDegree focused in Science, Computer Science or equivalent experience preferred.\nPossess strong abilities to manage, develop and improve people, processes, operations and technology. Drive for excellence, develop team and manage for success. Provide solutions to highly complex problems and apply a high degree of ingenuity, creativity and innovation.\nExtensive data modeling and data architecture skills\nStrong programming experience in Python and R.\nLower level programming experience in languages like C#, C++ or Java\nBackground in machine learning frameworks such as TensorFlow and Keras\nKnowledge of how to analyze and manage large data sets as well as strategies for visualizing and communicating results to solve business needs\nFamiliarity with cGMP, computer validation concepts and pharmaceutical regulatory compliance, including data integrity, quality analytics, 21 CFR Part 11, EU Annex 11, and familiarity with as 21 CFR parts 58, 210, 211.\nIf this is not the right move for you now but remain interested in a career at Gilead Sciences please connect with us via our talent community: https://gilead.avature.net/Gilead\n\nAbout Gilead\n\nGilead Sciences, Inc. is a research-based biopharmaceutical company that discovers, develops and commercializes innovative medicines in areas of unmet medical need. With each new discovery and investigational drug candidate, we seek to improve the care of patients living with life-threatening diseases around the world. Gilead\u2019s therapeutic areas of focus include HIV/AIDS, liver diseases, cancer and inflammation, and serious respiratory and cardiovascular conditions.\n\n#LI-SA1\n\n\nFor jobs in the United States:\n\n\nAs an equal opportunity employer, Gilead Sciences Inc. is committed to a diverse workforce. Employment decisions regarding recruitment and selection will be made without discrimination based on race, color, religion, national origin, gender, age, sexual orientation, physical or mental disability, genetic information or characteristic, gender identity and expression, veteran status, or other non-job related characteristics or other prohibited grounds specified in applicable federal, state and local laws. In order to ensure reasonable accommodation for individuals protected by Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veterans' Readjustment Act of 1974, and Title I of the Americans with Disabilities Act of 1990, applicants who require accommodation in the job application process may contact careers@gilead.com for assistance.\n\nFor more information about equal employment opportunity protections, please view the \u2018EEO is the Law\u2019 poster.\n\nNOTICE: EMPLOYEE POLYGRAPH PROTECTION ACT\nYOUR RIGHTS UNDER THE FAMILY AND MEDICAL LEAVE ACT\n\nPAY TRANSPARENCY NONDISCRIMINATION PROVISION\n\nOur environment respects individual differences and recognizes each employee as an integral member of our company. Our workforce reflects these values and celebrates the individuals who make up our growing team.\n\nGilead provides a work environment free of harassment and prohibited conduct. We promote and support individual differences and diversity of thoughts and opinion.\n\n\nFor Current Gilead Employees and Contractors:\n\n\nPlease log onto your Internal Career Site to apply for this job.\nApply Now: click Apply Now"}, "399": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking a Lead Data Scientist/Architect to work on multi-disclipinary teams to meet program requirements. Lead the development of big data capabilities and utilization as well as the coordination of cross-functional analytic initiatives, implementation of sophisticated analytics programs, machine learning and statistical methods to prepare enterprise data for use in predicting and prescriptive modeling. Utilize a blend of contemporary and traditional data science techniques, applied to both structured and unstructured data sets.\n\nBasic Qualifications:\nBachelor's degree in data science, engineering or statistics\nMinimum of ten (10) years of IT experience, focusing on data architecture or data services to include the following:\nThree (3) years of experience leading data teams in such efforts as: data migration, transformation, data lake implementation/support as well as O&M\nFive (5) years of proven expertise in Relational and Dimensional Data Modeling\nExperience with cloud architecture, specifically AWS, as it relates to data processing (i.e., EC2, S3, Reshift, etc.)\nExperience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members and senior levels of management\nPossess strong architecture and design experience, including experience deploying production enterprise applications in AWS that use AI/ML\nFamiliarity with Agile processes\nFamiliarity with Confluence, JIRA and Github\nExcellent problem-solving skills\nSecurity Clearance:\nMust have a Entry on Duty (EOD) clearance\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nStart your job application: click Apply Now"}, "400": {"company": "EAB", "description": "About EAB\n\nAt EAB, our mission is to make education smarter and our communities stronger. We harness the collective power of 1,600+ schools, colleges, and universities to uncover and apply proven practices and transformative insights. And since complex problems require multifaceted solutions, we work with each school differently to apply these insights through a customized blend of research, technology, and services. From kindergarten to college and beyond, EAB partners with education leaders, practitioners, and staff to accelerate progress and drive results across three key areas: enrollment management, student success, and institutional operations and strategy.\n\nAt EAB, we serve not only our partner institutions but each other\u2014that's why we are always working to make sure our employees love their jobs and are invested in their community. See how we've been recognized for this dedication to our employees by checking out our recent awards.\n\nFor more information, visit our Careers page.\n\nThe Role in Brief:\n\nAssociate Data Engineer\n\nAre you a data enthusiast who seeks to tease out meaning from complex data flows and assets? Are you a talented problem solver who can transform abstract problems into elegant technical solutions? We are looking for a Data Modeler to join our team of engineers and data analysts focused on designing, creating, and delivering data solutions as part of our state-of-the-art cloud based products. The successful candidate will have the opportunity to build a world-class solution to help our higher education partners solve challenging problems through data.\n\nThis role is based in Washington, DC.\n\nPrimary Responsibilities:\nResponsible for data modeling and schema design that will range across multiple business domains within higher education\nPartner with multiple stakeholders including partners, new product development, BI engineers to develop scalable standard schemas\nWork with partners to research and conduct business information flow studies\nCodify high-performing SQL for efficient data transformation\nCoordinate work with external teams to ensure a smooth development process\nSupport operations by identifying, researching and resolving performance and production issues\nBasic Qualifications:\n1+ years of experience working with relational or multi-dimensional databases\nExperience developing logical data models within a data warehouse\nExperience developing ETL processes\nDemonstrated mastery in one or more SQL variants: PostgreSQL, MySQL, Oracle, SQL Server, or DB2\nDemonstrated mastery in database concepts and large-scale database implementations and design patterns\nProven ability to work with users to define requirements and business issues\nExcellent analytic and troubleshooting skills\nStrong written and oral communication skills\nBachelor\u2019s degree in Computer Science or Computer Engineering\nIdeal Qualifications:\nExperience working in an AGILE environment\nExperience developing commercial software products\nExperience with AWS data warehouse infrastructure (redshift, EMR/spark)\nGIT expertise\nMaster's degree in Computer Science or Computer Engineering\nBenefits:\n\nConsistent with our belief that our employees are our most valuable resource, EAB offers a competitive and inclusive benefits package.\nMedical, dental, and vision insurance; dependents and domestic partners eligible\n401(k) retirement plan with company match\n20+ days of PTO annually, in addition to paid firm holidays\nDaytime leave policy for community service or fitness activities (up to 10 hours a month each)\nPaid parental leave for birthing or non-birthing parents\nPhase Back to Work program for employees returning from parental leave\nInfertility treatment coverage and adoption or surrogacy assistance\nWellness programs including gym discounts and incentives to promote healthy living\nDynamic growth opportunities with merit-based promotion philosophy\nBenefits kick in day one, see the full details here.\nAt EAB, we believe that to fulfill our mission to \u201cmake education smarter and our communities stronger\u201d we need team members who bring a diversity of perspectives to the table and a workplace where each team member is valued, respected and heard.\n\nTo that end, EAB is an Equal Opportunity Employer, and we make employment decisions on the basis of qualifications, merit and business need. We don\u2019t discriminate on the basis of race, religion, color, sex, gender identity or expression, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law.\nApply Now: click Apply Now"}, "401": {"company": "PayScale", "description": "Company Description\n\nPayScale is the world leader in modern compensation software. We believe data-informed discussions about compensation benefit both employers and employees and that greater pay transparency promotes equity, engagement and employee retention. We are bringing the dark art of compensation into the light by helping individuals understand the right pay for their position and more than 7,000 businesses retain and manage their largest investment: their people.\n\nWe\u2019re transforming the compensation industry and are looking to bring on talented data professionals like you with diverse perspectives. At PayScale, we acknowledge and value our differences as well as our combined strengths. We want all employees, regardless of their background, to feel respected personally and professionally. We foster a working environment that generates new ideas, promotes ownership and experimentation, and encourages highly motivated individuals to be truly creative.\n\nJob Description\n\nDoes empowering a company to make data driven decisions excite you? We are looking for a Data Scientist to do just that. We are a small team working on high impact projects that drive innovation in our customer facing products and across the organization. The Data Science team partners closely with data engineers, product managers, and other external partners to design and develop the machine learning applications that power our compensation tools.\n\nIn this role you will focus on building and improving algorithms around salary prediction, record matching, recommendations/search, client retention, and lead scoring.\n\nWhat You'll Be Doing\nAcquire, clean, and process data with reliable, maintainable code\nContribute to the development of a robust understanding of compensation strategies for the company with in-depth exploratory analyses\nIdentify how to maximize the value of and improve our products with data by collaborating with Product, Sales, Marketing and other internal teams.\nIteratively design, code, train, test, deploy, and improve machine learning algorithms\nEvangelize your machine learning services with written and oral presentations.\nIf you enjoy seeing a project all the way from concept to production this is an excellent opportunity within a collaborative SaaS company.\n\nTechnologies We're Using\nPython (pandas, scikit-learn, NumPy, SpaCy), SQL, Elasticsearch, Tensorflow, Snowflake, Postgres, Spark, Azure, AWS, Git, and Docker\nQualifications\n\nWe'd love to hear from you if:\nYou have 4+ years experience building machine learning models/services\nYou are thoughtful in the evaluation of your models, improving them over time as they interact with real users\nYou have excellent coding skills, especially in Python or R\nYou care about the reliability and maintainability of your code.\nFamiliarity/experience with unit testing and crafting testable code.\nYou have a working understanding of database systems and experience writing SQL queries.\nYou have some experience with cloud providers (AWS, Azure, or Google Cloud).\nYou can effectively communicate and share results with both technical and non-technical partners.\nYou have the ability and desire to work with a team of people solving complex problems that often require independent research with minimal supervision.\nYou have strong critical thinking and communication skills.\nAdditional Information\n\nPayScale provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. PayScale complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\n\nBenefits:\nFlexible Paid Time Off policy\n100% company paid medical/vision/dental/prescription premiums for employees (50% for eligible dependents and partners)\nFour Flexible Spending Account (FSA) options for pre-tax employee allocations towards:\nMedical\nDependent Care (can be used towards day care costs!)\nParking\nTransit\nLong Term Disability, Short Term Disability, and Company-paid Life Insurance\nMaternity and Paternity Leave\n10 paid holidays!\nSummer Office Closure, entire week of July 4th\n401-k with company match, vests immediately\nCasual dress code\nOnsite lockers, showers, and clothes dryer\nBike storage\nCoworkers you actually like...\nGender neutral bathrooms on most floors\nMothers' Room\nSitting-Standing ergo friendly desks\nWeekly company sponsored happy hours\nWork from home Wednesdays\nFido Fridays (our canine colleagues join us the first Friday of every month. WOOF)\nStart your job application: click Apply Now"}, "402": {"company": "PayScale", "description": "Position Description:\nNovetta is seeking a Machine Learning Engineer to contribute to the modeling process from problem definition, through data pipeline and model implementation; applying agile methods to ML development activities. They will work as part of a multi-disciplinary team and will impact multiple projects concurrently.\nDoD is shifting investment into the future of machine learning and artificial intelligence across the Defense Intelligence Enterprise to reimagine and revolutionize the intelligence process. In order to achieve this, Training Quality Data (TQD) must be harvested from current data holdings, data gaps must be characterized into targeting/collection requirements and synthetic data must be generated.\nResponsibilities:\nIdentify important and interesting questions surrounding our customer's challenges, then translate those questions into concrete analytical tasks;\nDevelop strategies to extract, resolve, and unify information of various types from numerous data sources;\nOrganize and mine massive data sets of both structured and unstructured data;\nProvide thought-leadership in the areas of machine learning, artificial intelligence, analytics and data science;\nWork with a diverse team of engineers, computer scientists, data scientist and analysts.\nBasic Qualifications:\nAcademic degree in a relevant field (e.g., Computer Science, Engineering, Mathematics, Statistics, Operations Research, Physics, etc.);\nDetailed experience with open source frameworks for Neural Network architectures including Keras, TensorFlow, PyTorch, or Caffe;\nDetailed experience and understanding of Machine Learning methods and frameworks including ensemble methods\nExperience implementing various types of Neural Networks including Convolutional Neural Networks and/or Recurrent Neural Networks\nDesired Skills:\nExperience with intelligence analysis mission sets.\nFamiliarity with network analysis, natural language processing, and/or risk modeling.\nExperience with FMA programs, analyzing supply chain data, or processing real time data feeds to produce actionable results.\nSecurity Clearance:\nMust have an active US Government Secret security clearance.\nStart your job application: click Apply Now"}, "403": {"company": "C3.ai", "description": "C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai\n\nAs a Data Scientist, you will participate in the definition of new analytics capabilities able to provide our customers with the information they need to make proper decisions to support our customers in operating the internet of things (IoT). In addition, you will help find the appropriate machine learning / data mining algorithms to answer these questions. Finally, you will be responsible for implementing this into the product and making it available to our customers.\n\nQualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve similar results at large-scale.\n\nYour Responsibilities:\nDriving adoption of Deep Learning systems into next-generation of C3.ai products.\nDesigning and deploying Machine Learning algorithms for industrial applications such as fraud detection and predictive maintenance.\nCollaborating with data and subject matter experts from C3.ai and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.\nRequirements:\nMS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields.\nApplied Machine Learning experience (regression and classification, supervised, and unsupervised learning).\nStrong mathematical background (linear algebra, calculus, probability and statistics).\nExperience with scalable ML (MapReduce, streaming).\nAbility to drive a project and work both independently and in a team.\nSmart, motivated, can do attitude, and seeks to make a difference.\nExcellent verbal and written communication.\nPreferred\nExperience with JavaScript and prototyping languages such as Python and R. Experience with Java and Scala is a plus.\nKnowledge in electrical engineering and cyber-physical systems is a plus.\nA portfolio of projects (GitHub, papers, etc.) is a plus.\nC3.ai provides a competitive compensation package and excellent benefits including:\nCompetitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people.\nC3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.\n\nStart your job application: click Apply Now"}, "404": {"company": "Tecolote Research", "description": "Data Science Analyst\nLocation: El Segundo, CA\nEducation Required: Bachelor\u2019s degree required, preferably in math, engineering, business, or the sciences.\nSkills Required:\nMinimum of 5 years' experience in business intelligence, analytics, data governance, data analysis, and/or predictive modeling\nProficient in one or more of the following: Power BI, Tableau, R, Python, JavaScript\nProficient in MS Office Suite\nDetailed, organized individual\nGood communication, presentation, and visualization skills\nInterest and ability to work in a dynamic work environment\nAbility to adapt to daily priority changes while not jeopardizing long term priorities\nAbility to perform ad-hoc research projects independently, summarize results in a written report, and present to an audience\nDepartment of Defense (DoD) Acquisition experience a plus\nGeneral familiarity with IT, database management, Cloud, SQL, .Net, SharePoint are a plus\nU.S. citizenship required\nAbility to obtain and maintain a security clearance (active clearance is a plus)\nResponsibilities: Job duties will consist of some combination of the following,\nProvide analytics and business intelligence support for U.S. government acquisition programs\nCommunicate with various levels of government leadership\nData mining, exploratory analysis, and data visualization\nAnomaly detection and data quality management\nApply supervised and unsupervised machine learning techniques for regression, classification, and exploration\nTime series analysis/forecasting\nGenerate performance metrics and KPIs; create interactive dashboards\nSupport government data management policy efforts: architecture definition, storage & integration, security, quality management, data dictionaries, data playbooks, etc.\nCollaborate with IT professionals and organizational change management specialists\nBenefits:\nWe offer competitive salaries commensurate with education and experience. We have an excellent benefits package that includes:\nComprehensive health, dental, life, long and short term disability insurance\n100% Company funded Retirement Plans\nGenerous vacation, holiday and sick pay plans\nTuition assistance\n\nTecolote Research is a private, employee-owned corporation where people are our primary resource. Our investments in technology and training give our employees the tools to ensure our clients are provided the solutions they need, and our very high employee retention rate and stable workforce is an added value to our customers. Apply now to connect with a company that invests in you.\nTo apply to this job, click Apply Now"}, "405": {"company": "IBM", "description": "Introduction\nAs a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.\n\nYour Role and Responsibilities\nIBM Watson Health is looking for talented individuals destined to usher in the next era of healthcare. We live in a moment of remarkable change and opportunity. The convergence of data and technology is transforming healthcare and life sciences organizations today. New opportunities are being created that never existed before to meet the demands of this transformation.\n\nThe Rapid Development is a team of Scientists and Cognitive Software Developers within IBM Watson Health Imaging. In collaboration with cross-functional Watson Health teams, IBM Research and external partners, the team develops cognitive solutions that combine imaging and clinical data to enhance clinical decision making. The team is responsible for developing and validating robust and scalable cognitive services (text analytics and image analytics) and applications, including validation and evaluation of technologies being transferred from Research and other collaborators. The team follows Agile and DevOps methodologies to enable rapid iteration and responsiveness.\n\nWe are looking for self-motivated and driven candidates that are passionate about working on cutting edge technologies and that thrive in a highly collaborative environment.\n\nJob Responsibilities\nDesign and development of robust algorithms and techniques using machine learning and one or both of (a) text analytics, Natural Language Processing (NLP) or (b) image processing, Computer Vision\nRapid development and validation of cognitive solutions by using and/or enhancing existing methodologies, frameworks and architecture\nDevelopment of criteria for testing algorithm and systems cognitive performance objectively from end-user and market perspective. Conduct performance evaluation and testing of algorithms and systems on test and real clinical data\nWork with clinical collaboration and joint development partners to develop cognitive solutions\nSupport collection and annotation of data for algorithm development and evaluation\nIntegration of cognitive systems and components in Watson Health architecture, including Watson Health cloud\nPlanning, processing and performing all jobs in an efficient manner with minimum supervision\nConduct product development in compliance with Watson Healths methodology, practices and Quality Management system.\nRequired Technical and Professional Expertise\n1-3 years experience with solving real-world problems using Data Analytics, Natural Language Processing (NLP) or Image Processing, and Machine Learning,\nStrong experience in Machine Learning, including deep learning and statistical models\nStrong Programming skills (Java/J2EE, C++, Python) and experience with software systems architecture, web services, web applications, and current software development tools, technologies and frameworks\nStrong publication record in peer-reviewed conferences and journals\nDemonstrated communication and cross-functional collaboration skills;\nPhD in Text Processing / NLP or Image Processing / Computer Vision\nFluent in English, spoken and written\nPreferred Technical and Professional Expertise\nStrong knowledge of either (a) clinical information analytics domain, having applied NLP and machine learning techniques on unstructured data in EMRs, or (b) medical imaging domain, having applied computer vision and machine learning techniques on modalities such as X-ray, CT, MR, Ultrasound, etc.\nInterest or experience with healthcare information protocols and common interoperability standards, such as IHE, HL7, DICOM, XDS and IHE, and healthcare systems such as PACS, EMR, EHR, HIS and RIS;\nPhD in Text Processing / NLP applied to medical reports, or Image Processing / Computer Vision applied to medical imaging.\nAbout Business Unit\nIBM Watson Health is pioneering a new partnership between humanity and technology with the goal of transforming global health and revolutionizing many aspects of the medical and pharmaceutical industries, as well as government sectors. We aspire to improve lives and give hope by delivering innovation to address the worlds most pressing health challenges through data and artificial intelligence insights.\n\nYour Life @ IBM\nWhat matters to you when youre looking for your next career challenge?\n\nMaybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.\n\nImpact. Inclusion. Infinite Experiences. Do your best work ever.\n\nAbout IBM\nIBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.\n\nLocation Statement\nFor additional information about location requirements, please discuss with the recruiter following submission of your application.\n\nBeing You @ IBM\nIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.\n\nApply Now: click Apply Now"}, "406": {"company": "OGE Energy Corp.", "description": "Position Summary:\n\nA student or recent graduate participating in on-the-job training. Providing opportunities to gain knowledge and experience in a field of study. Performs planned supervised work assignments.\n\nPrimary Duties:\nProvide general operational and administrative support to the business unit or department.\nDraft routine correspondence and create reports.\nAnswers and direct calls.\nMay schedule, plans, and coordinates meetings and events.\nMay audit system data for accuracy.\nMay coordinate with other departments on special projects.\nRequirements:\nA student currently working towards a degree in a Business discipline e.g. Business Management, Business Administration, etc., Human Resources, Marketing, Finance, Accounting, Public Relations, Corporate Communications, Information Technology, Supply Chain or other related discipline.\nPreferred Qualifications:\n\nExperience writing advanced SQL (or Python Pandas or Hadoop Hive) queries.\nAbility to create compelling visualizations in software such as SAS Visual Analytics, Tableau or similar applications.\nAbility to code in languages such as SAS, R or Python\nExperience working with geospatial data\nAbility to map business problems to analytical techniques and data.\nExperience conducting financial analysis: NPV, Discounted Cash Flows, IRR, etc.\nA high-degree of mathematical acumen; understanding of basic statistics.\n\nKnowledge, Skills, and Abilities:\nIntermediate skills and knowledge in use of personal computers and MS office products.\nStrong listening skills; ability to take direction.\nAbiility to follow established procedures to accomplish requirements of job.\nStrong oral and written communicate skills.\nStrong organizational skills; ability to manage multiple projects simultaneously and adhere to established timelines.\nProven time management skills.\nAbility to develop and/or analyze reports.\nAbility to conduct research through various methods.\nAbility to maintain a high degree of confidentiality.\nAbility to adapt quickly to a changing environment.\nStrong analytical skills.\nAbility to work effectively in a team environment.\nWorking Conditions:\nWork is performed in an office environment utilizing office equipment including a computer, monitor, keyboard and mouse.\nWork is often performed with short deadlines and may involve sensitive matters requiring objectivity and confidentiality.\nMay be required to work non-standard hours.\nMay travel occasionally to Company locations for meetings or events.\nSpecial Safety Requirements:\nAll positions in which driving is an essential function of the job, regardless if the job code is marked safety sensitive or not, will also be included as safety sensitive. Individuals in positions in which driving is an essential function are subject to the terms and conditions set forth in OGE Energy Corp.'s Drug Testing Plan.\nRequired Skills\n\nRequired Experience\n\nJob Location\nOklahoma City, US-OK\nApply Now: click Apply Now"}, "407": {"company": "Bill.com", "description": "About Bill.com\n\nBill.com is a leading provider of cloud-based software that simplifies, digitizes, and automates complex, back-office financial operations for small and midsize businesses. Customers use the Bill.com platform to manage end-to-end financial workflows and to process payments, which totaled over $70 billion for fiscal 2019. The Bill.com AI-enabled, financial software platform creates connections between businesses and their suppliers and clients. It helps manage cash inflows and outflows. The company partners with several of the largest U.S. financial institutions, more than 70 of the top 100 U.S. accounting firms, and popular accounting software providers. Bill.com has offices in Palo Alto, California and Houston, Texas. For more information, visit www.bill.com or follow @billcom.\n\nMission:\nWe are looking for a detail oriented, enthusiastic and dedicated risk data scientist to join Bill.com\u2019s risk analytics and data science team with a focus on fraud and credit risks. The incumbent will be working on data science projects related to key risk department initiatives. The data scientist will own key projects associated with predictive fraud detection, transaction risk modeling and loss mitigation following Bill.com\u2019s risk strategy roadmaps. This individual will also design experiments to understand the impact of customer experience when leveraging machine learning in complex risk strategy changes. This position requires a person who has experience with developing machine learning models and performing analytics preferably in risk domain.\nProfessional Experience/Background to be successful in this role:\nMinimum 2 year of industry experience in data science\nAn advanced degree (M.S., PhD.), preferably in Statistics, Physical Sciences, Computer Science, Economics, or a related technical field\nStrong track record of performing data analysis and statistical modeling using SQL, Python or similar tools\nMastery of a wide range of Machine Learning techniques, tools, and methodologies with a demonstrated capability to apply them to a broad range of business problems and data sources\nMachine Learning techniques include clustering, classification, regression, decision trees, neural nets, anomaly detection etc.\nAbility to clearly communicate complex results to technical experts, business partners, and executives\nComfortable with ambiguity and yet able to steer analytics projects toward clear business goals, testable hypotheses and action-oriented outcomes\nDesirable to have experience solving problems related to risk using data science and analytics\nExperience working with cross functional teams including product, engineering and operations\nExpected Outcomes in 12 Months\nExplore machine learning model application in different risk mitigation scenarios, including signup risk, transaction risk, network risk as well as credit risk\nWork closely with the risk policy and operations team to identify relevant risk signals and develop predictive risk models\nFollow risk team model development roadmaps to guarantee timely delivery of model governance related documentations\nEvaluate third party vendor data quality and identify new opportunities leveraging various data elements to improve customer experience without incremental risk exposure\nCompetencies (Attributes needed to be successful in this role):\nFunctional/Technical Expertise\nResult driven\nLearning Abilities/Tech Savvy\nCommunication\nTeam Player\nBill.com Culture:\n\u25cf Humble \u2013 No ego\n\u25cf Fun \u2013 Celebrate the moments\n\u25cf Authentic \u2013 We are who we are\n\u25cf Passionate \u2013 Love what you do\n\u25cf Dedicated \u2013 To each other and the customer\n\nApply Now: click Apply Now"}, "408": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nJoin a large, multi-disciplinary team building a new generation of analytic and investigative tools for a mission critical program. If you live and breathe data, and want to apply your considerable AWS skills to prepare data in ways that truly address mission requirements without compromise, this is the role for you.\n\nBasic Qualifications\nMinimum of five (5) years in modern data development, upgrading, support and design.\nExperience requirements may be substituted with a Bachelor's degree in Computer Science plus three years of experience in modern data development, upgrading, support, and design.\nExperience in establishing performance and statistical monitoring of enterprise databases to include, but not limited to; wellness checks, data integrity, privacy and security scans.\nExperience in supporting cloud database environments, specifically AWS (i.e., EC2, S3, Neptune or Redshift) to include backup and archiving of data.\nFamiliarity with Agile processes.\nFamiliarity with Confluence, JIRA, and Github\nExcellent problem-solving skills\nSecurity Clearance:\nActive Public Trust security clearance required.\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nApply Now: click Apply Now"}, "409": {"company": "Arm", "description": "We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.\n\nJob Description\n\n\nAbout Arm\n\nArm\u00ae technology is at the heart of a computing and connectivity revolution that is transforming the way people live and businesses operate. Our advanced, energy-efficient processor designs are enabling the intelligence in 86 billion silicon chips and securely powering products from the sensor to the smartphone to the supercomputer. Our large footprint in the stack of technologies that enables IoT applications, builds an unparalleled opportunity to be at the forefront of the Machine Learning and data driven revolution. IoT services group (ISG) is one of the two business units within Arm. ISG delivers Pelion as a platform to harness IoT data, gain insights and unlock new possibilities. The Arm Pelion\u00ae IoT Platform provides the operating system, cloud services, tools and developer ecosystem to enable the creation and deployment of commercial, standards-based IoT solutions possible at scale.\n\nWe are a fast growing, diverse and dynamic team of enthusiastic professionals who share a vision and real passion for building a technology foundation for this emerging industry. We are looking for a hardworking and hands-on applied machine learning scientist within ISG organization.\n\nThe role will be based in San Jose with occasional travel to other Arm sites, customers and partners.\n\nWhat will I be accountable for?\nYou work closely with the Pelion\u00ae IoT strategy and product teams to prototype machine learning and data science pipelines and solutions.\nYou will take lead in employing machine/deep learning technologies and demonstrating its value of improving Pelion products and services.\nYou will consult with business partners and support our key internal or external customers in applying machine learning to their use cases and problems.\nYou will track the state-of-the-art machine learning and data science technologies, and collaborate with Arm\u2019s research group to advance our intellectual property.\nYou will be curious and open-minded about different technologies and toolkits, and you can quickly adopt the right one for the task at hand.\n</p>\n\nJob Requirements\n\n\nWhat skills, experience, and qualifications do I need?\nMaster\u2019s degree with working experience or Ph.D. degree, in a quantitative discipline (computer science, statistics, mathematics, physics, computational neuroscience, economics, etc.) or related fields.\nDeep understanding of machine learning methods, including classification and regression (e.g. linear/logistic regression, Random Forest, XGboost, neural networks), clustering (e.g. PCA, K-means, etc.).\nApplied statistics and probability theory, such as central limit theorem, confidence interval, hypothesis testing, statistical inference, etc.\nExperience with at least one scripting language like Python, R, scala, etc. Ability to rapidly prototype and deploy quantitative solutions using common machine learning and data science toolkits or frameworks such as numpy, pandas, scikit-learn, TensorFlow, Pytorch, H2O, Spark.\nAbility to gather and manipulate both small and large datasets using SQL.\nThe ability to get along with business and engineering teams with a focus on driving impact.\nExperience with (or ability to learn) data visualization tools and web technologies, such as Tableau, D3.js, etc.\nNice to have experience with:\nModel compression (e.g. pruning, quantization, etc.) and neural architecture search.\nObject detection methods (e.g. Mask R-CNN, YOLO, etc.)\nModel deployment using open-source tools (e.g. TensorFlow Lite/Serving, Clipper, Python Flask, etc.)\nEmbedded system\nProgramming language like C++, C, Java, Javascript, etc.\nAt Arm, we are guided by our core beliefs that reflect our rare culture and guide our decisions, defining how we work together to defy ordinary and shape extraordinary:\n\nWe not I\n\nTake daily responsibility to make the Global Arm community thrive.\nNo individual owns the right answer. Brilliance is collective.\nInformation is crucial, share it.\nRealize that we win when we collaborate \u2014 and that everyone misses out when we don\u2019t.\n\nPassion for progress\n\nOur differences are our strength. Widen and mix up your network of connections.\nDifficult things can take unexpected directions. Stick with it.\nMake feedback positive and expansive, not negative and narrow.\nThe essence of progress is that it can\u2019t stop. Grow with it and own your own progress.\n\nBe your brilliant self\n\nBe quirky not egocentric.\nRecognize the power in saying \u2018I don\u2019t know\u2019.\nMake trust our default position.\nHold strong opinions lightly.\n\n#LI-PW1</p>\n\nBenefits\n\n\nYour particular benefits package will depend on position and type of employment and may be subject to change. Your package will be confirmed on offer of employment. Arm\u2019s benefits program provides permanent employees with the opportunity to stay innovative and healthy, ensure the wellness of their families, and create a positive working environment.\nAnnual Bonus Plan\nDiscretionary Cash Awards\n401(k), 100% matching on first 6% eligible earnings\nMedical, Dental & Vision, 100% coverage for employee only, shared cost for dependents\nBasic Life and Accidental Death and Dismemberment Insurance (AD&D)\nShort Term (STD) and Long Term (LTD) Disability Insurance\nVacation, 20 days per year with option to buy 5 more.\nHolidays, 13 days per year\nSabbatical, 20 paid days every four-years of service\nSick Leave, 7 days per year\nVolunteering, four hours per month (TeamARM)\nOffice location dependent: caf\u00e9 on site, fitness facilities, team and social events\nAdditional benefits include: Flexible Spending Accounts for health and dependent care, EAP, Health Advocate, Business Travel Accident Program & Commuter programs.\nARM, Inc. (USA) participates in E-Verify. For more information, please refer to www.dhs.gov/E-Verify\n\nAbout Arm\n\n\nArm\u00ae technology is at the heart of a computing and connectivity revolution that is transforming the way people live and businesses operate. From the unmissable to the invisible; our advanced, energy-efficient processor designs are enabling the intelligence in 86 billion silicon chips and securely powering products from the sensor to the smartphone to the supercomputer. With more than 1,000 technology partners including the world\u2019s most famous business and consumer brands, we are driving Arm innovation into all areas compute is happening inside the chip, the network and the cloud.\n\nWith offices around the world, Arm is a diverse community of dedicated, innovative and highly talented professionals. By enabling an inclusive, meritocratic and open workplace where all our people can grow and succeed, we encourage our people to share their unique contributions to Arm's success in the global marketplace.\n\nAbout the office\n\n\nThe Arm San Jose office is nestled in California's Silicon Valley, just south of San Francisco. Serving as Arm\u2019s North America headquarters, the office houses employees serving all divisions of Arm. World-renowned Stanford University is seen as a hub of innovation, helping to make San Jose one of the US\u2019s fastest growing cities.\nSan Jose, California USA\nArm Inc.\n150 Rose Orchard Way\nSan Jose, CA 95134-1358\nTo apply to this job, click Apply Now"}, "410": {"company": "AeroVironment", "description": "Machine Learning Engineer II\nLocation\n\n\nSimi Valley, CA\n\nEmployment type\n\n\nRegular - Full Time\n\nID\n\n651\n\nApply Now\n\nWe are currently a Machine Learning Engineer II to join our team.\n\nThe AeroVironment Engineering Autonomy team is looking to add a Machine Learning Engineer. The Machine Learning Engineer will have the opportunity to interact with R&D Group to develop a variety of innovative computer vision detection, classification, localization, and tracking solutions for defense and commercial applications. These development efforts will generally be small focused design teams which will require a senior machine learning engineer to use a range of skills and tools across traditional engineering, computer science, and mathematical disciplines including computer vision, machine learning, optimization, deep convolutional neural networks, and visual tracking. This position will work on a variety of stages of development including requirements definition, concept design, prototyping, detailed design, test and evaluation and validation and verification testing.\n\nJob Duties and Responsibilities\nSupport development of computer vision and machine learning algorithms capable of detection, classifying, localizing, and tracking objects-of-interest from a group 1 UAV using the existing gimballed camera payload.\nWrite and test software to support the integration of machine learning algorithms into aircraft (such as autopilots, payloads, or other functional components) or other robotic systems.\nExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect\nImplement Machine Learning systems and validate designs through a series of purpose-designed experiments.\nCreate objectives and develop models that help to achieve them, along with metrics to track their progress\nPerform analysis tasks using AeroVironment and industry developed tools.\nManaging available resources such as hardware, data, and personnel so that deadlines are met\nAnalyzing the ML algorithms to solve a given problem and ranking them by their success probability\nPerformance when deploying the model in the real world\nVerifying data quality, and/or ensuring it via data cleaning\nAnalyzing the errors of the model and designing strategies to overcome them\nStudy and transform data science prototypes\nResearch and implement appropriate ML algorithms and tools\nSelect appropriate datasets and data representation methods\nRun machine learning tests and experiments\nOther Matrixed Skills include:\nProficiency with a deep learning framework such as TensorFlow or Keras\nProficiency with Python and basic libraries for machine learning such as scikit-learn and pandas\nExpertise in visualizing and manipulating big datasets\nProficiency with OpenCV\nFamiliarity with Linux\nAbility to select hardware to run an ML model with the required latency\nComputational statistics\nMathematical optimization\nData mining\nExploratory data analysis\nPredictive analytics\nRequired Qualifications & Background\nU.S. Citizenship required\nBS in Computer Vision and Machine Learning with qualifications in any of the following fields: Mathematics, Optimization, Computer Science/Engineering, Electrical Engineering, Aerospace, or Mechanical Engineering with 2+ years of relevant experience.\nFamiliarity with C/C++ and Matlab required.\nDemonstrated ability to troubleshoot complex systems.\nExcellent verbal and written skills.\nMust be a team player and collaborate effectively.\nFamiliarity with office software and computer-based productivity tools.\nMust be willing to work on government contracts and the ability to obtain a security clearance.\nAble to excel in a fast-paced, deadline-driven environment.\nITAR Requirement:\n\nThis position requires the use of information which is subject to compliance with International Traffic Arms Regulations (ITAR). To conform to U.S. Government export regulations/ITAR, applicants must be a U.S. Citizen, lawful permanent resident of the U.S. (or, green card holder), protected individual as defined by 8 U.S.C. 1324b(a)(3), or eligible to obtain the required authorizations from the U.S. Department of State. Applicants cannot be hired until they are qualified to have such access. Some positions due to contracts will require current U.S. Citizenship.\n\nBenefits: AV offers an excellent benefits package including medical, dental vision, 401K with company matching, a 9/80 work schedule and a paid holiday shutdown. For more information about our company benefit offerings please visit: http://www.avinc.com/myavbenefits.\n\nWe also encourage you to review our company website at http://www.avinc.com to learn more about us.\n\nPrincipals only need apply. NO agencies please.\n\nWho We Are\n\nBased in California, AeroVironment (AVAV) is a global leader in unmanned aircraft systems (UAS) and tactical missile systems. Founded in 1971 by celebrated physicist and engineer, Dr. Paul MacCready, we\u2019ve been at the leading edge of technical innovation for more than 45 years. Be a part of the team that developed the world\u2019s most widely used military drones and created the first submarine-launched reconnaissance drone, and has seven innovative vehicles that are part of the Smithsonian Institution\u2019s permanent collection in Washington, DC.\n\nJoin us today in developing the next generation of small UAS and tactical missile systems that will deliver more actionable intelligence to our customers so they can proceed with certainty \u2013 and succeed.\n\nWhat We Do\n\nBuilding on a history of technological innovation, AeroVironment designs, develops, produces, and supports an advanced portfolio of unmanned aircraft systems (UAS) and tactical missile systems. Agencies of the U.S. Department of Defense and allied military services use the company\u2019s hand-launched UAS to provide situational awareness to tactical operating units through real-time, airborne reconnaissance, surveillance, and target acquisition.\n\nAeroVironment Incorporated is an equal opportunity employer, M/F/D/V and works in compliance with both federal and state laws. We are committed to the concept regarding Equal Employment opportunity. Qualified candidates will be considered for employment regardless of race, color, religion, age, sex, national origin, marital status, medical condition nor disability, genetics, veteran and all others that may apply.\nTo apply to this job, click Apply Now"}, "411": {"company": "Transamerica", "description": "Job Description Summary\nWe are looking for Data/Machine Learning engineers at all levels to help us build a robust and scalable data platform to support AI/ML data pipelines, reporting and data analysis as our business scales. We use cloud native (AWS) cutting-edge technologies like Spark, Kinesis/Kafka Streaming, Graph , infrastructure as code, CI/CD to deliver high-quality data solutions to analysts, data scientists, and partners. Were looking for an engineer that takes ownership in their work, has a strong focus on quality, and enjoys working in a collaborative environment.\n\nAt Transamerica, we believe achieving a secure future requires both smart financial planning and a healthy lifestyle. Were using data science, machine learning, computer vision, natural language processing, and Iot to revolutionize the way our customers save, invest, protect, and retire and to help them develop better wellness habits. As part of the Data Engineering team in our Analytics Execution group, you will work with data scientists and analytics engagement managers to develop innovative data-based solutions that transform the way we do business.\nJob Description\n\nQualifications:\nMust have a solid understanding of data engineering, integration, and warehousing concepts and patterns.\nMust have experience with design, build, and maintain batch and streaming data solutions at scale in both on-premises and cloud environments, specifically in the Hadoop ecosystem\nYoure proficient with Linux operations and development, including basic commands and shell scripting\nYou can demonstrate experience with DevOps methodologies and continuous integration/continuous delivery practices\nMust be fluent in Python, R, and Java\nMust have excellent experience command of SQL\nMust have good experience and knowledge with Data Modeling concepts.\nYou have a passion for data science and machine learning with a strong desire to develop your analysis and modeling skills\nPreferred Qualifications:\nMust have 3 -5 years of experience building data productionalized pipelines.\nMust have strong experience ingesting huge volumes of structured and unstructured data both in streaming and batch ingestions patterns.\n2 - 4 years of Cloud development experience with AWS and or Azure stack.\nExposure with and have solid experience with statistical analysis and machine learning libraries\nMust have previous experience with NoSQL database implementations\nYou understand the fundamentals of lambda architectures and serverless. applications\nMust be proficient in Tableau\nMust be comfortable with leveraging ETL tools, like Informatica.\nYou are proficient in Scala or Node.js\nYou have a masters degree in a quantitative field\nJob Description:\nPartner with data scientists, analytics engagement managers, and other data engineers to discover, collect, cleanse, and refine the data needed for analysis and modeling\nAnalyze large data sets to extract actionable insights and inform experimental design and model development\nDesign robust, reusable and scalable data driven solutions and data pipeline frameworks to automate the ingestion, processing and delivery of both structured and unstructured batch and real-time streaming data\nBuild models using basic statistical and machine learning techniques, partnering with data scientists for education and guidance\nWere looking for an engineer that takes ownership in their work, has a strong focus on quality, and enjoys working in a collaborative environment.\nWorking Conditions\nOffice environment\nApply Now: click Apply Now"}, "412": {"company": "Provisur Technologies", "description": "Ingenuity Center Manager - Food Scientist\n\nPOSITION SUMMARY/PURPOSE:\n\nManage all areas of the Product Development and Technology Center including the production floor, food science lab, and kitchen. Responsible for upkeep of equipment, facility, and resources associated within the Center. Study and define interactions of various food products with processing equipment. Act as resource support for customers and sales for equipment applications in food processing. Analyze and determine engineering modifications and changes needed to fulfill customers' requirements for equipment. Work with engineering on necessary changes. Manage all areas of food science interaction at the Ingenuity Center including; the production floor, food science laboratory, and preparation/demonstration kitchen. Follow all safety and standard manufacturing practices and adhere to government regulations. Interact with customers in a professional manner. Document and archive all data related to product and equipment testing.\n\nPOSITION ACCOUNTABILITIES:\nSpecify and/or procure raw material/ingredients for product testing. Interact with internal/external customers. Ability to operate all required equipment for product tests. Organize and record all pertinent test data. Prepare test report including statistical analysis if needed.\nManage food science laboratory, including external testing when required. Analyze laboratory data and document findings.\nManage PDTC facility upkeep; clean facility and equipment after product runs, dispose of product, conduct preventative maintenance of equipment and conduct basic troubleshooting of mechanical systems and equipment.\nManage preparation kitchen and demonstration kitchen. Prepare product samples for evaluation. Keep kitchens clean and organized. Maintain appliances that are up to date and utilized at our customer.\nEducate and enforce good manufacturing practices (GMP\u2019s) for all personnel working/entering the Ingenuity Center\nEstablish/follow and assure compliance to sanitation standard operating procedures (SSOP\u2019s).\nLab Assays - Perform bone digestions on meat and poultry samples.\nAs a manager in the organization, it is your responsibility to optimize the work of assigned department(s) and balance the workload appropriately; develop and implement efficiencies to improve the workflow; develop and oversee the training, development and evaluation of assigned staff and ensure smooth teamwork with other functions; and, ensure high quality standards are established and maintained.\nAdditionally, it is your responsibility to accomplish your own work in an organized, timely manner; and effectively manage approved budgets; generate and solicit continuous improvement ideas from your team and develop implementation plans; take personal responsibility for service excellence, sustainability and safe working practices; and, understand and ensure compliance with our Principles & Values and all company policies and procedures.\nJOB KNOWLEDGE/SKILLS AND ABILITIES:\nKnowledge of food production equipment and processes; especially for meat and poultry.\nKnowledge of and ability to perform standard lab tests on food products.\nAbility to give a technical presentation to customers.\nAdvanced computing skills: MS-Office, Windows, Outlook, Pivot Tables, and Charts with the ability to prepare technical presentation.\nStrong technical background with an understanding of hydraulics, electrical and electronics, pneumatics, technical drawing and mechanical design.\nStrong interpersonal skills with the ability to communicate at all levels and with customers.\nAbility to multi-task and establish priorities while maintaining composure.\nAbility to motivate, manage and develop workforce.\nAbility to set and work within department budget.\nAbility to supervise and develop others and delegate duties.\nHigh standards of professional ethics and business conduct\nStrong organizational and leadership skills.\nPositive attitude, pride in work, professional demeanor, and able to work well independently or in a collaborative team environment.\nPROFESSIONAL WORK EXPERIENCE:\n10 years of experience as a food scientist in meat and poultry industry (supplier or processor).\n5 years supervisory experience.\nEDUCATIONAL AND/OR TRAINING REQUIREMENT:\nMinimum of Bachelor\u2019s Degree in Food Science\nMaster\u2019s Degree preferred.\n\nTo apply to this job, click Apply Now"}, "413": {"company": "IBM", "description": "Introduction\nAs a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.\n\nYour Role and Responsibilities\nIBM Watson Health is looking for talented individuals destined to usher in the next era of healthcare. We live in a moment of remarkable change and opportunity. The convergence of data and technology is transforming healthcare and life sciences organizations today. New opportunities are being created that never existed before to meet the demands of this transformation.\n\nThe Rapid Development is a team of Scientists and Cognitive Software Developers within IBM Watson Health Imaging. In collaboration with cross-functional Watson Health teams, IBM Research and external partners, the team develops cognitive solutions that combine imaging and clinical data to enhance clinical decision making. The team is responsible for developing and validating robust and scalable cognitive services (text analytics and image analytics) and applications, including validation and evaluation of technologies being transferred from Research and other collaborators. The team follows Agile and DevOps methodologies to enable rapid iteration and responsiveness.\n\nWe are looking for self-motivated and driven candidates that are passionate about working on cutting edge technologies and that thrive in a highly collaborative environment.\n\nJob Responsibilities\nDesign and development of robust algorithms and techniques using image analytics, computer vision and machine learning\nRapid development and validation of cognitive solutions by using and/or enhancing existing methodologies, frameworks and architecture\nDevelopment of criteria for testing algorithm and systems cognitive performance objectively from end-user and market perspective. Conduct performance evaluation and testing of algorithms and systems on test and real clinical data\nWork with clinical collaboration and joint development partners to develop cognitive solutions\nSupport collection and annotation of data for algorithm development and evaluation\nIntegration of cognitive systems and components in Watson Health architecture, including Watson Health cloud\nPlanning, processing and performing all jobs in an efficient manner with minimum supervision\nConduct product development in compliance with Watson Healths methodology, practices and Quality Management system\nRequired Technical and Professional Expertise\n3-5 years experience with solving real-world problems using Data Analytics, Computer Vision and Machine Learning\nStrong experience in Machine Learning, including deep learning and statistical models\nStrong Programming skills (Java/J2EE, C++, Python) and experience with software systems architecture, web services, web applications, and current software development tools, technologies and frameworks\nStrong publication record in peer-reviewed conferences and journals\nDemonstrated communication and cross-functional collaboration skills;\nFluent in English, spoken and written\nPreferred Technical and Professional Expertise\nStrong knowledge of medical imaging domain, having applied computer vision and machine learning techniques on modalities such as X-ray, CT, MR, Ultrasound, etc\nInterest or experience with healthcare information protocols and common interoperability standards, such as IHE, HL7, DICOM, XDS and IHE, and healthcare systems such as PACS, EMR, EHR, HIS and RIS;\nPhD in Computer Vision or Image Processing applied to medical imaging\nAbout Business Unit\nIBM Watson Health is pioneering a new partnership between humanity and technology with the goal of transforming global health and revolutionizing many aspects of the medical and pharmaceutical industries, as well as government sectors. We aspire to improve lives and give hope by delivering innovation to address the worlds most pressing health challenges through data and artificial intelligence insights.\n\nYour Life @ IBM\nWhat matters to you when youre looking for your next career challenge?\n\nMaybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.\n\nImpact. Inclusion. Infinite Experiences. Do your best work ever.\n\nAbout IBM\nIBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.\n\nLocation Statement\nFor additional information about location requirements, please discuss with the recruiter following submission of your application.\n\nBeing You @ IBM\nIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.\n\nApply Now: click Apply Now"}, "414": {"company": "Liberty Mutual Insurance", "description": "Help shape the future of Data Science across Liberty!\n\nAs a technical member of the Office of Data Science (ODS), Enablement & Collaboration unit, you will work with a team of data science (DS) and machine learning (ML) experts to solve Liberty's most challenging data science problems.\n\nThe ODS was created to provide additional centralized support and expertise to DS teams across the global organization. Our projects focus on key areas of interest to multiple teams, bleeding edge research and experimentation, common tool development, and establishing best practices to ensure the scientific community at Liberty is well-positioned to rapidly meet the challenges of modern industry.\n\nIf you are interested in making an impact on an entire culture at a Fortune 100 company, the ODS is the place for you!\n\nAs a centralized group, our project scope is vast. Possible projects include:\nDesign new language models (NLP/NLU) to understand and build predictions or summaries from customer calls, claim notes, web chats, medical records, and beyond.\nDetect property hazards from aerial imagery, customer photos, geospatial data, etc. using computer vision (CV).\nExplore the advantages and limitations of privacy-preserving ML, to accelerate experimentation and better protect our customers' data.\nPush the boundaries in fundamental experimentation to boost and augment small-sample or rare-event data, transfer learning, and similar techniques.\nEngage in theoretical research in collaboration with MIT, via Liberty's investment in the MIT Quest for Intelligence, to shape the future of AI\n\nResponsibilities:\nWork on cross-functional R&D teams, including ODS and business-unit data scientists/analysts, doing hands on ML research in areas such as computer vision, natural language processing, interpretable ML, and privacy preserving ML.\nAccelerate the deployment of reproducible ML models by helping the business set and apply current best practices, including the use of open source software, container-based or serverless cloud platforms, and self-service operating models.\nDevelop common DS/ML tools and infrastructure across the business.\nSet the standards for statistical testing and experimental design, as well as other quality standards such as testing coverage, code review, etc. for data science\n\nWork with product owners and business units across Liberty to identify new opportunities where the ODS can accelerate research and development of DS and ML tools and techniques\n\nQualifications:\n\nBachelor's degree in Statistics, Economics, Computer Science, or any quantitative discipline with relevant work experience, required; advanced degree a definite plus.\nExtensive experience analyzing data and a broad understanding of core statistical and ML techniques.\nDemonstrated experience in deep learning, computer vision, natural language processing, and/or interpretable machine learning.\nDemonstrated proficiency in R or Python required.\nPossess strong analytical, strategic, project management, decision-making and problem-solving skills.\nDemonstrated ability to perform high quality work both independently and collaboratively.\nBenefits:\nWe value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits\nOverview:\nAt Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.\nWe're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.\nApply Now: click Apply Now"}, "415": {"company": "Travelers", "description": "Company Information\nSolid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n\nJob Summary\nInnovation is at the core of everything we do. We continue to ask ourselves, whats next? as we navigate the ever-changing insurance landscape. Continuing our journey toward the cutting-edge, we are looking for a forward-thinking individual that thrives in ambiguity, who believes that with every challenge comes a new opportunity for solutions. Thought leaders in the field of Data Science in emerging technology are at the core what we strive for to deliver business impact across the enterprise. In this role, you will work with a multidisciplinary team to design, develop & create analytical solutions through applications of Data Mining, Machine Learning, Artificial Intelligence and Emerging Technologies. The ideal candidate will increase the maturity of the groups current analytical capabilities by progressing from traditional Predictive Modeling to true machine intelligence, and take advantage of emerging technologies around Data Science and AI. This role thrives on change, exercises influence across the enterprise and can make sense of uncertainty. This candidate will be expected to be hands on as well as guide and mentor new modelers in the team.\n\nPrimary Job Duties & Responsibilities\nUnderstand business needs and apply Data Science/AI/Machine Learning technology to solve real-world business problems within and across business areas Ability to build and optimize models using machine learning techniques including feature selection & engineering, boosting, deep learning and ensembles\nAddress pain points of the business and provide additional insights across domains like Regression, Classification, Machine Vision, Natural Language Processing, Deep Learning, and/or statistical modeling\nAs a technical lead candidate will be working with various cross functional teams across the enterprise such as data engineers, data scientists, statisticians, actuaries, application developers, and several other key leadership roles\nAnalyze source data, working with structured and unstructured data (internal and external data)\nManipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships, and trends\nExtend companys data with third party sources of information when needed\nWill manage one or more initiatives simultaneously across Lines of Businesses and/or functions\nUnderstands Enterprise business needs and applies AI/Machine Learning technology to solve real-world problems that benefit horizontal goals & objectives\nPresent analysis and recommendations to a diverse group of enterprise-wide stakeholders.\nPotential to manage employees\nMinimum Qualifications\nPhD STEM (Science, Technology, Engineering, Mathematics) degree with 1 years experience or Masters STEM degree with 4 years experience or Bachelor's STEM degree with 6 yrs required. Moderate working knowledge of modeling/research/analytics or actuarial required. Relevant statistical analysis work experience required.\n\nEducation, Work Experience & Knowledge\nRelevant work experience in research and/or advanced analytic work (e.g. predictive modeling) in the insurance industry preferred.\n\nJob Specific & Technical Skills & Competencies\nAbility to read/revise/review a statistical software program (e.g. R, SAS, SPSS).\nAbility to develop advanced models and interpret model results.\nUnderstanding of advanced statistics underlying data models. Ability to apply emerging statistical procedures to work.\nWillingness to innovate with the possibility of failure.\nStrong communication, collaboration and relationship building skills with the ability to present and translate complex information to very senior leadership and non-technical teams in relevant business terms.\nExhibits high levels of learning agility in which they seek out and learn from unfamiliar experiences and then apply those lessons to succeed in the next new situation.\nAbility to leverage business knowledge to determine approaches to execution.\nAbility to take action in solving problems while exhibiting judgment and a realistic understanding of issues; ability to use reason; review facts, identify inconsistencies and weigh options; ability to make logical and timely decisions that address the right issues.\nPreferred Qualifications\n2+ years of experience in one or more of the following: Machine Learning Libraries, Computer Vision, Speech Recognition and Natural Language Processing\n4+ years of experience in programming with Python and/or R\n2+ years of experience in handling data and working with database tools, e.g., SQL, Hadoop or Spark\nProven ability to work creatively and analytically in a problem-solving environment\nExperience with Deep Learning Tools such as TensorFlow\nExperience with contributing to open source projects\nEqual Employment Opportunity Statement\nTravelers is an equal opportunity employer.\nApply Now: click Apply Now"}, "416": {"company": "VMLY&R", "description": "At VMLY&R, we create connected brands. We resist the usual ways of seeing, doing and thinking \u2014 harnessing creativity, technology and culture \u2014 to reimagine the entire connected consumer experience. Our goal? To create work that becomes part of people\u2019s lives, to drive value for our clients and, in the best of cases, to impact the world.\n\nThe Senior Data Scientist/Social Scientist will be based in VMLY&R\u2019s offices in Washington, DC, but may work at times from the client site in Prince George\u2019s County, MD. S/he will be a core member of our data science team manipulating large datasets, developing and building analytical tools and models, and creating and presenting challenging research materials to audiences of all levels and backgrounds, both internally and externally. S/he will be a key member of the team designing and building models and analyses that drive smart insights and at times will work across all partners on the Integrated Communications Contract team, including advertising and creative agencies, media buying entities, and niche communications firms. This position is expected to continue after the decennial Census is complete in 2020, and the data science team will transition to other projects and clients.\n\nMost critically, we are looking for an unmatched team player who are excited about being part of a once-in-a-career effort to mold the delivery of the largest social marketing campaign in the country\u2019s history. Background and specific areas of expertise are less important than drive, initiative, and willingness to take on items outside of your day-to-day role.\n\nResponsibilities\nCreate new analyses and data visualizations\nDevelop, select and deploy robust statistical and analytical tools and techniques\nTurn complex client problems into robust data solutions and fully owning the client\u2019s research needs from conception to delivery of final product\nWork with integrated teams of advertising creatives, researchers, social scientists and consultants to create a strong data-driven point of view while addressing all partners\u2019 needs\nConceptualize and build predictive models from large public use and survey data sets to address client needs; translate findings into smart, actionable, and timely insights\nUse and evaluate clustering techniques to identify actionable segments within large datasets and provide flexible profiling for external validation of the results\nAuthor clear, concise and technically sophisticated reports and presenting findings to clients (internal and external) of all levels and backgrounds; proactively identifying opportunities to build from these findings to next steps or new applications\nWork across the Integrated Communications Contract team on contract management efforts, including proposal writing, pricing and scoping projects\nAs part of the WPP Group, VMLY&R offers one of the best overall compensation packages in the business.\n\nRequired Skills & Experience\nA minimum of 5+ years\u2019 professional experience working in quantitative research\nBA and/or MA required, PhD preferred in a related field (economics, political science, communication, sociology, computer science, statistics, applied math)\nProven success working with large and complex datasets, especially Census or other large government datasets\nProficiency with SQL\nProficiency with statistical programs including R, Python and/or SAS\nExperience with Tableau, GIS or other mapping or data visualization platforms\nProven success in consulting environments presenting findings using presentation and/or data visualization software\nExperience working on quantitative research projects as part of a larger research team and within a federal government environment\nVMLY&R is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, gender identity, sexual orientation, national origin, disability status, protected veteran status, or any other characteristic protected by law. VMLY&R is a M/F Disabled and Vet EEO/AA Employer.\nStart your job application: click Apply Now"}, "417": {"company": "Provisur Technologies", "description": "Ingenuity Center Manager - Food Scientist\n\nPOSITION SUMMARY/PURPOSE:\n\nManage all areas of the Product Development and Technology Center including the production floor, food science lab, and kitchen. Responsible for upkeep of equipment, facility, and resources associated within the Center. Study and define interactions of various food products with processing equipment. Act as resource support for customers and sales for equipment applications in food processing. Analyze and determine engineering modifications and changes needed to fulfill customers' requirements for equipment. Work with engineering on necessary changes. Manage all areas of food science interaction at the Ingenuity Center including; the production floor, food science laboratory, and preparation/demonstration kitchen. Follow all safety and standard manufacturing practices and adhere to government regulations. Interact with customers in a professional manner. Document and archive all data related to product and equipment testing.\n\nPOSITION ACCOUNTABILITIES:\nSpecify and/or procure raw material/ingredients for product testing. Interact with internal/external customers. Ability to operate all required equipment for product tests. Organize and record all pertinent test data. Prepare test report including statistical analysis if needed.\nManage food science laboratory, including external testing when required. Analyze laboratory data and document findings.\nManage PDTC facility upkeep; clean facility and equipment after product runs, dispose of product, conduct preventative maintenance of equipment and conduct basic troubleshooting of mechanical systems and equipment.\nManage preparation kitchen and demonstration kitchen. Prepare product samples for evaluation. Keep kitchens clean and organized. Maintain appliances that are up to date and utilized at our customer.\nEducate and enforce good manufacturing practices (GMP\u2019s) for all personnel working/entering the Ingenuity Center\nEstablish/follow and assure compliance to sanitation standard operating procedures (SSOP\u2019s).\nLab Assays - Perform bone digestions on meat and poultry samples.\nAs a manager in the organization, it is your responsibility to optimize the work of assigned department(s) and balance the workload appropriately; develop and implement efficiencies to improve the workflow; develop and oversee the training, development and evaluation of assigned staff and ensure smooth teamwork with other functions; and, ensure high quality standards are established and maintained.\nAdditionally, it is your responsibility to accomplish your own work in an organized, timely manner; and effectively manage approved budgets; generate and solicit continuous improvement ideas from your team and develop implementation plans; take personal responsibility for service excellence, sustainability and safe working practices; and, understand and ensure compliance with our Principles & Values and all company policies and procedures.\nJOB KNOWLEDGE/SKILLS AND ABILITIES:\nKnowledge of food production equipment and processes; especially for meat and poultry.\nKnowledge of and ability to perform standard lab tests on food products.\nAbility to give a technical presentation to customers.\nAdvanced computing skills: MS-Office, Windows, Outlook, Pivot Tables, and Charts with the ability to prepare technical presentation.\nStrong technical background with an understanding of hydraulics, electrical and electronics, pneumatics, technical drawing and mechanical design.\nStrong interpersonal skills with the ability to communicate at all levels and with customers.\nAbility to multi-task and establish priorities while maintaining composure.\nAbility to motivate, manage and develop workforce.\nAbility to set and work within department budget.\nAbility to supervise and develop others and delegate duties.\nHigh standards of professional ethics and business conduct\nStrong organizational and leadership skills.\nPositive attitude, pride in work, professional demeanor, and able to work well independently or in a collaborative team environment.\nPROFESSIONAL WORK EXPERIENCE:\n10 years of experience as a food scientist in meat and poultry industry (supplier or processor).\n5 years supervisory experience.\nEDUCATIONAL AND/OR TRAINING REQUIREMENT:\nMinimum of Bachelor\u2019s Degree in Food Science\nMaster\u2019s Degree preferred.\n\nApply Now: click Apply Now"}, "418": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking an Senior Data Scientist who wants to develop innovative solutions for customers and internal product teams. We look to rapidly prototype solutions and deploy the most promising of them. We identify and leverage the latest techniques (fast.ai is a team favorite) so that our customers can stay one step ahead. On every project you'll learn something new (and likely teach us something as well). If that sounds appealing to you - we'd love to chat.\n\nResponsibilities include:\nDevelop solutions spanning multiple subject areas, from NLP to Image and Video.\nMaintain awareness of state-of-the-art machine learning and techniques, methods and platforms, including commercial and open source.\nImplement, configure and test machine learning and deep learning libraries and platforms (e.g. fast.ai, TensorFlow, Keras, XGBoost, LightGBM).\nTest solutions on AWS using services such as SageMaker, EC2, and Snowball Edge.\nWrite blog posts and presentations that clearly communicate complex machine learning concepts to both technical and non-technical audiences.\nContribute to visually-appealing, web-enabled prototype applications that illustrate relevant machine learning capabilities.\nBasic Qualifications:\nExperience with Python (2+ years).\nExperience with machine learning or statistics (2+ years).\nAbility to work both independently and collaboratively.\nHigh levels of curiosity, creativity, and problem-solving capabilities.\nStrong written and verbal communication skills.\nComfortable navigating the command line.\nDesired Skills:\nResearch experience in Machine Learning specific to Natural Language Processing, Computer Vision, or deep learning.\nExperience with managing data and creating algorithms using AWS.\nExperience with R, Java, or other programming languages.\nSecurity Clearance:\nActive TS/SCI with polygraph required.\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nApply Now: click Apply Now"}, "419": {"company": "States Title", "description": "About us:\n\nWant to infuse a $25B sector of the insurance and real estate industry with predictive analytics and a tech-forward customer experience? States Title is intelligently transforming closings by applying machine intelligence to the age-old processes and procedures in the $25B Title and Settlement industry. Our streamlined, efficient algorithms have revolutionized the title and escrow process and allowed us to scale rapidly. We are poised to transform this industry, repurposing the billions wasted in rote, manual tasks to make homeownership easier and less risky, helping people invest time and money into more meaningful parts of their lives.\n\nYou're fired up to:\nDesign, build, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services.\nBuild a next-generation enterprise data lake with raw production data as source of truth and always-on, versioned data pipelines.\nDocument data sources, data pipelines, and data infrastructure to share knowledge and understanding of the solutions being implemented.\nWork with teams across the organization to assist with data-related technical issues and support their data infrastructure needs.\nYou definitely have:\nExperience with scripting languages, particularly Python.\nExperience with cloud services, particularly Azure: Blob Storage, VMs, Data Factory, SQL Data Warehouse, HDInsight, etc.\nAbility to write complex SQL joins in your sleep and experience with stored procedures, triggers, etc.\nExperience with the command line for Linux systems (also preferably Windows).\nKnowledge of database modeling and data warehousing concepts.\nYou might even have:\nExperience with big data platforms and tools like Spark, Hive, Presto, Kafka, etc.\nExperience with compiled languages like Java, Scala, C#, etc.\nFamiliarity with ML concepts (supervised learning, feature engineering, etc) and experience with ML frameworks (Scikit-learn, TensorFlow, SparkML, etc).\nFamiliarity with data lake architecture.\nKnowledge of DevOps practices and experience with related tooling (containers, infrastructure-as-code, observability, etc).\nWe want the work you do here to be the best work of your life.\n\nWe believe the most valuable investment we can make - and the greatest boost we can give to your career - is to build an outstanding team of colleagues who are passionate about our mission.\n\nWe currently offer the following benefits and will continually evolve them with the goal of efficiently attracting, retaining, and leveraging the very highest quality talent.\nOur passionate, capable team will always be our #1 benefit\nLearn something new every day\nGet more done than you would anywhere else\nHighly competitive salaries and stock option grants\nHealth, dental, and vision benefits for you and your family\nFlexible work hours\nUnlimited vacation policy\nA modern, helpful 401(k) plan\nWellness and commuter benefits\nTo apply to this job, click Apply Now"}, "420": {"company": "PayPal", "description": "Minimum Qualifications:\nBS/BA degree in related field required or equivalent professional work-related experience.\n3+ years related professional experience or masters degree and 1+ year.\nExperience in online fraud or consumer risk management preferred\nResponsibilities:\nWorks on assignments that are of intermediate complexity with multiple steps in execution, and guided by generally defined processes and project requirements\nFocuses primarily on completing short-term goals of a project efficiently and effectively\nPartner with Risk Analysts and provide exceptional global solutions\nFocuses primarily on how to achieve overall analytic objectives of a project with speed and quality\nSuggests ideas for operational plans and objectives\nIdentify glitches in processes and tools and develop and execute solutions to overcome general issues and obstacles with little supervision.\nLearning in-depth analysis of alternatives and applying specialized knowledge\nSeeks improvement within defined tasks. Understands, evaluates, and executes improvement ideas from managers, stakeholders and partners\nRequirements:\nHigh proficiency in fundamental technical skills (Programming language like Java/C/C++; scripting language like Perl/Python; strong UNIX background; working knowledge of Hadoop, Map-Reduce, Hive, Pig, R; data warehouse skills)\nHas working knowledge analytic tools, processes, and methodologies to achieve the expected results with minimum supervision\nHas a good understanding of Risk business trends and directions to be able to put own work in the broad business context\nData driven, and results oriented with positive outlook\nDemonstrates effective verbal and written communication skills on a defined set of technical topics. Articulately expresses technical ideas and appropriately requests clarification when questions arise. Asks open-ended questions\nInterfaces primarily with own team to get own job done or cross-functional teams when needed.\nBe transparent and accountable\nBe data-driven and outcome-focused\nPersevere but know when to change course\nApply Now: click Apply Now"}, "421": {"company": "Covenant Eyes", "description": "Data Science plays a crucial role within our organization. If you are actively seeking opportunities within the Data Sciences field, we would love to hear from you!\n\nThe Data Scientist is responsible for researching, designing, and building software solutions to data-rich problems using data science techniques; including machine learning. This includes identifying business trends and problems through complex big data analysis as well as interpreting results from multiple sources using a variety of techniques. These techniques can range from simple data aggregation via statistical analysis to complex data mining independently.\n\nExperience we look for in a Data Scientist:\n\n\u00b7 Advanced degree in data science or machine learning fields, or equivalent experience\n\n\u00b7 Several years of hands on experience processing and analyzing big data\n\n\u00b7 Proven ability to discover problems and produce algorithmic solutions\n\n\u00b7 Experience working with machine learning for image recognition and related technologies preferred\n\nPlease feel free to submit your cover letter and resume for review.\nStart your job application: click Apply Now"}, "422": {"company": "Agoda", "description": "Working Location: Bangkok, Thailand\n\nWe welcome both local and international applications for this role. Full visa sponsorship and relocation assistance available for eligible candidates.\n\nOverview\n\nPart of Booking Holdings (BKNG), Agoda is part of largest Online Travel Agency (OTA) worldwide and the largest and fastest growing OTA in Asia\n\nWe are looking for ambitious and agile data scientists that would like to seize the opportunity to work on some of the most challenging productive machine learning and big data platforms worldwide, processing some 600B events every day and making some 5B predictions.\n\nAs part of the front-end and personalization team you will be exposed to real-world challenges such as: predicting customer intents in real time, ranking search results to maximize lifetime value, personalizing supplier and user generated content, classifying unstructured data such as images and text, making personalized recommendations, discovering insights from big data and innovating the user experience. To tackle these challenges, you will have the opportunity to work on one of the world's largest ML infrastructure employing dozens of GPUs working in parallel, 30K+ CPU cores and 150T of memory.\n\nAgodans come from over 70 countries: It's an incredible technical creative melting pot of talents pin picked from all corners of the planet, and it happens from one of the most exciting and vibrant places in the world today - Bangkok, Thailand.\n\nYour voice will be heard, you career will make a leap, and you will be able to make a difference in a business that touches many millions in every hour of the day!\n\nResponsibilities:\nDesign, code, experiment and implement models and algorithms to maximize customer engagement and business outcomes.\nMine a big data of hundreds of millions of customers and more than 600M daily user generated events and discover actionable insights to drive improvements and innovation.\nWork with developers and a variety of business owners to deliver daily results with the best quality.\nResearch discover and harness new ideas that can make a difference.\nQualifications:\n\nThe Musts\n3+ years hands-on data science experience.\nExcellent understanding of AI/ML/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks.\nSignificant proficiency in SQL and languages like Python, PySpark and/or Scala.\nCan lead, work independently as well as play a key role in a team.\nGood communication and interpersonal skills for working in a multicultural work environment.\nGreat if you have them\nPhD or MSc in Computer Science / Operations Research / Statistics or other quantitative fields\nExperience in NLP, image processing and/or recommendation systems\nHands on experience in data engineering, working with big data framework like Spark/Hadoop\nExperience in data science for e-commerce and/or OTA\n#sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #sydney #melbourne #perth #vienna #minsk #brussels #saopaolo #toronto #vancouver #montreal #copenhagen #estonia #helsinki #paris #nice #berlin #dublin #munich #hamburg #stuttgart #hongkong #budapest #telaviv #milan #rome #tokyo #osaka #amsterdam #oslo #warsaw #krakow #bucharest #moscow #singapore #seoul #barcelona #madrid #stockholm #taipei #london #manchester #liverpool #hcmc #yokohama #jerusalem #venice #florence #zurich #geneva #basel #beijing #shanghai #ENG #IT #4 #LI-PK1\nApply Now: click Apply Now"}, "423": {"company": "IntraEdge", "description": "Data Engineer\n9920\nScottsdale,\n3/27/2019 1:46:38 PM\n\nApplication Development\nContractor - W2\n\nJob Description\nData Engineer / Lead\n\n4-5 years of experience in ETL, SQL, Python, Data Management and Spark and strong fundamentals in distributed environments\nReal project implementations with Big Data technologies based on Spark\nExperience working on Serverless technologies\nExperience implementing NoSQL technologies - Mongo or Cassandra\nExperience with AWS cloud services: Lambda, S3, Glue, Redshift, and Athena, or their open source equivalent (Zeppelin, Presto, etc)\nData storage formats - Parquet, JSON, AVRO etc.\nExperience with real-time data sources and message ingestion for processing by filtering, aggregating, and preparing the data for analysis using technologies such as Spark Streaming and Kafka, AWS Kinesis, Firehose etc.\nExperience with data pipelining\nUnderstanding of best practices within the development process\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management\nCI/CD and DevOps tools such as BitBucket/Git, Bamboo, and Maven\nAWS technologies - Cloudwatch, CloudFormation, Security (IAM)\nAWS certification\n\nJob Requirements\n\nTo apply to this job, click Apply Now"}, "424": {"company": "Shape Security", "description": "About Shape Security:\nWe are security and web experts, pioneers, evangelists, and elite researchers. We believe in the power of the Internet to be a positive force; our mission is to protect every website and mobile app from cybercriminals. Shape\u2019s founders fought cybercrime at the Pentagon, Google, and other leading security companies. We are backed by some of the most prominent leaders and investors in the technology industry including Kleiner Perkins, Google Ventures, and more. Come be a part of our unparalleled team that is responsible for making the Internet a safer place for everyone.\n\nJob Description:\nShape Security is seeking a driven, analytical and highly professional individual to help shape the future of what we build at Shape Security. You will enjoy working with one of the richest data sets in the world, cutting edge technology, and the ability to see your insights turned into real products on a regular basis. The perfect candidate will have a background in a quantitative or technical field, will have experience working with large data sets, and is passionate about solving tactical problems day to day while keeping an eye on long term product strategy. You are focused on results, a self-starter, and have demonstrated success in using analytics to drive the understanding, growth, and success of a product.\n\nToday, Shape identifies and stops automated attacks and fraud against web and mobile applications of the Fortune Global 2000. Tomorrow, we\u2019ll need to fight even more sophisticated adversaries, while helping human users to have ever more frictionless experience.\n\nIf you have a passion for deriving actionable insights from complex big data sets, and love to help the product team make data-driven decisions, then we\u2019d love to talk with you.\n\nResponsibilities:\n\nAnalyze large volumes of web and mobile traffic of Global 2000 organizations both on a regular and ad-hoc basis, including exploratory analysis that uncovers current customer pain and future product opportunities\nBuilding and analyzing dashboards and reports that produce meaningful insights; define, evaluate and monitor key metrics that contributes to customer success;\nPerform cohort and sensitivity analysis that helps us identify key levers that maximize customer delight\nBe a strong voice for a data-informed point of view when working with cross functional teams (product, engineering, professional service, sales)\n\nRequirements:\n\n5+ years analytical experience working with large-scale datasets.\nStrong analytical skills including the ability to manipulate, model, interpret and visualize large quantities of structured data.\nA passion to use data to help inform product decisions.\nA strong understanding of experimentation and statistical analysis.\nProficiency in SQL and in at least one major programming language (e.g. Python, Java and/or C/C++.).\nProficiency in packages/tools/frameworks for data analytics and visualization (e.g. Jupyter notebooks, Pandas, Kibana, d3.js) highly preferred.\nA scrappy yet meticulous approach, and a love for problem solving!\nStrong interpersonal skills, personable, and persistent. Self-motivated, able to work well both independently and as part of an agile team.\nDemonstrated enthusiasm and capacity to learn new technologies quickly.\nBachelor\u2019s degree in a quantitative discipline such as Computer Science, Engineering, Statistics, Economics, or Operations Research required.\nStart your job application: click Apply Now"}, "425": {"company": "Northwest FCU", "description": "The Senior Data Intelligence Specialist operates as a member of the Data Operations Team. Supports the entire Credit Union\u2019s analysis and data needs. The successful candidate will take ownership of understanding the organizations strategic business needs, running analysis and providing highly effective feedback information for the entire Credit Union. They will have a strong understanding of the data, and a high level of understanding of the Credit Union\u2019s needs to be able to provide information for decision making at all levels.\n\nDUTIES& RESPONSIBILITIES:\nCollaborate with stakeholders throughout the organization to identify opportunities for leveraging data to drive business solutions\nResearching, designing, implementing, and deploying scalable data analytics vision and machine learning solutions to challenge various business issues\nMine and analyze data to drive optimization and improvement of product development, marketing techniques and business strategies\nCommunicate results of analysis and ideas to key decision makers\nUnderstand the Credit Union\u2019s strategic goals to be able to provide analysis based on data exploration\nHelp the Credit Union to evolve into an analytical and data driven culture\nWork closely with other team members to develop standards, promote efficiency, and prioritize the work load\nPreform Analysis using Python and R\nDevelop reports and dashboards using the Credit Union\u2019s BI Tools\nDevelop SQL Queries for reports and dashboards\nAnalyzing relational and transactional databases to provide data analysis\nCreate documentation around processes and procedures and manage code reviews\nApply industry standards best practices to development activities\nWork in an agile environment (methodology)\nWork with data team to ensure solutions are successfully executed, within agreed upon time frames\nMentor Junior Team Members to provide expertise on statistical and mathematical concepts\nRemain current on research techniques and become familiar with state of the art tools applicable to your function\nREQUIREMENTS:\n5 - 8 years of experience manipulating data sets and building statistical models\nBachelor\u2019s degree in Analytics, Economics, Finance, Mathematics or related field\nExperience using statistical computer languages (R, Python, SAS etc.) to manipulate data and draw insights from large data sets\nSubject matter expertise in data modeling\nStrategic thinking and analytical capability\nAbility to translate complex technical topics into business solutions and strategies\nExperience working with natural language processing and machine learning libraries\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, etc.\nA drive to learn and master new technologies and techniques\nAble to understand various data structures and common methods in data transformation\nExperience writing SQL, preferably in SQL Server or Hive (Hadoop)\nExperience with a BI analysis and reporting tools, preferably IBM Cognos Analytics or Tableau\nExceptional analytical, problem solving, and time management skills required Strong attention to detail\nHighly proficient in Microsoft Office and expert level understanding of Excel\nExcellent quantitative and qualitative analysis skills\nAbility to handle multiple projects with tight deadlines and adaptable to changing priorities\nAbility to work both independently and within a team environment, to build good working relationships and effectively manage multiple tasks\nExcellent interpersonal and communication skills, oral and written\nAdvance knowledge of Financial Institutions and Systems\nExperience with Hadoop Ecosystem and Pentaho\nApply Now: click Apply Now"}, "426": {"company": "Silicon Valley Bank", "description": "Silicon Valley Bank is the market\nleader in providing financial solutions to the world\u2019s most innovative\ncompanies, leaders and investors. Our clients are the game changers\nfueling the global innovation economy and transforming the way we live and\nwork. SVB has been an incredible growth story over the last 30 years and\ncontinues to grow and expand internationally. Come join a\ngrowing, global commercial bank at the heart of the innovation economy where\nyou will be able to help bring our clients\u2019 world-changing ideas to life.\n\nThe Enterprise Business Analytics\ngroup at SVB is responsible for providing analytical business solutions to the\nbank. We translate data into actionable analytical solutions and promote\ninformation-based decision making to support SVB's strategic goals. One\nresponsibility of the group is to create an insight foundation that is\nleveraged to develop analytical solutions and predictive modeling. In order to\ndesign and create information foundation, data scientists identify and explore\nrelevant data sources; then create business understanding of the data by\napplying data mining techniques.\n\nThe Data scientist in this role will\nbe responsible for complex data transformations and data mining efforts.\nThey will build processes for the team to be able to use insights effectively\nand efficiently.\nResponsible\nfor end to end Cards insight creation, support in Card campaign,\ndeveloping & building card related insights\nResponsible\nfor managing/maintaining Card programs i.e. Card Opportunities, Portfolio\nmanagement, Value at risk, Card Explorer, Spend program etc.\nData\nmining and developing relevant data transformation logic\nDesigning\nprocesses to integrate data from multiple sources to facilitate client\ncentric advanced analytics\nUnderstand\nand connect the dots to different aspects of Card program.\nBuild,\ndesign, and develop the insights for decision making as well as building/assisting\nthe dashboards design for Business Users.\nResponsible\nfor identifying and exploring all relevant data sources, generate the\nunderstanding, develop the logic to transforms into insights that can be\nleveraged into decision making and other needs.\nDocumenting\ndata transformation logic\nDeveloping\nefficient, scalable and repeatable processes to transform data on regular\nbasis\nCommunicating\nwith IT partners to share selected transformation processes by\nfacilitating and reviewing business requirements\nDesign,\nbuild, develop and maintain the Analytical solutions to understand Card\nClients behavior.\nDevelop\nanalytical solutions to recommend Card product team to produce meaningful\nresults.\nPartnering\nwith other data scientists/business analysts to make them familiar with\nthe transformed information so that it can be appropriately used by other\nanalysts and statisticians\nManaging\nprocesses designed and developed by the information foundation team\nUsing\nbest practices framework to ensure data quality and reconciliation checks\nare in place and are transparent to our users\nLeveraging\ncommunication skills to collaborate effectively with analysts across SVB\nEvaluating\neffectiveness of the transformation process and delivered information by\nworking with users of information\nPartnering\nwith business groups to understand the Business case/Use case to\ndevelop/design best-in-class analytical solution(s).\nAbility\nto research external insights and blend with internal insights to create\nand understanding of the market place (Clients/Prospects).\n#LI-MS1\nSolid\nunderstanding of writing and understanding of complex SQL queries\nExtensive\nknowledge and experience in Oracle SQL, PLSQL, and SAS tools/techniques\nDemonstrated\nexperience with the data mining tools SAS/Anaconda and SQL preferably\nthrough Oracle PL/SQL.\nStrong\nbackground in SAS programming and SQL coding is preferred\nExperience\ntransform business specifications and requirements into well documented\nand scripted SQL, PL/SQL processes.\nAbility\nto develop and enhance complex PL/SQL scripts, queries, and stored\nprocedures and ETL processes\nProven\nDocumentation (technical and user documentation) and Verbal and written\nCommunication skills\nGood\nunderstanding of BI Methodologies and Practice\nExperience\nwith systems integration, building system models by combining model\ncomponents and testing the integrity of modeling systems, proficient with\nmodel and systems implementation testing\nKnowledge\nof Data Governance and DQ framework is a plus\nBackground\nin data management in Banking/Finance industry is preferred\nExperience\nwith ETL and data modeling tools is a plus\nStrong\nanalytical and problem solving skills\nDemonstrated\nability to self-manage and multitask in a dynamic, ever-changing environment\nEffective\ntime management and organizational skills\nFlexibility\nto work/manage variety of projects\nBachelor/Masters\nin Computer Science, Finance, Accounting, Economics, Statistics or\noperational research\nWorking\nknowledge with Tableau is a plus\n6\nyears of experience in analytics and/or business intelligence space\nTo apply to this job, click Apply Now"}, "427": {"company": "IntraEdge", "description": "Machine Learning Engineer 10334 Phoenix, AZ 10/29/2019 7:38:00 PM\nIT\nContractor - W2\nJob Description\n*Understand the business problem and convert that problem into the Machine Learning algorithms. *Identify the various source of data, understand its relationships, connect it up and bring the data into common platform using ETL process, and perform data exploration using python IDE, SQL queries and BI tools like Tableau. *Use BigData Stack like Spark, Hadoop, Hive, to connect it up with the huge volumes of data, different Varieties of data, relational SQL and No-SQL databases and bring to the common place to explore to discover useful hidden patterns using analytics tools and techniques. *Perform Data Exploration to get the business insights from data, by using statistical techniques like Univariate, Bivariate, Multivariate and Cross Tables analysis and correlation techniques, prepare statistics to explore and evaluate the importance of the data and its features. Perform Data Pre-Processing to address outliers, encode variables to suit to the Machine learning algorithm going to be used. *Identify Machine learning stack more suitable to the problem in hand and data identified to represent the problem. *Use the various Machine learning models For Linear Classification, use techniques like Logistic regression binary and multi class classifications, Support vector machine (Maximum margin classifier) and Kernel tricks making non-Liner to linear). *For Non-Linear Classifications use techniques like KNN K-Nearest neighbors, Using trees for classifications, Neural networks and Na\u00efve bayes classifiers (Probabilistic classifier). *Use Linear regression models to predict the continuous dependent and use clustering techniques like K-Means and hierarchical to understand non-labeled data. *Use all GLM (generalized linear models), Tree models, Random forests, xgboost, use all ensemble and stack them together in stacking methods to improve the predictability of the model. *Train, test and evaluate the developed model. *Use various techniques like K-Fold Cross validation, batch normalization, batch and Stochastic gradient descent, Optimization techniques like momentum, RMS prop, Adam Optimization and Regularization techniques Ridge & Lasso. *Use techniques to reduce variance and reduce bias of the model. *Use NLP (Natural Language processing) techniques like word2Vector, Glove, and other sequence models to include text data related features into the model. *Own and conduct A/B tests for exploring various ideas to evaluate different models developed, understand how data is changed over time using time serious analysis ARIMA (Autoregressive integrated moving average) models *Use Markov chain models to track the events and predicting the probabilities of the events happenings *Use statics techniques Chi-Squire test, t-test, ANOVA analysis of variance etc. *Use basic mathematical concepts such as Bios and Variance, Probability, P-value, correlation and PCA and other sampling techniques.\nJob Requirements\n*Understand the business problem and convert that problem into the Machine Learning algorithms. *Identify the various source of data, understand its relationships, connect it up and bring the data into common platform using ETL process, and perform data exploration using python IDE, SQL queries and BI tools like Tableau. *Use BigData Stack like Spark, Hadoop, Hive, to connect it up with the huge volumes of data, different Varieties of data, relational SQL and No-SQL databases and bring to the common place to explore to discover useful hidden patterns using analytics tools and techniques. *Perform Data Exploration to get the business insights from data, by using statistical techniques like Univariate, Bivariate, Multivariate and Cross Tables analysis and correlation techniques, prepare statistics to explore and evaluate the importance of the data and its features. Perform Data Pre-Processing to address outliers, encode variables to suit to the Machine learning algorithm going to be used. *Identify Machine learning stack more suitable to the problem in hand and data identified to represent the problem. *Use the various Machine learning models For Linear Classification, use techniques like Logistic regression binary and multi class classifications, Support vector machine (Maximum margin classifier) and Kernel tricks making non-Liner to linear). *For Non-Linear Classifications use techniques like KNN K-Nearest neighbors, Using trees for classifications, Neural networks and Na\u00efve bayes classifiers (Probabilistic classifier). *Use Linear regression models to predict the continuous dependent and use clustering techniques like K-Means and hierarchical to understand non-labeled data. *Use all GLM (generalized linear models), Tree models, Random forests, xgboost, use all ensemble and stack them together in stacking methods to improve the predictability of the model. *Train, test and evaluate the developed model. *Use various techniques like K-Fold Cross validation, batch normalization, batch and Stochastic gradient descent, Optimization techniques like momentum, RMS prop, Adam Optimization and Regularization techniques Ridge & Lasso. *Use techniques to reduce variance and reduce bias of the model. *Use NLP (Natural Language processing) techniques like word2Vector, Glove, and other sequence models to include text data related features into the model. *Own and conduct A/B tests for exploring various ideas to evaluate different models developed, understand how data is changed over time using time serious analysis ARIMA (Autoregressive integrated moving average) models *Use Markov chain models to track the events and predicting the probabilities of the events happenings *Use statics techniques Chi-Squire test, t-test, ANOVA analysis of variance etc. *Use basic mathematical concepts such as Bios and Variance, Probability, P-value, correlation and PCA and other sampling techniques.\nStart your job application: click Apply Now"}, "428": {"company": "PayPal", "description": "We are seeking world-class problem solvers who have a passion for data and a relentless focus on execution and delivery. You will be most successful with a healthy combination of both, technical skills and business acumen. As a Data Analyst you will generate insights by conducting extensive analyses of PayPals rich data. In the process, you will develop a deep understanding of the payments business, our site functionality, further strengthen your analytic, leadership and presentation skills and gain exposure to a wide variety of functional teams within PayPal.\n\nKey Responsibilities\nUnderstand how to make data visually appealing and simple to both navigate and comprehend for end-users\nAggregate data from various sources to construct streamlined data pipelines and integrate data from multiple PayPal systems\nIdentify key metrics and build exec-facing dashboards to track progress of the business and its highest priority initiatives\nIdentify key business levers, establish cause & effect, perform analyses, and communicate key findings to various stakeholders to facilitate data driven decision-making\nWork closely across the matrix with teams like Finance, Marketing, Product, Engineering and senior executives\nLead and participate in special projects/initiatives: innovate and implement large-scale quality improvements to processes and/or systems by conducting data analysis and making recommendations, troubleshooting technical issues, and refining processes around customer support\nBasic Requirements:\nGraduated, or will be graduating, with a bachelors or masters degree in Computer Science, Math, Statistics or related field\nExperience with one or multiple of the following will be highly desirable; Python, Java, Tableau, Jupyter Notebooks, Teradata, Hadoop/Hive, Oracle, JavaScript, SQL, Airflow, Linux, Perl, PHP\nExcellent understanding of computer science fundamentals, data structures, and algorithms\nDemonstrated experience, familiarity and ease with handling large data sets and crunching numbers\nInformation Retrieval (search/recommendation/classification) experience or Human Judgment/User Interface experience\nStrong written and verbal communication skills with the ability to translate complex problems into simpler terms, and effectively influence both peers and senior leadership\nPosition Location: Varies\nTo apply to this job, click Apply Now"}, "429": {"company": "Dematic", "description": "Company Overview\n\n\nDematic is a leading supplier of integrated automated technology, software and services to optimize the supply chain. Dematic employs over 7,000 skilled logistics professionals to serve its customers globally, with engineering centers and manufacturing facilities located around the world. Dematic is one brand under the KION Group of companies and has implemented more than 6,000 integrated systems for a customer base that includes small, medium and large companies doing business in a variety of market sectors.\n\nHeadquartered in Atlanta, Georgia, Dematic is a member of KION Group, a global leader in industrial trucks, related services and supply chain solutions. Across more than 100 countries worldwide, the KION Group designs, builds and supports logistics solutions that optimize material and information flow within factories, warehouses and distribution centers. The company is the largest manufacturer of industrial trucks in Europe, the second-largest producer of forklifts globally and a leading provider of warehouse automation.\n\nThe Role\n\n\nPosition Summary:\n\nThis is an exciting opportunity to join the Software Center of Excellence of Dematic. As part of this global team of software experts, you will help develop robust organizational capabilities in sales, design, engineering and support to deliver exceptional software to our customers.\n\nAs a specialist, you will own end-to-end implementation of analytics & IoT engagements with Dematic customers, while driving the services pipeline as well as be a key voice internally for the further development of the analytics services program. This is both a cross-functional role within the organization as well as a key customer interfacing role. A successful candidate will have demonstrated exceptional performance, innovation, creativity and insight in a similar role.\n\nKey Responsibilities (Problem Solving, Critical Thinking):\nWorks with customer end-users to define analytics & IoT solution requirements and works with internal team to concept, design and deliver solution\nWorks independently, within teams, and with multiple types of skillsets (business, data architect, other technical resources)\nPerforms business process analysis, mapping and design\nEnsures high quality delivery of software consulting services and overall client satisfaction\nDrives development and documentation of services\nDisplays depth of knowledge to customers during sales-phase while representing breadth and depth of Dematic solutions and expertise\nSupports the sales organization and drive pipeline generation of analytics consulting services\nWhat We Are Looking For\n\n\nEducation:\n\nBachelor's Degree and/or advanced degree\n\nKnowledge / Qualifications:\n\nThe qualifications for the position of advanced analytics & IoT include proven success in Client Management, Project Management, and Consultative Selling and Services Delivery. Other important areas of experience and skills include:\nExperience working with business users to concept, generate and deliver analytics solutions, dashboards and reporting\nOverall knowledge of MHE technologies and warehouse systems or similar domains is preferred\nSpecific domain experience and knowledge in the logistics and supply chain industries is a plus\nExcellent written and verbal communication skills including presentation skills and knowledge of software tools (MS PowerPoint, MS Visio)\nStrong leadership and customer engagement skills\nA willingness to travel in order to satisfy client needs\nExperience conducting requirements analysis, meeting with business stakeholders and applying solutions to customer challenges\nWorking knowledge of advanced analytic tools such as SAS, R, or Python is required\nWorking knowledge of data visualization tools such as Tableau, QlikView, or Domo is required\nWorking knowledge of BI (business intelligence) or analytics tools preferred\nWorking knowledge of Microsoft SQL Server and/or Oracle databases is preferred\nWorking knowledge of cloud based technologies is preferred\nAt least 3 years of experience in a related role\nStart your job application: click Apply Now"}, "430": {"company": "Guild Education", "description": "Guild is hiring for a Decision Scientist who will sit at the intersection of data, product, technology, business operations, and internal strategy, to help inform Guild's most interesting business needs. You will work across the company to serve as a thought partner and data expert to help drive data driven decisions, build algorithms and tools.\n\nAs a Decision Scientist you will:\nServe as the primary analytics partner for operating teams across the organization including Marketing, Enrollment, Partnerships, Retention Services and Student Operations to help teams make the best data informed decisions by deeply understanding trends, advising on best practices for collecting data, and building statistical models\nMine structured and unstructured data to identify trends and run descriptive, predictive, and prescriptive analyses\nAggregate data from disparate data sources to help identify areas for product, operations, and marketing growth and optimization\nWork with product and engineering teams to collect new data and ensure data is captured in a way that it can be used to help the business grow\nDesign, develop, and deploy a/b tests and algorithms to help better serve our students\nServe as a cross-functional consultant to inform strategic and operating business questions. This could include uncovering a problem, identifying data sources to quantify the problem, synthesizing findings and solutions, analyzing the business case and tradeoffs, and managing the implementation of recommendations.\nLead special projects as they are identified\nIn addition to working on the Decision and Data Science team, in this role you will collaborate with other Guild leaders including: Noah Yetter (Staff Data Engineer), Katie Corder-Paul (Director of Student Operations), and Christine Hettinger (Group Product Manager).\n\nYou are a strong fit for this role if you have:\n5+ years of experience in decision science, data science, analytics or a related technical role in a fast-paced business or start up environment\nProven business experience with a scripting language like Python or R, SQL (Redshift/Hive/Presto experience preferred), Excel/Google Sheets, and BI Tools (Looker a plus)\nAnalytical, intellectually curious, excellent problem-solver who is comfortable working with messy and unstructured data and translating it into strategic recommendations.\nStrong written and oral communication skills - you can build analytical and decision support models, synthesize recommendations, and create effective presentations for all audiences\nTeam player mindset, with strong interpersonal and influencing skills\nPassion for our mission \u2013 Guild is pioneering a new path for education as a benefit in a complicated and regulated space \u2013 success means quickly and effectively adapting your expertise\nSomething else? Wonderful, we're curious to learn more about you!\nAbout Guild:\n\nGuild is increasing economic mobility for working adults by partnering with the largest employers in the country to offer education as a benefit to their employees via our marketplace of nonprofit universities and education institutions. Guild's proprietary technology platform facilitates the administration of this innovative benefit and our team of coaches helps each employee navigate the path back to school, providing individualized support from day one through program completion.\n\nWe also just became the latest female-led company to hit a $1billion valuation and the only B-corp with those qualifications. Our Series D round was led by Ken Chenault, General Catalyst Partners chairman and former CEO of AMEX, and joined by Emerson Collective, LeadEdge Capital, and Iconiq.\n\nGuild Education is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\nTo apply to this job, click Easy Apply"}, "431": {"company": "American Family Insurance", "description": "At American Family Insurance, we\u2019re driven by our customers and employees. That\u2019s why we provide more than just a job \u2013 we provide opportunity. Whether you\u2019re already part of our team in search of a new challenge or new to our company and ready for what\u2019s next, you\u2019re in the right place. Every dream is a journey that starts with a single step. Start your journey right here. Join our team. Bring your dreams.\n\nQuick Stats:\nJob ID:\nR13317 Data Scientist III (Open)\nSummary:\nDevelops, analyzes and models operational, economic, management, accounting and other organizational data to quantify the competitive performance of business segments, evaluate potential operational changes, and design new approaches and methodologies. Analyzes organizational data to recommend solutions to new and complex problems, develops innovative strategies, quantifies the competitive performance of the organization's operations and/or markets; models and evaluates the potential impact of changes. Applies and integrates statistical, mathematical, predictive modeling and business analysis skills to manage and manipulate complex high volume data from a variety of sources.\nResponsibilities:\n\n\nTravel Requirements\nThis position requires travel up to 10% of the time\nEducation/Licenses/Designations\n\nPreferred: Master's Degree in Mathematics, Statistics, Physics, Computer Sciences or Engineering, or related field; PhD strongly preferred\n\nSpecialized Knowledge and Skills Requirements\nDemonstrated experience providing customer-driven solutions, support or service.\nAbility to work as part of a team and to communicate effectively.\nProficiency in programming languages suitable for database access, scripting, statistical analysis, and system development. Understanding of software development best practices including source control, coding standards and testing frameworks.\nDemonstrated experience communicating complex findings in a clear and concise manor to divisional management.\nDemonstrated experience developing and managing complex projects.\nExperience shaping the strategy for projects to deliver maximum business value\nDemonstrated experience formulating, approaching, and solving complex analytical problems using a quantitative, scientific approach.\nDemonstrated experience working with large, complex datasets using big data technologies and script.\nDemonstrated knowledge and understanding of managing data to scale using data summarization, query, and analysis software and tools.\nAdditional Job Information:\n\n\nDepending on qualifications, we are open to considering candidates at the appropriate level.\n\nTop candidates will have an advanced degree (PhD or MS) in Computer Science or Computer Engineering.\n\nCandidates with experience in one or more of these disciplines preferred: NLP, Image, Video, or Speech.\n\nAdditionally, the following skills are definitely a plus: cloud computing skills (open to platform, Python coding skills, Hadoop, Hive, and Spark/SQL.\n\n\nJob Description:\n\n\nPrimary Accountabilities\nCreates business application and modeling framework, for new datasets, and discovers insights and relationships from large/complex datasets through investigative research using advanced mathematical and/or statistical techniques.\nExplores data using a variety of advanced statistical techniques to proactively identify relationships, create insights and answer business questions or guide future model development.\nBuild the hypothesis, identify research data attributes and determine best approach to address business issues.\nCombines business acumen with mathematical capabilities to build complex predictive models to support business objectives.\nBuilds complex programs for running mathematical or statistical tests on data and for understanding complex relationships across attributes.\nIncorporates findings and provides industry and competitor insights as part of model development and enhancement.\nResearches and maintains awareness of industry best practices and business strategies.\nBrings new and innovative ideas and approaches to develop business solutions.\nMonitors industry and competitor trends to determine potential impact to predictive models.\nIncorporates findings and provides industry and competitor insights as part of model development and enhancement.\nIdentifies, leverages and develops expertise in emerging technologies, open source tools, and harnesses new techniques (e.g., machine learning).\nNetworks with and contributes thought leadership to the broader external analytics community. Builds awareness of leading techniques, tools, and data resources.\nAssists with complex research or analytics projects related to large, complex business initiatives.\nInteracts with company senior leadership to inform on industry trends and emerging research topics. Serves as internal expert for new areas of analytics exploration.\nStay connected: Join our Talent Community!\n\nLI:DB1\nTo apply to this job, click Apply Now"}, "432": {"company": "Flexential", "description": "Marketing Data Scientist\n\nGeneral Description\n\nThe Marketing Data Scientist, a strategic role in Flexentials expanding marketing team, will aggregate and analyze existing intelligence and source new data to optimize go-to-market efforts and inform internal cross-functional strategic initiatives to increase the overall success rate of marketing pipeline, processes and programs. Reporting to the Sr. Director of Marketing Operations, this experienced data scientist, will have a business-first acumen, deliver data insights that enable us to develop a deep understanding of the B2B enterprise technology buyers, and the ability to discover and present actionable insights to leadership to stimulate revenue growth, maximize marketing return on investment (ROI) and enhance overall customer experience.\n\nResponsibilities\nProvide marketing team with data insights to inform strategy on customer segmentation, customer and prospect targeting for marketing programs and to inform strategic new product introductions, including the identification of upsell and cross-sell opportunities\nProvide data, information, and analysis to help business decision makers to make measurably different decisions than they would have otherwise\nFind net new insights in a creative way to find that aha moment to connect with business strategy\nUse data, analytics and business acumen to help guide strategy by identifying target market profiles and a hypothesis for Ideal Customer Profile (ICP) and propensity to buy\nWillingness to support organization wide related requests at it relates to marketing data sets\nPredisposition to hypothesize, test, revise, always working to improve and evaluate models\nUse advanced techniques that integrate traditional and non-traditional datasets and method to enable analytical solutions\nApply predictive analytics, machine learning, simulation, and optimization techniques to generate management insights and enable customer-facing applications\nParticipates in building analytical solutions leveraging internal and external applications to deliver value and create competitive advantage\nIntegrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.\nConducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.\nSupports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation.\nTranslates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions.\nSkills\nDatabase Technology: Competently and independently navigate relational data systems to produce their own datasets for analytical purposes (i.e. use T-SQL to write complex queries to retrieve data from enterprise level RDBMS systems)\nScripting: Independently craft custom scripts to tackle technical challenges that arise as part of the analysis process (i.e. write a Python script to move data between a transactional system and an RDBMS system)\nMachine learning: Strong interest in machine learning principles including statistical analysis, model creation and training and application of custom analytical models\nRequirements\nBachelors Degree in finance, analytics, data science or a related field of study\nMinimum of 5 years of experience in analytics, market insights, marketing strategy or similar role within the B2B enterprise technology space IT services preferred\nStrong understanding of marketing performance concepts and attributes, as well as corporate financial key performance indicators\nExceptional project management skills, detail orientation and complex problem-solving ability\nStrong interpersonal, verbal communication and presentation skills, with ability to tailor to varying audiences and stakeholders\nA cross-functional collaborator with the ability to relentlessly drive outcomes that benefit the business\nHigh level of proficiency in and understanding of marketing and sales force automation platforms (e.g., Marketo, SFDC), business intelligence tools (e.g., Qlik, Tableau, Domo), databases (e.g., Oracle, SQL) and Microsoft Office Suite\n\nStart your job application: click Apply Now"}, "433": {"company": "Sojern", "description": "About Us:\n\nSojern's mission is to help travelers go from dream to destination by showing the right travel ad at the right time to the right person, and we use technology and our significant data advantage to make that happen.\n\nOur customers are hotels, airlines, cruise lines and tourist attractions. Sojern has delivered over $13B in traveler bookings through advertising on their behalf; Our relentless focus on driving customer value and performance has grown our customer base to more than 8500 customers and helped us become a profitable, privately-held company. In late 2018, we closed a $120M Series D funding round with Technology Crossover Ventures to further accelerate our growth.\n\nIn addition to having the upside of a Series D startup at Sojern, Sojern's work culture encourages work-life balance with traditional working hours, flexible time-off and company-wide volunteer goals. Need more convincing that Sojern is a great place to work? Check out our Glassdoor reviews!\n\nAbout the Team:\n\nThe Data Science Engineering team develops methods to optimize advertising campaigns, defines new methods for measuring campaign performance, and applies machine learning at scale with more than 5000 models in production. Example projects include:\nBayesian statistics to model conversion rates and revenue\nThompson sampling and linear programming to balance campaign objectives\nStratified sampling and power analysis to run controlled experiments\nUsing Tensorflow and XGBoost on Kubeflow to predict a traveler's propensity to convert\nAnd as a part of engineering, we own the full data product life-cycle: from analysis and prototyping to production development.\n\nThe Role:\n\nWe are looking for a Senior Data Science Engineer to drive data science impact.\n\nThe Experience We're Looking For:\nYou have hands-on experience building production-level ML and data products.\nYou have expert-level understanding of data science topics.\nYou have at least 2 years experience as a data scientist with at least 1 year of experience within the Ad Tech ecosystem.\nYou have an MS or PhD in computer science or a quantitative discipline.\nThe Skills You Bring:\nYou write production code in Python, and can reason about algorithmic efficiency.\nYou effectively communicate with data scientists, engineers and product managers.\nYou work independently to solve data science challenges.\nYou use your grit and initiative to fill in gaps and drive projects to completion.\nThe Value You Deliver:\nYou drive technical impact by making meaningful, well-designed, reusable, efficient contributions to data-driven products.\nYou mentor and participate in code/design reviews.\nYou partner with product managers to improve requirements.\nYou innovate in the context of trade-offs.\n\n\nPerks:\nOpportunities: Be part of a growing team with training and support to help you grow\nOwnership: Lead creative and challenging projects\nGive Back: We give 40 hours a year to volunteer and organize office volunteer programs with local organizations\nCulture: Strong core business values, focus on teamwork, vibrant, social and fun environment\nSnacks: Variety of snacks in the office\nMeals: Monthly catered lunches & happy hours\nCompetitive Localized Benefits\nIATA Travel Discount\nTime Off: Flexible vacation days\nAt Sojern, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\n]]>\nTo apply to this job, click Apply Now"}, "434": {"company": "PayPal", "description": "Responsibilities:\n\nRisk Analytic Data Scientists are highly motivated team players who specialize in the investigation of fraud patterns and the creation of advanced proprietary fraud prevention components. Our researchers overcome challenges presented by big data, evolving fraud techniques and new payment technologies by leveraging domain expertise, story-based analytics and advanced mining algorithms. They lead the research and accompany the development of advanced components which help drive PayPal's competitive edge by providing accurate, split-second decision making capabilities in a high-risk environment.\n\nThe ideal candidates are problem solvers, equipped with strong analytical & quantitative skills suited to approach various kinds of challenges in complex environments. Adept at creative and critical thinking, they are able to deconstruct problems and transform personal insights into large scale, state-of-the-art solutions. Candidates must be quick learners with a strong sense of personal responsibility and a technical orientation.\n\nRequirements:\nBachelors Degree in Mathematics, Physics, Computer Science, Statistics, Engineering or similar.\nStrong analytical skills\nCode writing capability in any programming language (Python, R, Java, etc.)\n1-2 years related work experience\nExperience in Machine-Learning, Data Mining or Statistics an advantage\nHadoop experience (MapReduce, PIG, Hive, Spark) an advantage\nQuick-thinker, fast learner, wide general knowledge, problem solver\nTeam worker, responsible, delivery-oriented\nStart your job application: click Apply Now"}, "435": {"company": "Maxar Technologies", "description": "Why us?\nWe build advanced algorithms to gain analytic insights from a large range of open source and government data.\nWe enable machine learning systems, automate workflow, and design and develop custom applications for unique national-security mission.\nWe operate an end-to-end predictive analytic platform unlike any other within the US Government.\nWe provide training to expand your skills and challenges to develop them.\nOur clients missions are vital to national security, so were mission-first always.\nOur work environment is relaxed business casual.\nAt our core we believe and practice social responsibility.\n\nWhat would you be doing?\nExtracting and transforming data using programming languages such as Java and Python and associated open source data analytics libraries\nAscertaining unique ways to apply algorithms to derive specific customer data analytic results\nApplying big data analytics tools to large, diverse sets of collection data to assess risk of adverse threat activities\nExtending existing algorithms as required to support customer requirements\nApplying data science methods to create and data feeds to generate models that perform predictive analytics using a variety of approaches (such are natural language processing, association rule mining, etc.)\n\nMinimum Qualifications:\nMust have a current/active TS/SCI and be willing and able to obtain a CI Polygraph\nRequires 5 or more years of relevant experience\nRequires a Bachelor's degree in Engineering, Math, Physics, Computer Science or related field.\nExperience in at least one of these languages: R, VBA, Java, C++, SQL, Python\nDevelopment experience in a Linux/Unix/Windows environment\nOccasional local travel to government sites for customer meetings and demonstrations\nExperience conducting model feasibility research and algorithm development for machine learning\nExperience with distributed datasets and experience analyzing both relational and NoSQL data structures\nExperience working in an Agile environment,\nExperience developing and testing models\nExperience with Data Analytics\n\nDesired Skills:\nGraduate experience working with probabilistic and stochastic statistical analysis or computational intelligence\nAscertaining unique ways to apply algorithms to derive specific customer specific data analytics results\nApplying big data analytics tools to large, diverse sets of collection data to assess risk of adverse threat activities\nExtending existing algorithms as required to support customer requirements\nKnowledge of technical aspects of ISR systems\nExtracting and transforming data using programming languages such as Java and Python andassociatedopensourcedata analytics libraries\nExceptional oral and written communications\nOrganizational skills and excellent attention to detail\nCapability to work effectively in a geographically distributed development team\nApply Now: click Apply Now"}, "436": {"company": "PayPal", "description": "What does Success Look Like?\n\n\nIn your role as a Senior Data-Scientist, you will:\nWork with partners to translate business challenges into Data Science problems\nMine data and extract information in PayPals Big (!) Data environment\nLeverage Machine Learning algorithms to solve real-life problems\nWork with engineers and product managers to develop and deliver E2E data science driven solutions that bring real business value\nAnalyze various kinds of data to conclude actionable insights\nCarry out independent research and innovation in new content and technological domains, while supporting existing projects\nAbout You\nMasters, PhD, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.)\nProduct/Marketing data science work experience an advantage\nCode writing capability in any programming language (Python, R, Java, Scala, etc.) and familiarity with relevant ML packages\nHadoop experience (PIG, Hive, Spark)\nStrong analytical skills\nExcellent spoken and written English\nTeam worker, responsible, delivery-oriented\nApply Now: click Apply Now"}, "437": {"company": "PayPal", "description": "Responsibilities:\n\n\u2022 Provide business requirements and collaborate with internal teams on data capture strategy that will support advanced analysis and insights on sales pattern and consumer behavior \u2022 Design and implement data-driven systems that increase sales success\n\n\u2022 Explore new data sources to add signal to existing models and develop models for new sales opportunities\n\n\u2022 Define key sales performance metrics and create dashboards and reports that provide ongoing insight to business stakeholders\n\n\u2022 Perform ad hoc and in-depth analyses and then reporting/presenting insights\n\n\u2022 Surface insights on the sales conversion pipeline, customer segmentation, and customer success\n\n\u2022 Develop advanced and predictive models such as customer segmentation, lead prioritization, churn prediction and assist sales teams in using these models\n\n\u2022 Automate analyses and build analytics data pipelines via SQL and python based ETL framework\n\n\u2022 Creating forecasts using operational and statistical tools and models \u2022 Partner with regional heads of sales to develop regional sales strategy\n\nMininum Qualifications:\n\n\u2022 MS/PhD Degree in Statistics, Mathematics, Applied Mathematics, Computer Science, Operations Research, Engineering, Economics\n\n\u2022 5+ years experience in sales analytics\n\n\u2022 Experience in querying and manipulating raw datasets for analysis\n\n\u2022 Experience with visualizations, dashboards, and reports\n\n\u2022 Experience with data modeling, machine learning algorithms, and data science techniques,\n\n\u2022 Experience explaining technical concepts and analysis implications to varied audiences and translating business objectives into analyses\n\n\u2022 Experience working independently and as a member of a cross functional team\n\n\u2022 Experience with Tableau\n\n\u2022 Experience with Salesforce.com\nApply Now: click Apply Now"}, "438": {"company": "Chan Zuckerberg Initiative", "description": "Founded by Dr. Priscilla Chan and Mark Zuckerberg in 2015, the Chan Zuckerberg Initiative (CZI) is a new kind of philanthropy that's leveraging technology to help solve some of the world's toughest challenges \u2013 from eradicating disease, to improving education, to reforming the criminal justice system. Across three core Initiative focus areas of Science, Education and Justice and Opportunity, we're pairing engineering with grantmaking, impact investing, policy work, and movement building, to help build an inclusive, just and healthy future for everyone.\n\nOur Values\n\n\nWe believe we can help build a future for everyone.\nWe aim to be daring, but humble: We look for bold ideas \u2014 regardless of structure and stage \u2014 and help them scale by pairing engineers with subject matter experts to build tools that accelerate the pace of social progress.\nWe want to learn fast, but build for the long-term: We want to iterate fast and help bring new solutions to the table, but we also realize that important breakthroughs often take decades, or even centuries.\nStay close to the real problems: We engage directly in the communities we serve because no one understands our society's challenges like those who live them every day.\nOur success is dependent on building teams that include people from different backgrounds and experiences who can challenge each other's assumptions with fresh perspectives. To that end, we look for a diverse pool of applicants including those from historically marginalized groups \u2014 women, people with disabilities, people of color, formerly incarcerated people, people who are lesbian, gay, bisexual, transgender, and/or gender nonconforming, first and second generation immigrants, veterans, and people from different socioeconomic backgrounds.\n\nThe Opportunity\n\n\nOur mission is to support science and technology that will help make it possible to cure, prevent, or manage all diseases by the end of the century. Interdisciplinary teams of physicians, biologists, computational scientists, and engineers can expand our understanding of the human body and illness \u2014 the very science behind medicine. CZI fosters collaboration between scientists and engineers, develops tools and technologies, and builds support for basic scientific research.\n\nThe ideal candidate will have a background in a quantitative or technical field and experience working with large data sets and making data-driven decisions. If you are mission-driven, entrepreneurial, and committed to building transformative technologies, we want to hear from you.\n\nMeta is a product that helps biomedical researchers discover literature that's important to their work and delivers it in real-time to their personal feeds. Meta uses artificial intelligence to organize and track over 67 million biomedical diseases, genes, proteins, techniques, researchers, journals, papers, preprints, and more\u2014including full coverage of PubMed and bioRxiv. We believe that the complexity and scale of scientific knowledge is limiting how quickly researchers can understand, navigate and quickly make powerful connections across what is know. This is one of the fundamental challenges hindering the rate of discovery in basic scientific research.\n\nAs Data Scientist for Meta, you'll be helping bring Meta to the broader community of researchers around the world. If you want to make a difference and help accelerate innovation in science, come and join us!\n\nYou will\nLeverage data to understand product, identify areas of opportunity, and execute projects to drive growth and engagement of science product users.\nDrive projects focusing on user retention, user engagement, product-market-fit and growth, and mobile usage - working closely with product, engineering, data, research, and leadership teams.\nExplore the feedback and data about the customer experience, develop metrics as-needed, and ensure prioritization is data-driven and accommodating of short-term and long-term strategies for incorporating into the end-to-end product development cycle.\nDerive deep (quantitative and qualitative) insights around product use, stability, and performance of the customer experience across a variety of touch-points and data sets.\nSupport product team with analysis to support decision making with reports and presentations.\nUse tools like Snowflake Computing, Mode Analytics, Adobe Marketing Cloud, Google Analytics, Python, R, ETL, Excel, and many other tools to work efficiently at scale.\nManage communication and alignment across multiple partner teams.\nPartner with engineering and design to implement changes in existing products that are impactful for the customer experience and ensure the measurement of the outcomes of new product features that will launch are high quality and risks are understood.\nInform, influence, and execute new quality strategies and tactics using sound analysis and impact metrics to support your positions.\nYou have\n4+ years work experience or equivalent within tech, finance, consulting or a related industry.\nExtensive quantitative or statistical analysis experience - building product intuition, solving problems using data, and providing practical business insight using data.\nAdvanced experience in analytics supporting marketing, advertising, or growth; communicating technical content and analytical insights to multiple audiences.\nAdvanced experience with SQL.\nAbility to process and analyze data sets, and interpret them to make business decisions.\nExcellent communication skills and ability to manage a project or product.\nApply Now: click Apply Now"}, "439": {"company": "Alignment Healthcare", "description": "Data Scientist:\n\nAlignment Healthcare is a data and technology driven healthcare company focused partnering with health systems, health plans and provider groups to provide care delivery that is preventive, convenient, coordinated, and that results in improved clinical outcomes for seniors.\n\nWe are experiencing rapid growth (backed by top private equity firms), our Data Science team is looking for the best and brightest data scientists. Data drives the way we make decisions. We love our customers and understanding them better makes it possible to provide the best clinical outcome and care experience.\n\nThis position will play a key role in uncovering deep insights from data using advanced machine learning technologies and advanced statistical analysis, processing very large data sets using cloud-based data pipelines, variety of analytic tools, visualizations and delivering actionable healthcare insights & solutions.\n\nProblems you will work on every day will include:\nCollaborate with key business leaders to understand their business problems and come up with analytical solutions.\nBuild end-to-end data science solutions which will improve healthcare outcomes and reduce the cost for our members.\nDevelop conversational AI solutions to improve healthcare experience of our members.\nBuild customer segmentation models to better understand our customers, and tailor the clinical outcome and healthcare care experience for them.\nDevelop scalable and efficient modeling algorithms that can work in production systems.\nCollaborate with the engineering team to build end-to-end cloud based machine learning production pipelines.\nDesign and implement online experiments and experimental frameworks\nBasic Qualifications:\nMasters in Computer Science, Engineering, Mathematics, Statistics, or related field\n2+ years relevant experience in predictive modeling and analysis.\nExcellent communication, analytical and collaborative problem-solving skills\nExperience in building end to end data science solutions and applying machine learning methods to real world problems with measurable outcomes.\nDeep understanding and experience with various machine learning algorithms, including deep neural networks, natural language processing, kernel methods, dimensionality reduction, ensemble methods, HMM and graph algorithms.\nSolid data structures & algorithms background.\nStrong programming skills in one of the following: Python, Java, R, Scala or C++\nDemonstrated proficiency in SQL and relational databases.\nExperience with data visualization and presentation, turning complex analysis into insight.\nExperience in setting experimental analytics frameworks or strategies for complex scenarios.\nUnderstanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc.\nExperience with manipulating and analyzing complex, high-volume, high-dimensionality and unstructured data from varying sources\nPreferred Qualifications:\nPhD in Computer Science or related field\nHealthcare experience\nExperience in Big Data processing technologies: Hadoop, Spark, Cosmos\nExperience in Azure, AWS or other cloud ecosystems.\nExperience in NoSQL databases.\nPublished work in academic conferences or industry circles.\nDemonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic startup environment\nPosition Location:\nOrange, California\nAlignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.\n\nIf you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.\nStart your job application: click Apply Now"}, "440": {"company": "Silicon Valley Bank", "description": "Silicon Valley Bank is the market leader in providing financial solutions to the world\u2019s most innovative companies, leaders and investors. Our clients are the game changers fueling the global innovation economy and transforming the way we live and work. SVB has been an incredible growth story over the last 35 years and continues to grow and expand internationally. Come join a growing, global commercial bank at the heart of the innovation economy where you will be able to help bring our clients\u2019 world-changing ideas to life.\n\nThe role: as a Senior Data Scientist in Machine Learning and Predictive Analytics with the Enterprise Business Analytics team, you will be a key contributor to development and implementation of leading edge machine learning technologies. This position will be dedicated to our Early Stage Practice (\u2018ESP\u2019) which is focused on engaging and building authentic relationships with pre-Series A founders, clients, prospects and partners. Your automated machine learning solutions will ensure our ESP prospects and clients receive best practice relationship management.\nResponsibilities include:\nDevelop and implement cutting edge machine learning solutions that provide our client facing staff with foresight and direction to optimize their prospects and client interactions\nCreate and deliver clear, compelling communications to your internal business partners that demonstrate the power of your machine learning solutions\nSeek out and implement opportunities that apply machine learning to proactively alert, advise and recommend best actions to our team members.\nBachelors degree\n5 to 8 years of experience in the quantitative analytics, machine learning and/or statistics space\nDemonstrated proficiency with SQL and at least one scripting language such as Python, R, Julia or Scala\nHands on experience using machine learning techniques and deploying them into production\nSolid success integrating machine learning solutions into systems such as CRM to automatically create alerts, triggers and recommendations for client facing staff\nStrong communication skills to collaborate effectively with business partners across the company\nPreferred:\nGraduate level education in computer science, mathematics, quantitative economics, statistics or operations research, preferred\nExperience in financial services and/or an operational role in an early or growth stage company or consulting firm to early stage companies\nKnowledge of business development, customer acquisition and sales, growth, and revenue generating strategies that drive early stage company success\nMBA\nApply Now: click Apply Now"}, "441": {"company": "MassMutual", "description": "Position Summary:\n\nMassMutuals Advanced Analytics group is seeking an exceptional, highly motivated and self-directed data scientist. In this role, you will perform data-driven research, problem solving, and algorithm development through the systematic application of mathematics, statistics and computer science as well as cutting edge data technologies. Results of this work manifest themselves in a variety of ways, including interactive visualizations, presentations, publications, web applications, predictive algorithms, and APIs.\n\nThis is an opportunity to join a small but growing high performing team with diverse backgrounds in applied math, computer science and physics that have been tasked with developing, maintaining and extracting knowledge from a strategic data asset. Our work revolves around studying fundamental and high impact business questions that directly impact the direction of the company and industry at large.\n\nOverall Responsibility:\nSet strategy and assume a leadership role in a domain of expertise\nDevelop roadmaps for projects and services, data, and technology\nOversee operations of algorithm and system deployments\nPartner with executive leadership to ensure alignment of data science initiatives and company strategy\nLead projects and research initiatives\nDevelop algorithms and predictive models, create prototype systems, visualizations, and web applications\nDesign and analyze experiments\nAssemble data sets from disparate sources and analyze using appropriate quantitative methodologies, computational frameworks and systems\nDisseminate findings to non-technical audiences through a variety of media, including interactive visualizations, reports and presentations\nMentor junior team members\n\nCandidate Requirements:\nIndustry recognized expertise\n7+ years working with data and relevant computational frameworks and systems\n7+ years developing of probabilistic models and machine learning algorithms\nProficient level of understanding in the following areas and an expert in at least one: machine learning, probability and statistics (esp. Bayesian methods), natural language processing, operations research\nExceptional problem solving skills and willingness to learn new concepts, methods, and technologies\nExpert in data analysis using R or Python (numpy, scipy, matplotlib, scikit-learn, pandas, etc.) programming languages\nKnowledge of HTML/CSS/Javascript, d3.js and web application frameworks (Flask, Django, Play!, etc.)\nKnowledge of NoSQL systems, Hadoop/map-reduce, Spark, Hbase, etc.\nExperience in database design and SQL\nAbility to work in a highly collaborative environment\nOutstanding communication skills (publication history a plus)\n\nEducation - M.S. or Ph.D. in a quantitative discipline (Computer Science, Statistics, Applied Mathematics, Electrical Engineering, Physics, etc.) is required\nStart your job application: click Apply Now"}, "442": {"company": "Johns Hopkins University Applied Physics Laboratory", "description": "Introduction:\nThe Johns Hopkins University Applied Physics Laboratory (APL), a national leader in scientific research and development, located midway between Baltimore and Washington, DC is seeking an innovative, energetic semantic web / linked data scientist.\n\nJob Summary:\nWork with our multi-disciplinary team designing and implementing semantic web-based systems for ontology-centered knowledge representation and intelligence analysis.\n\nDuties (Listed in order of importance with the estimated amount of time spent at each task):\nWork with senior software engineers, semantic web technologists, ontologists, physicists, chemists, biologists, and related field subject matter experts to implement and deploy systems for analyzing big data within the realm of intelligence analysis. (40%)\nConceive and design innovative methods for employing semantic technologies to the counter-WMD and intelligence analysis problem sets. (10%)\nResearch and develop systems concerned with semi-automated or automated ontology construction alignment. (10%)\nIntersect semantic web / ontology based approaches with Natural Language Processing, Information Retrieval, and Data Mining techniques to make novel advancements in practical application and research of data science and analysis.(15%)\nDecompose real-world mission gaps into problems sets that can be addressed using set, information, and graph theoretic approaches. (10%)\nSupport system deployment, troubleshooting and user training. (10%)\nAuthor and present papers on current research activities. (5%)\nNote: This job summary and listing of duties is for the purpose of describing the position and its essential functions at time of hire and may change over time.\n\nRequired Qualifications:\nPh.D. or M.S. in Computer Science or similar academic discipline. Candidate must have strong understanding of core Computer Science academic theory regardless of degree. Practical experience building applications using standards and technologies falling within the semantic web stack (e.g., Jena, Sesame, Triple / Quad Stores). Proficiency with Resource Description Framework (RDF), Resource Description Framework Schema (RDFS) and SPARQL Graph Query Language, or similar technologies. Strong understanding Web Ontology Language (OWL), including the use of advanced features such as property restrictions, language profiles, consistency checking, and logical inference. Familiarity with Ontology engineering practices and modeling tradeoffs. Familiarity with and willingness to adopt upper ontology principles of Basic Formal Ontology (BFO) in systems design. Intermediate to advanced level of proficiency in object-oriented software engineering principles and including proficiency in software development using one or more modern languages such as Java and Python. Comfortable in an environment where only high-level requirements may exist in absence of a fully-defined detailed project schedule. Ability to creatively contribute towards developing new requirements by identifying customer needs and applying expertise and knowledge of available methods, tools, and concepts to those needs. Ability to own a task and take responsibility for completion with minimal supervision. Ability to clearly express oneself both orally and in writing. Must have some limited experience with integrated development environments, software architecture design and development, and software test and deployment.\n\nDesired Qualifications:\nSome familiarity with additional areas of study in the field of Intellgent Systems / AI such as knowledge discovery, Natural Language Processing, Information Retrieval, Classifiers, and Statistical Inference. Current TS/SCI.\n\nSpecial Working Conditions (travel, working in closed areas, extended hours): May require a small amount of travel within the National Capital Region to deploy production systems or attend meetings or conferences. Occasional travel out of the area for sponsor / partner engagements.\n\nSecurity: Applicant selected will be subject to a government security clearance investigation and must meet the requirements for access to classified information. Eligibility requirements include U.S. citizenship.\n\nBenefits: APL offers a comprehensive benefits package including a liberal vacation plan, a matching retirement program, significant educational assistance, a scholarship tuition program for staff with dependents, and competitive salaries commensurate with skills and experience. For more information about our organization, please visit our web site at www.jhuapl.edu.\n\nEqual Employment Opportunity:Johns Hopkins University/Applied Physics Laboratory (APL) is an Equal Opportunity/Affirmative Action employer that complies with Title IX of the Education Amendments Acts of 1972, as well as other applicable laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, sexual orientation, gender identity, national origin, disability, or protected Veteran status.\n\nTo apply to this job, click Apply Now"}, "443": {"company": "PulsePoint", "description": "PulsePoint\u2122, a global programmatic advertising platform with specialized healthcare expertise, fuses the science of programmatic targeting, distribution, and optimization with the art of brand engagement. The PulsePoint platform is powered by terabytes of impression-level data, allowing brands to efficiently engage the right audiences at scale while helping publishers increase yield through actionable insights.\n\nOur organization has a strong history of utilizing machine learning, contextualization, and targeting to distribute advertising to the right consumers at the right time and create real connections across the internet. We are now taking that knowledge and expertise to solve challenges within healthcare in order to create better health outcomes through Radical Health Personalization\u2122.\n\nThe goals of the PulsePoint Data Science team:\nOptimize and validate targeting mechanisms for specific health conditions\nImprove and optimize our proprietary contextualization, and recommendation engines that handle hundreds of thousands of transactions per second, billions of times each month\nCollaborate with internal Health experts to ideate and support rapid assessment, analysis, and prototyping of ideas for achievable commercialization.\nWhat you will be tasked to do:\nResearch and develop user profiling models to enhance our clinical trial recommendation engine to leverage both online and offline data.\nCollaborate with Product teams on data-driven products to support clinical trial platform design and delivery.\nSupport and enhance the existing work on health user profiling, prediction, and targeting tools.\nContribute on future project on patient/physician identity for cross-device tracking, profiling and targeting.\nSupport existing codebases for data integration and production support for our core models.\nWhat you need to be successful in this role:\n3+ years of full-time experience working as a Statistician/ Machine Learning Engineer/ Data Scientist\nAdvanced knowledge of Big Data technologies such as Hadoop, Hive, and Impala\nAdvanced knowledge of Python using the numpy/scipy/pandas/skilearn stack\nMS/PhD in Astronomy, Physics, Applied Mathematics, Statistics, Machine Learning, Computer Science; or BS with several years of applied machine learning experience\n** All applicants must submit a code sample or a GitHub link to be considered **\n\nAt PulsePoint\u2122, data is at the core of everything we do and Data Science is a high profile and high impact team, focusing on creating innovative solutions that rely on predictive modeling and big data analytics. We are looking for \"A\" players that have a combination of drive, focus, speed, efficiency and quality to drive statistical modeling, optimization and/or machine learning. You will be given ownership and autonomy over the research and development of your projects and will be expected to execute well and on time. We work on challenging problems that will make ads matter for people with health problems. Your work will directly influence our trajectory as a company.\n\nWhat we offer:\nSane work hours\nGenerous paid vacation/company holidays\nVacation reimbursement, sabbatical, pawternity leave, marriage leave, honeymoon bonus\nComprehensive healthcare with 100%-paid medical, vision, life & disability insurance\n$2,000 annual training and development budget\nComplimentary annual memberships to One Medical, NY Citi Bike and SF Ford GoBike\nMonthly chair massages\nFree fitness classes (spin, yoga, boxing)\nGym reimbursement, local gym membership discounts\nOnsite flu shots, dental cleanings and vision exams\nAnnual company retreat\nPaid parental leave and a lot of new parent perks\nEmergency childcare credits\n401(k) Match and free access to a financial advisor\nVolunteer Time Off and Donation Matching, ongoing group volunteer opportunities\nTeam lunches, Sip & Social Thursdays, Game Nights, Movie Nights\nHealthy snacks and drinks\nAnd there's a lot more!\n\nWant to peek inside the PulsePoint\u2122 offices? Check it out here: https://www.themuse.com/profiles/pulsepoint\nApply Now: click Apply Now"}, "444": {"company": "Optoro", "description": "Optoro is a fast-growing technology company that is revolutionizing the retail industry. Every year, more than 15% of retail goods are returned or simply never sell. This creates tons of unnecessary waste and costs retailers billions.\n\nOur mission is to make retail more sustainable by eliminating all waste from returns. Our technology platform connects every returned item to its best home, thereby increasing profitability for retailers, giving consumers great deals, and reducing environmental waste.\n\nBacked by some of the top investors in the country - including Kleiner Perkins, Revolution Growth, and UPS - Optoro is powered by its collaborative, unconventional, and resourceful employees who love solving big problems. We are looking for individuals with similar creativity and energy to help build a lasting company focused on the triple bottom line.\n\nOptoro's Data Science team is responsible for turning our massive data resources into actionable insights that inform our products and business processes. Our team values creativity, willingness to embrace new methods and technology, and the ability to solve problems independently. The team uses a wide variety of machine learning techniques - from linear regression to deep learning to hierarchical Bayesian models - while constantly pushing the bounds on real-time experimental methods including multi-armed bandits, reinforcement learning and more! Our goal is to create a step-change increase in the world's ability to efficiently and effectively optimize returns across the entire Optoro platform. We're looking for experienced Data Scientists that are passionate about helping us to achive that goal, using any and all means necessary.\n\nResponsibilities\nDevelop models via a wide variety of machine learning techniques that have demonstrable impact on business challenges.\nManipulate complex, high-volume, high-dimensionality data from varying sources to provide insights that enhance Optoro's SmartDisposition\u2122 routing algorithm and pricing approach.\nMonitor results of deployed algorithms for accuracy, drift over time, and robustness to new data and enact methods to continuously improve models.\nDesign and execute experimental tests of business logic using multi-arm bandit frameworks, traditional A/B testing and more.\nProduce reports and data visualizations using Tableau and other tools.\nRequirements\nStrong mathematical and statistical background; B.A. (graduate degree preferred) in a relevant quantitative field (e.g. applied mathematics, statistics, physics, computer science, operations research); or equivalent work experience in a relevant role.\n4+ years in a machine learning-focused role, including data extraction and cleaning, exploratory analysis, predictive modeling, and monitoring of deployed algorithms.\nDeep understanding of data analysis, machine learning, and data communication across multiple domain areas.\nExperience with the Python statistical programming stack (NumPy, Pandas, Scikit-Learn, TensorFlow, PyMC3, etc\u2026) and deploying algorithms in production environments. We also welcome candidates who come primarily from an R background but want to migrate to Python.\nAbility to deal with ambiguity in a fast-paced, dynamic environment.\nProven experience thinking creatively about challenging, analytical problems.\nExperience with supply chain, eCommerce, microeconomic theory, NLP, Ruby on Rails, Airflow, Kafka, and PostgreSQL are all a plus!\nOptoro is an equal opportunity employer.\nStart your job application: click Apply Now"}, "445": {"company": "Synechron", "description": "TECHNOLOGY\nSenior Data Scientist\nNew York, NY and Charlotte, NC, USA\n\nApply\n\nJob Description\n\n\nThe Data Science team is looking for a seasoned data scientist with a strong analytics, programming, and machine learning background. The ideal candidate will work closely with top tier financial services organizations to formulate solutions to complex business problems using multiple analytical tools and frameworks, including statistical analysis, natural language processing, machine learning, and deep learning. The ideal candidate will be able to identify client needs, propose effective solutions, and implement the solutions as part of a team.\n\nSynechron\u2019s collaborative culture and global network of Tier One banking clients provides an incredible environment for a data scientist to work on the most cutting-edge use cases in machine learning and artificial intelligence in finance. You will have the opportunity to work with some of the best data scientists anywhere in an environment which truly values innovation, creative thinking, and a proactive approach to problem solving. Exciting projects include building machine learning platforms for investment research, private wealth management, IPO underwriting, customer analytics, social AI, and retail and commercial banking. As a senior member of the Data Science team you will have the opportunity to lead teams and projects and to mentor junior data scientists in their development.\n\nResponsibilities\nDesign and develop scalable solutions to complex problems using statistical modeling, machine learning, Natural Language Processing, Optical Character Recognition, and deep learning;\nImplement solutions in Python in multiple environments including Spark, AWS, and Azure;\nManage junior data scientists in the implementation of machine learning solutions;\nMeet with clients to understand business use cases, identify needs, and formulate end-to-end solutions encompassing data ingestion, cleansing, modeling, and predictive and prescriptive analytics;\nManage the ingestion and cleansing of large data sets using big data tools such as Spark;\nTranslate solutions into business requirements;\nIndependently formulate new ideas for solving client problems or providing clients with new tools for growing revenue, reducing cost, improving customer acquisition and retention, and automating business processes.\n\nRequirements\n\n\nBasic Qualifications\nHold a MS or PhD degree in a quantitative discipline: computer science, applied mathematics, statistics, operations research, management of information systems, engineering, economics, social sciences or equivalent;\nProgramming skills in Python;\nPresentation skills including experience presenting complex ideas to clients and prospects;\nThe ability to independently formulate solutions to complex problems or to otherwise think of potential solutions without guidance;\n8+ years of total experience including 4+ years of experience developing machine learning systems in Python, Java, or a related programming language;\nHands on experience with data mining, machine learning, econometric analysis or equivalent;\nExperience in Hadoop or other MapReduce paradigms and associated languages such as Spark;\nExperience with Unix/Linux environment for automating processes with shell scripting.\nPreferred Qualifications\nStrong Python programming skills;\nKnowledge of deep learning and related open source libraries such as TensorFlow;\nFinancial Services experience and knowledge of the FS industry;\nDeep knowledge of Natural Language Processing;\nExperience with Spark and machine learning libraries such as MLlib;\nExperience in marketing and sales, being an innovator and disruptor is also a plus;\nBeing self-motivated, creative and collaborative;\nStrong presentation and communications skills.\n\nApply Now: click Apply Now"}, "446": {"company": "7Park Data", "description": "7Park Data is the world\u2019s leading alternative data intelligence firm. We have access to some of the most coveted alternative datasets \u2013 such as clickstream, geolocation, mobile app usage, credit and debit card, email receipt, and shipping cargo data \u2013 and we are continuously acquiring more.\n\nYou will be joining other extremely passionate data scientists, product managers, and engineers that share a common interest in tackling some of the most difficult data science and machine learning problems today. With the data products and machine learning systems you design, 7Park will arm influential decision-makers at financial and corporate giants with critical information they need to make smart, data-driven decisions. And, along the way, you will help advance the current work in artificial intelligence and predictive modeling.\n\nThe data science team has two major goals: to design and build data products that provide intelligence on real-time economic activity to our financial and corporate clients and to both research and develop machine learning systems to extract information from large volumes of structured and unstructured text.\n\nWe are looking for a talented and creative NLP Data Scientist to join our Natural Language Processing team. As an NLP Data Scientist, you will be responsible for the following:\nConducting research on some of the world\u2019s most interesting alternative datasets\nPlanning, developing, and applying cutting-edge machine learning systems and statistical modeling to extract insight from vast amounts of data at scale\nWriting production-ready code to make accurate and timely predictions on out-of-sample data\nDesigning systems to monitor the results of models in production, discover and address anomalies, and ensure the robustness and reliability of these models\nLeading projects from start to finish, collaborating with 7Park\u2019s senior management, product managers, engineers, external data partners, and clients\nThe ideal candidate will be passionate about building machine learning systems on real world data and have several years of industry experience and/or a Masters or PhD in computer science, mathematics, statistics, linguistics, physics, computational finance, or a similar quantitative field.\n\nIt is also very important that you enjoy working in a tight-knit and highly entrepreneurial startup that marries the creative, experimental problem-solving found in academia with the hacker ethos of shipping products quickly and often.\n\nRequirements\n3 - 5 years of relevant professional experience and/or a Masters or PhD in computer science, mathematics, statistics, linguistics, physics, computational finance, or similar quantitative field.\nStrong knowledge of machine learning, computer science, mathematics, and statistics.\nStrong programming skills in Python, R, and/or Scala.\nExperience with NumPy, SciPy, Pandas, Scikit-Learn, TensorFlow, and Keras. PyTorch is also acceptable.\nExperience with building distributed machine learning systems using Apache Spark and a working knowledge of MLlib.\nExperience with several of the following libraries and models: CoreNLP, NLTK, Gensim, SpaCy, Apache Lucene and Solr, Apache OpenNLP, TextBlob, Word2vec, and GloVe.\nA background in NLP, including experience with several of the following concepts: named entity recognition, named entity linking, natural language understanding, cognition, collaborative dialog, building blocks of language (morphology, syntax, semantics, pragmatics), knowledge representation, automated knowledge acquisition, formal reasoning, and sentiment analysis.\nBonus\nPublications in communities such as NIPS, ICML, or related.\nGitHub projects demonstrating your creative drive.\nKaggle wins demonstrating your competitive drive.\nExperience running or working at data-centric startups.\nExperience with knowledge graphs.\nWorking knowledge of GraphX and Spark Streaming.\nTo apply to this job, click Apply Now"}, "447": {"company": "Cimarex Energy", "description": "JOB SUMMARY:\nOur Data science team is advancing our business to harness the full capabilities of computation, robust datasets, analytics, statistical skills and innovation for our technical subsurface and operational business decision-making to drive value. We are looking to hire a top talent candidate that is passionate and committed to collaboratively working on challenging data science solutions for our businesses, including exploration, production, midstream, drilling, completions, and environmental stewardship.\nThe Data Scientist is responsible for analyzing large amounts of raw information to find patterns that impact business decisions utilizing machine learning and other advanced statistical methods. An aptitude for math, statistics, and analysis as well as critical thinking and problem-solving are required for this role. The individual will work closely with departments across the company to support and implement high-quality, data-driven decisions. Role will specifically focus on machine learning operations and model deployment.\nESSENTIAL DUTIES AND RESPONSIBILITIES:The following represents the majority of the duties performed by the position, but is not meant to be all-inclusive nor prevent other duties from being assigned when necessary:\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data\nAnalyze large amounts of data to discover trends and patterns\nBuild machine learning algorithms & advanced statistical models\nPresent information through data visualization software\nMake recommendations based on model outcomes\nDeploy models for collaborative use\nCollaborate within a multi-disciplinary team and with other teams throughout the organization\nOther duties as assigned\nSKILLS AND EXPERIENCE:\nBSC/BA in Computer Science, Engineering, or a related technical field required; Masters or PhD preferred\nMinimum of 3 years of experience in a Data Science/Machine Learning role in oil & gas\nProficient in Python & SQL (or another database management system)\nStrong expertise in exploratory data analysis\nStrong expertise in the deployment of machine learning models\nExperience in a data visualization software (Spotfire, Tableau, Seaborn/MatPlotLib etc.)\nCreativity, deductive thinking and problem solving skills are necessary\nStrong competence in performing operational due diligence\nAbility to influence scientific direction of projects\nStrong aptitude for learning a broad range of scientific disciplines and translating that into technological solutions\nExcellent verbal and written communication skills are necessary\nMust be able to create and deliver effective presentations\nStrong networking and interpersonal skills, both internal and external\nExperience in Neural Networks using Tensorflow/PyTorch/Keras preferred\nNatural Language Processing (NLP) experience preferred\nDemonstrated initiative in completing MOOC\u2019s that are Data Science related preferred\nHadoop, Spark, or another big data processing experience preferred\nCloud computing experience (AWS, Azure etc) preferred\n\nWORKING CONDITIONS AND PHYSICAL DEMAND:\nWork is typically performed in an office environment. Exposure to conditions such as extreme heat or cold is not likely, but possible. If incumbent is required to travel to operations site, personal protective equipment including but not limited to head protection, hearing protection, safety glasses, safety shoes and flame resistant clothing is required. Safety rules including OSHA and DOT requirements are strictly enforced. Some travel may be required.\nCimarex Energy Co. is an equal opportunity employer. Applicants and employees are considered for positions and are evaluated without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, marital status or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved.\n\nStart your job application: click Apply Now"}, "448": {"company": "Kareo Inc", "description": "What We Need\nA Senior Data Scientist with solid problem-solving skills to partner with the development teams.\nYour Area of Focus\nJoin a growing team of tech heads who love building things with ones and zeros\nWork in a fast-paced environment that sometimes fails fast and early, but always learns and improves\nBe unshackled by conventional thinking and allowed to use cool tech to solve hard problems\nPerform component design for a complex system or service. Considers scaling, reusability, maintainability, and performance into system or service design.\nStrong written and verbal communication skills and ability to train and mentor Junior engineers\nMake recommendations to product requirements and business solutions based on an understanding of how Kareo's products work under the hood\nWrite unit tests and integration tests for most of one's own work and ensure a high quality of deliverables\nYour Qualifications\nComputer Science Degree (or degrees) or enough experience to convince us you do not need one\nExtensive knowledge of Python or R\nAbility to understand and interpret data and programmatically make predictions\nExperience with statistical tools and visualizations techniques to extract hidden insights from large datasets\nAbility to use historical data to build models that can predict future outcomes and drive business decisions\nExperience with Microservices and CI/CD (Kubernetes is a plus)\nDeep understanding of latency, contention, computation, mutation, consistency, CAP theorem and system design trade-offs\nExperience in an UNIX environment\nExperience with SoA architectures and in SaaS products\nExtensive knowledge of RESTful APIs\nFamiliarity with relational databases such as MySQL, Oracle, and SQL Server\nExperience with data warehousing tools and technologies\nAbility to design and implement scalable big data pipelines and frameworks that can integrate external data sources and third-party APIs\nSolid experience with concurrency, multithreading, server architectures, and distributed systems\nExperience with distributed search engines like Elastic search\nStrong problem solving and critical thinking skills\nStrong attention to detail\nProcess oriented: you can teach us a thing-or-two about machine learning and real-time data analytics in high throughput environment\nDeep understanding of the inner workings of one or more programming languages and tech stack\nAbility to build REST APIs that can process and distribute data to 3rd party applications at scale\nExperience with building AI bots\nA good understanding of current industry trends and best practices\nYour Personal Characteristics\nBe Passionately Driven: We take pride in our work, inspire others to excel, and are always curious to learn more. We hold ourselves to the highest standards of quality and integrity. We work with urgency because we love what we do.\nDedicated to Customer Success: Helping our customers succeed is our number one goal and inspires every action we take. We want our customers' practices, and their patients, to thrive. We are empathetic, solution-oriented, and aligned with their needs.\nTogether We're Better:We are honest, approachable, and collaborative. We believe great teams with members that are willing to do what it takes to get the job done can accomplish more. We put the team first and win together.\nConstant Innovation: We reject the status quo. We take a unique approach and make every effort to bring clarity to a needlessly complex industry. We are creative problem solvers. And we apply the same innovative thinking to our business and healthcare as a whole. We believe in making things better.\nKareo is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\nApply Now: click Easy Apply"}, "449": {"company": "Esurance", "description": "Team. Culture. Community. That\u2019s Life at Esurance!\nThe Esurance Internship Program is a 12 week summer program offering students an opportunity to explore our culture, gain business expertise, and provide innovative solutions to enhance our organization. We\u2019re looking for a Data Science Intern to join our dynamic team of individuals who are committed to making insurance surprisingly painless! We\u2019re a socially conscious company that\u2019s focused on creating a diverse work environment.\n\nWhat our Data Science & Analytics Group is all about:\nEsurance has created a centralized data science & analytics (DSA) group that is responsible for helping business units make objective decisions using data. The group supports the company\u2019s overall business operations by delivering critical analytical insights and in-depth consultative analyses to senior management teams and our business partners.\nWhat we\u2019ve accomplished:\nWe have exploited our rich data repositories, industry-competitive data science tools, expertise and business SME knowledge to collaboratively build several machine learning models and applications which are used by our customers and associates on a daily basis across the range of operations of the company. Applications include accurate insurance pricing, customer lifetime value prediction, severe injury detection in Claims and prediction of customer churn.\nWhat we\u2019re working on:\nWe are building and deploying state-of-art machine learning and AI models to help our Claims, Product Pricing, Marketing, Sales and Service teams realize business value through automation, improved process efficiencies and optimal decision-making. Our recent efforts leverage deep learning expertise in NLP to take advantage of unstructured text data available in Claims reports, customer survey responses, emails and virtual chat sessions to uncover actionable insights.\nWhat you\u2019ll do:\nAs an intern of DSA, you will collaborate with some of our senior data scientists on various projects, a valuable opportunity to gain hands-on industrial experience for someone with career focus as a future data scientist. The data science intern will work closely with some senior team members with the following responsibilities:\nSupporting data science projects in data acquisition, cleaning, processing.\nResearching predictive algorithms using large amounts of structured and unstructured data.\nDesigning experiments to determine efficacy of solutions.\nProviding on-going performance monitoring of decision systems and statistical models\nFirst cohort runs from 5/18/2020 - 8/7/2020 for semesters students\nSecond cohort runs from 6/15/2020 - 9/4/2020 for quarters students\nWhat we\u2019re looking for:\nCandidates in a Masters or PhD program are strongly preferred.\nMinimum GPA: 3.4\nDemonstrate a strong interest in data science as a future career.\nExcellent knowledge of a language for statistical and scientific computing (R, Python, etc.).\nExtensive experience in data management and data scrubbing.\nStrong aptitude towards math and programming.\nAbility to communicate complex information in a way that is clear and easily understood.\nPrior exposure to machine learning techniques such as dimension reduction, regression, clustering, and classification to solve real-world problems.\n\nCompensation is nice! 12-week PAID summer internship. 40 hours per week\nYou\u2019ll be matched to a meaningful project that will build on your skills and background\nTackling complex, real-world problems, you\u2019ll have the opportunity to own your projects from start to finish, all while working as part of a team!\nAttend new hire orientation with your cohort on your first day\nProfessional Opportunities: Exposure to Esurance Executives, Work alongside skilled industry veterans and Participate in a Professional Development Course\nDevelopment Opportunities: Personal manager and mentor, Hands-on coaching and development, Exciting learning opportunities\nPersonal Opportunities: Weekly social events and lunches, A Volunteer Day (Community Service), Great location in San Francisco\u2019s Financial District, Walking distance to popular attractions\nPresenting your work: You will have two opportunities to present in front of the leadership team and your colleagues. Presentations will allow you to share what you have learned throughout your experience.\nLearn more about us:\nEsurance combines the spunk of a startup with the backing of Allstate (the largest publicly held personal lines insurer in the U.S.) to create a unique, energized, and exciting place to work.\nTo learn more about Life at Esurance, please review our Glassdoor page and see why our employees love to work for us!\nTo apply to this job, click Apply Now"}, "450": {"company": "Guidewire Software, Inc.", "description": "Guidewire\u2019s Cyence Risk Analytics products help the (P&C) property & casualty insurance industry to model new and evolving risks such as cyber. By combining internet-scale data listening, adaptive machine learning, and insurance risk modeling, Cyence Risk Analytics provides insights that help P&C customers face new risks, take advantage of new opportunities, and develop new products. To learn more about Cyence Risk Analytics, please visit https://www.guidewire.com/products/cyence\n\nWe are seeking a talented Principal Modeler to join our team. Your responsibilities as a modeler will include:\nDeveloping and implementing methodologies to quantify the impact of cyber security risk, as well as other emerging risks affecting the P&C industry\nExploring different data sources to come up with features and assumptions to enhance our set of risk models\nCalibrating, testing and validating different types of models in the insurance space\nIntegrating modeling processes in our production pipeline to feed our platform\nCommunicating technical details related to the models and their outputs to individuals from various backgrounds\nWorking together with cyber analysts, data engineers, modelers, and product managers\n\n\nWhat we are looking for:\nMaster\u2019s or PhD degree in a quantitative field (e.g. CS, Statistics, Sciences, Engineering, Economics)\nSolid statistics and predictive modeling foundations\n6+ years of experience in data analysis, feature engineering, data visualization and hypotheses testing\nExperience working different types of datasets (e.g. unstructured, semi-structured, with missing information)\nExperience in implementing parametric and non-parametric models in a production-level environment\nHigh level proficiency in Python or R, and SQL\nGood written and verbal communication skills\nAbility to think critically and creatively in a dynamic environment, while picking up new tools and domain knowledge along the way\nA positive attitude, and a growth mindset\nBonus:\nInsurance, actuarial modeling or financial modeling experience\nGeneral understanding of computer network and cybersecurity\nExperience with Cloud infrastructure (e.g. AWS), and open source data processing frameworks (e.g. Hadoop, Spark, Mongo and Cassandra)\nGuidewire exists to help property and casualty (P&C) insurers adapt and succeed at a time of accelerating change. We provide an industry platform that our customers rely upon to run, differentiate, and grow their business. Now serving 370+ customers in 30 countries, Guidewire is regarded by industry commentators as the leading vendor that has helped P&C insurers to replace aging legacy systems with modern software. Now Guidewire is intent on leading the next era of technology in P&C, industry platforms consisting of software, services and partner ecosystem and powered by the cloud.\nStart your job application: click Apply Now"}, "451": {"company": "Dell", "description": "Data Scientist Product Manager\nAustin, TX\n\n\nDell provides the technology that transforms the way we all work and live. But we are more than a technology company \u2014 we are a people company. We inspire, challenge and respect every one of our over 100,000 employees. We also provide them with unparalleled growth and development opportunities. We can\u2019t wait for you to discover this for yourself as a Data Scientist Product Manager.\n\nProduct Development Management is a fast-paced environment where innovative thinking is prized. Our team focuses on the delivery of products or computer-based systems for external customers. We lead and deliver the entire lifecycle from product definition and planning through to production and release. We also oversee modifications, upgrades and maintenance of the product or product line. And to make the whole process run smoothly and seamlessly, we\u2019re experts in analytics project management, from initiation through to delivery, and liaise with other departments on technical matters. We are looking for a candidate who has a strong background in product management, data science and analytical problem-solving.\n\nResponsibilities:\nBuild best in class AI products to create value for our customers and business.\nExperience shipping successful products, including defining vision, strategy, outcome-driven product roadmaps and creating and managing backlogs\nAnalyze customer behavior and business performance to design and develop impactful analytics solutions/products.\nDrive analytics program & product management while working with cross-functional teams.\nWork with software engineering, data engineers, data scientist, architects and business to design actionable strategic products.\nLead cross-functional engagements to define problem statements, collect data, build analytical models and make recommendations.\nLead end-to-end AI product development from understanding the user requirements to successfully delivering products in production environment.\nRequirements:\n6+ years of relevant Product Management experience with at least 2+ years\u2019 experience with AI/ML\nTypically requires 12+ years of related experience in a professional role with a Bachelor\u2019s degree; or 8+ years with a Master\u2019s degree; or 5+ years with a PhD; or equivalent experience\nExperience in most big data and statistical analytic tools: Python, Hadoop (Hive), SQL and machine learning algorithms/concepts.\nExperience with lean startup or agile/Pivotal methodologies for developing products.\nHands-on analytics capabilities, expertise in analytical problem-solving techniques and frameworks and the ability to deal with large volumes of data.\nStrong communication skills, including the ability to convey analytic insights effectively to both IT and business audiences\nStrong teamwork, business acumen, and customer advocacy skills\nPreferences:\nExperience working within global teams\nExperience with large, high-volume web sites\nBenefits\nWe offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities \u2014 all to create a compelling and rewarding work environment.\n\nDell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Learn more about Diversity and Inclusion at Dell here.\nApply Now: click Apply Now"}, "452": {"company": "PayPal", "description": "Design, develop and implement advanced predictive models using advanced data mining and machine learning techniques.\nCollaborate with other data scientists and engineers to formulate innovative solutions to experiment and implement advanced data mining techniques\nWork with large volumes of data; extract and manipulate large datasets using standard tools such as Python, Hadoop, R, SQL and SAS\nAnalyze data covering a wide range of information from user profile to transaction history. Identify new risk patterns through data mining\nCommunicate complex concepts and the results of the analyses in a clear and effective manner through creative visualization\nQualification\nAdvanced degree (MS or PhD) in science or engineering field with 4+ years of relevant experience\nData Mining experience in Python, R, H2O, Scala and/or other Big Data techniques. Familiar with various Machine Learning algorithms and Statistical methods\nAbility to deal with large amount of data and fluency with SQL or SQL-like tools.\nStrong problem solving and communication skills\nHave a passion for working on big data and professional experience in data mining, statistical analysis, predictive modeling, and data manipulation.\nFinancial services or eCommerce experience a strong plus\nApply Now: click Apply Now"}, "453": {"company": "Johns Hopkins University Applied Physics Laboratory", "description": "Do you love developing creative solutions to challenging problems?\n\nAre you passionate about providing real impact to the country's toughest national security problems?\n\nAre you searching for engaging work with an employer that prioritizes continual innovation?\n\nIf so, we are looking for someone like you to join our team at APL.\n\nAs a Senior Data Scientist at APL, you will get to work with state-of-the-art hardware, software, and techniques to develop computational algorithms and statistical methods that find valuable information hidden in large volumes of data.\n\nPosition Summary:\n\n\nThe Large-Scale Analytics Group (QAS) develops software systems that incorporate machine learning (ML) algorithms on big data platforms and graph databases as well as visual analytics to find details hidden deep within large and complex data sets. We support multiple agencies within the US Government by applying innovative analytics to uncover activities such as illegal activities, international trade fraud, illicit manufacturing of weapons of mass destruction, and cybercrime. You will implement and apply computationally tractable solutions and corresponding data architectures to address the needs of our sponsors. We are seeking a confident leader, creative thinker, motivated problem solver, standout colleague, and life-long learner that wants to strengthen the safety and security of our country. You will join a hardworking team in an inclusive environment that cultivates intellectual curiosity, innovation and creativity.\n\nAs a Senior Data Scientist you will...\nDesign creative algorithms and analytic pipelines for analyzing large-scale and complex data.\nLead analysis teams and develop proposals for new research. These proposals will be for sponsor-funded projects as well as internal research.\nDevelop large-scale data architectures using technologies like Hadoop, Spark, and distributed graphs to support analytic algorithms.\nBuild creative software applications and perform analytics on complex data.\nPresent results to both JHU/APL and Sponsor leadership.\nYou meet our minimum qualifications for this position if you\nPossess an M.S. or Ph.D. in Computer Science, Information Science, Mathematics, Physics, Operations Research, or a related discipline. 5 years of experience.\nHave experience with statistics, machine learning algorithms, and general algorithm development.\nHave knowledge of modern large-scale data systems and architectures.\nPossess solid software development skills, including in an Agile environment.\nExhibit excellent social skills, the ability to work independently, excellent written and oral communications skills, and good organizational skills.\nPossess an active secret clearance or higher; or are able to obtain a secret clearance at minimum. Preference for SSBI. If selected, you will be subject to a government security clearance investigation and must meet requirements for access to classified information. Eligibility requirements include US Citizenship.\nYou'll go above and beyond our minimum requirements if you\nPossess a Ph.D. in the disciplines listed above.\nHave experience leading software development and/or analysis teams.\nHave experience clearly presenting methods and results to business or government decision-makers.\nSpecial Working Conditions: [Travel, working in closed areas, extended hours]: Some local travel to sponsor sites may be required.\n\nWhy work at APL?\n\n\nThe Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation's most critical defense, security, space and science challenges. With a wide selection of challenging, impactful work and a robust education assistance program, APL promotes a culture of life-long learning. Our employees enjoy generous benefits and healthy work/life balance. APL's campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities atwww.jhuapl.edu/careers.\n\nAPL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, disability status, veteran status, or any other characteristic protected by applicable law.\nStart your job application: click Apply Now"}, "454": {"company": "Earnest", "description": "Earnest empowers people to live better lives\n\nWe're an accomplished team of design, math, finance and technology geeks who noticed some issues in our financial system and decided to do something about it. We created a company that combines data science, streamlined design, and technology to:\nBuild more affordable products\nBring them to more people\nEngage through more human experiences\nAs a Senior Data Scientist, you will report to the Head of Data and work on full stack-data science. Our modelers and engineers partner and own everything from data sourcing/ETL to model creation/testing and model deployment/maintenance. You will do compelling modeling and also work on state-of-the-art engineering.\n\nTeam Philosophy:\nEveryone on the team is considered and treated as a Senior, so you are given a lot of ownership over the projects you're working on. With this in mind, we expect you to write code that is well tested, modular, and maintainable. We frown at instances of destructive firefighting, caused by badly designed architecture or mismanaged projects.\nWe like learners. Hence, we create an environment where Data Scientists learn the skills and abstraction patterns of Software Engineers and Data Engineers learn the iterative model development workflow seen in Machine Learning. Expect an environment where you will be always learning and challenged to work with tools, languages, frameworks that are outside of your area of expertise.\nTools, Frameworks, and Languages you will work with:\nMachine Learning: We use state-of-the art open source tools and frameworks. The problem domain is constrained to tabular, time-series, and NLP data.\nLanguages: Python, SQL, R (occasionally you will also work with Node.js or Scala)\nStorage: Postgres, Redshift, S3\nCompute: Spark, Athena, EC2\nWorkflow Management: Airflow\nMisc: Looker, Github, Jira, Splunk, PagerDuty\nResponsibilities\nCreatively use new and existing data to increase the efficiency of our underwriting infrastructure\nWork with engineers to design machine learning solutions that operate quickly and effectively at scale. You will be involved in deploying models within Python microservices.\nMake recommendations to the executive and cross-functional teams that would help improve Earnest operations.\nWrite tooling or expand on existing internal frameworks (e.g., feature-generator repo).\nIdeal backgrounds and expertise:\n3+ years of industry experience developing machine learning models from inception to business impact.\nStrong programming skills - Python preferred (though open to R for candidates that have very strong background in the language).\nIntermediate to advanced knowledge of SQL and ability to wrangle data from many different data sources.\nDeep experience with ML/DL toolkits: Tensorflow, scikit-learn, XGBoost, Numpy, Scipy, Pytorch, PySpark.\nYou've earned a degree in Machine Learning, Statistics, Optimization, Physics, or related field, with experience building production-ready ML models and systems.\nFamiliarity with building inferential models (GLM, LMER), simulation techniques (MCMC), and hypothesis testing.\nUnderstanding of traditional relational databases (PostgreSQL, MySQL) and distributed systems (Redshift, BigQuery, Spark, Apache Hadoop)\nNice to Have:\nDomain experience developing software for Fintech, Banking, or related Consumer Financial Services companies\nKaggle Ranking (this can help speed up the interview process)\nAn active Github or Medium profile\nEarnest Perks & Benefits:\nHealth, Dental, & Vision benefits plus savings plans\nEmployee Stock Purchase Plan\n401(k) plan to help you save for retirement plus a company match\nTuition reimbursement program\n$1000 flight on each Earnie-versary to anywhere in the world and 25 days of annual PTO\nEarnest provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, sexual orientation, disability, genetics, gender identity or expression, or veteran status. Qualified applicants with criminal histories will be considered for the position in a manner consistent with the Fair Chance Ordinance.\nApply Now: click Apply Now"}, "455": {"company": "Alaant Workforce Solutions", "description": "Alaant is seeking a Data Analyst in the Glens Falls, NY area for our client who partners with local healthcare organizations to provide better health care solutions to the upstate New York region. In this role you will participate in analyzing and maintaining the accuracy and integrity of the costs in medical care.\n\nJob Details:\nAnalyze and maintain the accuracy and integrity of the cost standards data.\nReview and utilize purchase and pharmacy reports, review invoices and journal entries.\nReview and analyze individual department cost structures.\nRun monthly flex budget process, review flex budget reports and assists management with questions.\nPrepare miscellaneous cost analyses.\nParticipate in and provide support on a timely basis to each performance and profitability team.\nPrepare decision support system reports as requested by directors and managers.\nRequirements:\nMust have experience in creating, producing, and organizing data using statistics and business requirements.\n3 years of Database experience\n3 years of SQL Server/R Studio\n3 years of experience creating dashboards using Excel, Powerpoint or Tableau.\nBachelor's degree in Finance, Accounting, Information Technology or related field and 2 years of related experience required.\nFor more details on this role contact:\nJaime Toolan, Senior Talent Resource Manager @ 518-689-3155, Jaime.toolan@alaant.com\n\nAlaant Workforce Solutions wants all interested applicants to know they are seeking a diverse workforce and are actively recruiting candidates in accordance with diversity, inclusion and equal opportunity policies.\n\nConnect with us on LinkedIn, Facebook, Twitter, Instagram & Glassdoor\n\nAt Alaant we believe in People First! We Care. We Listen & We Support.\n\nwww.alaant.com\n\nINDNYH\nApply Now: click Easy Apply"}, "456": {"company": "Foundation Medicine", "description": "Data Scientist\nJob Location\n\n\nBoston, MA\n\nReq Number\n\n10842\n\nDepartment\n\n\nData Strategy & Prod Dev\n\nApply Now\n\n\nABOUT FOUNDATION MEDICINE\n\nFoundation Medicine, Inc. (FMI) began with an idea\u2014to simplify the complex nature of cancer genomics, bringing cutting-edge science and technology to everyday cancer care. Our approach generates insights that help doctors match patients to more treatment options and helps accelerate the development of new therapies. Foundation Medicine is the culmination of talented people coming together to realize an important vision, and the work we do every day impacts real lives.\n\nABOUT THE JOB\n\nData Scientist I, Data Products researches, prototypes, and otherwise enables the next generation of real-world data products. In partnership with product managers, engineers, and domain experts in oncology and genomics, the Data Scientist leverages FMI\u2019s real-world data assets, including FoundationCORE and clinico-genomic database (CGDB) for efforts in analyzing real-world clinical and genomic data. Specifically, the incumbent examines clinical use cases, such as biomarker-based outcomes analyses, examining genomic predictors of clinical outcomes, clinical utility of next-generation sequencing, and the impact of diagnostics on patient care. The Data Scientist I collaborates with internal and external stakeholders to explore and develop opportunities to provide clinical decision support tools based on FMI\u2019s data assets.\n\nKey Responsibilities:\nDesign, execute and present data query results of large genomics, clinical and process datasets to identify correlating information.\nDesign and develop standardized data templates for reporting and visualization of validation study results.\nProvide insights and collaborate with other functions in building a centralized validation database to store and trace all analytical and clinical validation data.\nMaintain and expand knowledge of and access to available and meaningful data sources within and outside of FMI, and their application to product development needs.\nCollaborate with the Medical, Commercial and Product Teams to design and execute quantitative analyses of real-world oncology cohorts.\nCreate data visualizations communicating insights to a range of audiences.\nDevelop prototype data products for internal and external users, especially in the area of clinical decision support applications.\nContribute to the scaling of data product tools to FMI\u2019s customers that utilize real world data insights.\nCo-author case studies and peer-reviewed publications.\nProvide support on projects of increasing complexity, as needed.\nOther duties as assigned.\nQUALIFICATIONS\n\nBasic Qualifications:\nMaster\u2019s Degree in Statistics, Bioinformatics, Computer Science, Biomedical Engineering, Mathematics, or related field and 1+ year of work experience in the fields of data science, data analysis, biostatistics, or bioinformatics\nOR-\nPh.D. in Statistics, Bioinformatics, Computer Science, Biomedical Engineering, Mathematics, or related field with no professional work experience.\nPreferred Qualifications:\nExpertise in biostatistics and epidemiology data sources and analysis.\nExperience with the statistical analysis of analyzing clinical health data, particularly survival and outcomes analyses.\nExperience with the development of clinical decision support tools.\nExperience with the statistical analysis of genomic data (+/- other omics data types).\nKnowledge of Next-Generation Sequencing (NGS).\nFamiliarity with regulatory requirements, including those of GCP and ICH.\nHistory of successfully completing highly-independent work.\nAbility to collaborate within cross-functional teams.\nStrong interpersonal skills that include excellent skills in written and oral communication, and problem solving with other departments and colleagues.\nDemonstrating of integrity and a commitment to values held at FMI: patients, innovation, collaboration, and passion.\nDemonstrated history of successfully managing multiple initiatives and maintaining one\u2019s own workflow.\nUnderstanding of HIPAA and importance of privacy of patient data.\nFoundation Medicine is proud to be an Equal Opportunity and Affirmative Action employer and considers all qualified applicants for employment without regard to race, color, religion, sex, gender, sexual orientation, gender identity, ancestry, age, or national origin. Further, qualified applicants will not be discriminated against on the basis of disability or protected veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also FMI\u2019s EEO Statement and EEO is the Law and Supplement. If you have a disability or special need that requires accommodation, please let us know by completing this form. (EOE/AAP Employer)\nApply Now: click Apply Now"}, "457": {"company": "Perfect World Entertainment", "description": "The Data Scientist provides data-driven insights related to several of Perfect World\u2019s services and products, including our popular games and the global game publishing platform.\n\nHe/she identifies the opportunities that would help improve the user acquisition, retention and monetization of our games.\n\nIdeal candidates will have a deep understanding of statistics and machine learning algorithms, experience working with large datasets, and an ability to communicate actionable insights directly to non-technical audiences.\n\nKey Qualifications\n2 years of industry experience in a Data Science or Analytics role.\nExperience with visualization software.\nWorking knowledge of SQL and Python/R.\nWorking experience of Machine Learning and predictive analytics.\nFamiliarity with the Hadoop framework, including the ability to interact with data through Hive, Pig, or MapReduce preferred.\nStrong communication skills, both written and oral, and an ability to convey complex results in a clear manner.\nData Science or Analytics experience in gaming or marketing strongly preferred.\nEducation\nMajor in a quantitative field, such as Computer Science, Applied Mathematics, or Statistics, or equivalent professional experience.\nStart your job application: click Apply Now"}, "458": {"company": "Sojern", "description": "*** Please note: This is a 12+ month PT Internship, 20 hours per week ***\n\nAbout Us:\n\nWant to join a company on the cutting edge of technology and travel? Want to be part of a fantastic and fun company that's revolutionising the online travel advertising space?\n\nSojern works with 93% of the Fortune 500 travel companies and has spent more than a decade analyzing the complete traveler path to purchase. We drive travelers from dream to destination by activating multi-channel branding and performance solutions on the Sojern Traveler Platform for more than 8,500 customers around the world.\n\nSojern made Deloitte's Technology Fast 500 list for the last 6 years in a row, and was recognised on the Top Company Cultures list by Entrepreneur Magazine and named a Best Place to Work by AdAge. The company is headquartered in San Francisco, with teams based in Dubai, Dublin, Hong Kong, London, Mexico City, New York, Omaha, Paris, Singapore, Sydney and Istanbul.\n\nNeed more convincing that Sojern is a great place to work? Check out our Glassdoor reviews!\n\nThe Role:\n\nThe Analyst & Data Science Intern role will focus on gaining an understanding of the online advertising ecosystem and use data to drive customer performance, operational efficiencies and company margin. An Analyst & Data Science Trainee will play a critical role within the Operations team by ensuring Sojern's clients' programmatic campaigns are structured and optimized in a way to drive optimal performance for Clients and Sojern. The intern will also have the opportunity to work cross functionally with Product, Engineering and Data Science. Upon completion of the program, interns who develop the necessary skill set will have the opportunity to apply for available full-time Data Science positions.\n\nIf you thrive in a fast-paced, innovative and collaborative environment, and are excited by the idea to make impactful data-driven decisions every day, then Sojern is the place for you!\n\nResponsibilities:\nManage Sojern Clients' programmatic campaigns by combining audience segmentation, bidding, delivery and pricing strategies to extract optimal conversion based performance by leveraging Sojern's travel data.\nSolve real client challenges by utilizing data mining and visualization to identify and implement new solutions.\nHave an opportunity to collaborate with the Product, Engineering and Data Science teams on a capstone project at the end of the internship.\nCollaborate with the global analyst team on automation projects and best practices.\nWhat you bring to the table:\nCurrent Graduate or Undergraduate student working towards a degree in data science, data analytics, statistics, or a related field.\nExperience with SQL and the Python Data Science toolkit (e.g. Jupyter, Pandas, Scikit-learn, Numpy).\nAbility to commit to 20 hours a week during normal business hours.\nCoursework covering topics such as sampling, hypothesis testing, regression, and Bayesian statistics.\nAbility to commit to the 12+ month program depending on current year in school.\nPerks:\nOpportunities: Be part of a growing team with training and support to help you grow\nOwnership: Lead creative and challenging projects\nGive Back: We give 40 hours a year to volunteer and organize office volunteer programs with local organizations\nCulture: Strong core business values, focus on teamwork, vibrant, social and fun environment\nSnacks: Variety of snacks in the office\nMeals: Monthly catered lunches & happy hours\nAt Sojern, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\n]]>\nTo apply to this job, click Apply Now"}, "459": {"company": "Software Resources, Inc.", "description": "Software Resources has an immediate long term contract job opportunity for a Data Scientist with a major corporation in Orlando, FL.\n\nDescription:\nRelevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, or software engineering.\nAn ideal candidate for the Lead Machine Learning Scientist role should have practical experience, a love of experimentation, and a passion for the problem we're trying to solve. In this position, you will play a central role in developing Client ways to leverage machine learning and statistical analyses. You'll use a mixture of supervised and unsupervised techniques to generate and test hypotheses and turning your results into actionable, impactful insights. You will be exposed to and incorporate a variety of statistical and machine learning techniques such as logistic regression, experimental design, generalized linear models, mixed modeling, CHAID/decision trees, neural networks and ensemble models.\n\nWhat You'll Do:\n\" Knowledge of statistical concepts such as regression, time series, mixed model, Bayesian, clustering, etc., to analyze data and provide insights.\n\" Conduct statistical analysis and build time series models using linear regression, ARIMA, DLM, VAR, and VECM. Responsible for creating and implementing AI, machine learning and deep learning algorithms to solve business problems. Design project specific custom model architectures, preprocessing and postprocessing pipelines and training and evaluation procedures. Deploy machine learning and deep learning models from prototype stage to production ready, highly scalable applications capable of real-time and batch inference. Develop models to derive information from text using natural language processing like parts of speech, named entity recognition, constituency parsing, and dependency parsing. Automatically summarize text, classify text, extract sentiment and infer latent topics from text data to predict company performance.\nResearch, prototype, and develop core machine learning and statistical analyses for commercial strategy data including revenue and capacity data.\nMix supervised and unsupervised methods to train classifiers.\nLeverage cloud-based technologies to collate and pre-process model input data.\nWork closely with our team to validate and improve experiment results.\nAbout You:\nYou're adaptable, driven, and have at least a BS in Computer Science, Statistics, Mathematics, Applied Mathematics, or a related field.\nYou're a leader: you can accomplish things on your own, but you also bring out the best in people around you.\nYou have 3+ years of experience in architecting, implementing, and evaluating machine learning and/or image processing approaches for unique datasets.\nYou're proficient in Python and common machine learning frameworks\nYou're familiar with cloud computing technologies and conducting experiments on cloud-based datasets (e.g. Amazon EC2, Amazon S3, Docker, Snowflake).\nYou have strong written and verbal communication skills to share findings with the rest of the team.\nPluses:\nMS/Ph.D. in a relevant field.\nDemonstrable experience as a primary developer for production Client solutions.\nProficiency in machine learning and statistics theory, as well as knowledge of recent advances in deep learning.\nRequired Education:\nBS Computer Science or Math\n\nDon't delay. Join the Software Resources team today!\nSoftware Resources specializes in connecting talented IT professionals with challenging job opportunities that transform jobs into careers.\nTo meet our clients hiring needs, we continuously source talented IT Professionals with all levels of expertise and in all disciplines. We offer world class major medical, dental and vision benefits, 401(k) with match, short term disability, Life Insurance and AD&D. You, our future employees, can make a tremendous difference to our company and our clients. Please apply to this job and experience the Software Resources difference. You can view all of our jobs at https://www.softwareresources.com/careers/\n\nCompany Overview\nSoftware Resources is a national staffing and recruitment firm delivering the best candidates to our clients and the best jobs to our candidates since 1992.\nWe are a certified woman owned business in business to place contract, contract-to-hire, and direct-hire talent in Technology (IT, creative, marketing), finance, accounting, and executive-level positions. We serve many vertical markets including Entertainment/Media, Cruise Industry/Leisure travel, Hospitality, Government, Personal Care, Professional Services, Energy/Utilities, Security, and Financial Services.\n\nHeadquartered in Lake Mary, FL in the Orlando metro area, we have branches and sales professionals across the US. Wherever you're located and whatever the need, count on Software Resources to provide exceptional candidates who are fully vetted and ready to go. Call (800) 774-8036 or visit us online at https://www.softwareresources.com/ and leave the recruiting to us!\n\nTo apply to this job, click Apply Now"}, "460": {"company": "Berg Health", "description": "NO AGENCIES - PLEASE!!!\n\nPosition Summary:\n\nThe Digital Health team is seeking a highly motivated, meticulous and detail-oriented individual for a multi-disciplinary team. The candidate will be instrumental in analyzing and making inferences from healthcare big data and must be goal oriented and should have strong background in statistics, epidemiology and possess some programming skills. The candidate should also be a quick learner, flexible and able to adapt to needs of the project.\n\nResponsibilities:\nExecution of meticulous and well thought out data analysis for building predictive algorithms on healthcare big data\nDevelopment and execution of data analysis protocols to support company's discovery pipeline\nDetailed documentation of data analysis methods and findings\nPresentation of scientific results internally and externally\nPreparation and submission of scientific manuscripts for review and publication\nOther duties, as assigned\nQualifications:\nRequires a Ph.D. in Statistics, Epidemiology, Public Health, Data Science or related field\nExperience working with healthcare claims, pharmacy and electronic medical record data (EMR) is a highly desirable.\nStrong skills in statistics and study design.\nProficiency in R and ability to work in Linux environment are required\nExperience with SQL, Hadoop, Python is preferred\nProven experience in applying Data Science methodologies to extract, process and transform data from multiple sources\nProven ability to find creative, practical solutions to complex problems.\nExcellent communication and interpersonal skills combined with superior and proven track record of technical and organizational skills.\nAbility to multitask and work in a team-oriented environment\n\nApply Now: click Apply Now"}, "461": {"company": "Hilton Corporate", "description": "Job Summary\n\nHilton is creating a best-in-class data & analytics department that will lead a connected ecosystem of data, technology, tools, techniques, people and processes. This innovative data & analytics function will drive advanced analytics and actionable insights to help drive Hilton's performance.\n\nWhat will I be doing?\n\nThe Data Science Team serves as internal advanced analytics elite consultants to key functions across Hilton's business, bringing predictive and prescriptive analytics through ML/AI. The team consists of data scientists, advanced analytics modelers, and data engineers, working closely with other DNA teams, Pricing and Revenue Management teams, as well as Product partners.\n\nWorking with the Sr. Director, Data Science, the Manager, Data Scientist, will be working with other Pricing scientists and directly influencing the creation and delivery of advanced Pricing and Revenue Management solutions/services. You will be responsible as a key resource for defining and recommending data science algorithms thru a service architecture framework.\n\nMore specifically, you will:\nWork closely with business, technology, and data science teams to gather, analyze and understand business requirements. This includes translating activities and business goals into analytical models and algorithm codes for application in a production scale environment.\nPerform analysis on existing as well as new data sets to identify and foster innovative advanced analytics opportunities.\nDocument, develop, code, and test data science modules into scalable solutions in a big data environment.\nWork with multi-functional teams to access data elements, understand the data being analyzed, and identify improvement opportunities for data ingestion process.\nFacilitate and identify repeatable testing and measurement strategies from results produced by analytics models/algorithms.\nProvide insights and solutions regarding data storage and optimization.\n\nWhat are we looking for?\n\nWe are looking for problem solvers, who are passionate about data and who love to have the opportunity to create improvements to data management. We believe success in this role will demonstrate itself through the following attributes and skills:\nSelf-starter, well organized, and a confident teammate willing to take ownership of responsibilities with a high level of positive energy and drive\nExcellent time management and project management skills that contribute to leading multiple priorities, working well under time constraints and effectively handling concurrent demands to prioritize responsibilities\nEffective communicator, collaborator, influencer and solution seeker across a variety of opinions\nAccountable individuals, who take ownership of projects, effectively communicate results and recommend improvements\nStrong communicators, both verbally and in writing, who effectively communicate at all levels of the organization\nTo fulfill this role successfully, you should demonstrate the following minimum qualifications:\nTwo (2) years of experience in data science, linear/integer and non-linear optimization, and/or applied statistics\nOne (1) year of hands-on experience in architecting, developing and implementing advanced analytics models, machine learning algorithms for scalable environments\nAdvanced programming skills in Python and/or R (and their related data science, machine learning, and visualization libraries)\nExperience with CPLEX, Gurobi, or comparable optimization suite\nExposure to Spark/Scala, Java, C/C++, SQL\nIt would be helpful in this position for you to demonstrate the following capabilities and distinctions:\nPhD Doctorate Degree in Data Science, Operations Research, Computer Science, Engineering, or related technical fields\nOne (1) year of experience in a full life-cycle analytics code development, deployment, and maintenance efforts involving distributed data sets\nExperience in pricing science and revenue management methods\nHands-on experience in statistics, machine learning, artificial intelligence, natural language processing, deep learning\nExperience in ETL management, SQL/no SQL platforms, Apache products (NiFi, KafKa) and data warehousing technologies (Snowflake, Redshift)\nWhat will it be like to work for Hilton?\n\nHilton is the world's leading global hospitality company, spanning the lodging sector from luxurious full-service hotels and resorts to extended-stay suites and mid-priced hotels. For nearly a century, Hilton has offered business and leisure travelers the finest in accommodations, service, amenities, and value. Hilton is dedicated to continuing its tradition of providing exceptional guest experiences across its global brands. Our vision to fill the earth with the light and warmth of hospitality unites us as a team to create remarkable hospitality experiences around the world every day. And, our amazing Team Members are at the heart of it all!\n\nEOE/AA/Disabled/Veterans\n\nApply Now: click Apply Now"}, "462": {"company": "Penske Logistics", "description": "Position Summary:\n\nThe Staff Data Scientist will be a key role in the Data Science and Analytics team tasked with providing technical leadership for the establishment of enterprise wide capabilities in data engineering and predictive analytics. The Staff Data Scientist will typically work on 3-5 large projects concurrently that have organization-wide impact. In addition to these projects, the Staff Data Scientist will provide technical consultation, advice and training on all major on-going Data Science and Analytics projects. As and when required, the Staff Data Scientist will also act as a project manager where vendors, suppliers and consultants are engaged on key strategic and emerging technology initiatives.\n\nMajor Responsibilities:\n\nIdentifying Analytics Opportunities\n\n\u2022 Identify business opportunities or problems to improve productivity and generate cost savings\n\n\u2022 Help in the development of business case with clear ROI to communicate and prioritize projects to senior leadership\n\nLead Data Science Projects\n\n\u2022 Lead the translation of business requirements into technical solutions\n\n\u2022 Identify appropriate techniques and algorithms for building model; Create, test and deploy model\n\n\u2022 Ensure organization wide adoption of solution\n\nTechnical Guidance on Analytics Projects\n\n\u2022 Advise analytics teams on technical concepts, including but not limited to ML algorithms, hyper tuning and scripting\n\n\u2022 Help with training effort and development of data engineering and data science associates in new technologies (ETL/various AWS services).\n\nProject Management\n\n\u2022 Ensure the creation of project plans, milestone charts and communication plan for key strategic initiatives\n\n\u2022 Conduct regular stakeholder and executive meetings to provide on-going communication and status\n\nLead technology change in Data Engineering and Analytics\n\n\u2022 Evaluate new technologies and determine if and how they can be applied\n\n\u2022 This will include evaluating and recommending new technology and services to enable a modern, flexible and state of the art unified data platform.\n\nQualifications:\n\n\u2022 Master's Degree required; preferred concentrations in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field.\n\n\u2022 PhD preferred in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field.\n\n\u2022 7 years of experience along with a PhD in a related field OR 10 years of experience along with a Master\u2019s degree in a related field required.\n\n\u2022 Experience Required in both Data Science and Data Engineering disciplines:\n\n- Data Science: Designing and building machine-learning applications using both structured and unstructured datasets is required. Practical experience programming using Python, R or other high level scripting languages is required. Demonstrated experience with one or more machine learning techniques including logistic regression, decision trees, and random forests and clustering is required.\n\n- Data Engineering: Experience with modern data infrastructure in designing data pipelines and ETLs is required. Knowledge of Big Data tools, frameworks, cloud architecture in a public cloud environment is required. Experience with both traditional on-premise Business Intelligence/Data Warehouse and Data Warehouse in the cloud.\n\n\u2022 Ability to collect and analyze complex data.\n\n\u2022 Advanced skill in machine learning, statistical modeling, SQL, and database concepts required.\n\n\u2022 Intermediate skill in statistical computing packages (e.g., R), and scripting languages (e.g., Python) required.\n\n\u2022 Regular, predictable, full attendance is an essential function of the job\n\n\u2022 Willingness to travel as necessary, work the required schedule, work at the specific location required, complete Penske employment application, submit to a background investigation (to include past employment, education, and criminal\n\nhistory) and drug screening are required.\n\nPhysical Requirements:\n\n-The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\n\n-The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines.\n\n-While performing the duties of this job, the associate may be required to stand, walk, and sit. The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms. The associate must be\n\nable to occasionally lift and/or move up to 25lbs/12kg.\n\n-Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus.\n\nAbout Penske Logistics\n\nPenske Logistics is a wholly owned subsidiary of Penske Truck Leasing. With operations in North America, South America, Europe and Asia, Penske Logistics provides supply chain management and logistics services to leading companies around the world. Penske Logistics delivers value through its design, planning and execution in transportation, warehousing and freight management. Visit www.PenskeLogistics.com to learn more.\nTo apply to this job, click Apply Now"}, "463": {"company": "Pivotal Software", "description": "LOCATION: Remote (home based) with some travel to New York, Washington DC, Boston.\n\nAbout Us VIDEO\n\nFounded in 2013, Pivotal Software, Inc. combines our leading cloud-native platform, tools, and methodology to empower the world's largest organizations to adapt to change and build great software. Our technology unleashes developer productivity, while fulfilling our mission to transform how the world builds software.\n\nYou\n\nAs a data scientist on Pivotal's Data Science team, you'll be working on a wide variety of data problems for a diverse range of clients. You will often be asked to learn new technologies and domains on the fly. You should be comfortable working under deadlines and making tough decisions. Consequently, you will frequently have to balance achieving an immediate goal with scalability and productionalizability.\n\nThe role offers room for personal and professional growth, and you won't be working in isolation. Data Science at Pivotal is an encouraging and supportive team, where ideas and challenges are addressed collaboratively. We're looking for the kind of person who will try and solve a problem on their own first, but isn't afraid to ask for help or say \"I don't know.\"\n\nUs\n\nThe Data Science team at Pivotal is primarily a consulting practice; we are tool agnostic, working with our customers to solve real world problems. Our customers, like us, are cross-disciplinary. We service engagements with use cases running from customer churn to optimization to detecting fraud and misconduct. We are not just doers, we are also educators and enablers.\n\nYour Day\n\nWhile there is no such thing as a \"typical day\", these are activities we frequently find ourselves doing:\nWorking with clients to uncover and frame new opportunities for data science. Clients often come to us without a clear understanding of what we can do, so this is our chance to open their eyes to new possibilities for their businesses.\nExploring client datasets, looking for actionable insights we can present.\nEngineering features, training models, tuning hyperparameters and evaluating the results. We emphasize rigor, because data science done right at this stage leads to models that shine in production.\nTaking the models we build into production. This is an exciting stage for anyone who likes collaborating with engineering teams and seeing their model become real when users interact with it.\nHelping our clients develop their internal data science practices, from hiring and recruiting to data capturing, so that they can be successful when we hand off the project.\nRequired Skills / Experiences\nClear and empathetic communicator. You'll be the one sharing your insights with clients and stakeholders at check-ins, documenting your work, and even explaining your model to client data teams as part of a handoff. As such, communication and empathy are essential parts of your toolkit.\nAdvanced knowledge of statistical modeling and/or machine learning methods. These are the tools we need to go from analysis to prediction.\nStrong programming skills. Left to our own devices most of us work in Python, but learning the client's tech stack is an important part of the job.\nStrong exploratory data analysis skills. Every engagement starts with an investigation of the data, and thorough EDA saves us a lot of headaches in the long run.\nSome travel is expected, depending on location and skillset. We mostly work out of the Pivotal office closest to the client, but sometimes we have to be on site for an extended period of time.\nAt least a bachelor's degree in an analytical or technical field. This could be applied mathematics, statistics, computer science, operations research, economics, etc. Higher education welcome and encouraged.\n\nThis role will support US government clients that require US citizenship. Given this, US citizenship is required for you to apply.\nDesired Skills / Experiences\n2+ years of work in a data-centric field (data science or data engineering).\nExperience with relational databases.\nExposure and experience working in a Linux environment.\nYou have a specialization in an area like NLP, optimization, or image processing.\nHands-on experience working in a distributed computing environment or proven theoretical understanding of parallelism.\nPivotal is an Equal Employment Opportunity employer that will consider all qualified applicants, regardless of race, color, religion, gender, sexual orientation, marital status, gender identity or expression, national origin, genetics, age, disability status, protected veteran status, or any other characteristic protected by applicable law.\nApply Now: click Apply Now"}, "464": {"company": "Pactera", "description": "Looking fora Data Scientis/Architect who has 8 yrs of exp in data design, data modelling, data flow, analytics in supply chain domain.\n\nHere\u2019s the detail JD:\nExpert programming skills in Python, R\nExperience in writing code for various Machine learning algorithms for classification, clustering, forecasting, regression, Neural networks and Deep Learning\nHands-on experience with modern enterprise data architectures and data toolsets (ex: data warehouse, data marts, data lake, 3NF and dimensional models, modeling tools, profiling tools)\nStrong knowledge of Supply Chain domain, preferably in the hi-tech industry\nStrong problem solving and abstract thinking skills\nKnowledge of data architecture and design patterns and the ability to apply them\nAbility to conceptualize and articulate ideas clearly and concisely\nExcellent communication, presentation and interpersonal skills\nStart your job application: click Easy Apply"}, "465": {"company": "Comtech Safety & Security Technologies", "description": "Data Analyst Windows/UNIX\nSeattle, WA\nwww.Comtech911.com\nABOUT THE OPPORTUNITY:\nThe MSAG Data Analyst position\u2019s primary responsibility is to support carrier service providers with address validation issues. The analyst works in a collaborative team environment and is responsible for Comtech address data, vendor outreach to resolve addressing issues by auditing and resolving fallout in a 911 customer-critical address data set. The analyst will also process data using Oracle SQL and other database tools, loading data into an Oracle database, validating address datasets, and preforming fallout resolution. The analyst\u2019s overall objective is to ensure that Comtech\u2019s address validation maintains the highest accuracy, which is used in routing 911 calls.\nMajor Duties and Responsibilities:\nThe data analyst will be responsible for increasing the accuracy of the database, including:\nResolve data inconsistencies, conflicts, inaccuracies, and other fallout of subscriber data.\nProvide reporting and feedback to team regarding address data inconsistencies.\nIdentify and create methods for proactively identifying potential fallout.\nIdentify data inconsistencies and conflicts in address data sets.\nIdentify and perform detailed analysis of all data sources for each application and subject area.\nWork towards aggressive timelines to maximize data accuracy.\nProvide the data mapping and associated transformation rules for each data item.\nWork with internal teams to learn and support 911 specific business processes.\nKnowledge & Skills:\nMust be able to work in both Windows desktop and Unix command line environments.\nMust have advanced experience with MS Office, specifically Excel and Access.\nMust have experience using databases and tables to perform analysis and reporting required.\nRequire strong experience using Oracle, mySQL, or other RDBMS.\nFamiliarity using geographic data sets and GIS a strong plus.\nFamiliarity with addressing and maps a strong plus.\nExperience & Other Requirements:\n4-year college degree or equivalent required.\nMinimum 2 years data analysis experience required.\nExhibit strong verbal and written communication skills.\nDisplay high levels of self-motivation.\nAbility to self-direct and take ownership required.\nCritical, creative, and conceptual thinking abilities required.\nAbility to manage multiple tasks and function as part of a team required.\nComtech is an Equal Opportunity Employer \u2013 M/F/Veteran/Disability/Sexual Orientation/Gender Identity\nTo apply to this job, click Easy Apply"}, "466": {"company": "Catalent Pharma", "description": "Job Description\n\n\nPosition Overview:\n\nCatalent hires people with a passion to make a difference to the health of millions of people globally. Your expertise, coupled with Catalent\u2019s advanced technologies and collaboration with thousands of innovative pharmaceutical, biotech and healthcare companies, will help bring life-enhancing products to the people you know and love. Your talents, ideas and passion are essential to our mission; to develop, manufacture and supply products that help people live better, healthier lives. Interested in learning more about life at Catalent? Start here\n\nPosition Summary\n\nCatalent is looking to recruit a Scientist, Process Development to join our growing team in Bloomington, In.\n\nA Scientist in Process Development has primary roles to design, execute and analyze laboratory and pilot scale experiments for process development and scale-up of processes for the expression of biologics/biopharmaceuticals. Bioprocesses can be in mammalian cell culture bioreactors, protein purification operations like chromatography and filtration, drug product process development and/or drug product formulation.\n\nThe Scientist in Process Development is responsible for leading development work for projects in order to develop robust processes that scale effectively to GMP manufacturing as needed. The Scientist in Process Development will also apply technical knowledge to develop robust processes or assays, designing, executing and interpreting internal and external client experimental plans including DOE, troubleshooting experiments. The Scientist in Process Development will guide Assistant and Associate Scientists with troubleshooting and experimental design, acting as project lead, including preparing and presenting data to clients informally and formally, with support of Senior or Principle Scientists as necessary. They will maintain necessary documentation in a lab notebook, authoring and reviewing technical reports, and supporting process transfer into manufacturing by providing written and oral communication of the process, training of manufacturing associates, review and approval of documentation, and on-floor support.\n\nIn concert with Catalent\u2019s Patient First philosophy, the Process Development Scientist ensures the manufacturing processes can be ran successfully, and that the quality of final product delivered to patients is consistent with expectations.\n\nThe Role\nScientist will have complete knowledge of varied aspects or a single specialized aspect of a discipline and some knowledge of principles and concepts in other disciplines\nApplies technical and functional knowledge to conduct experiments/research in assigned area\nMay act as a technical resource within own work group/project team\nWorks independently to solve problems of moderate scope\nActively participates, suggests solutions to problems\nThe Candidate\nBachelor\u2019s degree in science field with 5-7 years of experience OR\nMaster\u2019s degree in science field with 2-4 years of experience OR\nPhD in science field with 0-2 years of experience\nCatalent\u2019s standard leadership competencies that are used to interview and for Performance & Development:\nLeads with Integrity and Respect\nDelivers Results\nDemonstrates Business Acumen\nFosters Collaboration and Teamwork\nChampions Change\nEngages and Inspires\nCoaches and Develops\nPosition Benefits\nPotential for career growth within an expanding team\nDefined career path and annual performance review & feedback process\nCross functional exposure to other areas of Catalent\nMedical, Dental, Vision, and 401K are all offered from day one of employment\n19 days of paid time off annually + 7 paid holidays\nCatalent offers rewarding opportunities to further your career! Join the global drug development and delivery leader and help us bring over 7,000 life-saving and life-enhancing products to patients around the world. Catalent is an exciting and growing international company where employees work directly with pharma, biopharma and consumer health companies of all sizes to advance new medicines from early development to clinical trials and to the market. Catalent produces more than 70 billion doses per year, and each one will be used by someone who is counting on us. Join us in making a difference.\n\npersonal initiative. dynamic pace. meaningful work.\nVisit www.catalent.com/careers to explore career opportunities.\n\nCatalent is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, sexual orientation or gender identity. If you require reasonable accommodation for any part of the application or hiring process due to a disability, you may submit your request by sending an email, and confirming your request for an accommodation and include the job number, title and location to DisabilityAccommodations@catalent.com. This option is reserved for individuals who require accommodation due to a disability. Information received will be processed by a U.S. Catalent employee and then routed to a local recruiter who will provide assistance to ensure appropriate consideration in the application or hiring process.\n\nNotice to Agency and Search Firm Representatives: Catalent Pharma Solutions (Catalent) is not accepting unsolicited resumes from agencies and/or search firms for this job posting. Resumes submitted to any Catalent employee by a third party agency and/or search firm without a valid written & signed search agreement, will become the sole property of Catalent. No fee will be paid if a candidate is hired for this position as a result of an unsolicited agency or search firm referral. Thank you.\nTo apply to this job, click Apply Now"}, "467": {"company": "Argus Information & Advisory Services", "description": "Company Description\n\nAs one of the original innovators in lending, credit, fraud, and spend analytics, Verisk Financial integrates one of the industry\u2019s largest sets of data to help banks, financial regulators, retailers, and media companies grow their businesses. We combine data with predictive analytics to uncover new consumer and business insights and integrate this data with the most technologically advanced platforms.\n\nVerisk Financial | Argus is a leading provider of intelligence, decision support solutions, and advisory services to financial institutions across the global commerce ecosystem. Our clients include more than 50 top U.S., Canadian, and other international financial organizations, regulators, payment providers, merchants, and media. Argus is the leading source of segment-level portfolio management benchmarking data, analytics, models, and advisory services. We maximize value delivery to clients by combining proprietary data sets, cutting-edge software and analytic tools, domain expertise, and our unique results-oriented approach. Customers worldwide use our services for tailored data management solutions that include business intelligence platforms, profile views, mobile data solutions, enterprise database services, and fraud risk scoring algorithms for marketing, fraud, and risk mitigation. Our clients gain competitive advantage from our exclusive focus on leveraging global best-in-class analytics and methodologies to help achieve their business and regulatory objectives. To learn more about Argus please visit us at: www.argusinformation.com. We are proud to be a part of the Verisk family of companies!\n\nWith a history of impressive growth, an innovative culture, and offering industry-leading solutions, Verisk Analytics is an amazing place to work and make a difference. In 2018, Forbes magazine named Verisk to its World\u2019s Best Employers list and, in 2017, to its World\u2019s Most Innovative Companies list for the third consecutive year. We also earned the Great Place to Work\u00ae Certification for the third consecutive year in recognition of our outstanding workplace culture.\n\nVerisk is a leading data analytics provider serving customers in insurance, energy and specialized markets, and financial services. Using advanced technologies to collect and analyze billions of records, Verisk draws on unique data assets and deep domain expertise to provide first-to-market innovations integrated into customer workflows. We\u2019ve been delivering predictive analytics and decision support solutions to our customers for nearly 50 years, helping them protect people, property, and financial assets. At Verisk, you\u2019ll be part of an organization that\u2019s committed to serving the long-term interests of our stakeholders, including the communities where we operate.\n\nAt Verisk, you can build an exciting career with meaningful work; create a positive and lasting impact on the business; and find the support, coaching, and training you need to advance your career. Our culture of innovation means your ideas on how to improve our business will be heard. As key contributors to our success, our team members enjoy working in a business-casual, collaborative environment that offers state-of-the-art resources, advanced technologies, and an excellent benefits package.\n\nJob Description\n\nVerisk Financial is seeking an experienced Data Science professional who\u2019s excited to take on some of the world\u2019s most difficult data challenges. A Principal Data Scientist is a proven leader and mentor who loves getting their hands-on data and solving challenging problems with real-world impact. You will be able to shape how data science is done on a wide variety of problems at Verisk Financial and how we grow our data science function.\n\nWhat we are looking for:\n\nYou will have at least 5-7 years of experience in applied research and statistical modeling with a degree or higher (MS/Ph.D.) in statistics, mathematics, physics, or similar field\n\n\u00b7 A track record of creatively tackling challenging data problems\n\n\u00b7 Full understanding of common machine learning techniques and familiarity with ongoing research\n\n\u00b7 Success mentoring and growing exceptional data scientists\n\n\u00b7 Fluency with analytical programming, including libraries for cleaning, reshaping, exploring and visualizing data\n\n\u00b7 Strong knowledge of machine learning, computer science, mathematics, and statistics\n\n\u00b7 Experience with several of the following concepts: decision trees, random forests, and gradient boosting; linear regression; logistic regression; linear and non-linear dimensionality reduction using PCA, kernel methods, and dictionary learning; clustering with K-means, hierarchical clustering, and DBSCAN; autoencoders; generative models; and sequential data modeling\n\n\u00b7 Strong programming skills in Python, R, and SQL\n\n\u00b7 The ability to clearly convey complex concepts with plain language\n\n\u00b7 Demonstrated ability to produce high-quality, product-focused, scalable analysis\n\n\u00b7 Problem-solving with determination, perseverance, and grit\n\n\u00b7 You are motivated by working on hard problems with smart people\n\n\u00b7 Ability to prioritize\n\n\u00b7 Experience running or working at data-centric startups is plus\n\nQualifications\nStrong programming skills in Python, R, and SQL\n\u00b7 The ability to clearly convey complex concepts with plain language\n\u00b7 Demonstrated ability to produce high-quality, product-focused, scalable analysis\n\u00b7 Problem-solving with determination, perseverance, and grit\n\u00b7 You are motivated by working on hard problems with smart people\n\u00b7 Ability to prioritize\n\u00b7 Experience running or working at data-centric startups is plus\nAdditional Information\n\nVerisk Analytics is an equal opportunity employer.\n\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.\n\nhttp://www.verisk.com/careers.html\n\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\n\n</br>Apply now\nStart your job application: click Apply Now"}, "468": {"company": "Genomic Health", "description": "Genomic Health, a subsidiary of Exact Sciences is seeking an exceptional individual with strong statistical skills to participate in the development of genomic biomarker assays that help cancer patients and their physicians make better treatment decisions. The Data Scientist II will directly support more senior personnel in pursuit of all Nonclinical Biostatistics (NCB) efforts across our various internal customer groups. In particular, these efforts will support Process Engineering, New Technologies development, and R&D efforts across multiple projects.\n\nAdditional responsibilities may include but are not limited to: relevant study support for Assay Development and the Development Lab work (e.g., initial data display and analysis), Analytical Chemistry/Analytical Sciences, Commercial Lab support and data monitoring, and clinical data QC for clinical studies. The candidate will interact with more senior staff of NCB and under their direction/supervision, establish close working relationships with our internal customer groups.\n\nRESPONSIBILITIES / DUTIES:\n\n\u2022 Primary responsibility will be to support the NCB staff and our internal customers in the development of any and all assigned projects, including but not limited to:\nNew Technologies and their evaluation\nProcess monitoring subsystems\nGHI Commercial Lab data monitoring and QC\nTable formation and development of descriptive statistics as required\n\u2022 Support will consist of but will be limited to:\nCode development in SAS, R, or Python as directed\nData review under the guidance of the NCB designated technical lead\nProcess improvement and automation\nProcess troubleshooting under the direction of the NCB designated technical lead\n\u2022 Secondary responsibilities will include when appropriate, direct support for our customer base, and under some supervision provide statistical guidance and advice with respect to initial analyses, data visualization, and tabularization.\n\nQUALIFICATIONS:\n\n\u2022 MS or Ph.D. in Biostatistics / Statistics\n\u2022 A minimum of 2 (Ph.D.) or 6 (MS) years of relevant work experience in industry or academia\n\u2022 Sound knowledge of theoretical and applied statistics\n\u2022 Experience in analyzing high dimensional data, designing/performing DOE studies\n\u2022 Statistical process control, analytical method development, and validation\n\u2022 Good written and oral communication skills\n\u2022 Able to integrate and apply feedback in a professional manner\n\u2022 Able with direction to prioritize and drive to results with a high emphasis on quality\n\u2022 Ability to work as part of a team\n\u2022 Experience with Machine Learning, and Deep Learning frameworks desirable\n\nPHYSICAL REQUIREMENTS:\n\n\u2022 Use of computer, and or telephone for long periods of time may be necessary.\n\u2022 Considerable periods of time may be spent concentrating and or analyzing data\n\u2022 Considerable periods of time may be spent communicating verbally and in various written forms including presentation material and email with other people\n\u2022 At times, stress may be experienced.\n\u2022 Standing or sitting for long periods of time may be necessary\n\u2022 Some lifting (greater than 25 pounds) may be necessary; Facilities, Materials and Engineering employees occasionally must lift at least 50-75 pounds.\n\u2022 May be exposed to hazardous materials, tissue specimens and instruments with moving parts, lasers, heating and freezing elements, and high-speed centrifugation (GENERALLY LABORATORY & CUSTOMER SERVICE EMPLOYEES ONLY)\n\n#LI-CB1\n\nWe are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to age, color, creed, disability, gender identity, national origin, protected veteran status, race, religion, sex, sexual orientation, and any other status protected by applicable local, state or federal law. Applicable portions of the Company\u2019s affirmative action program are available to any applicant or employee for inspection upon request.\n\nPhysical Requirements\n\n\u2022 Use of computer, and or telephone for long periods of time may be necessary.\n\u2022 Considerable periods of time may be spent concentrating and or analyzing data\n\u2022 Considerable periods of time may be spent communicating verbally and in various written forms including presentation material and email with other people\n\u2022 At times, stress may be experienced.\n\u2022 Standing or sitting for long periods of time may be necessary\n\u2022 Some lifting (greater than 25 pounds) may be necessary; Facilities, Materials and Engineering employees occasionally must lift at least 50-75 pounds.\n\u2022 May be exposed to hazardous materials, tissue specimens and instruments with moving parts, lasers, heating and freezing elements, and high speed centrifugation (GENERALLY LABORATORY & CUSTOMER SERVICE EMPLOYEES ONLY)\n\nCompany Profile:\n\n\nGenomic Health is a global provider of genomic-based diagnostic tests that address the overtreatment of cancer, one of the greatest issues in healthcare today. Our goal is to improve the lives of people with cancer by providing personalized, biological information that helps them get the right treatment at the right time, and to avoid unnecessary treatments and their side effects. In this way, our work is truly life, changing.\nOur Oncotype IQ Genomic Intelligence Platform is a portfolio of diagnostic tests that help physicians and patients answer specific and critical treatment questions throughout the cancer journey\nWe currently offer Oncotype tests addressing breast, colon, prostate and lung cancers and hundreds of thousands of patients from over 90 countries have benefited from our tests.\nThe Oncotype DX breast cancer test is considered standard of care in the US and is included in all major international clinical guidelines for breast cancer treatment.\nWe are expanding our portfolio of tests to include additional liquid- and tissue-based tests through clinical research and internal product development as well as strategic partnerships.\nJoin the Genomic Health Team, and have the unique opportunity to make a difference in the lives of patients with cancer, while developing your career potential. We embrace our unique culture characterized by our Core Values of Community, Truth Seeking, Being Ahead of the Curve and Winning to be the best in the world at what we do. We maintain competitive total rewards programs designed to satisfy our employees\u2019 work life and personal life needs.\n\nAll qualified applicants will receive consideration for employment without regard to race, sex, gender identity, color, religion, national origin, protected veteran status, or on the basis of disability.\n\nApply Now: click Apply Now"}, "469": {"company": "Assurance Careers", "description": "About Assurance\nAt Assurance we are disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosystem. We are rapidly growing as we expand our product offerings and global footprint, and this growth continues to present new and exciting challenges as we push our industry into its future. We eliminate waste throughout the industry and calculate the complex into simple, valuable solutions to improve people's lives. We are humble, driven, and committed to improving the lives of millions.\n\nAbout the Position\nAs we build the future of consumer insurance in a modern age, data is at the core of everything that we do. The role requires team members who are adept at using large data sets to find opportunities for optimization and can leverage appropriate models to test the effectiveness of different courses of action. Our team uses a variety of data mining and analysis methods, a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Team members must be very comfortable writing production-ready code to include testing and maintenance infrastructure, and able to put models and analysis into production with no support from engineering (we own our stack end to end). At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise.\nTo be successful in this role, you must possess the following:\nProficiency in either Python or R, and expertise in SQL.\nExperience working with AWS or another cloud-based computing platform.\nExperience and working knowledge of data infrastructure, pipelines, and advanced data manipulation.\nExperience with BI tools like Tableau or Looker (preferred), or any other industry tool such Qlik, PowerBI, Spotfire, etc.\nExcellent communication ability \u2013 you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.\nBusiness Acumen \u2013 you are always eager to understand how the business works, and more specifically, how your work impacts the business.\nEnthusiastic yet humble \u2013 you are excited about the work you do, but you are also humble enough to embrace feedback \u2013 you don\u2019t need to be the smartest person in the room.\nThe following additional experience is desired:\nExperience retraining a model within a few days or update a model within one day.\nCapable of performing an in-depth analysis and summarizing findings in one day.\nComfortable having conversations with our executive team and non-technical team members to distill down their needs and to deliver actionable insights.\nAbout You\nYou have a proven ability to drive business results with data-based insights and are comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. You\u2019re capable of getting data for analysis on your own, without reliance on engineering, and you can build professional dashboards as standalone software products and tools. We\u2019re growing at a rapid pace, so it\u2019s important that you embrace the opportunity to blaze your own trail. You thrive in a fast-paced environment where priorities can shift rapidly as we corner opportunity. You can work independently, with little oversight or guidance.\nIf this sounds like a good fit for you, give us a shout, we\u2019d love to chat!\nTo apply to this job, click Apply Now"}, "470": {"company": "QuantumBlack", "description": "Analytics\nSenior Data Scientist - QuantumBlack\n\nBoston\n\nApply Now\n\nQualifications\n\nMSc or PhD level in the field of Computer Science, Machine Learning, Applied Statistics, Mathematics\nExperience in statistical modelling and machine learning techniques\nProgramming experience in at least two of the following languages: R, Python, Scala, SQL\nExperience in applying data science methods to business problems\nExperience in applying advanced analytical and statistical methods in the commercial world\nGood presentation and communication skills with the ability to explain complex analytical concepts to people from other fields\n\nWho You'll Work With\n\n\nAs a Senior Data Scientist at QuantumBlack in Boston you will work with other Data Scientists, Data Engineers, Machine Learning Engineers, Designers and Project Managers on interdisciplinary projects, using Maths, Stats and Machine Learning to derive structure and knowledge from raw data across various industry sectors.\n\nWho you are\n\nYou are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritizing impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.\n\nWhat You'll Do\n\n\nYou will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally.\n\nYou will influence many of the recommendations our clients need to positively change their businesses and enhance performance.\n\nRole responsibilities\nWork on complex and extremely varied data sets from some of the world\u2019s largest organisations to solve real world problems\nDevelop data science products and solutions for clients as well as for our data science team\nWrite highly optimized code to advance our internal Data Science Toolbox\nWork in a multi-disciplinary environment with specialists in machine learning, engineering and design\nAdd real-world impact to your academic expertise, as you are encouraged to write \u2018black\u2019 papers and present at meetings and conferences should you wish\nAttend conferences such as NIPS and ICML as one global team as well as Data Science retrospectives where you will have the opportunity to share and learn from your co-workers.\nWork with one of the largest and most advanced data science teams, support the Lead Data Scientists to develop data science products\nWhat you\u2019ll learn\nHow successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines\nBuild products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations\nBe able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.\nBest practices in software development and productionize machine learning by working with our Machine Learning Engineering teams which optimize code for model development and scale it\nWork with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualizations\nUsing new technologies and problem-solving skills in a multicultural and creative environment\nYou will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.\nReal-World Impact\u2013 No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.\nFusing Tech & Leadership\u2013 We work with the latest technologies and methodologies and offer first class learning programs at all levels.\nMultidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.\nInnovative Work Culture\u2013 Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.\nStriving for Diversity\u2013 With colleagues from over 40 nationalities, we recognize the benefits of working with people from all walks of life.\nOur projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimizing a Formula1 car\u2019s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture:\nHealthcare Efficiency\u2013 We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.\nEnvironmental Impact\u2013 We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.\nProduct Development\u2013 We worked with the CEO of an elite automotive organization to reduce the 18-month car development timeframe by improving processes, designs and team structures.\nVisit our Careers site to watch our video and read about our interview processes and benefits.\n\nMcKinsey & Company is an equal opportunity employer.\n\nIndustries\nHigh Tech\n\nFunctions\nTechnology\n\nApply Now\nshare this job\n\nJob Skill Group - CSS Associate\nJob Skill Code - SPDS - Specialist, Data Science\nFunction - Technology\nIndustry - High Tech\nPost to LinkedIn - Yes\nPosted to LinkedIn Date - Sun Sep 08 20:00:00 GMT 2019\nLinkedIn Posting City - Boston\nLinkedIn Posting State/Province - Massachusetts\nLinkedIn Posting Country - United States\nLinkedIn Job Title - Senior Data Scientist - QuantumBlack\nLinkedIn Function - Consulting;Information Technology;Science\nLinkedIn Industry - Computer Software;Information Technology and Services;Management Consulting\n\nApply Now: click Apply Now"}, "471": {"company": "Pactera", "description": "Job title: Data Analyst\nLocation: Hartford CT\nOne of leading companies in the healthcare industry is now hiring a hands-on Data Analyst with 5+ years\u2019 experience as one of those roles of data modeling, data analysis and even data architect and experience of OLTP and OLAP system design.\nShould be working with multiple data sources including Salesforce or Dynamics. Must be able to work with business and data sources independently to understand data availability and business insights that can be driven.\nExperience of owning & managing all changes to the models, solution designs, and architecture documentation; determining database structural requirements by analyzing client operations, applications, and programming; reviewing objectives with clients; evaluating current systems;\nExtensive experience in Relational Data Modelling, Dimensional Data Modelling, Logical/Physical Design, ER Diagrams, Forward and Reverse Engineering ERWIN diagrams, analyzing data sources and creating interface documents;\nProficient in data mart design and creation of cubes using dimensional data modeling \u2013 identifying Facts and Dimensions, Star Schema and Snowflake Schema;\nExperience in SQL and good knowledge in SQL/SAS programming and experience of ETL tool of SSIS and reporting tool of SSRS;\nGreat communication and a passion for driving insights from data, working with developers\u2019 analysts and business, writing or reviewing functional specs as needed etc.\nApply Now: click Easy Apply"}, "472": {"company": "Proofpoint", "description": "It's fun to work in a company where people truly BELIEVE in what they're doing!\n\nWe're committed to bringing passion and customer focus to the business.\n\nThe Role\n\nDo you have a passion for applying machine learning to hard problems in new application areas? Do you keep up with the latest on GANs, ResNets, CNNs, RNNs, and Deep Reinforcement Learning but have also mastered the classics like SVM and Random Forest? Are you looking for the opportunity to work with a great team that combines algorithm design, software engineering, and domain knowledge into products that are first of their kind? If so, we are looking for you. We need a Data Scientist who will work on analyzing data from malicious actors to help uncover cyber threats. Your primary focus will be applying your skills in various areas like anomaly detection, graph mining, clustering, and predictive analytics to help us build groundbreaking services that would revolutionize the industry.\n\nWe are a fast-paced, high-energy team where you will be given the opportunity to make a significant impact. The team has a solid engineering culture that values the craftsmanship of writing great software, enjoys learning, and solving big problems.\n\nYour day-to-day\nFeature engineering, building and optimizing classifiers, applying machine learning and deep learning expertise\nBlending data from disparate sources, mining the resulting data lake to build models\nContributing tested code to the team\u2019s git repo and working with engineering to implement models efficiently\nProcessing, cleansing and verifying integrity of data used for analysis\nConducting ad-hoc analysis and innovation around data visualization\nWhat you bring to the team\nExcellent understanding of machine learning algorithms, processes, tools and platforms including:\nSupervised methods - Na\u00efve Bayes, Logistic Regression, SVM, ConvNet, LSTM, Siamese Networks, etc.\nUnsupervised methods - K-means, DBSCAN, T-SNE, Spectral Clustering, SOM, LSH, etc.\nToolkits - numpy, scipy, scikit-learn, tensorflow, pytorch, keras, genism, vowpal wabbit, etc.\nPython proficiency\nGreat communication skills, ability to explain predictive analytics to non-technical audience\nProficiency in data exploration techniques and tools, e.g. SQL, Hive, etc.\nExcellent statistics, linear algebra, and optimization skills\nMS in Statistics, Machine Learning, Applied Physics or Computer Science (or technical degree with commensurate industry experience). PhD preferred\n#LI-JL3\n\nIf you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!\nTo apply to this job, click Apply Now"}, "473": {"company": "Fareportal Inc.", "description": "(We are unable to sponsor for this role or in the future)\n\nAt Fareportal, we create the technology that is driving innovation in the travel industry - one of the world's fastest-growing sectors. Our employees are the core of our organization and together we're revolutionizing the way people book travel.\n\nOur portfolio of brands including CheapOair and OneTravel receive over 100 million visitors annually and drive over $4 billion in annual revenue.\n\nIn addition to competitive pay and benefits, generous time off, and frequent company-wide social events, Fareportal provides employees with an environment that nurtures diversity, creativity, and success. Our open and Agile workspace gives our employees the time and space for collaboration, brainstorming, and research and development. At Fareportal, you'll be challenged, rewarded, and motivated to work effectively day in and day out.\n\nWe are looking for a machine learning engineer to join our team. You will be handling hundreds of millions of events per day, responsible for creating and supporting machine learning models that will drive our business.\n\nMachine Learning Engineers is at the heart of how Fareportal works and they are part software engineer and part machine learning / data scientist. You will focus on creating and supporting large scale models that we deploy to power our recommendation, pricing or other systems.\n\nThe ideal candidate will participate in the design and implementation of the entire model pipeline, from project ideation, figuring out which data to capture and store, coming up with features, to creating the final model.\n\nWe are passionate about making data-driven decisions and you will have the opportunity to shape the team's direction and create large impact.\n\nOur team loves Python and Scala (and is not afraid of Functional Programming) and we strongly encourage DevOps approaches.\n\nResponsibilities:\nSupport our data modeling efforts to ensure we are capturing the data needed to improve our modeling\ncapabilities.\nCreate features for our feature store\nBuild machine learning models\nUse a variety of techniques including predictive modeling, recommendation engines, revenue\nmanagement, conversion rate optimization, and site and user experience optimization.\nOur ideal candidate:\n\nWho You Are\nYou are smart and love to build systems that are well tested as well as flexible\nYou like being around smart people who will challenge you on a daily basis.\nYou love to ramp up on new technologies to build awesome things with us!\nPassionate about working with large unstructured and structured data sets and developing new\napproaches to relevance problems\nRequirements\nBachelor in Computer Science, Software engineering, Data Science or related disciplines (we are open to exceptions) - Only May 2020 Undergraduates\nGood knowledge of one of: Python or Scala\nSolid understanding of object oriented or functional programming concepts\nFamiliarity with version control concepts\nGood knowledge of machine learning\nGood knowledge of Pyspark\nGood knowledge of software engineering best practices\nApply Now: click Easy Apply"}, "474": {"company": "Adavance2", "description": "About the position\nAdvance2 is a fast-growing marketing optimization tech startup. We\u2019re bringing the world of marketing optimization to the next level leveraging Machine Learning. Advance2 automates data collection, model building, insights extraction and optimization of our clients\u2019 business.\nWe are looking for a Data Scientist to be part of the Product Development team. You will be working alongside a small cross-functional team of Engineers and Data Scientists. You will enjoy designing, developing and deploying to production data-based approaches to solving difficult business and product problems.\nThe Data Scientist will be responsible for leveraging their expertise in data processing, statistical modeling, ML, and AI to build product solutions at scale.\nYou will thrive in this role of you love problem-solving, analytical thinking and combining doing math on the whiteboard with coding.\n\nResponsibilities\nDesign, develop and deploy Machine Learning algorithms to production.\nCollaborate with Software Engineers to streamline and optimize model building and deployment.\nPartner with Product Managers to help prioritize and deliver product features.\nApply Machine Learning and Artificial Intelligence expertise to build prototypes and translate them into product features.\nContribute in creating a data-driven approach to complex business problems in the company.\nQualifications\nM.A./M.S. or Ph.D. degree in Statistics, Mathematics, Economics, Physics, or Engineering\n3+ years of experience in building predictive models using statistics and/or Machine Learning at scale.\nExperience with extracting and delivering causal relationship findings from predictive models.\nWorking knowledge of Python and related data science libraries (NumPy, Pandas, Scikit-learn, SciPy).\nMedia/Agency experience is a plus.\nExperience with data visualization is a plus.\n\nAbout Advance2\nAdvance2 is the next generation AI-driven marketing optimization platform. We help our clients continuously optimize their marketing budget with a holistic approach by leveraging Machine Learning and automation.\nWhile advanced Machine Learning algorithms are often perceived as black-boxes, we strive to bring a human touch to our AI engine, conveying the thought process underlying the AI recommendations with the help of advanced visualizations."}, "475": {"company": "Remitly", "description": "At Remitly, we help immigrant communities around the world send over $6 billion a year to their loved ones. Sending money is faster, easier, and costs less with our all-digital money transfer platform. Our vision is to transform the lives of immigrants and their families by providing the most trusted financial service products on the planet. At Remitly, your work has a direct and positive impact on people around the globe. Your work matters, every day.\n\nWe are looking for an exceptional Machine Learning Engineer to join our global ML team to work on data products that underpin our business. Our ML team currently builds systems that set our FX rates for customers, detect bad actors using our product, and forecast volume to inform our currency trading strategy. This role will focus on the Pricing space where you will develop models that are used to price tens of millions of dollars worth of volume in real time every day.\n\nIn this role, you will:\nBuild production systems that set FX rates for customers in real time.\nBe a subject matter expert in Pricing and Treasury, and a thought leader with respect to pricing choices throughout Remitly. In this capacity you will partner with Economists, Analysts, and Engineers to build the strategies and products that power our pricing engine.\nProvide insightful statistical and econometric analysis that extracts value from complex datasets and achieves targeted outcomes.\nHave a significant impact on Remitly's bottom line. Your work will impact our customer facing product and dictate the exchange rates customers receive on transactions every day. As an exceptional business thinker, you will also provide analytical expertise and judgement to other teams including Treasury and Marketing.\nYou are:\nCustomer centric. Your models will be directly impacting the economics of everyday life for immigrants and their families. As a senior team member in this space, this role requires a high degree of empathy and commitment to our customers to ensure model outputs align with our cultural values.\nOutcome oriented. All models start and end with a business problem. You enjoy seeing and measuring the results of your work and are excited to build products with a large impact to the company.\nEconomically minded. We approach many problems from a microeconomic perspective. You enjoy finding the simplest form for a problem and aligning your underlying models with business intuition and economic theory.\nEnergetic. You continually exhibit high energy and an ability to stay positive under pressure. We should be a self-starter, able to work independently, as well as work in a team-oriented and fast paced environment.\nCurious. You ask why, and you question every assumption. If you've ever said \"oh, I just did it that way because [Important Person] said so,\" you won't do well here. We need you to probe assumptions, question the status quo, and follow up on unexpected data results.\nConfident in your data and ideas. You can explain the method to your analysis and validate your results. Once the data supports your ideas, you're willing to advocate your recommendations to any stakeholder that needs to buy-in (fortunately for you, we're happy to rally behind your great idea).\nSuccessful candidates should have:\nAn MS or PhD in Computer Science, Economics, Statistics, Applied Mathematics or a related area\n6+ years of work experience building production ready systems, with at least 4+ years applying statistics and machine learning that resulted in data-driven business impact.\nSolid knowledge of both the theory and application of ML algorithms.\nProficiency with systems design and data processing. Candidates should have hands on experience with Python, ML libraries (e.g., scikit-learn, scipy, numpy, matplotlib, pandas etc), and SQL. Experience with AWS, Scala, Spark, and Hadoop are also sought but not necessary.\nStrong knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.\nAbility to present complex concepts in a clear narrative that influences stakeholders to take action.\nYou are curious, love to continuously improve and exhibit the aptitude to learn quickly.\nYou love making a difference.\nApply Now: click Easy Apply"}, "476": {"company": "National Debt Relief", "description": "Who We\u2019re Looking For:\n\nNational Debt Relief (NDR) is currently seeking an inquisitive, highly motivated, and creative Data Scientist who is passionate about helping customers get out of debt. The ideal candidate will have hands on experience transforming unique data into amazing products. At scale.\n\nAt NDR you will have access to an enormous amount of high-value business activity data including unstructured and semi-structured records around the sales process as well as post sales customer activity. You will participate in the end-to-end processes of machine learning, from proof of concept to deploying models in production. You will be asked to experiment, and conduct research work geared towards new product development.\n\nMeet some of our team members!\n\nPrincipal Duties and Responsibilities:\nWork with large, complex datasets and solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct end-to-end analysis that includes data gathering and requirements specification, data processing, analysis, and deployment to production.\nResearch and develop models to improve the quality of NDR user facing products; example application areas include lead scoring and end-user behavioral modeling.\nMake business recommendations with effective presentations of findings at multiple levels of the business through visual displays of quantitative information.\nDevelop processes and tools to monitor and analyze model performance and accuracy\nInteract cross-functionally with a wide variety of leaders and teams and work closely with Engineers and Product Managers to identify opportunities for improvement.\nBe fiercely competitive and maintain a sense of urgency, creativity, and curiosity for how to continue to improve internal and customer facing processes.\nQualifications:\nBA/BS in a quantitative discipline (Computer Science, Statistics, Bioinformatics, Math, Physics, Engineering) or an equivalent practical skillset.\nIndustry experience writing code (e.g., Python, Pytorch, SQL) and taking ML models/ algorithms to production.\n3+ years of expertise using advanced machine learning algorithms and statistics: clustering, decision tree learning, ensemble methods, regression, etc. on large data sets as well as a strong understanding of their real-world advantages/drawbacks. The successful candidate will have regularly used Python and SQL to extract data, design ETL flows and derive insights.\nA love for data - this is what we do. We are looking for people who are excited about different and unique data sets, and all the ways that they could be used to improve our business.\nDemonstrated skill in selecting the right statistical tools given a data analysis problem.\nExcellent written and verbal communication skills for coordinating across teams\nStartup experience while not essential is preferred.\nWhat We Offer:\n\nWe believe in a team-first culture, full of rewards and recognition for our employees. We are dedicated to our employees\u2019 success and growth within the company, through our employee mentorship and leadership programs.\n\nOur extensive benefits package includes:\nGenerous Medical, Dental, and Vision Benefits\n401(k) with Company Match\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\n10 weeks Paid Parental Leave\nPre-tax Transit Benefits\nDiscounted Gym Membership\nCiti Bike Annual Membership Discounts\nNo-Cost Life Insurance Benefits\nVoluntary Benefits Options\nASPCA Pet Health Insurance Discount\nAbout National Debt Relief:\n\nNational Debt Relief is one of the country\u2019s largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we\u2019re all about helping our customers through a tough financial time in their lives with education and individual customer service.\n\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\n\nNational Debt Relief is a certified Great Place to Work\u00ae!\n\nNational Debt Relief is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other status protected by law.\nApply Now: click Apply Now"}, "477": {"company": "Coinbase", "description": "Location: San Francisco, CA\n\n\nCoinbase has built the world's leading compliant cryptocurrency platform serving over 30 million accounts in more than 100 countries. With multiple successful products, and our vocal advocacy for blockchain technology, we have played a major part in mainstream awareness and adoption of cryptocurrency. We are proud to offer an entire suite of products that are helping build the cryptoeconomy, and increase economic freedom around the world.\n\nThere are a few things we look for across all hires we make at Coinbase, regardless of role or team. First, we assess whether a candidate demonstrates our values: Clear Communication, Positive Energy, Efficient Execution, and Continuous Learning. Second, we look for signals that a candidate will thrive in a culture like ours, where we default to trust, embrace feedback, disrupt ourselves, and expect sustained high performance because we play as a championship team. Finally, we seek people with the desire and capacity to build and share expertise in the frontier technologies of crypto and blockchain, in whatever way is most relevant to their role.\n\nAt Coinbase, our vision is to build an open financial system for the world, and to get there we'll need to continually learn from our data. Data scientists are focused on this critical step of converting data into learnings.\n\nYou'll spend part of your time working directly with product teams \u2014 engineers, designers, and product managers \u2014 to ensure we're focused on the biggest opportunities and interpreting our data correctly. And you'll spend the other part of your time with the Data team building analytics models and systems that help scale our insights more broadly, both throughout the company and directly in the product.\n\nWhat you'll be doing:\nMeasure business performance, develop core metrics and create dashboards to track and understand them.\nWork with product and engineering teams to design experiments for new product ideas, and analyze the results to provide actionable recommendations.\nPerform deep analyses and build models to understand customer behavior, and extract key insights that impact product decisions.\nSynthesize data learnings into compelling stories and communicate them throughout Coinbase.\nAct as a strategic partner to product and engineering leaders to help prioritize opportunities and inform product strategy.\nPrototype new analytics & machine learning models that improve both our insights and the product directly.\nWork across multiple subject matter experts to drive new data initiatives, automation of reports, establish best practices and mentor junior members in the team.\nLead analytics projects to completion.\nWork with the broader Data team to find ways to scale our insights through better systems and automation.\nWhat we look for in you:\nDemonstrate our core cultural values: clear communication, positive energy, continuous learning, and efficient execution.\nUnderstanding of statistical concepts and experience in applying them.\nExperience in data analyses using SQL.\nExperience in at least one programming language (e.g. R, Python, Java, Ruby, Scala/Spark, or Perl).\nBe able to independently create plans for analytics projects and build collaboration within the team.\n(For Senior Data Scientist)BA / BS degree or equivalent practical experience. 5+ years relevant experience, or MS degree, 3+ year or PhD degree in related fields + 2 years.\nNice to haves:\nBe able to proactively manage prioritization of work and deliver work with great quality and influence the broader team in creating leverage.\nPrevious experience working with financial services data is a plus.\nExperience with Looker, Tableau or other business intelligence platform.\nDomain experience in product, marketing or growth analytics.\nExperience manipulating large amounts of structured and unstructured data.\nCoinbase is committed to diversity in its workforce and is proud to be an equal opportunity employer and to review all of our job postings to minimize biased language. Coinbase does not make hiring or employment decisions on the basis of race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other basis protected by applicable local, state or federal law. Coinbase will also consider for employment qualified applicants with arrest and conviction records in a manner consistent with San Francisco's Fair Chance Ordinance and similar local laws.\nApply Now: click Easy Apply"}, "478": {"company": "Northrop Grumman", "description": "Are you ready to leverage your security clearance, knowledge and technical experience in a new role?\n\nAdversaries, cybercriminals and cyber terrorists, are working every hour of every day to develop new means to compromise networks, to seize valuable intellectual property and personal data, and to gain an advantage on the digital battlefield. At Northrop Grumman, our mission is to see to it that they fail. Speed, stealth and precision keys to controlling the physical domains of land, sea, air and space are imperatives in controlling the cyber domain. Our talented employees make advances every day based on these imperatives and are committed to providing the most advanced protection for our customers against the rapidly evolving cyber threat spectrum. Our company is trusted with securing some of the most high-risk systems and continues to be the trusted provider of mission-enabled solutions for the security or our nation and allies. This is without a doubt one of the most exciting times to join our team. So come join us and experience the value of performance.\n\nNorthrop Grumman Mission Systems is seeking multiple Data Scientists to support fast-paced cutting edge programs ensuring national security and defense. The positions are located in the Annapolis Junction, MD greater area.\n\nThis position represents immediate opportunities across multiple programs. Though each program has specific labor categories which must be met prior to placement, all candidates must minimally meet the knowledge, skills and abilities listed below.\n\nNGCIMSMD\nRocktober\n\nBasic Qualifications:\n\nBachelor's Degree in related technical discipline (including but not limited to computer science, data science, information systems, science, engineering, math, economics, or aerospace) from an accredited college or university is required. Four (4) years of additional systems engineering/architecture experience on projects with similar software processes may be substituted for a bachelor's degree.\n\n5+ years of Experience with data analysis and applications, that address a business issue or provide a competitive advantage for an organization. (5 Years with Bachelors in Science; 3 Years with Masters; 0 Years with PhD)\nExperience creating data mining architectures/models/protocols, statistical reporting, and data analysis methodologies to identify trends in large data sets.\nStatistical or data visualization skills.\nUS Citizen with Active TS/SCI w/Polygraph clearance\n\nPreferred Qualifications:\n\nBachelor's degree in a STEM discipline (Science, Technology, Engineering, or Math) along with 2 or more years of data science experience.\nKnowledge of statistical datasets and implementation techniques and tools for the most efficient metrics, including present and future capacity requirements.\nExperience with Tableau, SAS, Apache Spark, BigML, D3, MATLAB, or other data science tools.\nExperience taking big data and turning it into metrics or prediction information for decision making.\nStrong statistical and data visualization skills.\n\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\nStart your job application: click Apply Now"}, "479": {"company": "Grand Rounds", "description": "About us:\nGrand Rounds is a new kind of healthcare company. Founded in 2011, the company is on a mission to raise the standard of healthcare for everyone, everywhere. The Grand Rounds team goes above and beyond to connect and guide people to the highest quality healthcare available for themselves and their loved ones. Grand Rounds creates products and services that give people the best possible healthcare experience. Named a 2019 Best Place to Work by Glassdoor and Rock Health\u2019s 2018 Fastest Growing Company, Grand Rounds works with inspiring employers and doctors to empower them to be the change agents we need to make our shared vision a reality.\n\nThe Role:\n\nData Scientists at Grand Rounds work on problems that are core to the company\u2019s mission. Major challenges include developing systems and models to identify the highest quality doctors in the country as well as methodologies to uncover the subtle differences between each physician\u2019s clinical expertise. Additionally, patient-level modeling allows us to understand the specific healthcare needs of every person. With a high fidelity understanding of both patients and physicians we are able to route patients to both appropriate and high quality care.\n\nIn addition to developing the company\u2019s core technologies, data scientists provide decision support analysis for many teams across the organization including product development, sales, marketing, and strategy. Data scale ranges from small data sets that fit on a single laptop to large multi-terabyte clinical information in distributed database systems.\nIn your first 30 days, you will:\nOnboard with the Grand Rounds team in San Francisco, setup your dev environment, get access to data systems, and become familiar with the tech stack\nLearn about on-going initiatives involving data scientists, product managers, and engineers\nSpend time with members of the Analytics, Medical, and Patient Care teams and learn how our teams collaborate\nBecome familiar with the data landscape and hit the ground running on a primary project\nIn your first 60 days, you will:\nAccelerate on-going development efforts around physician quality and expertise models\nMaster the ins and outs of claims data: ICDs, CPTs, and all that\nCollaborate with engineers to improve the claims warehousing infrastructure\nCollaborate with engineers to develop a process/pipeline for model updates that seamlessly flows data to production systems\nIn your first 90 days, you will:\nIntegrate into long-term multi-data-scientist ventures and deliver on one or several short-term individual projects\nDevelop internal tools and codebases that are useful for other data scientists and/or engineers\nSpend time with Staff Physicians and other medical domain experts to learn about the world of healthcare\nDevelop an understanding of both immediate business objectives as well as longer term company aspirations to develop intuition around prioritization and trade-offs between short-term deliverables and longer term R&D efforts\nResponsibilities:\nDevelop creative solutions to diverse problems including engineering challenges, unstructured data messes, ontology development, and machine learning applicationsLead and develop major projects from end-to-end encompassing planning, design, technical implementation, debugging, roll-out to Product & Engineering, testing, and iteration\nOperate at level of sophistication in statistics, machine learning, or computer science that is publication-worthy\nRegularly monitor pull requests, perform code reviews, and produce excellent peer reviews on projects prior to shipping to Product & Engineering\nEvaluate and experiment with new technologies and tools prior to wider adoption by the team\nWork closely with analysts, data scientists, product managers, and engineers\nQualifications:\nExcellent verbal communications, including the ability to clearly and concisely articulate complex concepts to both technical and non-technical collaborators\nBS with 8+ years or MS with 6+ years or PhD with 3+ years of experience. Degree(s) should be in a technical discipline such as Computer Science, Engineering, Statistics, Physics, Math, quantitative social science\nWork experience as an engineer highly desired\nExperience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc\nRequired: SQL, Python, R, linux shell scripting\nDesired: Scala, Java, or Ruby\nExperience with machine learning and computational statistics packages (sci-kit learn, nltk, statsmodels, networkx, gephi, arules, glmnet, bigrf, caret, igraph, MLLib, GraphX, MADlib, Weka, etc)\nExperience with visualization tools (seaborn, d3, plotly, bokeh, ggplot2, rCharts, networkD3, Shiny, Tableau, CartoDB, etc)\nFrequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform\nBonus Points for: experience with web application frameworks (Shiny, Flask, Tkinter, Ruby on Rails, Pyramid, Django, etc)\nDouble Bonus Points: previous work on medical applications and/or with claims data\nThis is a full time position located in San Francisco, CA.\n\n\n-----\nGrand Rounds is an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics or any other basis forbidden under federal, state, or local law. Grand Rounds considers all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.\n\nApply Now\nApply Now: click Apply Now"}, "480": {"company": "C3.ai", "description": "C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai\n\nC3.ai is looking for a Data Scientist (Federal) to solve challenging, novel, and large-scale enterprise problems for Federal clients. In this capacity you will represent C3.ai as a technical expert and help our team to frame problems, choose appropriate machine learning algorithms, and identify opportunities to leverage the C3.ai Suite.\n\nRecent examples of successful engagements include predictive maintenance on oil and gas equipment and aircraft subsystems, supply chain optimization, manufacturing yield optimization, chronic disease prevention, customer spend prediction, and equipment lifetime optimization.\n\nQualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve results at large-scale.\n\nThis role requires US Citizenship or US Permanent Residence.\n\nYour Responsibilities:\nBecome an expert in the C3.ai Suite and associated tools to teach, enable, and assist C3.ai customers to build their own applications.\nDesign and deploy machine learning pipelines for C3.ai's federal customers.\nCollaborate with data and subject matter experts from C3.ai and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.\nRequirements:\nUS Citizenship or US Permanent Resident\nBachelor's degree\nStrong understanding of machine learning algorithms & principles (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning), and their application\nStrong background in mathematics, statistics, and computer science\nExcellent programming skills in Python\nAbility to drive a project and work both independently and in a team\nSmart, motivated, can do attitude, and seeks to make a difference\nExcellent verbal and written communication\nPreferred\nMS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred.\nActive Department of Defense (DoD) security clearance (Secret or higher)\nExcellent programming skills in JavaScript. Experience with Java and Scala is a plus.\nExperience with deep learning, natural language processing, computer vision, or reinforcement learning\nA portfolio of projects (GitHub, papers, etc.)\nC3.ai provides a competitive compensation package and excellent benefits.\n\nC3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.\nTo apply to this job, click Apply Now"}, "481": {"company": "LiveRamp", "description": "ABOUT LIVERAMP\n\n\nLiveRamp (NYSE: RAMP) is the leader in data connectivity, helping the world's largest brands use their data to improve customer interactions on any channel and device. We thrive on mind-bending technical challenges and value entrepreneurship, humility, and constant personal growth.\n\nABOUT THIS JOB\n\n\nDo you love working with smart people who inspire you to be better and work harder every day? Do you want to join a high growth business and work with some of the world's biggest data sets? Do you want the freedom and responsibility necessary to continuously improve our measurement solutions? Then come join us!\n\nThis role will be based in Boston, MA as part of our rapidly growing Data Science consultancy team and may require some travel.\n\nROLE OVERVIEW\n\n\nBeing a part of the Data Science Consulting Team, you will work to deliver our data science solutions to a wide range of external clients including some of the largest platforms, retailers, and brands across the globe. Focusing on the measurement of advertising effectiveness, you will lead pre-sales meetings to learn first-hand our clients' requirements as well as build and deliver appropriate solutions to effectively improve advertising strategies. You will build long-term relationships with LiveRamp's partners while closely collaborating with Product Management and Strategic Partnership Teams.\n\nYou'll be encouraged to think outside the box and use the most appropriate tools for the job utilizing the latest offerings from Google Cloud Platform.\n\nRESPONSIBILITIES\nIdentify and implement bespoke data science solutions for our partners\nDeliver our offline sales measurement product for US clients\nBe a subject matter expert for clients on measurement methodologies and statistics\nBuild and evolve long-term relationships with counterpart teams of clients\nMake suggestions to improve current workflows and products\nSupport our commercial teams as an SME for LiveRamp's Data Science & Measurement offerings\nYOU WILL HAVE\n3-5 years of experience as a data scientist, measurement expert or statistician\nThorough understanding of statistics\nPrevious commercial or research experience in campaign measurement or A/B testing\nExperience leading client relationships\nUnderstanding of experimental design\nHands-on experience in Python and SQL\nThe ability to communicate complex analytical information clearly to non-analytical audiences\nBachelor's Degree in a numerate discipline (e.g. Maths, Science, Computing)\nInterest in digital marketing\nBONUS POINTS FOR\nExperience of advertising effectiveness measurement\nKnowledge of a wide range of Machine Learning algorithms\nPrevious consulting experience\nExperience with Cloud Compute technologies\nUnderstanding of software development best practices\nKnowledge of digital marketing\nPre-sales experience\nEMPLOYEE BENEFITS\nStock. Every employee is a stakeholder in our future.\nFood. Enjoy catered meals, boundless snacks, and the occasional food truck.\nFun. We host events such as game nights, happy hours, camping trips, and sports leagues.\nPeople. Work with talented, collaborative, and friendly people who love what they do.\nHealth and Saving. Receive the benefits of comprehensive health, dental, vision and disability insurance along with a 401k matching plan.\nLocation. Work in Boston, MA and take advantage of our commuter benefits.\nLiveRamp is an affirmative action and equal opportunity employer (AA/EOE/W/M/Vet/Disabled) and does not discriminate in recruiting, hiring, training, promotion or other employment of associates or the awarding of subcontracts because of a person's race, color, sex, age, religion, national origin, protected veteran, disability, sexual orientation, gender identity, genetics or other protected status. Qualified applicants with arrest and conviction records will be considered for the position in accordance with the San Francisco Fair Chance Ordinance.\nTo apply to this job, click Easy Apply"}, "482": {"company": "SurveyMonkey", "description": "About SurveyMonkey\n\nSurveyMonkey (NASDAQ: SVMK) is a leading global survey software company on a mission to power the curious. The company's People Powered Data platform empowers over 17 million active users to measure and understand feedback from employees, customers, website and app users, and the market. SurveyMonkey's products, enterprise solutions and integrations enable 350,000+ organizations to solve daily challenges, from delivering better customer experiences to increasing employee retention. With SurveyMonkey, organizations around the world can transform feedback into business intelligence that drives growth and innovation.\n\nSurveyMonkey is a place where the curious come to grow. By embedding inclusion into our processes, policies, and culture, we are building a workplace for our 1,000+ employees across North America, Europe, and APAC where people of every background can thrive. We've won multiple awards and received recognition for our forward-looking policies, including extended parental and bereavement leave, vendor benefits standards, and Take 4 sabbaticals. SurveyMonkey was recognized by Great Place to Work\u00ae and FORTUNE as a top workplace in 2018 and 2019, and the company has also won numerous awards as a leader in global survey software, including being named among CNBC's Disruptor 50 and the Forbes Cloud 100.\n\nOver the past two years we've become a public company and expanded our platform with enterprise-grade features in privacy, security and compliance, putting SurveyMonkey on the path to rapidly expand our presence within the Fortune 500. We have ambitious goals to grow our international footprint as well, and every member of our troop plays a critical role in driving this growth and transformation. It's an incredible time to join the company and be a part of our next chapter!\n\nThe Role\n\n\nWe are looking for a seasoned machine learning and data mining expert to join our data science team to lead the execution of groundbreaking R&D projects.\n\nAs a senior member of the Data Science team, the successful candidate will play a leading role in deriving key insights from large amounts of our people-powered data, suggest and implement new product features, and make improvements in existing models for better user experience. He/She will work on developing machine learning algorithms and systems, and need to be capable of implementing and utilizing intelligent tools and technologies. He/She will help internal constituents to achieve extraordinary value for our customers. This role also involves technical leadership and mentorship of data scientists and machine learning engineers. Furthermore, you'll be instrumental in developing & growing a team of data scientists, and have the opportunity to set technical directions and establish team culture.\n\nRequirements\nExpertise in machine learning model development, including data preprocessing, feature engineering, classification and prediction model development, and model deployment.\nStrong programming skills, expert knowledge of algorithms, and data structures (Python preferred).\nPrior experience and continued interest in mentorship and technical development of junior data scientists.\nExcellent problem-solving, critical thinking, creativity, organizational, design, and interpersonal skills.\nAbility to work well with all levels of engineers.\nConfirmed ability to handle multiple projects with strict deadlines.\nPrior experience in partnering with product and engineering teams to solve problems and identify trends and opportunities.\nExcellent customer experience intuition; demonstrate success in inventing innovative and user-friendly products.\nPreferred Qualifications\nMaster's or PhD in Computer Science or a data-driven physical science, or equivalent, plus 4 or more years of relevant industry experience.\nIndustrial data-mining / analytics experience including applied techniques in data mining, machine learning, natural language processing (NLP) or graph mining preferred.\nExpert knowledge of Airflow, Pytorch/Tensorflow, Scikit-learn and Pandas is a plus.\nApply Now: click Apply Now"}, "483": {"company": "Union Bankshares", "description": "Requisition Number 19-0552\nPost Date 11/26/2019\nTitle Senior Data Modeler & Analyst\nLocation Innsbrook VA\nCity Glen Allen\nState VA\nDescription Position Description:\n\nThe Senior Data Modeler/Data Analyst is a critical role in translating business needs into the information required to deliver solutions. The role will be a key leader across multiple projects working with Data Architects in understanding architectural directions,\ngathering and analyzing business requirements, and developing the appropriate data structures. In addition, the role will have significant influence in Data Governance and Enterprise shared data initiatives. This position will play a key role in the transition\nfrom traditional reporting to a more dynamic, real-time analytics environment ensuring a foundation to deliver information to internal consumers at all levels in the organization.\n\nPosition Accountabilities:\n\n\u2022 Consult, facilitate understanding and translate data requirements into logical, physical and semantic layer models across the analytical data environment.\n\u2022 Ensure data structures are designed for flexibility to support future business needs.\n\u2022 Profile and analyze source system data to determine data relationships, design constructs, consistency and quality.\n\u2022 Enable and lead analytics user community in the understanding, location and selection of appropriate data sources to achieve key business goals\n\u2022 Ensure that data designs follow architectural best practices and appropriate business rules\n\u2022 Facilitate data integration, conformity, data quality, integrity and consolidation\n\u2022 Be an advocate for best practices while balancing business value and reasonable practicality\n\u2022 Create and Maintain critical data documentation and metadata that allows data to be understood and leveraged as a shared asset.\n\u2022 Set the strategy and repeatable process for maintaining the Enterprise Data model using automated tools.\n\u2022 Analyze and evaluate data definition and modeling environment providing key recommendations for improvement. Assist in defining data modeling standards, and foundational best practices.\n\u2022 Identify gaps and opportunities with regard to data governance and data ownership, and provide recommendations for improvements incorporating best practices.\n\u2022 Facilitate understanding of high quality data management discipline throughout the corporation\n\u2022 Work with the Data Governance lead to enhance/establish data stewardship and data quality management programs.\n\u2022 Develop and maintain relationships across IT and across the business with special focus on roles that are heavy consumers of data for analytical purposes; anticipate customer needs and proactively develop solutions\n\nOrganizational Relationship:\n\nThis position reports to the Director of Data Warehousing & Analytics.\nRequirements Position Qualifications\n\nEducation & Experience:\n\n\u2022 A Bachelor\u2019s Degree in a technology area of study; preferably in Computer Science, MIS or Analytics\n\u2022 7+ years equivalent work experience in Information Technology\n\u2022 5+ years in a structured IT organization with a strong PMO, a variety of methodologies, and strong technical environment management disciplines\n\u2022 5+ years of experience in Data Analysis, Data Architecture and/or Data Warehousing; preferably in a shared or enterprise data environment\n\u2022 5+ years direct experience in Data Modeling and Data Solution Development\n\u2022 2+ years of experience in banking and/or financial services\n\u2022 Deep experience in logical, physical and semantic data modeling\n\u2022 SQL Query development skills for analyzing and profiling data\n\u2022 Experience with multiple SDLC methodologies \u2013 Waterfall and Agile\n\nKnowledge & Skills:\n\n\u2022 Excellent communication, leadership and collaboration skills\n\u2022 Competency with some leading data profiling tools (such as SQL, BI tools, etc)\n\u2022 Experience with Enterprise Data Warehouse initiatives including Data Model development, Semantic/Data Access Layer Development, Reporting and Dashboard Creation; developing solutions for shared data usage\n\u2022 Experience with a Data Modeling tool (such as Erwin) and in developing processes to manage data model development, principles, and standards\n\u2022 Experience with a commercially available industry focused data model preferred\n\u2022 Exposure to and understanding of Analytical Architectures\n\u2022 Consulting and Facilitation Skills\n\u2022 Advanced decision making and problem solving skills\n\u2022 Business acumen, knowledge and professionalism\n\u2022 Strong analytical, problem solving, and work management skills\n\u2022 Customer-focused ability to communicate across all levels of the organization\n\u2022 Proactive Leadership style; self-starter and strong attention to detail\n\u2022 Proficient in MS Office (Word, Excel, Access, PowerPoint, MS Project, Visio, SharePoint)\n\nWe are proud to be an EEO/AA employer, Minority/Female/Disability/Veteran.\n\nWe maintain a drug-free workplace.\n\nStart your job application: click Apply Now"}, "484": {"company": "Knowesis Inc.", "description": "Job Description:\n\nKnowesis is looking for personnel to support the United States Special Operations Command Preservation of the Force and Family (USSOCOM POTFF) program in identifying and implementing innovative, valuable solutions across the Special Operations Forces (SOF) enterprise aimed at improving the short and long-term well-being of SOF warriors and their families.\n\nDuties and responsibilities may include, but are not limited to: \u2022 Enter, clean, and conduct basic data manipulation and analysis.\u2022 Build and disseminate databases and spreadsheets designed to record POTFF related programmatic data.\u2022 Provide consultation and assistance to supported units and POTFF staff to identify opportunities and methods for capturing data relating to POTFF programs and initiatives.\u2022 Prepare reports and presentations that accurately convey data trends and associated analysis.\u2022 Enter and analyze data within government systems.\nRequired Experience:\nProficient with the suite of Microsoft Office programs, including Word, Excel, and Access.\nPrior experience using statistical software application such R, Tableau, or other data visualization software.\nPossess excellent communication skills, presentation skills,and shall be highly detail oriented.\nA certification, documented experience and heavy interest in Human Performance or Sports Science is preferred.\nA qualified candidate will:\nWork in consultation with POTFF program staff and the Government\u2019s POTFF biostatistician.\nServe as the analytical lead in support of program manager.\nBe able to use statistics and data visualization techniques to provide an accessible way to see and understand trends, outliers, and patterns in data.\nBe able to read, write, and speak English fluently and clearly in order to effectively communicate with all personnel for which they will interact.\nPossess sufficient initiative, interpersonal relationship skills and social sensitivity such that they can relate constructively to a variety of contacts from diverse background.\nA certification or documented experience with Human Performance is preferred.\nEducation: Bachelor\u2019s Degree in quantitative science, social science or related discipline (Bachelor\u2019s Degree in Sports Science with minor in a quantitative science may be acceptable).\n\nClearance Type: Secret or ability to obtain Secret Clearance\n\nPosition Location: Client site on Joint Base Lewis McCord.\n\nBenefits\n\nAbout Knowesis\nFounded in 2007, Knowesis Inc. has been providing data driven decisions and solutions to federal healthcare clients from day one. Our core capabilities include analytics and information management, planning and operations, and communication and engagement strategies. Knowesis\u2019 highly qualified, customer-focused professionals are committed to providing information and advice to enable client success through holistic, thorough, thoughtful, and aligned approaches. Our clients leverage these capabilities to support data driven decisions for their key business functions. Knowesis is dedicated to earning the loyalty of clients and staff through work ethic, collaboration, and humility. Our intent is to be a positive impact to our clients, team, and community.\n\nKnowesis is Service Disabled Veteran Owned (SDVO) (CVE certified) and Small Disadvantaged Business (SBA certified 8a) with offices in San Antonio, Texas and Fairfax, Virginia. We offer a highly competitive compensation and benefits package inclusive of medical, dental, and paid time off.\nFor more information about working with Knowesis, please visit our website at http://www.knowesis-inc.com.\n\nKnowesis is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. Knowesis will consider all qualified applicants for employment without regard to race, color, religious creed, national origin, ancestry, age, sex, sexual orientation, genetic information, physical or mental disability, veteran or marital status, or any other class protected by law. To comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability, Knowesis will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the Company would result.\n\nKeyword: Data Scientist\nFrom: Knowesis Inc.\n</br>Apply now\nStart your job application: click Easy Apply"}, "485": {"company": "Stanley Black & Decker", "description": "Title\nLead Data Scientist\n\n24-Sep-2019\n\nBusiness\nUS - Corporate\n\nState/Country/Province\nConnecticut\n\nNo. of Positions\n1\n\nJob Description\nLead Data Scientist\n\nStanley Black and Decker (SBD) is committed to deep and ongoing investment in Data & Analytics capability. SBD believes that advanced analytics using massive data, while already important to our business, will increasingly become fundamental \u2013 even transformational \u2013 to the value we deliver to our customers and shareholders.\nSBD is seeking a Lead Data Scientist who will be responsible for collecting data and developing insights related to innovative new business initiatives at Stanley Black & Decker focused on the digital enablement of work sites and the Internet of Things.\n\nEssential Job Functions\nLeverage big data and data science to discover patterns and solve strategic & tactical business problems using massive structured and unstructured data sets across multiple environments\nDevelop analytic capabilities (e.g. models and processes) that drive better outcomes for both customers and the company\nDrive the collection, cleansing, processing and analysis of new and existing data sources.\nBuild, test, and deploy predictive models and/or machine learning algorithms on large static and/or streaming data sets\nReport findings by creating useful and appropriate data outputs and visualizations tailored for the intended audiences\nLearn & stay current on analytics developments in one or more business domains: Internet of Things, Manufacturing, Supply Chain, Forecasting, Marketing and Sales, Pricing, etc.\nLearn & stay current on developments in one or more analytics domains: Optimization, Machine Learning, Deep Learning / AI, Simulation, etc.\nGenerate innovative ideas, establish new research directions, shape and execute the information strategy in support of technical projects and new product developments\nWork with and support other team members, management, and partners\nEssential Skills & Experience\nAdvanced degree (MS/PhD) in a relevant technical field (e.g., Computer Science, Mathematics, Applied Mathematics, Statistics, Operations Research, Industrial Engineering, Econometrics) with 5+ years\u2019 experience in related data science, analytics, and model building roles\nExperience working with large complex data sets, real time/near real time analytics, and distributed big data platforms (Hadoop & MapReduce and/or Cassandra/Spark)\nStrong practical knowledge of analytical techniques and methodologies such as machine learning/supervised and unsupervised techniques, segmentation, mix and time series modeling, response modeling, lift modeling, experimental design, neural networks, data mining and optimization techniques\nStrong knowledge of analysis tools such as Python, R, MATLAB, Spark or SAS. R/Spark on Hadoop or Cassandra preferred.\nStrong background in applying statistical machine learning techniques to predictive modeling and experience with Machine Learning libraries (via R, H2O, Python, Spark, etc.)\nProficiency in programming in Python, R, SQL, JavaScript, Java/Scala/Ruby and shell scripting\nProficiency in consuming REST based API (with JSON payload) is a plus.\nFluency in big data platforms including Hadoop, MapReduce, Hive, Spark, PIG\nFamiliarity with Cloud based HaaS/PaaS solutions such as AWS EMR, MS Azure.\nA strong understanding of data profiling and data cleansing techniques\nNatural curiosity and a strong passion for empirical research and problem solving\nStrong written and verbal communications skills; comfortable communicating with senior levels of both business and technology leadership\nCompetencies\nDepth in relevant field(s) for data science, including:\nStatistical Analysis & Modeling\nMachine Learning Algorithms & Techniques\nDeep Learning / Neural Networks\nOptimization Techniques\nUnderstanding Business Problems\nData Wrangling & Exploration\nProblem Solving Mindset\nClear Communication\nTechnical Fluency\n#Elu#LI-JF1\n\nAll qualified applicants to Stanley Black & Decker are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran\u2019s status or any other protected characteristic.\n\nRequisition Number\n65459BR\n\nFunction\nInformation Management\n\nCity\nNew Britain\n\nEEO Statement\nAll qualified applicants to Stanley Black & Decker are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran\u2019s status or any other protected characteristic.\n\nFeatured Category on SBD Careers\nData & Emerging Technology (IT, Data Science, Data Analysis)\nApply Now: click Apply Now"}, "486": {"company": "Clearwater Analytics", "description": "About Clearwater Analytics\u00ae\n\nClearwater Analytics\u00ae is a global SaaS solution for automated investment data aggregation, reconciliation, accounting, and reporting. Clearwater helps thousands of organizations make the most of investment portfolio data with cloud-native software and client-centric servicing. Every day, investment professionals worldwide trust Clearwater to deliver timely, validated investment data and in-depth reporting.\n\nClearwater aggregates, reconciles, and reports on more than $3 trillion in assets across thousands of accounts daily for our Fortune 500 clients.\n\nDESCRIPTION\n\nThe Innovation Center at Clearwater Analytics solves significant problems with new technology and techniques. The Innovation Center explores and uses machine learning, RPA, blockchain and any other technology that creates step-change for our clients, markets and employees. Clearwater's system is used by some of the world's largest technology firms, fixed income asset managers, and custodian banks. These firms rely on Clearwater's ability to solve difficult, seemingly impossible problems. Clearwater's Innovation is a key driver of those solutions.\n\nClearwater is looking for talented individuals who thrive on solving problems and developing new skills. We offer a competitive compensation package, exposure to cutting-edge financial market issues & information, business casual workplace, beautiful surroundings and work-life balance.\n\nResponsibilities\nDeveloping a solution to a problem in a way that hasn't been done before that has had dramatic positive results\nChanging the technical direction of a team through persuasion, leadership, and force of will onto a better path\nLeading a community of interest in a technology or domain that is not a standard part of the enterprise, but whose adoption would significantly impact the company for the better\nDemonstrating the ability to decompose problems to their root causes and then follow an engineered approach to finding appropriate solutions\nUnderstand machine learning requirements from product, engineering and data science to create machine learning technical specifications\nBuild platform for machine learning model training, batch evaluation, automated re-training, continuous monitoring and deployment in a micro-service architecture\nInteract with data, compute and serving infrastructure for shipping machine learning models\nBuild visibility into machine learning and system performance and optimize if necessary\nREQUIREMENTS\n5+ years of software development experience\nIndustry engineering experience with machine learning projects\nExperience in data analysis, engineering and statistical modeling\nExperience with AWS\nExperience with machine learning libraries like pyTorch, TensorFlow, Keras, Sagemaker\nFamiliarity in data-oriented programming such as Spark, Python, R, Hadoop, SQL with solid understanding of query performance and tuning\nKnowledge of Clojure and Java\nA demonstrated pattern of continuous improvement of both self and team\nVery strong problem solving skills\nDesired Experience and Skills\nBachelor's degree in Computer Science or related field is a plus\nWhat we offer:\n\n\nHeadquarters in the heart of downtown Boise\nBusiness casual atmosphere in a flexible working environment\nTeam focused culture that promotes innovation and ownership\nAccess to cutting edge investment reporting technology and expertise\nContinual learning, professional development and growth opportunities\nCompetitive salary and benefits package; including health, vision and dental\nAdditional benefits including PTO, 401(k) with 4% employer match\nStart your job application: click Apply Now"}, "487": {"company": "Nurx", "description": "Nurx is looking for a Data Scientist who loves answering complex business and health questions through data. This is a rare opportunity to help build a data-driven culture from the ground up and impact the lives of millions by helping reinvent the healthcare system. We're building a system to support delivery of medical care in a modern and truly empathetic way.\n\nThis is a hybrid role in which you will run deep analyses on structured and unstructured data and also build and maintain ETLs to fetch data into the Nurx warehouse. You will be asked to work with your peers to determine the best algorithm to solve any given problem, and be able to create your own data structures to execute the solution.\n\nOn this team, you'll work closely with Product, Operations, Finance, Marketing and Engineering. You'll be reporting to the Head of Data & Research and will engage with all aspects of Nurx to discover insights on how to drive operational efficiency, help plan for staffing, and most importantly, increase our ability to better our patient's health.\n\nWhat you'll do:\nDeliver the insights necessary to help Nurx scale its Operations and Medical teams.\nIdentify, track, and report regularly on key operational performance metrics.\nBuild intuitive dashboards to empower other team members with actionable data.\nPerform Data Cleansing, Data Mining and Data Modeling to analyze trends, and create forecasts in order to help Nurx understand more about its patients.\nPerform quantitative analysis, and ad-hoc reports to support key operations decisions, including staffing plans, process optimizations, and personnel performance management.\nTake an active role in key strategic decision making and analytics across the company.\nFlex into other areas of the organizations to help drive data driven decision making. Assist the Product, Finance, and Engineering teams derive key insights as needed.\nEngage with stakeholders to understand business problems and translate their questions into insights and easily digestible summaries.\nA bit about you:\nMinimum of 3+ years of experience in data science, business intelligence / consulting / investment banking / healthcare / public health or related experience.\nBachelor's Degree in: Math, Finance, Economics, Statistics, Data Science, Physics or related field.\nProven experience with Data Collection via ETLs and an understanding of data warehouse organization.\nExperience with machine learning tools and techniques such as clustering and classification.\nExperience with statistical modeling, and forecasting.\nProven ability to write, optimize and execute complex SQL queries.\nStrong comfort level with manipulating complex data structures in Python, R, Scala, or other programmatic data analysis languages.\nExpertise in A/B testing is ideal. Bonus points if you've used and understand Splunk, Looker, or Mode.\nAnalytical mindset, with the ability to focus on a problem, ask insightful questions, and gain expertise quickly.\nCompetent understanding of statistical principles (eg. statistical significance).\nAbility to derive meaning from raw data in order to influence product decisions and direction.\nNice to Haves:\nPrior experience with or interest in distributed data store environments.\nPassionate about improving the state of healthcare in the United States and beyond.\nAbout us:\n\nAt Nurx, we're creating a future where healthcare is easily accessible and affordable for everyone and building software that empowers people to be in control of decisions about their own health.\n\nOur platform enables doctors to give patients personalized care at lower costs and prescriptions delivered straight to their door. We are committed to disrupting the healthcare system and increasing access to healthcare for millions across the country, starting with birth control and PrEP.\n\nBenefits:\nTalented and collaborative team who will both support and challenge you.\nMarket competitive salary and equity.\nMedical, dental, commuter, wellness, and engineering technology benefits.\n401(k) retirement plan.\nPaid holiday, vacation, and sick leave.\nTake what you need vacation (and we really mean it!).\nThis position is full-time and based in San Francisco, CA.\nStart your job application: click Apply Now"}, "488": {"company": "NetApp", "description": "33643\n\nAre you data-driven? We at NetApp believe in the transformative power of data \u2013 to expand customer touchpoints, to foster greater innovation, and to optimize operations. We are designed for simplicity, optimized to protect, created to embrace future opportunity, and open to enrich choice. We are the data authority for hybrid cloud, and we are helping our customers realize the full potential of their data.\n\nWe\u2019ve built a Data Fabric for a data-driven world \u2013 to simplify and integrate data management across the resources that are best for the business. With the Data Fabric, our customers can harness the power of cloud data services, build cloud infrastructures, and modernize storage through data management.\n\nBy harnessing the power of hybrid cloud data services, customers gain the freedom of choice to securely manage and move data \u2013 anywhere, on any cloud. Only NetApp can help organizations deliver data-rich customer experiences when they rapidly test and deploy new applications that easily use data and services regardless of where they reside or in what form.\nJob Summary\nNetApp\u2019s Cloud Operations and Engineering Services team provide enablers for a world class engineering team using data to support decisions. We are looking to apply Machine Learning and Artificial Intelligence to identify new opportunities for technical issue reduction, productivity gains, leverage assets, and automation. The ideal candidate has a solid data science background who actively listens and collaborates well with engineers, service owners, and leaders to create value out of the data ensuring short- and long-term needs are met. You are savvy with exploring and visualizing data, uncovering relationships and outliers, developing and evaluating statistical models, machine learning algorithms, and data modeling techniques, etc.\nResponsibility\nDesigns, develops, and implements data management systems of analytic frameworks for the business\u2019s data.\nUses analytical rigor and statistical methods to analyze large amounts of data, extracting actionable insights using advanced statistical techniques such as data analysis, data mining, optimization tools, and machine learning techniques and statistics (e.g., predictive models, LTV, propensity models).\nAble to work with large data (structured and unstructured), and be proficient in extracting relevant feature data from relational and non-relational databases\nConstantly innovating by building new features; improving modeling techniques to boost model performance; maintaining and refining the processes and procedures for building high-end analytic modeling solutions.\nInteracting with business teams ensuring effective working relationships, translates business requirements into quick prototypes and building data-fueled solutions that drive the business closer to its overall goals and objectives.\nFormulates new and creative ideas for leveraging the business\u2019s vast collection of data in the databases\nAssures the data is available, meaningful, and visible.. Where needed applies data cleansing.\nWriting coherent reports and presentations on high-end analytical projects.\nConstructs forecasts, recommendations and strategic/tactical plans based on applying data science techniques to business data.\nConsistent exercise of independent judgment and discretion in matters of significance.\nEngages with service owners, engineers, and managers to VP level as part of shaping and implementing initiatives delivering results.\nJob Requirements\nSelf-motived, team player. Dependable with a strong work ethic.\nBelieves in automated testing, and is able to develop modular, layered software that performs well and is easy to understand.\nDemonstrated ability to think strategically about business, product, and technical challenges.\nStrong programming (such as Scala, Spark, Hadoop MapReduce), and statistical modeling skills (like Python or R) and Machine learning (ML) techniques include clustering, classification, regression, decision trees, neural nets, support vector machines, genetic algorithms, anomaly detection, association rules, sequential pattern discovery, and text mining\nProficiency in the use of statistical packages\nExperience in software design and development.\nHas experience and/or interest in refactoring legacy systems to use more modern technology.\nStrong oral and written communication skills.\nAbility to work collaboratively with other engineers and have strong influencing and leadership skills.\nAbility to handle multiple tasks concurrently with competing deadlines.\nAptitude for troubleshooting and resolving issues even in unfamiliar environments.\nAbility to work on complex issues that require a detailed analysis of a variety of factors.\nAbility to work collaboratively within a team -- yet the ability to work independently, as well.\nAbility to develop longer-range project plans and schedules to complete complex projects or new product development.\nExperience in an environment that included revision control and project lifecycle tooling (Agile preferred).\nAbility to perform well in very dynamic environment.\nEducation & Experience\nThe successful candidate will possess 3+ years minimum of experience in data science or data engineering on an Enterprise SaaS solution, platform, marketplace, or other software-led product in an agile B2B environment, and 5+ years of experience overall.\nAdvanced degree in Computer Science, Statistics, Applied Mathematics or other analytical or quantitative-based field.\nDeep mastery of a wide range of ML techniques, tools, and methodologies with a demonstrated capability to apply them to a broad range of business problems and data sources.\nExperience with text mining, NLP and Deep Learning packages.\nExperience with implementing and shipping predictive data and analytics products.\nProficiency in SQL, Python/R and experience with MapReduce frameworks.\nExperience with Asset Management, Services Management or Operational software a plus.\nSuperb communication skills for both oral and written communication; ability to communicate confidently across all levels inside and outside of the organization.\n\nSo get ready to tap into the data visionary within, and join us as we accelerate digital transformation and empower our customers to change the world with data!\n\nIf you ask a NetApp employee why they work here, the answer is inevitably the same: the people. At NetApp, our culture is at the heart of what we do. We place importance in trust, integrity, teamwork, and caring above all else. NetApp is a place where people are empowered to make a difference. Empowered to innovate. Empowered to collaborate. Empowered to help ourselves and others be data-driven and change the world. We take care of each other, our customers, our partners, and our communities simply because it\u2019s the right thing to do.\n\nWe work hard but also recognize the importance of work-life balance for our employees because what\u2019s important to them is important to us! Recently we implemented Family First, which encourages employees to take paid time off to bond with a new child (through birth or adoption) or to care for a family member with a serious health condition. Our volunteer time off program is best in class, offering employees 40 hours of paid time off per year to donate their time with their favorite organizations. We provide comprehensive medical, dental, wellness and vision plans for you and your family. We offer educational assistance, legal services, and access to discounts and fitness centers. We also offer financial savings programs to help you plan for your future.\n\nJoin us and see what empowerment can do.\n\nEqual Opportunity Employer Minorities/Women/Vets/Disabled\n\nNearest Major Market: Durham\nNearest Secondary Market: Raleigh\nJob Segment:\nDatabase, Scientific, Medical, Engineer, Product Development, Technology, Engineering, Healthcare, Research\n\nApply now \u00bb\n\nTo apply to this job, click Apply Now"}, "489": {"company": "Southern California Edison", "description": "Job Description\nENERGY FOR WHATS AHEAD\n\nAre you looking to make a difference in your career? Were working on smarter grids, cleaner energy and tools to help people manage energy more efficiently.\nAbout Transmission and Distribution\n\nSouthern California Edisons (SCE's) Transmission and Distribution Organizational Unit (T & D) is responsible for planning, engineering, constructing, operating, and maintaining transmission and distribution facilities throughout the 50,000-square-mile territory. T&D is the steward of roughly $19 billion in assets that safely and reliably deliver electricity to 14 million residents via SCEs 5 million customer accounts.\nPosition Overview\n\nThe Senior Data Scientist Advisor is responsible for leading the modeling of complex analytical problems, discovering insights, and identifying opportunities using statistical, algorithmic, mining, and visualization techniques. In addition to advanced analytical skills, the senior advisor will be responsible for developing business requirements and coordinating with groups in and outside of the Transmission and Distribution group. You will be responsible for developing, presenting, and communicating results. You will also be responsible for leading and mentoring other Data Scientists.\nTypical Responsibilities:\nLead data scientists on developing models that meet or exceed business requirements.\nGenerate advanced analytical approaches using predictive modeling, optimization and simulation abilities.\nApply statistical and pattern recognition techniques to perform description, prediction, and optimization.\nDevelop and implement tools for data acquisition, extraction, transformation, management, and manipulation of large and complex data sets. Explore, model, mine, and experiment with data to answer critical business issues. And, generate and communicate business insights.\nQualifications\n\nMinimum Qualifications\nBachelors in a quantitative discipline such as Statistics, Mathematics, Engineering, Computer Science, or information sciences such as business analytics or informatics.\nTen or more years of experience in Predictive Modeling or Machine Learning or Statistical Modeling or Data Mining.\nProficient with R and Python.\nDesired Qualifications\nMS or PhD in a quantitative discipline such as Statistics, Mathematics, Engineering, Computer Science, or information sciences such as business analytics or informatics.\nExperience in leading and mentoring junior team members and guiding them on data science and advanced analytics (machine learning, predictive analytics) development.\nIn-depth industry/business knowledge in Electric Utility industry.\nProficiency with SQL and/or SAS.\nStrong Leadership skills and experience.\n\nComments\nCandidates for this position must be legally authorized to work directly as employees for any employer in the United States without visa sponsorship.\nRelocation may apply to this position.\nSouthern California Edison, an Edison International (NYSE:EIX) company, serves a population of approximately 15 million via 5 million customer accounts in a 50,000-square-mile service area within Central, Coastal and Southern California. Join the utility leader that is safely delivering reliable, affordable electricity to our customers for over 125 years.\n\nSCE is a proud Equal Opportunity Employer and will not discriminate based on race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or any other protected status.\n\nL1-EA1\nApply Now: click Apply Now"}, "490": {"company": "Proofpoint", "description": "It's fun to work in a company where people truly BELIEVE in what they're doing!\n\nWe're committed to bringing passion and customer focus to the business.\n\nThe Role\n\nDo you have a passion for applying machine learning to hard problems? Do you keep up with the state of the art in deep learning, clustering, and model explainability, but know when to fall back on simple, battle-tested approaches like logistic regression, DBSCAN, and k-nearest neighbors? Are you cuckoo for cuckoo graphs (or any other graphs, for that matter)? If so, Proofpoint's Analytics and Intelligence team is looking for you!\n\nOur team combines algorithm design, software engineering, and domain knowledge into first-of-their-kind security products leveraging massive email, SaaS, and threat intelligence data sets. Your primary focus will be applying your skills in areas like anomaly detection, graph mining, clustering, generative analytics, and of course classification, to build groundbreaking new services that protect people from malware, phishing, social engineering, and other cyber attacks.\n\nWe're a fast-paced, high-energy team where you'll be given the opportunity to have a significant impact. The team has a solid engineering culture that values the craftsmanship of writing great software, enjoys learning, and thrives on solving big problems.\n\nYour day-to-day\nWork with product management, engineering, and UX from problem definition to first hypothesis to final delivery\nTrawl massive data sets \u2013 mail flow with billions of messages per day, browser and SaaS activity for millions of users, an intelligence graph with trillions of data points \u2013 for insight into cybersecurity\u2019s biggest challenges\nBlend information from disparate sources to build and optimize classification, regression, and clustering systems\nConduct ad-hoc analysis and innovation around data visualization and information design\nMentor and uplevel junior data scientists\nWhat you bring to the team\nAdvanced degree in computer science, statistics, or applied math, or real-world experience in security research and data science\nThe rigor and precision of a scientist, with an artist\u2019s intuition and flair\nExperience applying ML algorithms and techniques to living, breathing data\nAn abiding interest in data science trends, from the mainstream to the bleeding edge\nA history of building scalable processes to collect, manipulate, and analyze massive volumes of data\nFamiliarity with mature data science toolchains like Python\u2019s (NumPy, SciPy, Pandas, scikit-learn, PyTorch, Gensim, etc.)\nIf you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!\nStart your job application: click Apply Now"}, "491": {"company": "Shutterfly", "description": "The Data Scientist will be responsible for designing and directing experiments and observational studies to optimize our marketing efforts. This role requires an individual with a strong ability to communicate and collaborate across functional teams, in addition to outstanding analytical and critical thinking skills. The role will have a strong focus on experimental design.\n\nResponsibilities:\nDirectly impact resource allocation decisions by designing and directing experiments and observational studies\nPartner with the marketing and business strategy teams to define and test hypotheses that answer critical business questions\nPerform deep-dive statistical analysis on large, complex, multi-dimensional datasets.\nDevelop and contribute to a base of understanding that allows us to make optimal resource allocation decisions\nQualifications:\nAdvanced degree (MS, Ph.D.) in quantitative fields, and 2-3 years of experience with a range of techniques, tools, and methods related to data mining and statistical analysis\nStrong ability with a statistical language such as R, Python or SAS, and hands-on experience using a variety of analytical methods\nExperience with or strong working knowledge of experimental design concepts, regardless of industry/discipline\nHands-on experience with SQL, working knowledge of database design\nFamiliarity with internet marketing data collection methods and marketing technology, including search marketing, social marketing, and ad serving platforms\nCreative mind with strong communication and interpersonal skills; talented with simplifying abstract business issues and large amounts of data into actionable analyses; must be able to interact with diverse groups of technical and non-technical people\nTrack record of contributing to successful end-to-end analytic solutions (clarifying business objectives and hypotheses, communicating project deliverables and timelines, and informing action based on findings)\nStrong desire to articulate business recommendations based on analytical work\nThis position is full-time and based in Redwood City, CA\nTo apply to this job, click Apply Now"}, "492": {"company": "DICK'S Sporting Goods - Corporate", "description": "Description\n\nThe core data science team at Dick's Sporting Goods is seeking a data scientist to support product teams within the technology organization. The team builds end-to-end machine learning solutions that drive business value in all parts of the organization. A few examples of projects that the team is currently working on are demand forecasting, search algorithm optimization, supply chain optimization, and visual search. We are looking for diverse teammates with strong technical skills who also have a passion for learning and deploying the latest machine learning algorithms. An ideal candidate will have a knowledge base in search algorithms, NLP, and/or forecasting.\n\nThe Role You'll Play:\n\n\n\nMachine Learning Applications & Analyses\nApply machine learning and data mining techniques to extract actionable insights from large-scale, high-dimensional data.\nBuild end-to-end algorithmic solutions that focus on improving the customer's experience both in-store and on our website.\nCompile data from disparate data sources leveraging both qualitative and quantitative data to build holistic views of customer's experience.\nCommunicate and present complex analyses and models to all levels of leadership across the organization.\nClient Liaison\n\nWork with a variety of business units throughout the organization to help translate their requirements into specific analytical deliverables.\nContinue to improve and advance communications and collaborations amongst the various analytics teams and business units.\nTraining\nLead or support formal and/or informal training for team members on the various tools used for team members within the analytics team or client teams.\n\nQualifications\n\nEducation\nMaster's Degree Preferred In: Statistics, Computer Science, Operations Research, Engineering, Mathematics, Economics, or other quantitative fields\nAdditional experience will be considered in lieu of an advanced degree.\n\n\nExperience/Technology\n\nStatistics / Machine Learning with applications in R or Python.\nPractical experience with SQL or a SQL-like language.\nCreating visualizations and presentations for non-technical users.\nBonus Points\nPublication in top conferences or journals\nExperience applying machine learning techniques in a retail environment\nExperience with Kubernetes based systems such as Kubeflow\nExperience with any of the following: search algorithms, NLP, or time-series forecasting\nExperience in a deep learning framework such as Tensorflow or PyTorch\n\nTo apply to this job, click Apply Now"}, "493": {"company": "Mojio", "description": "Position Title: Data Scientist\nLocation: Campbell, California or Vancouver, Canada\n\nAt Mojio, we're connecting the cars of today for the journeys of tomorrow. Backed by leading investors including Amazon, Bosch and Deutsche Telekom, Mojio is driving the global adoption of its connected car technology via its growing portfolio of customers, including T-Mobile and Vivint in the US, Deutsche Telekom in Europe and Telus in Canada. With more than 10 billion miles worth of real-world driving data processed to date, we have created one of the largest and fastest-growing big data pools in the automotive industry. If you're interested in joining us on our mission to give every vehicle a voice, apply now!\n\nThe Opportunity\n\nYou will work on awesome data science and AI problems including:\nCreating data algorithms for new product features around connected car such as predictive maintenance, driving scoring, etc.\nCreating insights and analytics based around Mojio's partners growing numbers of vehicles, users and trips.\nSupport data processing that contributes to the growing use of anonymous data that can provide value to users and the larger ecosystem\nData science around data for users, vehicles and mobility as a service.\nAI processing for both batch solutions (end of trip, night time) or online streaming (while driving) dataset types\nDrive efficient and leading-edge solutions to create deep learning and other derived insights from time-based data as well as video and image feeds\nContribute to the strategic direction around big data and leading-edge AI/analytics in the connected car space\nProviding solution while maintaining privacy and security requirements.\n\nWho You Are\n\nPreferred Qualifications:\nMinimum 2 years for industry experience.\nMasters or PhD in Computer Science with preferably a focus on data science/AI\nExperience with big data processing for analytics and/or AI\nExperience with Azure or AWS cloud systems\nExperience with efficient processing of large data systems with technologies like Spark, Neural Networks, TensorFlow etc.\nKnowledge of Scala is a big plus.\nExperience with streaming data either time-series data or media\nOther job requirements:\nAbility to work with a distributed team to creating great collaborative solutions\nAn open mind to new opportunities and new solutions that have not been done before\nGood architectural knowledge to provide platform and efficient solutions rather than one-off snowflakes.\nStrong interest in connected car, autonomous and the future of transportation.\nCoding skills in one or more of: C/C++, C#, Python, Java, R as well as higher level frameworks such as Spark, Storm, NoSQL, Hadoop/HBase, etc.\nOur Perks and Benefits\nCompetitive salary, bonus and options package\nExcellent benefits (health, dental and vision)\nLifestyle Savings Account\nFree lunches provided three days per week and two days lunch stipend\nOur kitchen is always stocked with healthy (and some not-so-healthy) snacks\nEducation Tuition Program\nTeam outings\nFree Mojio for your car (obviously!)\nPhone bill reimbursement and many more!\nAll qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, gender identity, sexual orientation, or on the basis of disability.\n\nPosted positions are not open to third party recruiters/agencies and unsolicited resume submissions will be considered free referrals.\nStart your job application: click Easy Apply"}, "494": {"company": "Systems & Technology Research", "description": "STR is a government research contractor specializing in advanced research and development for defense, intelligence, and homeland security applications. We pride ourselves in developing cutting-edge technologies with significant and immediate impact on our national security. Our product is our staff; we prioritize cultivating a team of driven and talented scientists and engineers that together culminate into a premier company.\n\nEvery Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.\n\nThe Role:\n\nAs a Data Scientist, you will live by our motto that \u201cData is Destiny.\u201d You will work with a diverse collection of massive datasets, including social media, structured and unstructured text, geospatial, time series, and imagery data. You will design, test, and validate statistical tests and machine learning models in support of cutting-edge problems in the national security space. Your expertise as a data scientist will aid a diverse team of researchers to build state-of-the-art tools and technologies that are deployed to extract and enrich intelligence used by analysts. If you would like to help intelligence and defense analysis keep pace with modern machine learning and software techniques, then this role is for you!\n\nWho you are:\nA degree in a scientific field such as Statistics, Mathematics, or Computer Science\nExperience in statistical modeling including performance evaluation and uncertainty quantification\nProficiency with a scientific programming language, preferably Python, and familiarity with Numpy, Pandas, and/or Scikit-learn packages\nExperience in grooming sparse, incomplete, and noisy datasets\nMotivated collaborator and an excellent communicator of ideas to both technical and non-technical audiences\nUS citizen and willing to obtain a U.S. Security Clearance\nEven better:\nMS or PhD in a scientific field such as Statistics, Mathematics, Computer Science, or Data Science or 2+ years of relevant work experience\nFamiliarity with handling and analyzing data at scale, for example using Hadoop, Dask, Spark, and MapReduce\nWorking knowledge of data store tools such as SQL and Elasticsearch, and experience interacting with databases\nExperience with deep learning and neural network training, testing, and evaluation with fluency in Tensorflow or PyTorch\nSpecialized expertise in a data-rich field such as time-series analysis, graph analytics, geospatial analysis, image processing, or Bayesian programming\nActive U.S. Security Clearance\nCompensation:\nCompetitive salary\nComprehensive benefits (Medical, Dental, Vision, Disability, Life)\n401k company match\nCompetitive and flexible paid time off\nContinued higher education reimbursement\nProfit sharing (Additional match to 401k)\nPhone reimbursement plan\nAnd more!\nSTR is dedicated to fostering a diverse and inclusive workforce where all employees, regardless of race, ethnicity, gender, neurodiversity, or other personal characteristics, feel valued, included, and empowered to achieve their best. We recognize that each employee\u2019s backgrounds, experiences, and perspectives are essential for providing our customers with innovative solutions to challenging national security problems. STR\u2019s commitment to attracting, retaining, and engaging talented and diverse professionals is demonstrated by our participation, sponsorship, and support in local and national minority organizations.\n\nApplicants must be US Citizens.\nApply Now: click Apply Now"}, "495": {"company": "Attune", "description": "Company Description\n\nRunning a small business is hard. Getting insurance for your small business is even harder. It takes forever, the process is antiquated, and one wrong decision can be disastrous.\n\nAt Attune, we\u2019re changing small business insurance in a big way.\n\nAt the forefront of the insuretech industry, we are rebuilding small business\u2019s access to insurance from scratch, making it instant, easy, and safe. How? Instead of requiring that a business answers hundreds of questions (seriously), our sophisticated platform aggregates the necessary data from different sources, and then uses incredibly advanced analytics to create tailored products that can be delivered in mere minutes, not days or weeks.\n\nWe are at the beginning of our journey and are looking for innovators who are curious and excited to drive change.\n\nBacked by Two Sigma, AIG, and Hamilton Insurance Group, we have the horsepower and partners to make a big impact. Unlike other start-ups, Attune has the funding, expertise, and support to modernize and move quickly. If you are energized by making the complex, simple; the time consuming, easy; and the antiquated, tech-enabled, we want you on our team.\n\nDisrupting an industry through data, technology and speed isn't easy \u2013 but the challenges we\u2019ll tackle together are some of the most rewarding you\u2019ll experience in your career.\n\nJob Description\n\nYou'll join a growing analytics team that drives Attune\u2019s business model forward by solving some of the most complex analytical problems in the industry. You will partner with the actuarial, underwriting, claims, product, revenue and customer service functions within Attune to frequently test new hypotheses, implement learnings and create edge.\n\nResponsibilities include:\nWorking on initiatives like: improving insurance risk predictions, analyzing drivers of claims, understanding user engagement patterns, finding the best potential customers to contact, reducing load on our customer service team, and identifying abnormal broker behavior\nCreating new predictive models in insurance pricing, pricing elasticity, reserving, claims analytics and etc.\nExploring new datasets to see how they can add value to the business\nHelping to incorporate analyses and models into daily workflows for other departments\nContributing to our ETLs, internal web applications, and BI dashboards\nDoing quick ad-hoc analyses and supporting engineers to troubleshoot issues\nQualifications\nExperience working in an statistics, analytics or data focused role\nExperience with predictive modeling in general\nFamiliarity with advanced statistical analysis methods (e. g., bayesian statistical modeling, hierarchical modeling and etc) in addition to machine learning regression/classification/clustering techniques\nWorking knowledge of bayesian software language (STAN, JAGS, or OpenBUGS) a plus\nWe are flexible about what tools you've worked with, but comfort in either Python or R is a must, as is basic SQL.\nWe don't require experience with deep learning or with tools for working with massive data sets\nProperty Casualty insurance experience and knowledge is a plus, but not a must\nTraits for success:\nYou enjoy working with programmers and other data scientists to constantly improve the integrity and automation of your work. You are frequently sharpening your software skills.\nYou are well organized and can handle many unrelated requests without losing track of them.\nYou are quick with numbers and back-of-the-envelope calculations.\nYou have strong written and verbal communication skills.\nYou are a hands-on problem solver who is comfortable with ambiguity and loves a fast-paced environment.\nYou have strong interpersonal skills and are capable of building relationships to drive success.\nAdditional Information\n\nWhat we offer you:\nAn opportunity to change the small business landscape.\nA great working environment that lives continuous improvement and encourages sharing ideas and taking risks to find better ways of doing things.\nA culture that promotes great relationships both inside the office and outside through activities in our community and company sponsored intramural clubs and events.\nEquity compensation.\nMedical, dental, and vision from day one and 401(k) matching.\nFully stocked kitchens with free snacks & drinks.\nAttune Insurance Services, LLC is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, or protected Veteran status.\nStart your job application: click Apply Now"}, "496": {"company": "Reddit", "description": "The front page of the internet,\" Reddit brings over 330 million people together each month through their common interests, inviting them to share, vote, comment, and create across thousands of communities. Come for the cats, stay for the empathy.\n\nWe are looking for a Staff Data Scientist to work with our Ads team. You will work closely with engineers and product owners from our Ads team to understand how our data can be used to tell a compelling story to brands. In addition to strong analytical skills, this person has a solid business acumen and understanding of what is important to advertisers.\n\nResponsibilities:\nServe as a thought-partner for Product Managers and Engineering Managers in influencing the ads roadmap and strategy by identifying opportunities through deep-dive analyses and/or modeling.\nDeeply understand ad auctions and how bid densities affect CPMs, CPCs and revenue\nDevelop familiarity with managed/reserved, takeover and self-serve environments and specific interplays amongst those ads.\nHelp improve the team's understanding of ads targeting, ads pacing, frequency capping, underdelivery and other aspects related to ads delivery.\nDevelop models to improve ads performance and advertiser ROI\nWork with cross-functional stakeholders and partners including PMs, Engineers, Solution Engineers and Sales.\nWhat We Can Expect From You:\nMasters degree or above in a quantitative major (e.g., mathematics, statistics, economics, finance, computer science)\n5+ years of experience in quantitative analytical roles, preferably for a consumer-facing service/app\n2+ years of experience in online advertising\nProficiency with statistical analysis and programming languages (e.g., R / Python)\nStart your job application: click Easy Apply"}, "497": {"company": "ASML", "description": "Introduction\n\n\nASML US brings together the most creative minds in science and technology to develop lithography machines that are key to producing faster, cheaper, more energy-efficient microchips. We design, develop, integrate, market and service these advanced machines, which enable our customers - the world\u2019s leading chipmakers - to reduce the size and increase the functionality of their microchips, which in turn leads to smaller, more powerful consumer electronics. Our headquarters are in Veldhoven, the Netherlands, and we have 18 office locations around the United States including main offices in Chandler Arizona, San Jose and San Diego California, Wilton Connecticut, and Hillsboro Oregon.\n\nJob Mission\n\n\nData Science Organization at ASMLis looking for an experienced Data Scientist who has a passion to build data products and data systems.\n\nThe Data Science team began to make the most use of a vast data acquired from our hardware and software products from 2014. As our vision expands, the opportunity to make important contributions to the company and to our customers through data analytics is also expanding. We seek a Principle Data Scientist with practical experience in exploring big data opportunity at ASML.\n\nAs a Principal Data Scientist, you will be responsible for utilizing disparate data sources in novel ways, with the aim of generating actionable insights. The insights can create new offerings or improve the capabilities, performance and efficiency of existing products and services throughout the company.\nJob Description\n\n\nYou will work closely with individual team leads to formulate problem statements and work through the lifecycle of delivering these insights to production. You will design and organize large and complex data sets from varied sources, while thinking strategically about uses of data and issues such as scalability. You will deliver mathematical and statistical models with proven predictive power.\n\nKey Responsibilities / Performance Requirements:\nUnderstand existing business flow and product features, dive into the underlying data, apply relevant Data Mining techniques and/or Machine Learning algorithms and propose data analytic product to improve the product intelligence\nImplement the applicable Machine Learning or statistics based algorithm for prediction and optimization and deliver the trained model to production\nDesign, build and support algorithms of data transformation, conversion, computation on Hadoop and other distributed Big Data Systems\nEducation\n\n\nPhD or MSof Computer Science/Engineering/Mathematics or equivalent\n\nExperience\nFive or more years of relevant experience\nExcellent understanding (algorithm level) of machine learning, statistics, and optimization\nExperience with popular data analysis and machine learning libraries (sklearn, TensorFlow, H2O, MLlib, etc.)\nFamiliar with Hadoop ecosystem and good understanding about its key components (HDFS, Hive, Pig, Spark, etc.)\nHands-on experience on data analysis, machine learning modeling, and data visualization with large scale dataset in Hadoop system using Hive, Spark, MLlib, etc.\nHands-on experience with different database architectures (SQL, NoSQL, Hive, HBase, etc.)\nExtensive knowledge of at least one scientific or statistical programming language such as Matlab, R or Python (must include SciPy, NumPy, Pandas)\nPrior work and/or research demonstrates experience in the following areas: data mining, pattern discovery, anomaly detection, root cause analysis\n\nDesired:\nExperience in deep learning\nExperience with different tools in Hadoop system (Zepplin, Jupyter, Storm, Sqoop, Flume, Ambari, etc.)\nProficient in one or two of the languages: Java, Python, C++, Scala in Linux/Unix\nPersonal skills\nStrong verbal and written communication skills\nAbility to articulate at a system level\nDesire and ability to work well with others in a team environment.\nContext of the position\n\n\nThis position primarily works in an office environment. It requires frequent sitting, standing and walking. Daily use of a computer is required. May stand for extended periods when facilitating meetings. The physical demands of the position described herein are essential functions of the job and employees must be able to successfully perform these tasks for extended periods. Reasonable accommodations may be made for those individuals with real or perceived disabilities to perform the essential functions of the job described.\n\nOther information\n\n\nEEO/AA (W/M/Vets/Disability) Employer\nStart your job application: click Apply Now"}, "498": {"company": "Zynga", "description": "Position Overview\n\n\nAs a data scientist you will be working closely with Zynga\u2019s central analytics functions on a wide array of topics including (but definitely not limited to):\nAutomated ML platforms (e.g. propensity modeling and segmentation)\nEnd-to-end marketing optimization and automation\nReal-time in-app content personalization\nAI driven CRM solutions\nReal-time bidding optimization\nZynga\u2019s experienced central data team includes data scientists, analysts and product managers working closely with engineering and business stakeholders.\n\nThis role will focus on building automated data-driven workflows and predictive modeling across all of Zynga\u2019s business functions.\n\nMain Responsibilities:\nLead, define and develop creative and new business opportunities and products while communicating findings and results with leadership and product teams\nBuild production-grade systems for deploying predictive models and other ML solutions\nBuild algorithm-driven automated workflows for performance optimization\nWork closely with product management and engineers to design, deploy, and evaluate ML models and optimization algorithms\nDesign and evaluate innovative approaches for advancing data science at Zynga\nDesired Skills and Experience:\n\nBA in Computer Science, Math, or other quantitative field; Masters or PhD preferred\n5+ years of work experience in data science or analytics roles\nKnowledge of predictive modeling algorithms and frameworks\nKnowledge of machine learning trade-offs and model evaluation\nExperience building automated workflows (e.g. Python)\nDemonstrated experience with scalable compute technologies (e.g. PySpark)\nKnowledge of virtualization technologies (e.g. Docker)\nExperience working with large datasets in a cloud environment\nAbility to work independently and effectively in a fast-paced environment with changing priorities\nZynga is an equal opportunity employer. We are proud of our broad community; we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. We welcome job-seekers, players, employees, and partners from all backgrounds. Join us!\n\nWe will consider all qualified job-seekers with criminal histories in a manner consistent with applicable law.\n\nZynga is committed to providing reasonable accommodation to applicants with disabilities. If you need an accommodation during the interview process, please let us know.\nTo apply to this job, click Apply Now"}, "499": {"company": "Pharmaceutical Product Development", "description": "The Senior Data Scientist at PPD executes\nadvanced analytics modeling based on exploratory data analysis from complex and\nhigh-dimensional data sets through application of statistics, machine learning,\nprogramming, data modeling, simulation, and/or advanced mathematics to\nrecognize patterns, identify opportunities, and generate valuable predictive\nbusiness insights in support of innovative business decisions. Supports\norganization leadership through data-driven decision validation and support.\nEffectively collaborates with cross-functional\nstakeholders to identify questions and business challenges and determine\nplans of action in order to effectively define, design, and develop\nmachine learning models and algorithms to derive insights into each\nproblem.\nGenerates and tests hypotheses and analyzes and\ninterprets the results.\nNavigates large, complex data sets for data mining,\nprofiling, and curation, and natural language processing (NLP), as well as\nidentifies related data that is fundamental to successfully applying\npredictive and machine learning techniques.\nDesigns, develops and programs methods, processes, and\nsoftware programs to consolidate, cleanse, and analyze unstructured,\ndiverse data sources to recognize patterns, identify opportunities, and\ngenerate actionable business insights and solutions.\nDesigns, develops, and evaluates predictive models and\nalgorithms that lead to optimal value extraction from the data in order to\nsupport business process improvements and solve business challenges.\nIdentifies meaningful insights from large data and\nmetadata sources in support of continuous improvement efforts and business\nprocess upgrades through exploratory data analysis.\nEffectively communicates and guides stakeholders\nthrough the machine learning process; Interprets and communicates findings\nand solutions from analysis and experiments to a broad audience, including\nbusiness leadership.\n#GD\n#PPDHP\nLI-NA1\nEducation and Experience:\nBachelor's degree or equivalent and relevant formal\nacademic / vocational qualification\nPrevious experience that provides the knowledge,\nskills, and abilities to perform the job (comparable to 5 years).\nKnowledge, Skills and\nAbilities:\n\nStrong working knowledge of application of statistics,\nprogramming, data modeling, simulation, and advanced mathematics to\nbusiness questions for data analysis\nDemonstrated skills with exploratory data analysis\ntechniques involving structured and unstructured data, machine learning\n(e.g. decision trees, neural networks, clustering, classification,\nBayesian networks), model validation techniques, and data visualization\ntechniques\nIn depth knowledge in one or more of the following\ntechnical areas: Snowflake, AWS EMR, Python, Spark, R, Shiny, jupyter, and\nassociated packages and libraries from numpy, pandas, SciPy or NLTK\nThorough knowledge of and exposure to cloud\narchitectures across NoSQL, lambda functions, kafka, sagemaker,\ntensorflow, etc.\nProficiency with the following data science approaches:\ndata engineering, pipelining and wrangling tools, data visualization and\nmodeling tools, and mathematical approaches to imperfect data\nSubstantial knowledge of data management approaches\nsuch as relational databases, data schemas, object stores, column stores,\ntriple stores, graph stores, and/or document stores\nProven ability to deliver accurate work products in a\ncross-functional matrix environment spanning data warehousing, data\nmodeling, and data analytics while managing multiple competing priorities\nSound analytical skills and demonstrated proficiency in\ndeveloping detailed analysis, models, plan calculations, and tools\nSolid executive presence with ability to communicate\neffectively and influence at all levels\nDemonstrated creativity in identifying non-traditional\ndata sources in addition to rigorous application of leading analytic\ntechniques\nPPD values the health and well being\nof our employees. We support and encourage individuals to create a healthy and\nbalanced environment where they can thrive.\nBelow is listed the working environment/requirements for this role:\nAble to communicate, receive, and\nunderstand information and ideas with diverse groups of people in a\ncomprehensible and reasonable manner.\nAble to work upright and stationary\nfor typical working hours.\nAbility to use and learn standard\noffice equipment and technology with proficiency.\nAble to perform successfully under\npressure while prioritizing and handling multiple projects or activities.\nVery limited travel (under 5\")\n#GD\nApply Now: click Apply Now"}, "500": {"company": "Strivr", "description": "At the intersection of technology, science, business and sports, STRIVR offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.\n\nSTRIVR was founded in 2015 out of Stanford University\u2019s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon and Fidelity to innovate and elevate employee development.\n\nMore than just content inside a headset, immersive learning provides realistic, high-impact experiences driven by L&D experts, instructional designers, data scientists, and immersive content specialists. STRIVR offers the only end-to-end solution available today, bringing together the software, hardware, content and services needed to deliver effective training at scale.\n\nRecognized by Fast Company\u2019s Most Innovative Companies for 2019, we take pride in our passion for innovation and we use that energy to fuel our work. Our culture thrives on teamwork, grit, transparency and impact, and celebrates every win. It\u2019s an exciting time to join our fast growing team!\n\nAt STRIVR, our Data Science team develops cutting-edge techniques to improve people\u2019s performance in the real world based on their experiences in the virtual world. As a Data Scientist at STRIVR, you will be laying the foundations of how users\u2019 performance is evaluated in immersive learning environments and will be at the forefront of defining approaches to immersive analytics.\n\nYour responsibilities:\nDevelop new ways to measure user behavior and to evaluate performance in the virtual environment\nIdentify research areas, develop and implement approaches , and communicate insights in a compelling narrative\nBuild forecasting models to predict real-world performance based on behavior in the immersive environment\nDevelop optimization models to customize the training flow for each user based on their behavior\nIncorporate your research outcomes into standard analytics offering\nYour skills:\n5+ years of industry experience as a Data Scientist\nAn advanced degree in a quantitative field (e.g Economics, Statistics, Sciences, Engineering)\nExperience developing and implementing in-depth approaches, including statistical and econometric analyses\nExperience designing and training machine learning models\nProficiency with Python (or R), and SQL. Familiarity with Javascript and HTML is a plus.\nStrong communication skills. Presentation skills is a plus.\nPassion for using data to improve immersive experiences\nTo apply to this job, click Easy Apply"}, "501": {"company": "Outreach", "description": "About The Team\n\nData is at the core of Outreach's strategy. It drives our customers and ourselves to the highest levels of success. We use it for everything from customer health scores and revenue dashboards, to operational metrics of our AWS infrastructure, to helping increase product engagement and user productivity through automated natural language understanding, to predictive analytics and causal inference via experimentation. As our customer base continues to grow, we are looking towards new ways of leveraging our data to save our customers time and improve their sales efficiency.\n\nThe mission of the Data Science team is to accelerate the success of our internal and external customers through trustworthy data analysis and experimentation. As a member of the team, you will be on the ground floor, working directly with the VP of Data Science to define and implement our strategy for delivering data products. You will be responsible for delivering models, data-driven functionality, and end-user features based on these models that will be deployed into production, as well as analyzing the data to produce actionable insights.\nYour Daily Adventures Will Include\nPlaying key role in designing and developing machine learning, NLP, and recommendation algorithms.\nWorking with internal and external customers to understand their pain points and brainstorm solutions\nDesigning A/B testing experiments and doing end-to-end data analysis to understand user experience and propose improvements.\nWorking alongside experienced engineering, design, and product teams to help deliver new customer-facing features and products.\nOur Vision of You\n2+ years experience in Data Science\nYou have experience of building production ML systems, and deep knowledge of modern ML algorithms\nYou have experience working with distributed data processing frameworks such as Spark.\nYou have experience using ML frameworks such as Tensorflow, SparkML, and Scikit-Learn.\nYou have a deep understanding of algorithms and evaluation methods used in production-grade ML systems.\nYou have strong programming skills in at least one object oriented programming language (Java, Scala, C++, Python, etc.)\nYou understand the entire lifecycle of machine learning product development, from inception to production\nYou are hands on, able to quickly pick up new tools and languages, and excited about building things and experimenting\nYou go above and beyond to help your team\nYou are honest, admit mistakes, and own fixing them\nYou are a motivated and talented craftsperson: always looking to sharpen and adapt your skills\nYou have a MS degree in Computer Science, Statistics, or a related field, or equivalent industry experience. PhD degree and publication track record at conferences such as KDD, SIGIR, WWW, ICML, NIPS, ACL, CIKM, RecSys, etc. are preferred.\nWhy You\u2019ll Love It Here\n\n\u2022 100% medical, dental, and vision coverage for full-time employees\n\u2022 Unlimited PTO (and people actually use it!)\n\u2022 401k to help you save for the future\n\u2022 Company-organized and personal paid volunteer days to support the community that supports us\n\u2022 Fun company and team outings because we play just as hard as we work\n\u2022 Diversity and inclusion programs that promote employee resource groups like OWN (Outreach Women's Network)\n\u2022 A parental leave program that includes not just extended time off but options for a paid night nurse, food delivery, gradual return to work, and the Gottman Institute's Bringing Home Baby course for new parents\n\u2022 Employee referral bonuses to encourage the addition of great new people to the team\n\u2022 Plus, unlimited snacks and beverages in our kitchen\nTo apply to this job, click Apply Now"}, "502": {"company": "The Syllogisteks Company", "description": "Must be able to work as our W2 employee Data Analyst\nManage North America Customer Master Data (Grower & Retailer) for Crop Protection, Seed Growth, Row Crops and Licensing businesses to support Commercial, Product Supply, Finance and Global business processes for operational and project related purposes.\n\nResponsibilities:\nAccountable for the creation and ongoing maintenance of customer master data in SAP and ancillary systems (Integrated Reference Data (IRD), SalesForce, Master Data Management (MDM), etc.) to ensure the availability of timely, accurate, high quality customer master data.\nAccountable to proactively identify and resolve customer master data related issues.\nIdentify best practices and process improvements for data management based on investigation/analysis and solicited feedback.\nIncorporate process changes into appropriate audit and training materials.\nCoordinate with IT support for enhancements and production support issues.\nParticipate on or manage small customer data related projects within or outside of the team.\nMaintain key operational metrics: timeliness and accuracy to support operational excellence and a strong internal control environment.\nRequired Skills / Experience:\nBachelors Degree\nFast learner; seeks to understand a number of processes with consistency and accuracy\nDetail oriented and highly focused on delivering results\nSelf-starter and ability to work as part of a team\nProactive problem solving skills with the ability to identify, analyze and interpret data\nStrong communication skills to interact with internal and external stakeholders\nAssist with writing documentation as needed for customer master training, policies, standards and procedures and train accordingly\nDesired Skills / Experience:\nKnowledge of breeding, agriculture, and/or biotechnology\nExperience in ERP data governance, data management or working with customer or supply chain data\nUnderstanding of complex database systems and management of large data sets\nAdditional information:\nWhat top 3 things are you looking for on resumes of quality candidates? (preferably hard skills) What type of specific experience would stand out on a resume?\n- Ability to multi-task and seamlessly switch gears from task to task throughout the day.\n- Critical thinking to solve issues that arise and grounded judgement to ensure appropriate action is taken.\n- Strong communication skills\nWhat is the long-term plan for the role?\n-With the integration I cant say, but this role will be open on the team as long as it can be.\nWhat will your interview process look like? Phone screen? Face to Face? Both?\n-Interviews will be face to face\nIs there anything else the suppliers should know in order to find the right candidates? What type of person works best within your team?\n- A team player that isnt afraid to jump in and help out others when their work is complete. Someone that likes problem solving and working with others to create a solution.\nTo apply to this job, click Easy Apply"}, "503": {"company": "PwC", "description": "PwC Labs is focused on standardizing, automating, delivering tools and processes and exploring emerging technologies that drive efficiency and enable our people to reimagine the possible. Process improvement, transformation, effective use of innovative technology and data & analytics, and leveraging alternative delivery solutions are key areas of focus to drive additional value for our firm.\n\nThe AI Lab focuses on implementing solutions that impact efficiency and effectiveness of our technology functions. Process improvement, transformation, effective use of technology and data & analytics, and leveraging alternative delivery are key areas to drive value and continue to be recognized as the leading professional services firm. AI Lab is focused on identifying and prioritizing emerging technologies to get the most out of our investments.\n\nTo really stand out and make us ?t for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\n\nAs a Director, youll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nArrange appropriate assignments and experiences to support others learning and development.\nSeek out different ways to use current and relevant technological advances.\nAnalyse marketplace trends - economical, social, cultural, technological - to identify opportunities and create value propositions.\nDeploy methods to keep up with, and stay ahead of, new developments and ideas.\nOffer a global perspective in stakeholder discussions and when shaping solutions/recommendations.\nDrive and take ownership for developing networks that help deliver what is best for stakeholders.\nProactively manage stakeholders to create positive outcomes for all parties.\nUphold the firms code of ethics and business conduct.\n\nJob Requirements and Preferences:\nBasic Qualifications:\n\nMinimum Degree Required:\nBachelor Degree\n\nAdditional Educational Requirements:\n\nIn lieu of a Bachelor Degree, 12 years of professional experience involving technology-focused process improvements, transformations, and/or system implementations.\n\nMinimum Years of Experience:\n10 year(s)\n\nPreferred Qualifications:\n\nDegree Preferred:\nMaster Degree\n\nPreferred Fields of Study:\nEngineering, Economics, Statistics, Mathematical Statistics, Mathematics, Operations Management/Research, Computer and Information Science\n\nPreferred Knowledge/Skills:\n\nDemonstrates thought leader-level abilities with, and/or a proven record of success directing efforts in the following areas:\nUnderstanding statistical or numerical methods application, data mining or data-driven problem solving;\nDemonstrating thought leader level abilities in the use of statistical modelling, algorithms, data mining and machine learning algorithms;\nUnderstanding business development such as client relationship management and leading and contributing to client proposals;\nDemonstrating proven delivery within a number of large scale projects;\nDemonstrating ownership of architecture solutions and managing change;\nCommunicating project findings orally and visually, to both technical and executive audiences;\nDeveloping people through effectively supervising, coaching, and mentoring staff;\nLeading, training, and working with other data scientists in designing effective analytical approaches taking into consideration performance and scalability to large datasets; and,\nManipulating and analyzing complex, high-volume, high-dimensionality data from varying sources.\nDemonstrates thought leader-level abilities with, and/or a proven record of success directing efforts in the following areas:\nDemonstrating thought leader-level abilities in commonly used data science packages including Spark, Pandas, SciPy, and Numpy;\nLeveraging familiarity with deep learning architectures used for text analysis, computer vision and signal processing;\nDeveloping end to end deep learning solutions for structured and unstructured data problems;\nDeveloping and deploying A.I. solutions as part of a larger automation pipeline;\nUtilizing programming skills and knowledge on how to write models which can be directly used in production as part of a large scale system;\nUnderstanding of not only how to develop data science analytic models but how to operationalize these models so they can run in an automated context;\nUsing Data visualization software such as tableau and qlikview in addition to web visualization libraries;\nDemonstrating proven ability with NLP and text based extraction techniques; and,\nUsing common cloud computing platforms including AWS and GCP in addition to their respective utilities for managing and manipulating large data sources, model, development, and deployment.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nTo apply to this job, click Apply Now"}, "504": {"company": "Fareportal Inc.", "description": "(We are not sponsoring for this role or in the future)\n\nAt Fareportal, we create technology that is driving innovation in the travel industry - one of the world's fastest-growing sectors. Our employees are the core of our organization and together we're revolutionizing the way people book travel.\n\nOur portfolio of brands including CheapOair and OneTravel receive over 100 million visitors annually and drive over $4 billion in annual revenue.\n\nWe are looking for a Lead Machine Learning Engineer/Data Scientist to join our team. You will be handling hundreds of millions of events per day, responsible for creating and supporting machine learning models that will drive our business.\n\nMachine Learning Engineers is at the heart of how Fareportal works and they are part software engineer and part machine learning / data scientist. You will focus on creating and supporting large scale models that we deploy to power our recommendation, pricing or other systems. The ideal candidate will participate in the design and implementation of the entire model pipeline, from project ideation, figuring out which data to capture and store, coming up with features, to creating the final model.\n\nWe are passionate about making data-driven decisions and you will have the opportunity to shape the team's direction and create large impact.\n\nOur team loves Python and Scala (and is not afraid of Functional Programming) and we strongly encourage DevOps approaches.\n\nResponsibilities:\nLead a team of machine learning engineers, data scientist, data engineers\nSupport our data modeling efforts to ensure we are capturing the data needed to improve our modeling capabilities.\nCreate features for our feature store\nBuild machine learning models\nUse a variety of techniques including predictive modeling, recommendation engines, revenue management, conversion rate optimization, and site and user experience optimization.\nOur ideal candidate:\n\nWho You Are\nYou are smart and love to build systems that are well tested as well as flexible\nYou like being around smart people who will challenge you on a daily basis.\nYou love to ramp up on new technologies to build awesome things with us!\nPassionate about working with large unstructured and structured data sets and developing new approaches to relevance problems\nYou like to share your knowledge and guide other fellow data scientist and engineers\nRequirements\n5+ years' experience developing, maintaining, and testing machine learning models.\nA strong technical advocate with a background in Java, Scala, or Python. Preferably familiar with Jupyter notebook environments and Spark or pySpark.\nStrong understanding of the machine learning tooling for either Python or Scala (e.g. Pandas, XGBoost, Spark)\nStrong understanding of machine learning\nNice to have\nExperience with CI/CD infrastructure and a strong supporter of unit / integration testing\nTo apply to this job, click Easy Apply"}, "505": {"company": "Divvy", "description": "About the Company\n\nAt Divvy, Our vision is to become the financial nervous system of every small-to-medium business in America. Our FREE one-stop-shop financial SaaS platform enables businesses to spend smarter by providing instant insight and transparency into company-wide spend and the ability to easily manage it; all in real-time! (+ many more features!)\n\nWith over 3,000 clients, extreme monthly growth, $240 million in venture capital raised from top investors, and 250+ mission-driven employees, we\u2019re well on our way.\nWhat You'll Be Doing\nDesigning and implementing data science infrastructure to support inference in a production application environment ( eg. building out Spark, Kafka/Pulsar, Postgres, analytical database like Snowflake environments)\nApply your expertise in deep learning, quantitative analysis, data mining, and the presentation of data to see beyond the numbers to increase revenue and improve our competitive position\nPartner with Product and Engineering teams to solve problems and identify trends and opportunities\nInform, influence, support, and execute our product decisions and product launches\n\nThe Data Scientist Analytics role has work across the following four areas:\nData Infrastructure and architecture\nDesigning and implementing data science infrastructure to support inference in a production application environment ( eg. building out Spark, Kafka/Pulsar, Postgres, analytical database like Snowflake environments)\nAutomating analyses and authoring pipelines via python\n\nLeadership\nInfluencing product teams through presentation of data-based recommendations\nCommunicating state of business, experiment results, etc. to product teams\nSpreading best practices to analytics and product teams\nMentoring and leveling up data scientists and analysts\n\nProduct\nForecasting and setting product team goals\nDesigning and evaluating experiments\nMonitoring key product metrics, understanding root causes of changes in metrics\nBuilding key data sets to empower operational and exploratory analysis\nEvaluating and defining metrics\n\nExploratory Analysis\nProposing what to build in the next roadmap\nUnderstanding ecosystems, user behaviors, and long-term trends\nIdentifying new levers to help move key metrics\nBuilding models of user behaviors for analysis or to power production systems\nQualifications\nMultiple years of experience doing the following: Designing and implementing data science infrastructure to support real-time inference in a production application environment ( eg. building out Spark, Kafka/Pulsar, Postgres, analytical database (snowflake, redshift, etc.) infrastructure)\nMentoring and leveling up data scientists and analysts\nAutomating analyses and authoring pipelines via python\nInfluencing product teams through presentation of data-based recommendations\nCommunicating state of business, experiment results, etc. to executives\nSpreading best practices to analytics and product teamsDesigning and evaluating experiments\nEvaluating and defining metrics\nInfluencing product feature roadmap with data\nUnderstanding ecosystems, user behaviors, and long-term trends\nBuilding models of user behaviors for analysis or to power production systems\nTotal Rewards\nAt Divvy we\u2019ve been intentional in designing scalable benefits, rewards, and perks that meet our workforce where they are while managing expectations as we scale. Just as pay parity was foundational for us in base salary, and remains our commitment and priority, our total rewards programs reflect our commitment to inclusivity and access for all.\n\nAt Divvy, you\u2019ll enjoy:\n\u2022 Employer contribution to health insurance premiums for all Full Time employees (minimum 60% independent of individual or family coverage selected)\n\u2022 Stock option grants for Full Time employees (new hire, promotion, evergreen)\n\u2022 Unlimited PTO\n\u2022 401K\n\u2022 $100 Divvy Uses Divvy each month (for personal use and engagement with our product)\n\u2022 $1000 Divvy Travel annually on your anniversary date of hire (take time to recharge)\n\u2022 Earn rewards by saving on business or personal travel with Divvy Travel powered by TripActions\n\u2022 Complimentary well-stocked kitchen and break rooms\n\u2022 Paid parental leave for Full Time employees (12 weeks for birthing/adoptive parents, 6 weeks for non-birthing parents)\n\u2022 Onsite services to make life easier (dental, vision, wellness, auto services, hair cuts, wellness, financial education, annual flu shots)\n\u2022 New 150,000 sq ft headquarters under construction with anticipated move-in summer 2020 (includes 2,000 sq ft Rogue and Peloton activated fitness facility with locker room, bike/ski storage and work room, full size outdoor basketball court, cafe, learning and development center, and continued support of gender neutral restrooms)\n\nPerks are nice, but perks don\u2019t make a company or individual successful - the work does. At Divvy, we\u2019re building the financial nervous system of business - faster, better, smarter, and the work compels us to show up each day for our customers and our teams while feeling well supported in our benefits.\n\n**We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.**\nTo apply to this job, click Apply Now"}, "506": {"company": "AstraZeneca", "description": "Sr. Data Scientist/Principal Data Scientist, Oncology\n\nThe Machine Learning and AI team in AstraZenecas Oncology Data Science group is where we develop and apply sophisticated algorithms and techniques to solve the hardest problems in oncology drug discovery and development. The team uses their scientific, quantitative, and problem-solving skills to work on a broad range of challenges across the whole oncology portfolio, working collaboratively with other scientists across a range of disciplines to scope, define, and deliver projects that both advance the state of the art in data science and accelerate the delivery of innovative medicines to patients.\n\nNOTE: This position can be filled in either GAITHERSBURG MARYLAND OR WALTHAM, MASSACHUSETTS\n\nAs a Senior Data Scientistor Principal Data Scientist, you will play a key role on the front line in this rapidly growing team working to extract insight from complex biomedical data. You will develop your leadership skills and apply and develop your expertise in rigorous quantitative data science to provide solutions to a variety of data science problems, researching, recommending and delivering novel methodologies to solve the problems that matter to the oncology pipeline.\n\nExamples of projects the team works on include developing machine learning models for digital biomarkers, patient risk stratification for clinical trials, new algorithms for survival analysis, approaches to quantitatively analyse wearable data, linking of medical imaging data with omics and longitudinal outcomes to identify and/or validate new drug targets, and much more!\n\nThe level of the position will be determined by the candidates experience, skills and education.\n\nTypical Accountabilities\n\nFor our Sr. Data Scientist you will typically be accountable for:\nProviding advanced data science and machine learning expertise to AstraZeneca projects, researching and recommending data science solutions, and appropriately communicating with non-technical stakeholders.\nCollaborating in a multidisciplinary environment with world leading clinicians, data scientists, biological experts, statisticians and IT professionals.\nPublishing your work to ensure that AstraZeneca drives the data science agenda in the pharmaceutical industry.\nFor our Principal Data Scientist you will additionally be accountable for:\nDeveloping novel data science and machine learning solutions where off-the-shelf methodologies do not fit.\nLeading small (2-3 person) data science projects of defined scope.\nCoaching/mentoring junior data scientists and others to drive the development of data science as an AZ capability.\nEducation, Qualifications, Skills and Experience\n\nEssential for our Sr. Data Scientist\nMSc degree in rigorous quantitative science (such as mathematics, computer science, engineering)\nPractical software development skills in standard data science tools (such as R or python)\nKnowledge of range of mathematical and statistical modelling techniques, and drive to continue to learn and develop these skills.\nDesirable\nPhD degree in rigorous quantitative science (such as mathematics, computer science, engineering)\nExperience within the pharmaceutical industry\nOutstanding communication, business analysis and consultancy\nEssential for our Principal Data Scientist\nMSc degree in rigorous quantitative science (such as mathematics, computer science, engineering)\nExtensive hands-on experience applying data science tools in practice.\nPractical software development skills in standard data science tools (such as R or python)\nExtensive knowledge of mathematical modelling and statistical modelling techniques and drive to continue to learn and develop these skills\nOutstanding communication, business analysis and consultancy\nDesirable\nPhD degree in rigorous quantitative science (such as mathematics, computer science, engineering).\nExperience within the pharmaceutical industry.\nIn-depth experience of working in a global organization with complex/geographical context\nStart your job application: click Apply Now"}, "507": {"company": "Revel IT", "description": "Data Analyst. We have a contract need (or contract-to-hire) for a Data Analyst who will utilize industry standard tools and query languages to lead the collection, analysis and understanding of data within operational data repositories, data warehouses and Business Intelligence solutions. The role will act as a data and Business Intelligence subject matter expert and work closely with business stakeholders to collect requirements and map out short and long-term plans for data and Business Intelligence solutions.\n\nEssential Functions:\n40%: Lead and participate in cross-functional teams to transform business needs into requirements for data and business intelligence solutions.\n20%: Create data dictionaries, metadata, and/or ad-hoc reporting to document findings and share understanding of clients' data assets.\n10%: Work with business partners and IT teams to research and analyze data quality issues and identify and prioritize solutions.\n20%: Analyze and develop data models to ensure that data structures appropriately support business requirements.\n10%: Proactively identify opportunities to use business intelligence solutions to better support business management and/or improve efficiency of tools.\nRequirements\nEducation Level: Bachelor's Degree in Computer Science, MIS, Information Management, Engineering or related technical field of study\n6+ years of IT experience in a data management, Business Intelligence, or data quality role.\nAdvanced experience developing requirements for operational reporting systems, data warehouse systems, reports, and dashboards.\nAdvanced experience in Metadata Management/Data Dictionary management.\nAdvanced SQL skills is required; Experience with Oracle PL/SQL is a plus.\nExperience integrating and transforming structured and unstructured data using tools such as Informatica.\nExperienced using a variety of reporting, data analysis, and data visualization tools, such as Tableau, SAP BusinessObjects, SAS, custom dashboards.\nExceptional ability to visually present and communicate data, analyses and findings.\nExperience with a variety of software development methodologies (Waterfall, Agile, etc) will be a plus.\nMust be skilled at translating technical terms for a non-technical audience, and non-technical terms for a technical audience.\nAdvanced experience creating and managing enterprise data models\nAdvanced experience presenting and communicating findings/recommendations to cross-functional teams and/or leadership.\nMust possess strong data analysis, debugging and problem solving skills and a demonstrated ability to identify root causes.\nBusiness acumen and ability to understand complex business processes in a fast-paced environment.\nAbility to coach and develop less experienced personnel.\nAbility to take lead role in small projects or smaller efforts of larger projects.\nRevel IT (formerly known as Fast Switch) is one of the fastest-growing, privately held, IT Staffing companies in the nation. Our client base includes 32% of the Fortune 25.\n\nWe have major offices in Dublin, OH, Phoenix, AZ, Los Angeles, CA, and Austin, TX and are rapidly expanding into new markets from coast to coast.\n\nOur reputation is one of straight talk, creative solutions, aggressive pricing, and flawless execution ... outperforming the giants of our industry every day. We embrace the strategy inferred in Winston Churchill's famous quote, \"The short road to ruin is to emulate the methods of your adversary.\" At Revel IT, we are constantly asking ourselves, \"Is there a better way?\" Almost every day, we answer, \"Yes.\" #revelitjobs\nStart your job application: click Easy Apply"}, "508": {"company": "Ericsson-Worldwide", "description": "Date: Nov 12, 2019\n\nEricsson Overview:\n\nEricsson is world\u2019s leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.\n\nUsing innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planet\u2019s greatest challenges.\n\nWe are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have the freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.\n\nJob Summary:\n\nResponsibilities:\nPartner with Ericsson\u2019s machine intelligence (MI) team to prioritize and answer the most important questions where machine learning and AI breakthroughs will have material impact\nUse your experience in analytics tools and scientific rigor to produce actionable insights. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical model, deep learning, reinforcement learnings and other machine learning systems\nCollaborate with business leaders, subject matter experts, and decision-makers to develop success criteria and optimize new products, features, policies, and models\nMentor junior data scientists on technologies, methodologies and best practices\nDevelop methodologies, standards/best-practices and systems for reusable MI assets across Ericsson businesses\nDevelop and nurture MI communities within Ericsson and its ecosystem in the areas of expertise\nCollaborate with others on the best way to document and present the findings and experiments of the data analysis, including benchmarking against (de-facto) industry standards and baselines, to the stakeholders\nCollaborate with product development teams to industrialize the findings\nCommunicate key results to senior management in verbal, visual, and written media\nEngage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MI\u2019s needs\nPresent and be prominent in Machine learning related forums and conferences, e.g., presenting papers, organizing sessions and be a Panelist\nTechnologies we use and teach:\nR, Python\nHive and other Bigdata family\nStatistics (Frequentist/Bayesian methods, experimental design, causal inference)\nShiny/D3/Tableau, etc.\nKey Qualifications and Education:\nBS, MS, or PhD in Computer Science, Mathematics, Physics, Economics, or related field\n3 to 5 years\u2019 experience and knowledge in Statistics, e.g., hypothesis formulation, hypothesis testing, descriptive analysis and data exploration.\nDemonstrated skills in Machine Learning, e.g., linear/logistics regression discriminant analysis, bagging, random forest, Bayesian model, SVM, neural networks, etc.\nStrong Programming skills in various languages (C++, Scala, Java, R)\nStrong skills in the use of current state of the art machine learning frameworks such as Scikit-Learn, H2O, Keras, TensorFlow, and Spark\nAbility to clearly communicate complex results to technical and non-technical audiences\nVersatility and willingness to learn new technologies on the job\nAdditional Skills a Plus:\nCertification: Machine Learning MOOCS\nFamiliarity with Linux/OS X command line, version control software (git), and general software development\nExperience in programming or scripting to enable ETL development\nFamiliarity with relational databases\nPrevious industry experience or internships in product related analytics\nIndependent research experience\nDISCLAIMER: The above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of employees assigned to this position. Therefore employees assigned may be required to perform additional job tasks required by the manager.\n\nWe are proud to be an EEO/AA employer M/F/Disabled/Veterans. We maintain a drug-free workplace and perform pre-employment substance abuse testing.\n\nEricsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, protected veteran status, union membership or genetics information. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact.\n\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development.\n\nEricsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, gender identity, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, protected veteran status, union membership or genetic information.\n\nEricsson will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by Ericsson or (c) consistent with Ericsson\u2019s legal duty to furnish information.\n\nEmployee Polygraph Protection Act Notice - Employers are generally prohibited from requiring or requesting any employee or job applicant to take a lie detector test, and from discharging, disciplining, or discriminating against an employee or prospective employee for refusing to take a test or for exercising other rights under the Act. For more information, visit https://www.dol.gov/whd/regs/compliance/posters/eppac.pdf.\n\nEricsson is an equal opportunity employer and is committed to providing reasonable accommodation for qualified disabled individuals during the application and hiring process. Ericsson will make modifications or adjustments to the job application or interview process that will enable a qualified applicant to be considered for a position. If you require an accommodation due to a disability, please contact Ericsson at hr.direct.dallas@ericsson.com or (866) 374-2272 (US) or (877) 338-9966 (Canada) for further assistance.\n\nPrimary country and city: United States (US) || || Plano || ServEng\nTo apply to this job, click Apply Now"}, "509": {"company": "Regeneron", "description": "Known for its scientific and operational excellence, Regeneron is a leading science-based biopharmaceutical company that discovers, invents, develops, manufactures, and commercializes medicines for the treatment of serious medical conditions. Regeneron commercializes medicines for eye diseases, high LDL-cholesterol, atopic dermatitis and a rare inflammatory condition and has product candidates in development in other areas of high unmet medical need, including rheumatoid arthritis, asthma, pain, cancer and infectious diseases.\n\nThe Molecular Profiling group is looking for a talented data scientist with experience in genomic data analysis and algorithm development. The scientist will analyze preclinical and clinical data to support target and biomarker discovery & validation, as well as develop statistical and computational methods to advance our understanding of complex biological systems.\nDevelop computational methodologies to integrate and model multi-modal data to help address the gap in understanding new molecular biology.\nWork with leadership to identify novel therapeutic targets and biomarkers via mining proprietary pre-clinical and clinical data.\nDevelop data analysis pipelines and establish data analysis best practices for emerging genomic technologies.\nCollaborate with colleagues in research to design experiments and define data analysis plans.\nCommunicate results with collaborators, refine analysis based on feedback.\nPrepare clear, concise and easy-to-understand presentations and documentations for collaborators, senior management and government agencies.\n#LI-GP1\n\nRequirements:\nPhD + 0-3 years minimum in computational biology, biomedical engineering, bioinformatics, applied mathematics, or related quantitative field, with a track record of high quality publications\nExperience in analysis, interpretation, and visualization of sequencing data (e.g. bulk/single-cell RNA-seq, CRISPR screening)\nExpertise in statistical data analysis and algorithm development\nHigh proficiency in analytical and programming tools such as Python and R, and their associated packages for statistics, modeling and visualization\nHands-on experience in machine learning, predictive modeling, and/or image analysis is highly preferred\nFamiliarity with Unix/Linux, shell scripting, SGE clusters, AWS environment\nProven problem-solving skills and collaborative nature in fast-paced environment.\nAbility to work both independently and collaboratively\nExcellent communication and presentation skills\nThis is an opportunity to join our select team that is already leading the way in the Pharmaceutical/Biotech industry. Apply today and learn more about Regenerons unwavering commitment to combining good science & good business.\n\nTo all agencies: Please, no phone calls or emails to any employee of Regeneron about this opening. All resumes submitted by search firms/employment agencies to any employee at Regeneron via-email, the internet or in any form and/or method will be deemed the sole property of Regeneron, unless such search firms/employment agencies were engaged by Regeneron for this position and a valid agreement with Regeneron is in place. In the event a candidate who was submitted outside of the Regeneron agency engagement process is hired, no fee or payment of any kind will be paid.\n\nRegeneron is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability status, protected veteran status, or any other characteristic protected by law.\n\n#LI-GP1\nStart your job application: click Apply Now"}, "510": {"company": "7Park Data", "description": "7Park Data, a Vista Equity portfolio company, is the world\u2019s leading alternative data intelligence firm. We have access to some of the most coveted alternative datasets \u2013 such as clickstream, geolocation, mobile app usage, credit and debit card, email receipt, and shipping cargo data \u2013 and are constantly acquiring more.\n\nYou will be joining other extremely passionate data scientists, product managers, and engineers that share a common interest in tackling some of the most difficult data science and machine learning problems today. With the data products and machine learning systems you design, 7Park will arm influential decisionmakers at financial and corporate giants with critical information they need to make smart, data-driven decisions. And, along the way, you will help advance the current work in artificial intelligence and predictive modeling.\n\nThe data science team has two major goals: to create and build data products that provide intelligence on real-time economic activity to our financial and corporate clients and to research and develop machine learning systems to extract information from large volumes of structured and unstructured text.\n\nWe are looking for a talented and creative Data Scientist to join our data science team. As a Data Scientist, you will be responsible for the following:\nConduct research on some of the world\u2019s most interesting alternative datasets\nPlan, develop, and apply cutting-edge machine learning systems and statistical modeling to extract insight from vast amounts of data at scale\nWrite production-ready code to analyze, structure, and make accurate and timely predictions\nDesign systems to monitor the results of models in productions, discover and address anomalies, and ensure the robustness and reliability of these models\nLead projects from start to finish, collaborating with 7Park\u2019s senior management, product managers, engineers, external data partners, and clients\nAn ideal candidate will be passionate about building machine learning systems on real world data and have several years of industry experience and/or a Masters or PhD in computer science, mathematics, statistics, linguistics, physics, computational finance, or a similar quantitative field.\n\nIt is also very important that you enjoying working in a lean, tight-knit, and highly entrepreneurial startup that marries the creative, experimental problem-solving found in academia with the hacker ethos of shipping products quickly and often.\n\nCompensation package: includes highly competitive salary, bonus and 401(k) plan.\n\nRequirements\nAt least 5 years of relevant professional experience and/or a Masters or PhD in computer science, mathematics, statistics, linguistics, physics, computational finance, or similar quantitative field.\nStrong knowledge of machine learning, computer science, mathematics, and statistics.\nStrong programming skills in Python, R, and/or Scala.\nExperience with NumPy, SciPy, Pandas, Scikit-Learn, TensorFlow, and Keras. PyTorch is also acceptable.\nExperience with building distributed machine learning systems using Apache Spark and a working knowledge of MLlib.\nExperience with several of the following concepts: decision trees, random forests, and gradient boosting; linear regression; logistic regression; linear and non-linear dimensionality reduction using PCA, kernel methods, and dictionary learning; clustering with K-means, hierarchical clustering, and DBSCAN; autoencoders; generative models; and sequential data modeling.\nBonus\nPublications in communities such as NIPS, ICML, or related.\nGitHub projects demonstrating your creative drive.\nKaggle wins demonstrating your competitive drive.\nExperience running or working at data-centric startups.\nExperience with knowledge graphs.\nWorking knowledge of GraphX and Spark Streaming.\nStart your job application: click Apply Now"}, "511": {"company": "Novartis", "description": "50-80%. The amount of time the average data scientist spends preparing data. You will help drastically reduce this number to unlock efficiencies in how we discover new drugs.\n\nPassionate about making connections between data sets at scale to unearth more needles from many more haystacks? We are looking to fill a position that sits precisely at this point in early computational drug discovery: between large-scale processed raw data on one side and individual molecular insights on the other side. If you are a versatile data scientist who enjoys casting problems into generic computational solutions to catalyze efficiencies in data-driven drug discovery, this is for you.\n\nYour responsibilities include but are not limited to:\n\u2022 Engage with computational peers across the research organization to identify recurrent problems that can be solved at scale, focusing on all data domains that are of practical use in drug discovery.\n\u2022 Design, implement, and maintain robust methods, algorithms, and packages (python, R) that help the computational community solve old and new problems with ease.\n\u2022 Define, refine and promote the computational glue that is between large-scale data processing (such as NGS pipelines) and insights at very detailed level.\n\u2022 Ideate and implement visualizations, dashboards & webservices for data dissemination to computational peers as well as to non-computational collaborators.\n\nPosting Title\nData Scientist \u2013 Data Connector\nTo apply to this job, click Apply Now"}, "512": {"company": "Assurance Careers", "description": "About Assurance\nAt Assurance we are disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosystem. We are rapidly growing as we expand our product offerings and global footprint, and this growth continues to present new and exciting challenges as we push our industry into its future. We eliminate waste throughout the industry and calculate the complex into simple, valuable solutions to improve people's lives. We are humble, driven, and committed to improving the lives of millions.\n\nAbout the Position\nAs we build the future of consumer insurance in a modern age, data and machine learning are at the core of everything that we do. The role requires team members who take insights, actions, and models from our data scientists and translate that into software products that enable business optimization. We currently have more than 40 models in production and are doing about 5 million real-time predictions per day. Our team uses a variety of data mining and analysis methods, uses a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Our ML Engineers design and build the prediction services that makes this development possible with no support from engineering (we own our stack end to end). At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise.\nTo be successful in this role, you must possess the following:\nA drive to move fast and deliver business value.\n4+ years of backend software engineering in a team environment.\nExperience writing and debugging complex database queries and code.\nAbility to quickly learn new technologies to help the team explore new solutions.\nExcellent communication ability \u2013 you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.\nBusiness Acumen \u2013 you are always eager to understand how the business works, and more specifically, how your work impacts the business.\nMentorship of others \u2013 you raise the bar on coding standards and providing meaningful feedback on code changes.\nEnthusiastic yet humble nature \u2013 you are excited about the work you do, but you are also humble enough to embrace feedback \u2013 you don\u2019t need to be the smartest person in the room.\nThe following additional experience is desired:\nExperience with writing production-level Python.\nUnit and integration testing.\nUse of cloud technologies (AWS, GCP, Azure).\nParticipate in agile methodologies (daily standup, sprint planning, retros).\nProfiling and performance tuning of production code a bonus.\nDirect experience with using ML libraries like sklearn, or Spark ML in a production environment a huge bonus!\nWe\u2019re changing the world of consumer insurance and financial services everyday through the power of Machine Learning and Data Science \u2013 join us on the journey!\nStart your job application: click Apply Now"}, "513": {"company": "Gusto", "description": "Gusto is looking for experienced data scientists with expertise in building and deploy predictive models and algorithms in order to help us grow, prevent fraud, control financial risk, and deliver products that help our customers build great places to work.\n\nThe Data Science team leverages Gusto's data to deliver data-informed insights for our customers and guide product direction and decision-making. We operate full-stack, conducting analyses, prototyping and deploying predictive models and statistical tools both for internal use and for our customers. Here are a few areas where we contribute today:\nRisk and Fraud - Gusto processes >$10B of payroll annually, so preventing fraud on our platform is critical for our survival. We also expedite payments for many of our customers, and with new features like Flexible Pay, we gives employees the freedom to choose their own pay schedule and get paid as soon as the next day for the hours they've already worked. We work with our Risk teams to build and deploy models for fraud prevention and underwriting our payment programs.\nGrowth - We work with our Marketing, Sales and Growth teams to help, from predictive models of lead and customer value to providing upsell and cross-sell recommendations.\nGreat Places to Work - Gusto pays hundreds of thousands of employees as small businesses all over the US. We are working with our Product teams to leverage this valuable payroll, benefits and HR data to build features that help our customers build great places to work.\nHere's what you'll do day-to-day:\n\n\nBuild and deploy models and data products to support growth, prevent fraud, control risk and delight our customers.\nEnhance and contribute to the team's core analysis and modeling systems and libraries\nIdentify new opportunities to leverage data to improve Gusto's products and help our business\nPresent and communicate results to stakeholders across the company\nHere's what we're looking for:\n\n\nAt least 5 years experience conducting statistical analyses on large datasets, ideally in a business context (can supplement with academic experience where appropriate)\nExperience applying a variety of statistical and modeling techniques using Python, R or another statistical modeling language, as indicated by familiarity with many of the following techniques - generalized linear modeling, regularization, ensemble models (e.g., random forest, gradient boosting), Bayesian analysis methods\nStrong programming skills - comfortable with all phases of the data science development process, from initial analysis and model development all the way through to deployment\nExcellent communication skills - able to effectively deliver findings and recommendations to non-technical stakeholders in a clear and compelling fashion\nPhD or Masters plus equivalent experience in a quantitative field\nExperience applying predictive modeling to fraud, credit or growth problems is a plus.\nAbout Gusto\n\n\nOur customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto.\n\nGusto is a modern, online people platform that helps small businesses take care of their teams. On top of full-service payroll, Gusto offers health insurance, 401(k)s, expert HR, and team management tools. Today, Gusto offices in Denver, San Francisco, and New York serve more than 100,000 businesses nationwide.\nTo apply to this job, click Apply Now"}, "514": {"company": "Quartet Health", "description": "Company Description:\n\nQuartet is a healthcare technology company striving to improve the lives of people with mental health conditions and was ranked #29 of Modern Healthcare's 2019 Best Places to Work in Healthcare. We connect people to a personalized care team to get them the right care at the right time. Our collaborative technology platform and range of services brings together physicians, mental health providers, and insurance companies to effectively improve patient outcomes and drive down healthcare costs.\n\nBacked by $153MM in venture funding from top investors like Oak HC/FT, GV (formerly Google Ventures), F-Prime Capital Partners, Polaris Partners and Centene Corporation, Quartet is headquartered in NYC and is currently operating in several markets across the United States Pennsylvania, Washington, Northern California, New Jersey, North Carolina, Louisiana, and Illinois.\n\nRole Description:\n\nWe are looking for talented data scientists with a passion for addressing business needs through data modeling and analysis to join our team. As an individual contributor on this team, you will work side-by-side with senior members of the team and internal partners from across the organization. This position requires strong problem-solving, analytical and communication skills; experience with multitasking and prioritizing in a fast-paced environment; and the tenacity to execute against deliverables in a timely, high-quality fashion.\n\nAs a data scientist at Quartet, you will work on a range of projects -- developing statistical analyses to study impact of Quartet interventions; predicting mental health needs among populations; building machine learning models to suggest timely and appropriate behavioral health care interventions for patients. You'll develop a deep understanding of Quartet interventions and the predictive models and algorithms that enable effective integration of mental health into primary care to steer patients towards better health. You will learn and apply statistical methodologies to measure outcomes and impact of interventions.\n\nYou'll work with datasets that include millions of detailed medical, pharmacy, lab claims, EHR, and application data. You will help with development and validation of new algorithms that enhance our system in terms of scalability, reliability and accuracy.\n\nThe ideal candidate will be an entrepreneurial, motivated data scientist who is well-versed in data analysis and algorithm implementation and eager to learn new things and make an impact on the industry. Health data experience is a plus, but it's not necessary.\n\nResponsibilities:\nWork with an interdisciplinary technical team to develop statistical models in Quartet's platform.\nApply statistics, data mining, machine learning techniques to develop studies to evaluate patient outcomes and recommendations to meet patients' and doctors' needs.\nDesign and develop effective models, features, and algorithms involving multiple datasets - user activity, medical claims, pharmacy claims, lab test claims etc.\nDerive insights from descriptive analysis that drive a data-informed process for experimenting with new products to improve patient outcomes.\nLearn and contribute to team efforts to make our code scalable, our work output data-rich and actionable, and our research reproducible.\nQualifications:\n2-3 years experience as a data scientist.\nFormal training in statistics and computer science.\nKnowledge of mathematical fundamentals: probability theory, linear algebra and statistics.\nStrong data transformation and extraction skills with SQL databases.\nStrong statistical programming skills in both Python and R.\nComfort/self-sufficiency with Amazon Web Services infrastructure.\nComfort/self-sufficiency with Linux servers.\nComfort/self-sufficiency with git for version control.\nAbility to execute, starting from problem definition, to a working implementation.\nAbility to clearly communicate across disciplines and work collaboratively.\n\nEmployee Benefits for Quartet include: Unlimited vacation, volunteer opportunities, catered lunches, snacks, team events and outings, mental healthcare coverage of 15 free therapy sessions + unlimited copay reimbursements, medical, dental + vision coverage, generous parental leave, commuter benefits, 401K, stock option grants, gym benefits.\n\nWant to know what Quartet life is like? Click here to meet our team.\n\nQuartet is committed to building a diverse team and fostering an inclusive culture, and is proud to be an equal opportunity employer. We embrace and encourage our employees' differences in race, religion, color, national origin, gender, family status, sexual orientation, gender identity, gender expression, age, veteran status, disability, pregnancy, medical conditions, and other characteristics. Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Quartet does not accept unsolicited headhunter and agency resumes. Quartet will not pay fees to any third-party agency or company that does not have a signed agreement with Quartet.\n\nPlease note: Quartet interview requests and job offers only originate from quartethealth.com email addresses (e.g. jsmith@quartethealth.com). Quartet will also never ask for bank information (e.g. account and routing number), social security numbers, passwords, or other sensitive information to be delivered via email. If you receive a scam email or wish to report a security issue involving Quartet, please notify us at: security@quartethealth.com.\n\nHave someone to refer? Email talent@quartethealth.com to submit their details to us.\n\nStart your job application: click Easy Apply"}, "515": {"company": "ShopKeep", "description": "About Us\n\nBorn out of frustration with the traditional cash register business, ShopKeep was designed by a retailer with a noble aim: to rescue independent business owners from the nightmare of archaic point of sale systems, and replace them with something beautiful, simple, and affordable. It turned out that by doing this, we were giving our fellow merchants a fighting chance against the big guys.\n\nToday, our mission is simple: empower independent business owners to dream big and to fight smart. We're doing this through our cloud-based architecture, amazing customer care, and intuitive software that delivers the data small business owners need to run smarter businesses.\n\nAt ShopKeep, we've been successful because of our awesome team that believes small businesses make up the heart of our communities.\n\nAbout This Role\n\nThe Data team at ShopKeep is a results-focussed team using data to provide solutions across the company. We are a B2B SaaS company, with terabytes of data - from our digital marketing channels and our sales pipelines, all the way through our merchant life cycle, including billing, onboarding, product/feature usage, transactions and customer care.\n\nWe are looking for an experienced data scientist to help us use this data to drive measurable improvements across ShopKeep. We are convinced our data holds the keys to figure out ways to optimize our business and find valuable insights. We are looking for a data scientist who believes the same and has some relevant experience.\n\nWhat You Will Do\nUse your data science expertise to build and productionize statistical learning models in areas of customer acquisition, LTV, retention and product engagement.\nWork with the marketing team to understand and help find actionable insights from the data to drive measurable improvements.\nWork with the product team to build solutions that empower our merchants.\nBuild pipelines to pull in new sources of data for your models in a way that is scalable and robust. Manage / debug previously written pipelines.\nBe a data story teller - communicate data insights and findings to stakeholders, both technical and non-technical.\nStrive to understand the nuances of the business and processes and become a trusted partner to your stakeholders.\nWhat We'd Like to See\n2 years+ experience building and productionizing predictive models with Python\nBackground in data mining and statistical analysis\nGood pattern recognition and predictive modeling skills\nComfort with a git-based workflow\nFluency with Python / Pandas and a deep desire to improve\nUnderstanding of probability, simulation, and statistical inference\nExperience writing SQL\nBonus Points For\nTime series modeling\nData visualization tools (especially Looker)\nColumnar databases (especially Redshift)\nDocument databases (especially ElasticSearch)\nPostgres\nApache Spark\nExperience with the AWS ecosystem\nBenefits\n\nWe provide the essentials...\nHealth, Life and Disability Benefits\nEmployee Assistance Program (EAP)\nGenerous Referral Bonus Program for Technology Roles\nFlexible Paid Time Off (PTO)\n401(k) Match\n...and the fun-damentals:\nLively and enriching Engineering culture\nRegularly scheduled hackathons, meetups and Tech Talks\nOpportunity to attend Engineering Conferences, thanks to our generous company conference budget\nNewsletters produced by Engineering teams\nCross-office collaboration between our NYC and Belfast teams with the opportunity to travel to our different offices\nRegular team events, including Happy Hours and Game Nights\nCatered lunches\nBreak area to play and relax\nStanding desks\nShopKeep is an Equal Opportunity Employer\n\nWe are an Equal Opportunities Employer. We don't discriminate based on gender, gender identity, sexual orientation, race, nationality, or any other individual characteristics. We practice equality of opportunity in employment and select the best person for the job.\n\nApplying\n\nWe like CVs, but links to your Github profile, your personal projects, your Twitter, your blog, your open source contributions, and so forth will give us a better idea of who you are.\nTo apply to this job, click Apply Now"}, "516": {"company": "Northrop Grumman", "description": "Are you interested in expanding your career through experience and exposure, all while supporting a mission that seeks to ensure the security of our nation and its allies? If so, then Northrop Grumman is the place for you. As a leading global security company, we provide innovative systems, products and solutions to our customers worldwide. We are comprised of diverse professionals that bring different perspectives and ideas, understanding that the more experiences we bring to our work the more innovative we can be. As we continue to build our workforce we look for people that exemplify our core values, leadership characteristics, and approach to innovation.\n\nNorthrop Grumman Corporation is seeking a Sr. Data Scientist to support the Office of the Deputy Undersecretary of the Army, Army Analytics Group's Research Facilitation Laboratory located in Monterey, CA.\n\nThe research team conducts advanced analytics and research support for U.S. Army and other DoD customers. The team works with administrative, personnel, survey, and medical data representing millions of individuals.\n\nProjects focus on health, resilience, and readiness among military service members, and include population-based studies, machine learning applications, measurement analysis, and pilot program evaluations.\n\nThe Data Scientist could support several projects.\n\nRole & Responsibilities:\n\nDevelop data mining and modeling plans; describe, explore, and verify data quality; select, clean, construct, integrate, and format data; select modeling techniques; generate training, testing, and validation designs; build and evaluate models; develop visualizations of model results.\n\nDevelop statistical models and methods to support predictive analytics to help senior leaders achieve and sustain individual readiness and optimize human performance.\n\nApply statistical, mathematical, and analytical techniques related to Health, Resilience, and Personal Readiness.\n\nProvide analysis and develop information papers, presentations, and other correspondence as required.\n\nPerform data consolidation, cleansing and analysis, and presents data from one or more source systems, cleansing and analysis, and presents data from one or more source systems.\n\n** This requisition may be filled at a higher grade based on qualifications listed below.\n\nBasic Qualifications:\n\nThis requisition may be filled at either a level 3 or a level 4.\n\nBasic Qualifications for a level 3 are:\nBachelors degree in a STEM related discipline, plus5 years applicable experience or a Master's with3 years experience applicable experience and/or a PhD with0 years experience; degree must be from an accredited college or university in Data Science, Statistics, Biostatistics, Applied Mathematics, Computer Science, Physics, Engineering, or other technical degree in a relevant field.\nBasic Qualifications for a level4 are:\nBachelors degree in a STEM related discipline, plus9 years applicable experience or a Master's with7 years experience applicable experience and/or a PhD with4 years experience; degree must be from an accredited college or university in Data Science, Statistics, Biostatistics, Applied Mathematics, Computer Science, Physics, Engineering, or other technical degree in a relevant field.\nThe Other Required Basic Qualifications Include:\nProficiency with data analysis\nExperience and proficiency with machine learning models, such as logistic regression, support vector machines, principal component analysis, clustering techniques (e.g., k-means, hierarchical), tree-based techniques, neural networks, and deep learning models.\nProficiency in Python\nSoftware Development Experience\nFamiliarity with databases and SQL.\nAbility to communicate results clearly and effectively.\nAbility to collaborate in a team environment.\nAbility to comprehend and analyze complex problems.\nU.S. Citizenship and the ability to obtain/maintain Department of Defense (DoD) Secret clearance is required.\nPreferred Qualifications:\n5+ years of experience and a Master's Degree in Data Science, Statistics, Biostatistics, Applied Mathematics, Computer Science, Physics, Engineering, or Psychology.\nDemonstrated experience in Deep Learning: DNN, CNN, RNNs (LSTM), GANs\nExperience in Natural Language Processing\nExperience working in anomaly or rare event detection.\nFamiliarity with developing data visualization products in tools such as Tableau.\nStrong data visualization skills.\nExperience working with DoD customers.\nExperience with operational machine learning pipelines\nExcellent written and oral communication.\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\nTo apply to this job, click Apply Now"}, "517": {"company": "Puget Sound Energy", "description": "Puget Sound Energy is looking to grow our community with like-minded, top talented individuals like you! With our rapidly growing, award winning energy efficiency programs, our pathway to an exciting and innovative future is now.\n\nPSE's Customer Solutions team is looking for qualified candidates to fill an open Senior Data Scientist position!\nJob Description\nThe Senior Data Scientist on the Customer Insights team works to attain the company\u2019s strategic goals via the extensive use of advanced analytics. He/she is responsible for the continuous improvement of PSE as an energy partner in the northwest through an analytical focus on customer experience.\n\nUpholds the safety compliance standards inherent in PSE\u2019s operating and/or field procedures related to work responsibilities. Promotes and supports a culture of total safety.\nJob Responsibilities\nDevelop predictive models, NLP models, customer segmentation schemas, etc. to drive personalized messaging and increase customer engagement.\nDevelop energy consumption models to help customers manage their usage and identify problems such as faulty meters or energy theft\nComplex data analysis to identify opportunities to improve our customer experience.\nDesign and analyze A/B and multi-variate tests.\nPerforms customer survey analytics/modeling and participates in survey design.\nProvides leadership for cross-functional projects and enterprise data and analytics solutions..\nEffectively communicates and collaborates across groups to provide insights to the organization.\nPerforms other duties as assigned.\nMinimum Qualifications\nBachelor\u2019s degree in mathematics, statistics, economics, finance or other relevant field.\n7 years experience in an analytic role using data and analysis to drive decision making.\nExperience applying quantitative methods and building production quality machine learning, deep learning, and/or NLP models.\nProficiency with Python or R.\nStrong working knowledge of SQL.\nExperience with visualization tools like Tableau or Power BI.\nAbility to synthesize large quantities of data and complex analyses into actionable information.\nA leader and collaborator who is comfortable in an environment where priorities and context change rapidly.\nDesired Qualifications\nGraduate degree in mathematics, statistics, economics or finance.\nData mining and management experience.\nExperience working with AWS and/or SAP HANA.\nExperience building end-to-end production machine learning or deep learning solutions.\nExperience working with customer and/or meter data.\nAdditional Information\n\nFamilies and businesses depend on PSE to provide the energy they need to pursue their dreams. Our steadfast commitment to serving Washington communities with safe, dependable and efficient energy started in 1873. Today we're building the Northwest's energy future through efforts like our award winning energy efficiency programs and our leadership in renewable energy.\n\nAt PSE we value and respect our employees and provide them opportunities to excel. We offer an expansive pay package that includes competitive compensation, annual goals-based incentive bonuses, comprehensive benefits, 401(K), a company paid retirement pension plan, and an employee assistance and wellness program.\n\nPuget Sound Energy is committed to providing equal employment opportunity to all qualified applicants. We do not discriminate on the basis of race, color, religion, sex, national origin, age, sexual orientation, gender identity, marital status, veteran status or presence of a disability that with or without reasonable accommodation does not prevent performance of the essential functions of the job. Should you have a disability that requires assistance and/or reasonable accommodation with the job application process, please contact the Human Resources Staffing department at jobs@pse.com or 425-462-3017.\n\nNearest Major Market: Seattle\nNearest Secondary Market: Bellevue\n\nApply Now: click Apply Now"}, "518": {"company": "Mathematica Policy Research", "description": "Position Description:\n\nMathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development.\n\nWe are looking for aData Scientist in our Washington DC office. Data scientists lead data processing and analysis tasks, such as monitoring data quality, developing documentation, applying statistical and data science methods, and creating data visualizations. Data scientists are expected to work on multi-disciplinary teams, overseeing and mentoring junior data scientists. The work of our data scientists supports our company's core offerings in program evaluation and data analytics, which yield crucial evidence and information for policy and decision makers.\n\nData scientists contribute throughout the course of a project on tasks such as the following:\nLeading multidisciplinary teams to answer research questions or build solutions that involve linking health or healthcare data (e.g., Medicare claims or HCUP) to other administrative data (e.g., Hospital Compare files)\nDesigning, planning, and overseeing the data science workflow on tasks and projects, involving descriptive statistics, machine learning or statistical analysis, data visualizations, and diagnostics using programming languages such as R or Python\nCommunicating results to collaborative project teams using data visualizations and presentations using tools such as Markdown (e.g., R Markdown), notebooks (e.g., Jupyter or Databricks), or interactive visualizations (e.g., R Shiny or Dash).\nDeveloping and implementing systems to ingest, process, and manage datasets\nDeveloping and maintaining documentation using Atlassian Confluence and Jira\nImplementing quality assurance practices such as version control and testing\nLeading or supporting proposal sections or applications\n\nPosition Requirements:\nDemonstrated enthusiasm for applying data science and statistics to social impact projects in academic, extra-curricular, and/or professional settings\nAn excellent academic record, including courses in subjects such as statistics, data science, math, computer science, and/or social science, and the following credentials:\nPhD, or 3+ years of experience in a social policy field post Masters or immersive bootcamp (e.g., Metis)\nMastery of R or Python to manipulate data, conduct analyses, and create data visualizations\nAbility and desire to work independently as part of remote, interdisciplinary teams\nAbility and desire to mentor junior data scientists and contribute to Mathematicas growing health data science community of 50+ staff\nAbility to version code using Git\nStrong oral and written communication skills.\nNice-to-have Skills:\n\nExperience with reproducible research principles, interactive visualizations, tidyverse, AWS, Google Cloud Platform, R Shiny, R Markdown, pandas, healthcare claims and administrative data (e.g., Medicare, Medicaid, electronic health records, all-payer claims databases, HCUP), and/or scikit-learn.\n\nPlease submit a cover letter, resume, and salary expectations. You will be asked to attach these materials during the online application process. Please click the \"Apply Now\" icon after the Position Description to attach your documents. Letter of recommendations not expected or required.\n\nMathematica offers our employees competitive salaries and a comprehensive benefits package, as well as the advantages of being 100 percent employee-owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the companys growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength.\n\nVarious federal agencies with whom we contract require that staff successfully undergo a background investigation or security clearance as a condition of working on the project. If you are assigned to such a project, you will be required to obtain the requisite security clearance.\n\nWe are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.\n\nStart your job application: click Apply Now"}, "519": {"company": "Seen by Indeed", "description": "Seen by Indeed is a free service that connects qualified job-seekers (that's you) with top companies hiring tech roles.\nWith one application you can be considered for thousands of tech roles from leading companies on Seen.\n\nHow Seen Works\nWe find out what's important to you and match you with your dream job\nGet started Complete a 5-minute application to be considered for roles at hundreds of leading companies\nGet matched Companies apply to you with opportunities that reflect your role, location and salary specifications\nGet career coaching Level up with free 1:1 coaching, our team will make sure you're ready to tackle any interview\nGet your dream job\nSkills and Requirements\nWe look for top tech talent to join the Seen platform. Each candidate is reviewed on the following to make sure you're a good fit for our network\n\nIn Demand Skills\nFrom strong communication skills to experience with the latest technologies, you have what employers are looking for\n\nStand Out Qualities\nYou bring unique qualities and traits that stand out and make an impact\n\nChange ready\nYou are ready for a career changes and will be responsive to employers who reach out with job opportunities\n\nGet matched with top tech companies on Seen!"}, "520": {"company": "Group O", "description": "Group O is seeking a strong candidate with the ability to design machine learning projects to address specific business problems determined by consultation with business partners to fill an exciting Data Scientist position, in the Chicago IL or Atlanta GA area for a Group O partner.\n\nResponsible for the development and implementation of machine learning algorithms and techniques to solve business problems and optimize member experiences. Primary duties may include are but not limited to: Design machine learning projects to address specific business problems determined by consultation with business partners. Work with data-sets of varying degrees of size and complexity including both structured and unstructured data. Piping and processing massive data-streams in distributed computing environments such as Hadoop to facilitate analysis. Implements batch and real-time model scoring to drive actions. Develops machine learning algorithms to build customized solutions that go beyond standard industry tools and lead to innovative solutions. Develop sophisticated visualization of analysis output for business users.\n\nBS/MA/MS/PhD in Statistics, Computer Science, Mathematics, Machine Learning, Econometrics, Physics, Biostatistics or related Quantitative disciplines. 5 years experience in predictive analytics and advanced expertise with software such as Python, or any combination of education and experience which would provide an equivalent background. Experience leading end-to-end data science project implementation. Experience in the health-care sector. Experience in Deep Learning strongly preferred.\nApply Now: click Apply Now"}, "521": {"company": "Esurance", "description": "Esurance combines the spunk of a startup with the backing of Allstate (the largest publicly held personal lines insurer in the U.S.) to create a unique, energized, and exciting place to work. We're a digital company powered by smart, innovative, caring people. And our success depends on our associates, who bring diverse perspectives and a sense of community to work with them every day. When we ask them what they love about working at Esurance, the answers are always the same. It's about team, culture, and community. That's life at Esurance!\nEsurance has created a centralized data science & analytics (DSA) group that is responsible for helping business units make objective decisions using data. And we\u2019re hiring a Lead Data Scientist in San Francisco, CA to join today! Our Data Science team supports the company\u2019s overall business operations by delivering critical analytical insights and in-depth consultative analyses to senior management teams and our business partners.\n\nWhat you\u2019ll do:\nAs a Lead Data Scientist you will lead a small team while taking a hands on approach within the Data Science Group. You will work within project teams to provide technical and analytical leadership, leading all aspects of the development of project deliverables including cross-functional program management, data gathering and manipulation, analysis and modelling, and communication of insights and recommendations. In this role, you will interact often with our Senior Leadership team through presentations of various project findings.\nTo be successful as a Lead Data Scientist at Esurance you will bring the following skills:\nGraduate degree in technical field (CS, Physics, Mathematics, Data Science, etc)\n5+ years post-graduate work experience\n5+ years of experience coding in a major programming language such as R or Python\n4+ years of experience applying machine learning techniques to solve business problems\nExperience with Hadoop ecosystem a strong plus\n\nEsurance offers an exciting total rewards package to include:\nBonus potential for all positions\nBenefits eligibility on day 1\n401k + company matching\nTuition reimbursement & student loan repayment program\nPet insurance discount\nGive time, get time volunteer program\nAnd much more!\nTo perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.\nApply Now: click Apply Now"}, "522": {"company": "United Airlines", "description": "We have a variety of career opportunities around the world - come find yours!\n\nOverview\n\nEngages in value added activities that generate practical solutions to complex business problems leveraging big data, explores and defines new business alternatives, and drives improvement in business decisions through innovations, research & development, and product knowledge. In addition, must have in-depth subject matter and professional expertise as well as thorough knowledge of the business tools and systems which render judgment and professional opinion an essential component of the job.\n\nMeet the CIEO team:\n\nhttps://www.youtube.com/watch?v=PfMzLZsHPfk\n\nResponsibilities\nInvestigates and identifies patterns in big data to generate business insights\nResponsible for sourcing data leveraging their expertise for product enhancements, and/or research & development activities as part of a team, with an orientation to generating practical business s insights, solutions and delivering value\nLeverages in-depth knowledge of business data/systems and understanding of the business process to identify and implement solutions and influences business processes that will result in significant bottom-line contributions and/or efficiency improvements\nStays abreast of changing business trends, data sources, and tools and enables the company in staying ahead of its competition\nSets short-term direction for research efforts and/or analyses\nDesigns and/or implements analysis to drive critical financial, operational, and/or strategic decisions\nDrives management decisions through descriptive and inquisitive data analytics using tools such as SAS, machine learning, BI tools, and/or other data extraction tools\nDesigns and develops predictive and prescriptive models for several efforts, and interfaces with client organizations and IT\nSome communication and presentation to organization leaders are required, with emphasis on data visualization skill, quality, and timeliness\nShare accountability for training other staff professionals within the organization. Mentor individuals for acquiring and/or maintaining the technical skills for which scientist can serve as the subject matter expert\nDevelops and delivers presentations aligned with CIEO standards\nRequired\nBS in a quantitative field such as Engineering, Operations Research, Statistics, or a related quantitative field\n6+ years (or 4.5+ years if MS in a quantitative field or 3+ years if PhD in a quantitative field) of airline or related business experience at successive levels in analytical fields solving complex business problems\n3+ years of in-depth experience in data modeling through use of statistical/machine learning toolkits such as SAS, R, Python, JMP, and Minitab, and/or BI tools like Spotfire and Tableau\n2+ years of demonstrated ability in innovation to create business value through data mining, data analytics, predictive modeling, information retrieval, machine learning and/or artificial intelligence techniques\nAdvanced quantitative skills, subject matter knowledge and data source expertise in at least one business area, good business technical communication, verbal/written communication, and presentation and sales skills\nAdaptability to changing business environment\nGood interpersonal skills and ability to interact with clients at all levels and influence business strategy\nStays abreast of changing industry trends and enable the company in staying ahead of its competition\nSuccessful completion of interview required to meet job qualifications\nReliable, punctual attendance is an essential function of the position\nPreferred\nAdvanced degree (MS, PhD, or equivalent) in quantitative field\n1+ years of airline business experience\nKnowledge of United/industry data sources\nExisting productive connections with academia to keep abreast of new developments\n\n\nEqual Opportunity Employer \u2013 Minorities/Women/Veterans/Disabled/LGBT\nTo apply to this job, click Apply Now"}, "523": {"company": "Raybeam", "description": "*If you are interested in the position please click on the link to begin the application process.*\nhttp://careerseval.raybeam.com\nWho are we? Raybeam Inc. is a consulting company focused building engineering and data solutions spanning business intelligence, brand and direct marketing, customer engagement for over twenty years in Silicon Valley and beyond. We have offices near Boston and San Francisco and support a strong list of clients including Google, Facebook, Microsoft, eBay, Disney and Hilton Worldwide.\nWhat do we do? We provide technology solutions by architecting and developing enterprise systems using a variety of programming languages, tools and platforms. This can range from building data warehouses, to web applications to implementing reporting platforms. We work in small teams, own the projects that we work on, and have direct input into the business decisions of our clients.\nWhat we\u2019d like to see in you:\nExperience in, design and build innovative data solutions, from discovery to delivery for clients and external stakeholders\nTranslate business problems to an analytics problem, recommending and applying the most appropriate methods to yield insights and results\nLeading sessions and meetings to drive analytics roadmap, long-term strategy with quarterly milestones and outlook\nProvide mentorship and guidance to teams of analyst; inspire innovative thinking in the analytics space\nRequirements:\n5-8 years of industry experience leading analytics projects\nExperience with customer and user tracking on web and mobile app\nExperience in applied analytics in space of sales, finance, marketing, or product engineering; track record of success\nFamiliarity with cloud platforms such as Google Cloud Platform, Microsoft Azure, AWS, IBM Cloud to use/deploy analytics resources\nStrong working knowledge of SQL and architecting relational databases. NoSQL is a plus\nProficient in at least one or other language for applied to statistics, data analysis, or machine learning - Python, R, Matlab, SPSS\nWhat do you get from working for Raybeam?\nThe opportunity to work for a variety of Fortune 500 companies.\nExcellent resume builder due to the exposure to a variety of technologies and experiences.\nThe chance to have input into business decisions of our clients.\nA fun, supportive work environment that promotes camaraderie and growth.\nThe chance to travel and network with important figures in the industry.\nThe opportunity to learn technologies that you\u2019ve always wanted but never had the chance.\nWe have fantastic benefits including competitive pay, fully paid health insurance (including vision), free daily lunch, 401k contribution, long term disability insurance, flexible schedule, annual company outing, generous vacation/sick time, holidays and more!\n\nTo apply please follow the link below to take a short 10 minute phase one data analyst quiz and then send a follow up cover letter to raybeam-hr@raybeam.com explaining why you would be a good fit for the role. Thank you!\nStart your job application: click Easy Apply"}, "524": {"company": "American Axle & Manufacturing", "description": "We are AAM. We have the POWER to move the world.\n\nAt AAM, we're looking for associates who push boundaries and drive solutions for the future. Innovators. Thinkers. Dreamers. Doers. No matter the role or function, every associate is a piece of what makes AAM great. Were growing and building #TeamAAM to be the best. Join us!\n\nJob Posting Title\n\nSenior Data Scientist\n\nJob Description Summary\n\nWe are looking for a Senior Data Scientist that will help us discover the information hidden in vast amounts of data and help us support our business. Your primary focus will be in applying data mining/statistical techniques, creating patterns and predictions. Ensuring validity of data using statistical languages to develop and launch descriptive, Predictive and prescriptive analysis. Work closely with the business to understand business needs.\n\nJob Description\nPerform Operational Support.\nWork on Major Projects and Responsible for Deliverables.\nData mining using state-of-the-art methods\nStrong skill in critical thinking\nExpert in AWS service and components (S3, EMR, EC2, Lambda, Kafka, green grass)\nProcessing, cleansing, and verifying the integrity of data used for analysis\nDoing ad-hoc analysis and presenting results in a clear manner\nExperience in IoT solutions\nEnhancing data collection procedures to include information that is relevant for building analytic systems\nMaster of Python, R, and SQL languages\nExtensive experience writing algorithms, statistical models, and predictions.\nModel creation using Python\nData visualization using MS Power BI, R Shiny\nExpert in classification, regression, clustering, anomaly detection, decision tree, Na\u00efve Bayes, Support Vector Machines\nWork with business users to conduct user acceptance testing.\nAll other duties as assigned.\nRequired Skills and Education\nBachelors Degree (Computer Science, Statistics, and Mathematics)\n5 years relevant experience\nPython, R Programming, R Shiny\nExpert in creating/modifying statistical data models\nExpert in Data Science - Experience creating Statistical Algorithms like Random Forest, Logistic regression, Na\u00efve Bayes, SVM etc.\nBig data ecosystem. (Impala, Spark, Hive, SQOOP etc)\nExpert in Microsoft Power BI Dashboards and reports\nExpert in creating statistical models to do real time machine learning.\nSQL expert\nGood understanding of ETL systems\nExpert in Data Science - Experience creating Statistical Algorithms like Random Forest, Logistic regression, Na\u00efve Bayes, SVM etc.\nBig data ecosystem. (Impala, Spark, Hive, SQOOP etc)\nExpert in Microsoft Power BI Dashboards and reports\nExpert in creating statistical models to do real time machine learning.\nSQL expert\nAbout American Axle & Manufacturing\n\nFor over 20 years, customers around the world have entrusted AAM to design, engineer, validate and manufacture driveline, metal forming, powertrain, and casting technologies for automotive, commercial and industrial markets. Today, we are a premier global Tier 1 automotive supplier with broad capabilities across multiple product lines to deliver efficient, powerful and innovative solutions for our customers. Weve earned the trust of our suppliers and our customers through our steadfast commitments to quality, operational excellence and technology leadership.\n\nAAM delivers power. We deliver power literally through vehicle components, systems and innovation, but we also deliver power in ways unseen. We power our associates, their families, and the communities in which we operate. Our global team of over 25,000 associates has a clear vision of where AAM is going and how we are going to get there. After all, they are the reason we are a leader in the automotive industry. We are powering the future. We are AAM. Move with us, and join #TeamAAM.\n\nAAM will not discriminate against any Associate or applicant for employment because of age, race, color, gender, religion, weight, height, marital status, sexual orientation, genetic history or information, gender identity or expression, disability, protected veteran status, national origin, or other characteristic protected by law. AAM will take affirmative action to ensure that applicants are employed, and that Associates are treated equally during employment, without regard to their age, race, color, gender, religion, weight, height, marital status, sexual orientation, genetic history or information, gender identity or expression, disability, protected veteran status, national origin, or other characteristic protected by law. For the Disabled Job Seeker: We offer reasonable accommodations for qualified disabled individuals who are applicants for employment. To request assistance or accommodations, please e-mail aamhr@aam.com . AAM is an equal opportunity/affirmative action employer.\nTo apply to this job, click Apply Now"}, "525": {"company": "Kraken Digital Asset Exchange", "description": "About Kraken\n\nOur mission is to accelerate the adoption of cryptocurrency so that you and the rest of the world can achieve financial freedom and inclusion. Founded in 2011 and with over 4 million clients, Kraken is one of the world's largest, most successful bitcoin exchanges and we're growing faster than ever. Our range of successful products are playing an important role in the mainstream adoption of crypto assets. We attract people who constantly push themselves to think differently and chart exciting new paths in a rapidly growing industry. Kraken is a diverse group of dreamers and doers who see value in being radically transparent. Let's change the way the world thinks about money! Join the revolution!\n\nAbout the role:\n\nThis role is San Francisco based but can also be remote.\n\nWe are looking for a data scientist who is innovative, highly-motivated, and proactive.\nFor this role, you will be part of a team that builds cutting-edge trading products in the cryptocurrency industry. You will be responsible for transforming data and generating actionable insights into our customer behavior and measuring the performance of our trading engine. You will collaborate and lead projects with product management, engineering, marketing, and growth teams. You will transform data from complex systems, generate performance metrics, and share the results with stakeholders at all levels of the company.\nGreat benefits, amazing perks, remote work and travel opportunities, stock incentives, beautiful HQ office, and a flexible PTO policy make Kraken a great place to work. If you value having a seat at the table and want to make a big impact on guiding the direction of marketing and growth at one of the top crypto exchanges in the world, this role is for you.\nRequirements\nA degree in Statistics, Computer Science, Physical Sciences, Economics, Math or a related technical field.\n5+ years industry experience in data science or analytics\nA consistent track record of performing data analysis using Python, R, and/or SQL\nExperience using statistics and predictive analytics to solve complex business problems.\nThe versatility and willingness to learn new technologies on the job.\nThe ability to clearly communicate complex results to technical and non-technical audiences.\nFamiliarity with other data tools such as Hive, Vertica, Tableau & Ruby is a plus\nResponsibilities\nPartner with Kraken\u2019s engineering, marketing, product, and finance teams to identify, prioritize, and answer the most important questions where analytics and modeling will have a material impact.\nDrive cross functional analytic projects from beginning to end: build relationships with partner teams, frame and structure questions, collect and analyze data, summarize and present key insights in support of decision making.\nWork with engineers to evangelize data best practices and implement analytics solutions.\nCollaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models.\nCommunicate key results with self-serve tools (dashboards, analytics tools) for leadership and product management.\nDevelop anomaly detection, and data modelling tools to monitor key performance indicators to improve the efficiency of the products.\nDesign experiments for product teams to test hypothesis and help with idea generation and refinement.\nBuild key datasets and data pipelines using Python/ETL frameworks.\nWe\u2019re powered by people from around the world with their own unique backgrounds and experiences. We value all Krakenites and their talents, contributions, and perspectives.\n\nCheck out all our open roles at https://jobs.lever.co/kraken. We\u2019re excited to see what you\u2019re made of.\n\nLearn more about us:\n\nWatch \"Working at Kraken\"\nFollow us on Twitter\nCatch up on our blog\nTo apply to this job, click Apply Now"}, "526": {"company": "Ancestry", "description": "About Ancestry:\nWhen you join Ancestry, you join our family tree. Backed by history, science, and technology, were creating a new world of connection, innovation, and understanding. Whether its reuniting long-lost relatives through DNA or unearthing new family stories from historical records, Ancestry empowers life-changing experiences. With over 20 billion digitized historical records, 100 million family trees, and 15+ million DNA kits sold, Ancestry is bringing the power of personal discovery to people around the world.\n\nAncestry is looking for a highly motivated Data Scientists to join our Data Science Discovery team in San Francisco.\n\nYou will be a member of the global Data Science & Machine Learning Team, tackling our toughest and most exciting data science challenges. Ancestry's Data Science team has a wide reach across the company, working with Product, Science, and Marketing teams. We find ways to provide new and meaningful discoveries to our customers. We build machine learning models to improve our content or create new content that unlock stories for Ancestry customers.\nAs a Data Scientist on the Data Science Discovery team, you will be involved in the end to end process of data acquisition, data cleaning, model building, and model testing. You will help our users to find their ancestors and discover interesting family history events. You will utilize cutting edge machine learning algorithms and statistical analysis techniques to provide personalized discovery experience to our users.\nWhat You Will Do\nMachine learning for recommender systems and personalization\nDeep learning for natural language processing\nRanking algorithms for search and recommendation\nFeature engineering for people, family, records, photos and more\nNLP for query and document analysis, processing and understanding at a large scale\nRanking result evaluation and analysis\nWho You Are\nYou have either a PhD in a relevant field, such as recommendation systems, machine learning, deep learning, NLP or search OR a Masters plus one year of full-time industry experience\nYou have strong modeling skills in Python or R and a solid understanding of core CS algorithms and coding skills in Python, Java or C/C++\nBig Bonus Points For\nExperience with Big data, such as Hadoop/Hbase/Pig/Hive is a plus\nExperience with Solr/Elasticsearch is a plus\nExperience with Spark is a plus\nAdditional Information:\nAncestry is an Equal Opportunity Employer that makes employment decisions without regard to race, color, religious creed, national origin, ancestry, sex, pregnancy, sexual orientation, gender, gender identity, gender expression, age, mental or physical disability, medical condition, military or veteran status, citizenship, marital status, genetic information, or any other characteristic protected by applicable law. In addition, Ancestry will provide reasonable accommodations for qualified individuals with disabilities.\n\nAll job offers are contingent on a background check screen that complies with applicable law. For San Francisco office candidates, pursuant to the San Francisco Fair Chance Ordinance, Ancestry will consider for employment qualified applicants with arrest and conviction records.\n\nAncestry is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Ancestry via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Ancestry. No fee will be paid in the event the candidate is hired by Ancestry as a result of the referral or through other means\n\nTo apply to this job, click Apply Now"}, "527": {"company": "Stripe", "description": "Generate insights and impact from data.\n\nWe're looking for data scientists to join the Analytics team who are excited about applying their analytical skills to understand our users and influence decision making. If you are naturally data curious, excited about deriving insights from data, and motivated by having impact on the business, we want to hear from you.\n\nYou will:\nWork closely with product and business teams to identify important questions and answer them with data.\n\nApply statistical and econometric models on large datasets to: i) measure results and outcomes, ii) identify causal impact and attribution, iii) predict future performance of users or products.\n\nDesign, analyze, and interpret the results of experiments.\n\nDrive the collection of new data and the refinement of existing data sources.\n\nCreate analyses that tell a \"story\" focused on insights, not just data.\n\nWe're looking for someone with:\n3+ years experience working with and analyzing large data sets to solve problems.\n\nA PhD or MS in a quantitative field (e.g., Economics, Statistics, Eng, Natural Sciences, CS).\n\nExpert knowledge of a scientific computing language (such as R or Python) and SQL.\n\nStrong knowledge of statistics and experimental design.\n\nAbility to communicate results clearly and a focus on driving impact.\n\nNice to haves:\nPrior experience with data-distributed tools (Scalding, Hadoop, Pig, etc).\n\nYou should include these in your application:\nResume and LinkedIn profile.\n\nDescription of the most interesting data analysis you've done, key findings, and its impact.\n\nLink to or attachment of code you've written related to data analysis.\n\nTo apply to this job, click Apply Now"}, "528": {"company": "Smartsheet", "description": "Smartsheet is looking for an experienced Data Scientist to help drive analyses, generate insights, and influence decision making. With thousands of subscribing organizations and millions of users there is lots of opportunity to make meaningful impact and drive growth through analytics within Smartsheet. The ideal candidate is intellectually curious, has strong analytical skills and has the ability to communicate key insights effectively. This individual will work closely with departments across the company and will be a part of a highly efficient and results oriented Business Intelligence team. This full time position reports to the Data Science Manager and is based in Smartsheet's corporate offices in Bellevue, WA.\n\nResponsibilities:\nMine large datasets and draw actionable insights\nPresent discoveries and insights to line of business teams and give recommendations to encourage data-driven decision making\nPartner with cross functional teams across Marketing, Sales, Product Management, Engineering in operationalizing the initiatives\nIdentify areas for further investigation\nRequirements:\nBA/BS in Computer Science, Mathematics, Operations Research, Physics, or other technical field. Advanced degree preferred but not required\n3+ years of experience in quantitative analysis, combined with strong business judgment and an ability to present analysis in a clear and compelling manner\nProficient in implementing various statistical models and data mining tools (predictive modeling, clustering, logistic regression, multivariate regression, decision trees, neural networks)\nHands on experience in executing analysis using tools such as SQL, R, Python, Excel, Tableau and Google Analytics.\nAbility to research and learn new technologies, tools, and platforms\nAbility to draw conclusions from data and recommend actions\nAbility to thrive in an unstructured environment, working autonomously on a strong team to find opportunity and deliver business impact\nA self-starters who can, with minimal guidance, drive projects from concept through completion\nFocus to make quick strikes, iterate, and produce in high volume\nSmarts to pick up new concepts at light speed\nAgility to quickly adjust priorities and shift direction\nFlexibility to contribute to other projects as required\nAbout Smartsheet\n\nIn 2005, Smartsheet was founded on the idea that teams and millions of people worldwide deserve a better way to deliver their very best work. Today, the company delivers a leading cloud-based platform for work execution, empowering organizations to plan, capture, track, automate, and report on work at scale, resulting in more efficient processes and better business outcomes. Smartsheet went public on the New York Stock Exchange in April 2018 and currently enables collaboration, better decision making, and accelerated innovation for over 76,000 domain-based customers in 190 countries, including 96 of the Fortune 100.\n\nSmartsheet is an Equal Opportunity Employer. Individuals seeking employment at Smartsheet are considered without regard to race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, citizenship status, or any other legally protected category.\nStart your job application: click Apply Now"}, "529": {"company": "Blink Health", "description": "Blink Health is a well-funded healthcare technology company on a mission to make prescription drugs more accessible and affordable for everyone. We're scaling up in a highly complex vertical to change the way Americans access the prescription drugs they need.\n\nOur proprietary platform and supply chain allows us to offer everyone whether they have insurance or not amazingly inexpensive prices on over 15,000 medications. With the addition of telemedicine and home delivery for prescriptions, Blink is providing a life-changing experience for people all over the country and fixing how opaque, unfair and overpriced healthcare has become. We are a highly collaborative team of builders and operators who invent new ways of working in an industry that historically has resisted innovation. Join us!\n\nSuccess:\n\nThe Data and Analytics team is a small team building the Big Data infrastructure at Blink; responsible for architecting and building infrastructure, frameworks and tooling to enable data driven decisions in addition to developing reports, dashboards, and metrics to provide accurate and timely information. The team also supports various product and business groups with recommendation and in-depth analyses. Our data platforms are built using tools available on AWS including Redshift, Data Pipeline, Spark, Looker.\n\nAs a data scientist, you will be a thought leader within the analytics team designing and building our metrics framework, and evolving it as we grow. You will work closely with engineers and business stakeholders across the company, developing and maintaining key performance and insight reports that help product teams and leadership make decisions on products and services. You will set a high bar for owning performance metrics ideation, creation, and enhancements.\n\nHow to achieve success/acumen:\n\nAll Blinkers are expected to operate with our value of \"Good Giving\" in mind. Our culture is infused with the dedication and enthusiasm of employees who continuously strive to make a difference. Here's how you will do that in this role.\n\nGood Execution - Do your best work\n\nDo your best work by investigating, designing, and building high quality analytics metrics and frameworks. Maintain and optimize analytics as needs evolve, and work with multiple internal customers to define models, then train and support your customers to self-service on analytics tools.\n\nGood Owner - Be the CEO of your role\n\nBe the CEO of your role through helping teams ship new products and features successfully with the right information to understand how to serve our customers; taking responsibility for the long term success of products, projects, and people.\n\nGood Learning - Learn something new every day\n\nLearn something new every day through leading by example to put new ideas into action, being willing to fail fast and learn. Demonstrate interest in learning new techniques and developing best practices.\n\nGood Feedback - Consider the perspective of others\n\nConsider the perspective of others by listening actively and responding effectively through a variety of channels. Give and receive candid and constructive feedback. Promote trust and encourage teamwork allow the teams to do their best work with you.\n\nRequired Experience:\n5+ years experience having worked in an analytics role. Experience in scripting with SQL, extracting large sets of data, and designing KPIs.\n3+ years experience working with analytics platforms such as Looker, QuickSight, Tableau to create new analytics capabilities.\nDemonstrated versatility in working with different types of data and data models: financial, digital marketing, transactional e-commerce, event-level product data, etc.\nDemonstrated expertise in SQL with a track record of designing and building product analytics.\nDemonstrated expertise at communicating effectively with other engineers, designers, product managers, and leaders, with collaborative examples on creating top-tier analytics solutions.\nBA/BS or Master's degree in a quantitative field such as; Statistics, Computer Science, Engineering, Mathematics, Data Sciences.\nExcellent written and verbal communication skills.\nDesired Experience:\nHealthcare-relevant company experience as part of the required experience above, with demonstrated industry knowledge of handling sensitive information.\nWhy Join Us:\n\n\nAt Blink, we put humans first. We want everyone at Blink to be able to do the best work of their lives. We are a relentlessly learning, constantly curious and aggressively collaborative cross-functional team dedicated to inventing new ways to improve the lives of our customers.\n\nLearn more:\nBlink Website\nBlink Pharmacy App for Android\nBlink Pharmacy App for iOS\n\nWe are an equal opportunity employer and value diversity of all kinds. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nStart your job application: click Easy Apply"}, "530": {"company": "Northwestern Mutual Life Insurance Company", "description": "At Northwestern Mutual, we are strong, innovative and growing. We invest in our people. We care and make a positive difference.\n\nAre you interested in leveraging your data science skills to help derive data driven insights that are used to inform our company strategy? Are you looking for a role that combines data science skills with an opportunity to gain big picture knowledge of NM\u2019s business?\n\nCorporate Strategy is looking for a Data Scientist to deliver insights and provide data driven decision support for key initiatives of company strategy and measurement related to client and sales analyses to understand both growth and economic impact.\n\nThe Team:\n\nThe Strategic Intelligence Team in Corporate Strategy is an advanced analytics team that works with senior leaders to inform company strategies and decision-making through an objective viewpoint by leveraging the team\u2019s expertise in Client-Product-Field data, deep NM business knowledge, and utilizing statistical and advanced analytical techniques as appropriate.\n\nThe Role:\nUse advanced statistical and analytical techniques to inform highly complex and sophisticated business questions\nCombine deep business expertise with advanced statistical modeling and analysis skills to discover and identify new insights, predict and prescribe outcomes, turn new insights into actionable opportunities, and provide the tracking and measurement of results.\nPerform data driven research, utilizing quantitative techniques, through a variety of analytical tools.\nTell a story with data \u2013 Share insights, findings, and implications with stakeholders via interactive presentations, visualizations, and written communications.\nExamples of the types of Analytical Research projects you may work on:\nDrivers of Permanent Life Insurance Sales growth and incremental sales measurement impact across Permanent Life Insurance growth initiatives.\nAnalysis of Financial Advisor productivity to measure/assess the cumulative impact on Financial Advisor productivity across several initiatives designed to drive productivity growth\nAnalyze the impact of planning across both client behaviors (product, policy size, and purchase behaviors) as well as impact to Financial Advisor practices (activity, lives, etc.)\nThe Work:\nBe at the forefront of Analytical Research and Development at NM, leveraging data-based insights & decision support, to guide senior business partners in the activation of data driven insights and opportunities\nProvides data driven decision support for key initiatives of company strategy and measurement related to client and sales analyses to understand both growth and economic impact.\nTests new insights and hypothesis through tracking & measurement of a specific opportunity\nDetermines requisite data elements and partners with data engineers to design integrated datasets for analytical research purposes.\nDevelop solutions, mathematical models, algorithms, machine learning techniques, and robust analytics to support analytic insights and visualization\nIdentifies opportunities to enhance the team\u2019s analytical capabilities by evaluating current processes, working with business partners, and taking initiative to apply new and improved approaches.\nPerforms diagnostic and prescriptive analysis, derives new findings and insights, and highlights business implications in presentations to stakeholders.\nThe Desired Skills:\nBachelor\u2019s degree in data science, statistics, math, computer science, economics, or related field.\nPreferred: Advanced graduate level degree in a quantitative discipline (statistics, applied mathematics, computer science, econometrics, or related field)\n5+ years relevant experience to include research and data analysis, experiment design and measurement, or application of statistical research techniques.\nExpertise in one or more development or statistical analysis tool such as R, SAS, SQL, SPSS, or other tools. Tableau experience is a plus.\nProven excellence in research, quantitative analysis, problem solving, and analytical working techniques.\nStatistical knowledge and intuition\nStrong aptitude and desire for learning new analytical and visualization tools, modeling, and quantitative techniques.\nInitiative to independently design and develop own deliverables while still being a team player. Demonstrated ability to deliver results and recommendations in written, verbal and presentation form at an appropriate level for a business audience.\nDesirable qualifications: Experience in financial service industry\nGrow your career with a best-in-class company that puts our client\u2019s interests at the center of all we do. Get started now!\n\nWe are an equal opportunity/affirmative action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity or expression, sexual orientation, national origin, disability, age or status as a protected veteran, or any other characteristic protected by law.\n\nReq ID: 27195\nPosition Type: Regular Full Time\nEducation Experience: Bachelor's Desired\nEmployment Experience: 6-8 years\nLicenses/Certifications:\nFLSA Status: Exempt\nPosting Date: 11/25/2019\nStart your job application: click Apply Now"}, "531": {"company": "Amyris", "description": "Amyris has developed a high-throughput genetic engineering platform for designing and building custom microbes to serve as living factories. Using an industrial scale fermentation process, our microbes convert cheap sugars into a wide variety of high-value target molecules. Our end products directly impact millions of lives. We are pragmatic idealists seeking a profitable way to make the world a better place. We are convinced synthetic biology is here to stay and will have a major positive impact on our planet and everyday life.\n\nWithin Amyris R&D, we are searching for a highly energetic, curious, and self-motivated scientist with a strong background in statistics, computing and biology to join our Computational Biology team. Research at Amyris is a highly multidisciplinary effort that needs brilliant contributions from life sciences and engineering disciplines in order to take projects from concept to market. From hacking directly on DNA in the lab to full scale factory production, every aspect of our work is facilitated and accelerated by quantitative science and software & hardware automation. The Computational Biology team works hand-in-hand with bench scientists and builds tools that enable genome engineering, protein engineering, metabolic modeling, omics experiment analysis, and statistical design of experiments in pursuit of making better microbial strains. In short, we help accelerate the design-build-test-analyze cycle in synthetic biology.\nResponsibilities\nIteratively develop computational algorithms, analysis and visualization tools to meet evolving scientific needs and to aid rapid data-driven decision making. Data types include: genotype (NGS), phenotype (metabolomics, proteomics, GC/MS, spectroscopy, fermentation), material flow\nBuild version-controlled, computable workflows to analyze rich, high-throughput phenotype data\nInteract closely with biology, analytical chemistry, and fermentation scientists\nCollaborate with automation engineers and software developers of in-house enterprise systems to mine experimental data and metadata\nRequired Qualifications\nDegree in quantitative discipline such as computer science, mathematics, computational biology, electrical engineering, bioengineering. For the Data Scientist role: Ph.D. plus 1-3 years experience, or M.S. plus 6 years experience. Experience managing a team required for the Senior Data Scientist role.\nAt least three years experience in analyzing & visualizing large scientific datasets representing biological & chemical phenotypes\nUndergraduate-level understanding of biology: genetics, cell physiology, biochemistry, evolution\nIndustrial programming experience, i.e. having written or maintained large codebase using software best practices (e.g. unit tests) and distributed version control\nExpert coder in Python\nKnowledge of machine learning frameworks\nOutstanding communication and interpersonal skills\nAbility to thrive in a fast-paced yet intellectually rigorous environment\nCreativity, independent thinking, and passion\nExperience with the following a plus\nBackground in mass spectrometry informatics, HTS, spectrophotometry, or industrial fermentation\nExperience in a microbiology or synthetic biology setting\n#LI-RJ1\n\nAmyris, a leader in industrial synthetic biology, uses its innovative bioscience solutions to achieve renewable products by converting plant sugars into hydrocarbon molecules. Amyris\u2019 molecules are used in wide range of specialty & performance chemicals, flavors & fragrances and in applications ranging from cosmetics to biofuels. Learn more at www.amyris.com.\n\nAs a VEVRAA Federal Contractor, Amyris is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. Amyris complies with applicable state and local laws governing nondiscrimination in employment.\n\nIf you are a recruiter or placement agency, please do not submit resumes to any person or email address at Amyris, Inc. prior to having a signed agreement. Amyris is not liable for and will not pay placement fees for candidates submitted by any agency other than its approved recruitment partners. Furthermore, any resumes sent to us without an agreement in place will be considered your company\u2019s gift to Amyris and may be forwarded to our recruiters for their attention.\n\nFor a full list of our current openings, please visit our website at www.amyris.com.\nTo apply to this job, click Apply Now"}, "532": {"company": "Niantic", "description": "Do you want to help connect people all over the world, and work on a team building the next generation of planet scale, real world AR games? We're looking for hardworking people to help our company become more data focused. Folks with the ability to be dedicated, thorough, and independent but also to work effectively in a collaborative, fast-paced environment.\n\nResponsibilities\nTranslate quantitative findings in concise and clear messages to leadership and external partners.\nEmbedded within a product you are the data guru responsible for setting and monitoring the targets, diagnosing problems, quantifying the impact, and coming up with solutions.\nResponsible for defining analytics requirements for new & evolving products.\nHave a product-first mindset that aligns with our mission, values and strategy.\nDrive consensus; independently deliver data insights to drive decisions to cross functional teams.\nBe a hands-on, self-starter and help the company make evidence based decisions.\nQualifications\nExpert level SQL experience; deep experience with statistical packages such as Python or R.\nDeep understanding of statistics and data analytics concepts, especially with regression and time series data.\nExperience with data visualization to help communicate the significance of data to others in the organization.\nKnowledge and experience with A/B testing or randomized control trials.\nBA/BS in statistics, applied mathematics, economics, computer science, machine learning or related field.\nGraduate degree in relevant fields preferred but not required.\n3-5+ years of work experience in data science or analytics role.\nExperience working on one or more launched products.\nJoin the Niantic team!\n\n\nNiantic is the world's leading AR technology company, sparking creative and engaging journeys in the real world. Our products inspire outdoor exploration, exercise, and meaningful social interaction.\n\nOriginally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok\u00e9mon Company, and Alsop Louie Partners. Our current titles include pioneering global-control game Ingress, record-breaking AR game Pok\u00e9mon GO, and recently released third title, Harry Potter: Wizards Unite.\n\nNiantic is an Equal Opportunity and Affirmative Action employer. We believe that cultivating a workplace where our people are supported and included is essential to creating great products our community will love. Our mission emphasizes seeking and hiring diverse voices, including those who are traditionally underrepresented in the technology industry, and we consider this to be one of the most important values we hold close.\n\nWe're a hard-working, fun, and exciting group who value intellectual curiosity and a passion for problem-solving! We have growing offices located in San Francisco, Sunnyvale, Bellevue, Los Angeles, London, Tokyo, Hamburg, and Zurich.\nTo apply to this job, click Easy Apply"}, "533": {"company": "Alarm.com", "description": "Position Overview:\n\nAre you passionate about solving complex puzzles and problems? Do you get excited by extreme data sets and analyzing data from the Internet of Things? Alarm.com is a rapidly expanding, entrepreneurial technology company that is seeking an ambitious, hardworking, expereince Data Scientist to help build and maintain large-scale statistical models that turn billions of data points into insights and actions. Few companies innovate across as broad of a range of technologies as Alarm.com. This position is ideal for the candidate who seeks a team-oriented, friendly company culture where one can work closely with smart and productive people.\n\nResponsibilities:\nProposes and evaluates innovative solutions for analyzing, clustering, associating, and classifying data.\nDevelops and validates algorithms via analysis, computer simulation, and prototyping\nExtends analytics platform for connected devices and sensors.\nWrites and debugs production code that spans the vertical from database to computational layer to web service\nWorks with QA team to identify and cover every edge case imaginable.\nHelps maintain large-scale analytics infrastructure, including distributed storage and computation clusters\nRequirements:\nBachelor's Degree; Mathematics, Statistics, Data Science, or other related fields, Master's is a plus\n4+ years of experience required\nExpertise in machine learning, statistics, control theory, computational modeling, or finance\nExperience in SQL and familiarity with other programming languages. Some development experience in at least one scripting language (PHP, Python, Perl, etc.)\nExperience with business intelligence tools (MicroStrategy, Tableau, Qlik, BOBJ, Cognos) and statistical packages in R, Python, etc.\nUnderstanding of Data Management and the data lifecycle\nExcellent written/oral communication and interpersonal skills\nStrong problem solving skills\nAn interest in technology\nCOMPANY INFO\n\nAlarm.com is the leading cloud-based platform for smart security and the Internet of Things. More than 6 million home and business owners depend on our solutions every day to make their properties safer, smarter, and more efficient. And every day, we're innovating new technologies in rapidly evolving spaces including AI, video analytics, facial recognition, machine learning, energy analytics, and more. Alarm.com earned the Top Workplace award for our employee culture and the meaningful work we do to give property owners peace of mind, help them conserve energy and water, and stay connected to loved ones. We're seeking those who are passionate about creating change through technology and who want to make a lasting impact on the world around them.\n\nCOMPANY BENEFITS\nAlarm.com offers competitive pay and benefits including a wide choice of healthcare options with generous company subsidy, a health savings account option with company contribution, 401(k) with employer match, paid holidays and paid time off increasing with tenure, paid maternity and paternity leave, company paid STD/LTD and life insurance, flexible spending accounts, and a casual dress work environment.\n\nAlarm.com is an Equal Opportunity Employer\nStart your job application: click Easy Apply"}, "534": {"company": "Telaria", "description": "What We're About\n\nTelaria (NYSE: TLRA), (formerly Tremor Video), is the leading independent data-driven software platform built to monetize and manage premium video inventory with the greatest speed, control, and transparency, wherever and however audiences are watching.\n\nWe are looking to leverage our vast amounts of advertising data to make informed decisions around business optimizations and efficiencies. We are a small and efficient team building out a solution in an exciting space with lots of green field ahead of it. Believing we're just scratching the surface of the power of our data, we're actively searching for passionate and analytical data scientists to help us extract actionable insights in order to improve our product offerings.\n\nWhy You'll Be Excited\nHaving a large stake and impact on the product and business direction and bottom-line\nCollaborating with innovative and goal-focused engineering and business teams\nApplying statistics, modeling and ML to improve the efficiency of systems relating to bid traffic shaping and infrastructure costs\nDiving into a wide range of advertising business topics, such as forecasting, revenue yield, auction dynamics, and exchange optimization\nInfluencing and steering the improvement and development of our data platforms, data pipelines, and data science processes\nPerforming deep dive analyses to understand and optimize the key levers of our growth\nWhy We'll Be Excited About You\nYou have strong verbal and written communication skills that help you express your work in meaningful ways to cross functional teams\nYou are passionate about digging into data sets\nYou are able to write efficient and well-structured SQL queries on large data sets\nYou have a solid background and understanding of statistical analysis, experimental design, and machine learning aspects (regression, classification, clustering, supervised/unsupervised, etc.)\nYou have experience with data extraction, exploration, and analysis using programming languages (Java, Python, R, or similar) and data technologies (Spark, etc.)\nYou have a degree in Mathematics, Statistics, Computer Science, or another applicable quantitative field\nYou have familiarity with concepts relating to feature extraction and selection\nBonus: You have previous advertising domain knowledge/expertise\nWhy We (and You'll) Love It Here\nWe are a technology and data-driven business\nWe embrace analytical thinking, kind, and results driven people\nWe have a plethora of challenging and interesting problems to solve\nWe help and support each other in creating a productive work/life balance\nCompensation & Benefits:\n\nAt Telaria we place an emphasis and importance on ensuring our total rewards are competitive, aligned with industry and to help you create a productive work/life balance. Benefits are highly subsidized and include medical, company paid dental, vision, employer contributed Health Savings Account, 401k matching, corporate gym discounts, pre-tax health and commuter savings, life insurance, 5 and 10-year Sabbatical programs, Discretionary Time Off (a.k.a. open vacation policy!), Paid Parental Leave, an Employee Referral Program, Employee Stock Purchase Plan (ESPP), and much more! All this is within a collaborative work environment you can personalize and topped with engaging programs like Micro-Mentorship, and Team Sports.\n\nTelaria values diversity and is proud to be an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nApply Now: click Easy Apply"}, "535": {"company": "Two Sigma", "description": "Two Sigma is a different kind of investment manager. Since 2001, we have used data science and technology to derive insights to forecast the future and discover value in markets worldwide. Our team of scientists, technologists and academics looks beyond traditional finance to understand the bigger picture and to develop creative solutions to some of the world\u2019s most difficult economic problems. Our work spans markets and industries, from insurance and securities to private investments and new ventures.\n\nThe Strategic Data Science team\u2019s mission is to unlock new high-potential revenue streams by harnessing Two Sigma\u2019s data, technology and modeling capability into a scalable and portable prediction engine and monetizing this engine into new investment products or non-investment business lines.\n\nIn particular, the Strategic Data Science team is working on building a systematic and data-driven private investment focused modeling environment, with application to investment products across the Two Sigma businesses. The team\u2019s ambition is to leverage Two Sigma\u2019s accumulated know-how, proprietary data-science platform and scientific investment approach in highly fragmented, illiquid and unstructured markets. By leveraging these tools, we can develop a meaningfully differentiating investment process in an industry dominated by institutions relying on local knowledge, personal networks and incomplete information.\n\nThe Strategic Data Science team is seeking a data scientist to join our growing team and contribute to building the initial data and modeling platform used to guide our team\u2019s investment process and asset selection. With statistics, economics, and computation at the heart of all our work, we will be most successful when data science is used to empower our team to make data-driven, evidence-based investment decisions that scale quickly. Our mission is to give our team a significant competitive edge in this alpha-phase of the initiative, while also building a platform that scales and provides an enduring advantage: the world\u2019s first data-driven private asset prediction engine.\n\nYou will take on the following responsibilities:\nIndependently generate and articulate hypotheses on what may affect private markets, asset valuations, and private deal processes\nLeverage existing data sets, as well as identify and trial new data sets, in order to interrogate yours \u2014 and the team\u2019s \u2014 hypotheses\nPresent your work internally to the working teams, other modeling teams, members of Two Sigma\u2019s leadership team and various Two Sigma businesses\nSpend time with private market partners to better understand how it works, how software is used, and what data is critical to industry practitioners daily workflows\nDevelop a deep understanding of private markets\nYou should possess the following qualifications:\nStrong independent development of predictive models in common open-source statistical programming languages\nExperience working with high-dimensional and sparse datasets, as well as recognition of when and how to combine such datasets to enhance their value\nFamiliarity with time-series and spatial analysis methods and software, particularly mapping tools\nDesire to work in a dynamic and evolving research and development environment, where you may be working on several parallel research tracks and will be expected to switch context frequently\nStrong communication skills, with an emphasis on the ability to understand your audience and flexibility to communicate complex topics to non-experts\nTwo Sigma employees enjoy the following benefits:\nCore Benefits: Fully paid medical and dental insurance premiums for employees and dependents, competitive 401k match, employer-paid life & disability insurance\nPerks: Onsite gyms with laundry service, wellness activities, casual dress, snacks, game rooms\nLearning: Tuition reimbursement, conference and training sponsorship\nTime Off: Generous vacation and unlimited sick days, competitive paid caregiver leaves\nWe are proud to be an equal opportunity workplace. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity/expression, age, status as a protected veteran, status as an individual with a disability, or any other applicable legally protected characteristics\n\nApply Now: click Apply Now"}, "536": {"company": "BlackLine", "description": "Responsibilities:\nBring Creativity to Data products.\nApply machine learning methods to a variety of finance and accounting problems.\nResponsible for building and maintaining the machine learning systems, data, platform and processes.\nBuild, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.\nPerform qualitative and quantitative data analysis.\nCleanse and transform raw data used in machine models.\nPerform data munging, data mining, clustering & classification methods, pattern recognition.\nComfortable with statistics, calculus and multivariate analysis.\nParticipate in ML POCs, validate the results and develop production implementations.\nBuild and optimize scalable machine learning solutions in the public cloud.\nFamiliar with SQL, Python, R, SparkML, TensorFlow, GCP, AWS, SQL Server.\nDevelop production systems in Python.\nWork independently to research and solve business and technical problems.\nPlan their work individually and as part of a team.\nMentor and train other Data Scientists on the team.\nQualifications:\nStrong practical experience with machine learning techniques in the industry, accounting and financial industries is a plus.\nExtensive experience solving analytical problems using quantitative approaches.\nExperience with machine learning algorithms for building ML models, their accuracy, cleanliness, reliability.\nExperience with predictive and prescriptive analyses, modeling, and segmentation.\nHave strong passion for empirical data research for practical applications.\nAbility to communicate complex quantitative analysis in clear, precise, and actionable\nComfortable with complex, high-volume, high-dimensionality data from varying sources.\nVery comfortable with data engineering methods and pipelines.\nExpert knowledge of analysis tools such as R, Matlab, or SAS\nExperience with data warehousing, relational databases, ETL, BI, data mining.\nExperience in SQL, R, Python languages.\nStrong familiarity with GCP and AWS, SQL Server.\nPractical experience with GIT version control.\nComfortable working with open source tools in a Unix/Linux environment.\nExperience with and ownership of data-informed decision-making.\nExperience translating business requirements into functional, and non-functional requirements.\nStrong sense of product and data ownership.\nWorks independently without the need for supervision.\nStrong written and verbal skills \u2013 able to explain the work in plain language.\nMS/PhD in Computer Science or other quantitative disciplines\nTo apply to this job, click Apply Now"}, "537": {"company": "Numerator", "description": "This data scientist position is a highly-autonomous, product-focused role designed to create value and drive impact across the Product organization, while also influencing the evolution and strategic direction of our company as a whole. The role is cross-functional by nature and is responsible for developing data products and analytics, defining methodologies, conducting research and analysis on a variety of subject areas, and driving bottom-line growth through building operational efficiencies and leading special projects for our clients. The ideal candidate is a seasoned data scientist (e.g. quantitative analyst) with diversified experiences across several industries, who's held various positions within analytics or engineering functions. Since a major requirement for this role is to understand, author, and deploy production code, the ideal candidate should also be experienced with processing large quantities of data, building algorithms alongside software engineers, and foundationally rooted in applied statistics.\n\nResponsibilities- What you get to do!\nIdentify new opportunities to build and/or improve new product features and data products\nPartner with Product, Data, and Engineering teams to identify, investigate and deliver solutions related to product and back-end data issues\nDeliver complex projects involving heavy data and statistical modeling (e.g. sampling, segmentation, classification, predictive modeling, etc.)\nLead the discovery and development of new and existing methodologies and algorithms\nRegularly communicate outcomes, new initiatives and improvements, etc. to stakeholders\nProvide data science consulting and support to both internal and external clients\nWhat we are looking for\nBS in Mathematics, Statistics, Computer Science, Economics, Physics, or other behavioral and/or equivalent quantitative science\n3+ years of industry experience as a data scientist (or equivalent role). For data science boot camp graduates, 2+ years of experience as a data scientist post-graduation\nExperience with defining key product metrics, setting team goals, and building internal tools to monitor progress against KPI's\nProficiency in Python and/or R, SQL, Spreadsheets\nExperience with applied statistics across various data types and sizes\nExperience with communicating complex analyses and methodologies effectively to non-technical stakeholders\nOutstanding written and verbal data storytelling, demonstrated consulting skill and ability to tailor communication style and depth to a variety of audiences\nHighly autonomous, versatile, intellectually curious and resilient within a dynamic and fast-paced organization\nExtra, Nice to haves\nExperience with developing, deploying and maintaining back-end production code, including (but not limited to) applied ML frameworks and applications (e.g. SciKit Learn, TensorFlow, etc.)\nProven track record of delivering solutions to a production environment\nSolid understanding of SQL and transactional databases (e.g. MySQL, Postgres, etc.), and experience with building data models and/or improving warehouse architecture\nExperience with understanding, analyzing and modeling user data and behavioral trends\nEnthusiasm for identifying and pursuing new business and product opportunities\nExperience working with marketing insights, shopping data or in the retail industry\nDemonstrated ability to systematically break down large, vague feature requests into deliverable work product\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\n\n.\nStart your job application: click Apply Now"}, "538": {"company": "Wish", "description": "Want to join our NEW centralized data science team working on company level data projects?\n\nData driven decision-making is an integral part of life at Wish. It drives our success with customers and merchants. We\u2019re looking for talented Data Scientists to continue to improve our user experiences and grow the business through data and quantitative techniques. You should have a proven track record of using data to drive the understanding, growth, and the success of a product. You should be impact-driven, self motivated, and resourceful.\nWe are looking for Data Scientists focusing on analytics to:\nDefine and evaluate key metrics and understand their trade-offs.\nDiscover new leverage points to grow the business.\nDrive deep understanding of our user and product to develop actionable insights and recommendations.\nUnderstand and discover the root cause of metrics movement.\n\nDesired Skills & Experience\nA minimum of two years of data analytics related experience.\nBachelor degree in a quantitative field.\nProficient in SQL.\nPreferred Skills\nDemonstrated track record of successful projects in applying quantitative techniques to improve a product or business.\n3+ years analytics related experience in the technology industry.\nProficient in R or Python for data analytics\nWish is transforming the way the world shops by offering a convenient and personalized mobile shopping experience. Our mission is to offer an unlimited selection of affordable quality goods to be accessible for everyone on a global scale. We bring together world-class technical talent with a passion for connecting relevant products to relevant people.\n\nLearn more about us:\nIntro to Wish\nOur CEO discusses Wish\nCrunchbase\nRecruiting Video\n\nWish values diversity and is committed to creating an inclusive work environment. We provide equal employment opportunity for all applicants and employees. We do not discriminate based on any legally-protected class or characteristic. Employment decisions are made based on qualifications, merit, and business needs. If you need assistance or accommodation due to a disability, please let your recruiter know. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.\nApply Now: click Apply Now"}, "539": {"company": "DTE Energy", "description": "The future is bright at DTE Energy! We are one of the largest Fortune 500 diversified utilities in the United States with an aspiration to be the best-operated energy company in North America and a force for good in the communities we live and serve. We have businesses in 26 different states and are comprised of regulated utility and non-utility businesses. Our utility business provides electric and gas service to approximately 3 million customers. Our non-utility businesses include a diversified portfolio of energy related companies, ranging from gas storage and pipelines to renewable power development.\n\nDTE Energy\u2019s utility and non-utility businesses are poised for significant growth. We look forward to working with highly motivated and team-oriented individuals to energize our efforts of growing economically and environmentally.\n\nRecently, DTE Energy has been recognized as an outstanding place to work and has received the following accolades:\n\n* Gallup Great Workplace Award for consecutive years\nCivic 50 Award for corporate citizenship excellence\nIndeed\u2019s annual \u201c50 Best Places to Work\u201d award for two years running\nMetropolitan Detroit\u2019s 101 Best and Brightest Companies to work For\nJ.D. Power Customer Satisfaction Award\nProfessional Women\u2019s Magazine/Black EOE Journal \u201cBest of the Best\u201d\nComputerworld\u2019s 100 Best Places to Work in IT\nBest Employers for a Healthy Lifestyle Gold Award\nDetroit Free Press Green Leaders Award\n\nDTE Energy is an equal opportunity employer and considers all qualified applicants without regard to race, color, sex, sexual orientation, gender identity, age, religion, disability, national origin, citizenship, height, weight, genetic information, marital status, pregnancy, protected veteran status or any other status protected by law.\n\nExternal Pre-Hire Assessment Required: Professional Pre-Hire Assessment\nTesting Required: Not Applicable\nJob Summary\nResponsible for translating business requirements into analytical constructs and using data to propose solutions for effective decision making. Collects, validates, transforms, and cleanses data, as well as performs quantitative analysis to derive insights. Runs analytical experiments in a methodical manner and regularly evaluates alternative models and techniques. Develops predictive models to forecast business performance metrics and provides recommendations for strategic decisions. Responsible for teaching others the tools, techniques and best practices in self-service reporting, data analysis and predictive analytics.\nKey Accountabilities\nPerforms in-depth analyses (e.g., cost-benefit, invest-divest, forecasting, predictive, what-if, impact analysis, etc.) to help the company focus on key decisions to improve safety, employee engagement, operational efficiency, product quality, and customer satisfaction\nDevelops, modifies, and automates reports, builds and prototypes dashboards to provide insights, and provides analytical solutions\nResponsible for discovering insights from Big Data to help shape or meet specific business needs and goals.\nDevelops and maintains analytical models through understanding data, evaluating technologies, optimizing algorithms, experimenting and validating models\nDelivers effective presentations that tell compelling stories about analytical insights\nPerforms data cleansing and blending processes to produce analytic data sets for use by a variety of downstream purposes\nImplements new statistical, mathematical, machine learning or other methodologies for modeling or analysis\nUtilizes business knowledge to translate goals into data-based deliverables, such as predictive models, pattern detection analysis or optimization algorithms\nTrains and enables self-service reporting capability and use of Business Intelligence tools for supported business unit(s)\nConducts research to identify relevant data for developing prototypes and proof-of-concepts\nCollaborates with cross-functional stakeholders to understand business needs, formulate complete end-to-end analyses that includes business requirements, data gathering, analysis, scaleable solutions, and presentations\nMinimum Education & Experience Requirements\nThis is a dual-track base requirement job; education and experience requirements can be satisfied through one of the following two options:\nBachelor\u2019s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 3 years of experience working in a data analytical or computer programming function; or\nMaster\u2019s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 1 year of experience working in a data analytical or computer programming function\nOther Qualifications\nPreferred:\nMaster\u2019s or PhD degree in Data Science\nExperience in quantitative analytics (e.g. data mining, regression analysis, hypothesis testing, predictive modeling techniques, and model optimization)\nKnowledge and intermediate-level skills in data modeling, data structure, and the application of complex SQL queries with data from multiple sources, including Big Data platform (e.g., Hadoop, AWS, Azure)\nFamiliarity with Cloud environments\nExperience with SAP Business Intelligence tools and SAP CRM, ISU, and BW data\nFamiliarity with Continuous Improvement concepts and applications (e.g., six sigma, lan)\nStrong written and verbal communication skills\nUtility/energy or customer-oriented industry experience\nOther Requirements:\nIntermediate-level experience with data mining and statistical analysis using analytical packages/tools (e.g., R, SAS, SPSS, Stata, MATLAB, Minitab, etc.)\nIntermediate-level experience in articulating business questions, pulling data from relational databases (e.g., SAP BW, ORACLE, SQL SERVER) and using advanced excel and statistical tools (e.g., Minitab, Alteryx, Advanced Excel with VBA, R, Python, SAS, SPSS, Stata, MATLAB, etc.) to conduct in-depth analysis to support decision making\nIntermediate-level proficiency in business intelligence tools (e.g., Microsoft PowerBI, Tableau, SAP, Business Objects (BOBJ), etc.)\nIntermediate-level programming skills in SQL, C/C++/C#, PHP, Java, Python, R, ASP, or SAS\nUnderstanding of applied research design and machine learning (e.g. multivariate statistical analysis, unsupervised and supervised learning, predictive modeling)\nSelf-starter and quick learner; advances self and others' knowledge and skill sets in business processes, data science, new analytical frameworks, technologies, and applications\nInterpersonal, analytical and problem-solving skills, including ability to communicate technical information and complex data analytics to a non-technical audience\nAdditional Information\nIncumbents may engage in all or some combination of the activities and accountabilities, and utilize a variety of the competencies cited in this description depending upon the organization and role to which they are assigned. This description is intended to describe the general nature and level of work performed by incumbents in this job. It is not intended as an all-inclusive list of accountabilities or responsibilities, nor is it intended to limit the rights of supervisors or management representatives to assign, direct and control the work of employees under their supervision.\nTo apply to this job, click Apply Now"}, "540": {"company": "Spectrum Communications and Consulting", "description": "What\u2019s significantly better than working on a typical data science team? How about working on a data science team in which you\u2019re directly making an impact in the revolutionary field of artificial intelligence even as an entry level team member? (well, statistically significant that is). Pardon the pun, but at Spectrum we\u2019re certain that our team is pumped up to work not only with like-minded data-savvy and fun loving professionals, but also to work with cutting edge new tools like our predictive, artificially intelligent proprietary software. So, if your confident that you want to make a direct impact in your next job today, then please keep on reading.\n\nResponsibilities\n\nBeyond working with state of the art technology you will have many different fantastic projects to work on as a Data Scientist at Spectrum. Here are just a few different responsibilities you can expect off the bat:\nWork with IT teams, management and/or data scientists to determine organizational goals\nMine data from primary and secondary sources\nClean and prune data to discard irrelevant information\nAnalyze and interpret results using standard statistical tools and techniques\nPinpoint trends, correlations and patterns in complicated data sets\nIdentify new opportunities for process improvement\nProvide concise data reports and clear data visualizations for management\nSome Characteristics That Define You\n\nWe understand that as a Data Scientist for Spectrum, you have many different professional goals and personal interests. As such here are just a few different things that typically define our team members on the Data Science team:\nAnalytical. In order to solve problems and build innovative new digital marketing campaigns, it is essential that you know how to take an idea and analyze it from all of its angles.\nPatient. As a data scientist, you know that you work with extremely large data sets on a daily basis. As such we are looking for someone who is not only meticulous, but patient enough to sit and sift through that data in a thorough way.\nCreative. Beyond just analyzing data sets, you are an explorer and a puzzle solver. Pulling insights out of your data and understanding how those insights can better shape our tools is something that you live to do.\nStudent. More so than most industries, the field of data science is always changing and evolving. As such, you are always looking to learn new things and gain new skills.\nBusiness-Savvy. Beyond the wicked data science skills you bring to the table, we also want you to consider the business implications of our data tools. From the ways our team will use them to how our customers will use them, we always want you to keep the user and the business application in mind.\nRequired Skills and Experience\n\nOn top of the many intangible skills you bring to the table, there are many skills that can help improve the efficiency and success of your work at Spectrum. Here are a few of those required skills and experience that you will come in with as a Data Scientist on our team:\nA bachelor\u2019s degree/pursuing a bachelor's degree in computer science, mathematics, statistics, information systems, or a related field\nExperience with statistical modeling\nFundamental knowledge of R and/or SAS languages\nExperience with SQL databases and database querying languages\nExperience with data mining and data cleaning\nExperience with data visualization and reporting techniques\nWritten and verbal expression\nBenefits\n\nAs a Data Scientist at Spectrum there are a ton of fantastic perks and benefits that come along with your work. Here are just a few of the benefits you can expect when joining the Spectrum family:\nComprehensive medical & dental insurance\nRetirement planning & company matching\nGenerous PTO, including sick days & holidays\nA state-of-the-art office environment\nNintendo Switch in-office gaming such as FIFA, Arms, Mario Kart, and Rocket League\nYear-round gym memberships\nPaid continuing education\nCasual dress code\nFlexible scheduling\nFree-Lunch-Friday\nCompany sponsored parties and group activities outside of the office\nStart your job application: click Apply Now"}, "541": {"company": "Snowflake", "description": "About Snowflake\n\nSnowflake is growing fast and we're scaling our team to help enable and accelerate our growth. We're passionate about our people, our customers, our values and our culture! We're also looking for people with a growth mindset and the pragmatic insight to solve for today while building for the future. And as a Snowflake employee, you will be accountable for supporting and enabling diversity and belonging.\n\nSnowflake started with a clear vision: make modern data warehousing effective, affordable, and accessible to all data users. Because traditional on-premises and cloud solutions struggle with this, Snowflake developed an innovative product with a new built-for-the-cloud architecture that combines the power of data warehousing, the flexibility of big data platforms, and the elasticity of the cloud at a fraction of the cost of traditional solutions.\n\nWe're looking for a talented Product Analyst to come aboard. In this role, you will work closely with our Product and Engineering teams to uncover insights about how customers use Snowflake, helping to inform Product's decision making and focus Engineering efforts. You will also work on long-running analytical initiatives marked by greater complexity and less structure that will yield substantial product enhancements. This is a strategic, high-impact role that will help shape the future of Snowflake products and services.\n\nAs a Data Scientist at Snowflake you will:\nSleuth through large amounts of data to uncover feature-usage patterns, subtle issues with the system, potential performance enhancements, and areas to improve user experience.\nCollaborate closely with Engineers and Product Managers to inform product decision making with data and to identify opportunities to create more value for our customers.\nBuild dashboards to help Engineering and Product Managers monitor performance and availability of our system.\nAnswer questions from executive team for board reporting, publications, and industry reports.\nThink creatively to find optimal solutions to our complex, often unstructured problems.\n\nOur ideal candidate will have:\n\n\nBS/MS in quantitative discipline (Math, Statistics, Operations Research, Economics, Engineering, or CS)\nExpert-level experience working with SQL and relational data (3+ years on a regular basis).\n3+ years of experience with Python, including scikit-learn, numpy, and pandas.\nExperience working with large-scale machine generated data (e.g., log, application, or customer-usage data).\nHands-on experience with MPP databases, such as Snowflake, Redshift, BigQuery, Vertica, etc.\nAbility to clearly present learnings to business leaders and technical stakeholders.\nThe ability to thrive in a dynamic environment. That means being flexible and willing to jump in and do whatever it takes to be successful.\n\nSnowflake is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, color, gender identity or expression, marital status, national origin, disability, protected veteran status, race, religion, pregnancy, sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.\nStart your job application: click Easy Apply"}, "542": {"company": "Novartis", "description": "Two companies and one incredible alliance.\n\nNovartis and Microsoft have formed alliance to leverage data & Artificial Intelligence (AI) to develop transformative medicines faster and more cost-effectively for patients worldwide.\n\nWe are seeking a thought leader and team builder to join the Novartis Innovation AI Lab to advance the field of Life Science and healthcare analytics. In this newly formed alliance with Microsoft, you will lead Visualization capabilities for Novartis .\nYour responsibilities:\nIn this newly created role, you will:\n\u2022 Build Novartis\u2019 Visualization center of excellence to make it a team of international reputation\n\u2022 Take a hands-on role and coach data science teams to deliver on highly visible multiple projects\n\u2022 Serve as an ambassador for Novartis Data Science by presenting and publishing articles at conferences, business meetings and academic institutions\n\u2022 Facilitate design and creation of knowledge repositories\n\u2022 Collaborate with the digital and DSAI teams\n\u2022 Coach and mentor associates\n\u2022 Inspire others on culture change\n\nWhy consider Novartis?\n\n750 million. That\u2019s how many lives our products touch. And while we\u2019re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people\u2019s lives?\n\nWe believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you\u2019re given opportunities to explore the power of digital and data. Where you\u2019re empowered to risk failure by taking smart risks, and where you\u2019re surrounded by people who share your determination to tackle the world\u2019s toughest medical challenges.\n\nWe are Novartis. Join us and help us reimagine medicine.\n\nPosting Title\nHead Data Scientist \u2013 Visualization Lead, Novartis AI Innovation Lab\nTo apply to this job, click Apply Now"}, "543": {"company": "Oden Technologies", "description": "About Oden:\n\n\nWe are on the brink of the fourth industrial revolution.\n\nManufacturing has long been an analog world, but this is rapidly changing. There is a staggering opportunity for improving the efficiency of current manufacturing processes, and enabling the next generation of manufacturing through the effective gathering, analysis, and productionization of data and insights. Oden is driving this revolution.\n\nWe have combined industrial hardware, wireless connectivity, large-scale data processing architectures, and advanced machine learning algorithms within the Oden platform so all manufacturers can monitor, analyze and optimize their production, across their diverse set of processes. Our goal is to democratize efficiency, sustainability, and competitiveness in the manufacturing domain.\n\nWhy We Do It:\n\n\nWe like to enable those who make things - to make more, to waste less, to serve their customers, and to thrive in a competitive world. Help enough makers, and the world can give us all the abundance we want for less cost and environmental impact. We\u2019re on the verge of a 4th industrial revolution for everyone who makes things.\n\nYou:\nCare about the purpose of the product and company.\nAre never satisfied with the way things are, but excited about the way things could be.\nTinker. You embrace data and different technologies and want to see how they can work together.\nEmpathize with customer needs and enjoy novel ways of posing and solving their problems.\nLive by transparent and scientific thinking. You put in the work to find the best ideas with those around you.\nAre happy to put on steel toe boots and hit the factory floor to work with the production manager.\nThe Role:\n\n\nAs a Data Scientist on the Engineering Team you will be responsible for building statistical and machine learning models that improve the efficiency of manufacturing using telemetry collected from Oden\u2019s factory cloud. This includes real-time metrics that capture various properties of the manufacturing process, context about these metrics provided from external systems and human input, and offline measurements that describe the quality of the resulting products. Problems of interest range from diagnostic to predictive, eventually leading up to closed loop process control.\n\nYou will be working closely with Oden\u2019s data and product engineers to address customer needs. You will push the envelope on how machine learning can provide value to process engineers, operators and materials scientists. This is a crucial role for Oden, and requires someone who will uphold the highest standards of quality, accountability, and attention to detail.\n\nResponsibilities:\nInteracting with customers to understand and pose relevant data analysis problems.\nDeveloping and validating models and methods that address these problems, and working with the engineering team to deploy these as solutions\nGeneralizing solutions and innovating to create the next generation of product features\nEngaging with the technical community to present results externally, keep up to date on recent advances, and advance the state of the art\nMinimum Qualifications:\n\n\n5 years professional experience as a Data Scientist or advanced degrees (M.S. or PhD. in Statistics, Data Science, Computer Science with ML focus, or related fields)\nExperience with Python and SQL\nExperience with designing, building and deploying performant statistical models on large data sets (bonus: experience with time series data, and with real-time data analysis)\nFamiliarity with process improvement and exploratory techniques (e.g. design of experiments and optimization)\nEnthusiasm to own projects end-to-end; from experimentation to customer delivery\nExperience predictive modeling or machine learning on large datasets\nBonus:\n\n\nMaterials Science, Chemistry, or a related physical science expertise\nWhat We Offer You:\n\n\nMeasurable impact to the world and the chance to help real people - family businesses, entrepreneurs, engineers.\nExposure to many tech disciplines, most of which are rapidly evolving.\nA bridge between the physical and cloud worlds of tech. Our platform unites big data visualizations with sensors, M2M tech, and heavy industrial equipment.\nA platform that has the potential to evolve beyond what we have envisioned now.\nScientific and transparent thinking, for everyone involved.\nWe have backing by world leaders of both industry and tech that will ensure long term growth and development for us.\nWe\u2019re an equal opportunity employer (EOE).\n\nDiversity at Oden means building a team that is rich across all boundaries of race, ethnicity, gender identification, sexual orientation, disability, religion, age and thinking style. We welcome all backgrounds, life experiences, and worldviews as this is the catalyst for the rapid evolution of our product and our organization. Diversity allows us to tackle new challenges, embrace change, make well-informed decisions, and ultimately Make Things Better. In alignment with our \u201cPeople First\u201d company value, Oden has a passionate internal team dedicated to the promotion of diversity and inclusion initiatives as a core component of our culture.\n\nOur diversity initiatives apply to our practices and policies on recruiting, compensation and benefits; professional development; promotions; social activities and the ongoing development of a psychologically safe work environment.\nApply Now: click Easy Apply"}, "544": {"company": "Covenant Eyes", "description": "Data Science plays a crucial role within our organization. If you are actively seeking opportunities within the Data Sciences field, we would love to hear from you!\n\nThe Data Scientist is responsible for researching, designing, and building software solutions to data-rich problems using data science techniques; including machine learning. This includes identifying business trends and problems through complex big data analysis as well as interpreting results from multiple sources using a variety of techniques. These techniques can range from simple data aggregation via statistical analysis to complex data mining independently.\n\nExperience we look for in a Data Scientist:\n\n\u00b7 Advanced degree in data science or machine learning fields, or equivalent experience\n\n\u00b7 Several years of hands on experience processing and analyzing big data\n\n\u00b7 Proven ability to discover problems and produce algorithmic solutions\n\n\u00b7 Experience working with machine learning for image recognition and related technologies preferred\n\nPlease feel free to submit your cover letter and resume for review.\nApply Now: click Apply Now"}, "545": {"company": "Veracyte", "description": "The Position:\n\nVeracyte, Inc. is a leading genomic diagnostics company that is fundamentally improving patient care by resolving diagnostic uncertainty with evidence that is trustworthy and actionable. The company's products uniquely combine genomic technology, clinical science and machine learning to provide answers that give physicians and patients a clear path forward without risky, costly surgery that is often unnecessary.\n\nAs a senior team member, you\u2019ll design and build solutions that help commercialize and operationalize new diagnostic solutions. Specifically, you\u2019ll be responsible for designing and building systems used in our sequencing and data analysis platform. You\u2019ll work closely with software engineers, bioinformatic scientists and product teams to design and lead development of Next Gen Sequencing (NGS) data analysis platform and pipeline. You\u2019ll design and architect solutions to scale data analysis pipelines in a hybrid IT infrastructure in the public AWS cloud. Additionally, you\u2019ll assist with software development activities and streamline operations and processes in patient testing workflows. You\u2019ll work with technical leaders to identify and architect the hardware and software infrastructure needs at the company.\n\nWho You Are:\n\nYou want to leverage your skills and experiences in a high impact role for a growing, life science company creating cutting edge technology. As an experienced software engineer you\u2019ve also had team lead experience. You demonstrate excellent problem solving and collaboration skills with key stakeholders. You have a bachelor\u2019s degree in Computer Science and at least 5 years of experience developing data science platform(s). If you are currently on an H1b visa, we will assume the costs to transfer the visa.\n\nOther experiences and technologies you've enjoyed working with in the past:\nDeveloping sequencing data pipelines and/or data science platform\nJava technologies\nETL tools like Docker, Kubernetes\nAutomation frameworks like Ansible, Chef\nScripting languages like python, R, Powershell\nRelational databases like PostgreSQL\nCloud platforms like AWS and related technology stacks\nAdministering Unix/ Linux OS environments\nExperience working in regulatory environment is a plus (GxP, HIPAA etc.)\nAbout Veracyte\n\nVeracyte, Inc. is a leading genomic diagnostics company that is fundamentally improving patient care by resolving diagnostic uncertainty with evidence that is trustworthy and actionable. The Company\u2019s products uniquely combine genomic technology, clinical science and machine learning to provide answers that give physicians and patients a clear path forward without risky, costly surgery that is often unnecessary. Since its founding in 2008, Veracyte has commercialized three genomic tests, which are transforming the diagnosis of thyroid cancer, lung cancer and idiopathic pulmonary fibrosis and collectively target a $2 billion market opportunity.\n\nAt Veracyte, we are more than just a diagnostics company. We are redefining diagnostic truth and changing patient care as we know it. We are improving the lives of patients by enabling the evolution of evidence-based clarity from scientific discovery. Our team embraces challenges - the more complex, the better. We are laser-focused and know how to prioritize. We act with a sense of urgency, because when it comes to advancing patient care, every minute matters. We take ownership of our work and are deeply committed to the success of our team. And, above all, we value integrity - in our work and how we treat all of our stakeholders, including each other.\n\nOur accomplishments and innovation have earned us widespread recognition, from appearing on The Wall Street Journal Next Big Thing list to receiving the 2016 Edison Award, which honors product innovation and excellence. Yet the honor we are proudest of is being named a Top Workplace by the Bay Area News group four years in a row, based solely on feedback from our employees.\n\nVeracyte affords equal employment opportunities to all qualified persons, regardless of race, color, religion, national origin, age, sex, disability, sexual orientation, gender expression, veteran or marital status. Veracyte participates in E-Verify in the United States\nApply Now: click Apply Now"}, "546": {"company": "Envision Experience", "description": "This role will be based in the Vienna, Virginia office and will support WorldStrides career exploration programs, Envision.\nFounded in 1967, WorldStrides is the largest and most trusted student travel organization in the nation. Each year, thousands of teachers and 200,000 students from all 50 states and several foreign countries travel with WorldStrides to destinations throughout the United States and the world. Our mission is\u201cEnriching Students\u2019 Lives through Experiential Travel.\u201d We strive to achieve this by extending education into the worldwide classroom and providing unique opportunities for learning through seeing, experiencing and interacting. We have more than 1500 employees who are personally committed to providing safe, life-enriching experiences for your students. We strive to help teachers make an even greater impact on their students by educating and inspiring them in ways that textbooks alone cannot.\n\nDescription\n\nThe Principal Analyst is responsible forprocuring, segmenting, and selecting prospects for company\u2019s direct response campaigns utilizing predictive modeling, as well as other uses of predictive modeling in the business. They will be responsible forsupporting the business by performing analyses on sales and marketing datasets, interpreting results and developing actionable insights and recommendations for use across the company. This position will develop data visualizations and reports using a variety of business intelligence, statistical, charting as well as other reporting tools. In addition, the Analyst will be responsible for data mining and testing against hypotheses which impact Key Performance Indicators. The Data Analyst should be able to work with SQL databases and other programming/scripting languages. The role requires a well-developed business acumen and the ability to ask the right questions to build concise analysis and predictive models that perform well. Ideal candidates enjoy working in demanding and fast-paced environments and are proactive, goal-oriented and team players.\n\nDuties\nManage relationships with prospect list vendors, set the data procurement strategy, data order management.\nDevelop predictive models from past campaigns. Use results for segmentation, targeting and scoring of the prospect lists.\nProvide wide range of organizational analysis with objective to increase effectiveness of campaigns, optimize spend, and provide insight for planning and budgeting\nConsult with organizational customers to understand the goals and objectives of WorldStrides\u2019 business and perform analyses to support new projects and initiatives\nAnalyze overall customer data trends to create and communicate actionable insights that help drive decision making\nCreate and automate business intelligence reports/tools to quickly identify changes in trends/key metrics, elevate issues, and identify areas for improvement\nFurnish analysis with analytical insight while maintaining completeness, accuracy, and documentation. Identify areas and define solutions to maximize value-add to the organization\nSupport pre- and post-campaign analyses for sales and marketing campaigns\nRequirements\nBS/BA degree (preferably in a data-related field or business)\n2-4+ years of experience in analytics focused on predictive modeling\nExperience in SQL, R or Python, Excel, relational databases, database concepts, and database design. Tableau and/or Power BI experience, REST API, and text analytics is a plus\nAbility to develop useful analytical tools and effectively communicate complex findings and ideas in plain language\nStrong interpersonal, oral and written communication and presentation skills\nAbility to work on multiple projects simultaneously and to provide regular status updates proactively\nHighly self-motivated contributor who works well as an individual and within a team/matrix environment\nStrong familiarity with Direct Mail and Online Marketing\nApply Now: click Apply Now"}, "547": {"company": "Agoda", "description": "Working Location: Bangkok, Thailand\n\nWe welcome both local and international applications for this role. Full visa sponsorship and relocation assistance available for eligible candidates.\n\nOverview\n\nPart of Booking Holdings (BKNG), Agoda is part of largest Online Travel Agency (OTA) worldwide and the largest and fastest growing OTA in Asia\n\nWe are looking for ambitious and agile data scientists that would like to seize the opportunity to work on some of the most challenging productive machine learning and big data platforms worldwide, processing some 600B events every day and making some 5B predictions.\n\nAs part of the front-end and personalization team you will be exposed to real-world challenges such as: predicting customer intents in real time, ranking search results to maximize lifetime value, personalizing supplier and user generated content, classifying unstructured data such as images and text, making personalized recommendations, discovering insights from big data and innovating the user experience. To tackle these challenges, you will have the opportunity to work on one of the world's largest ML infrastructure employing dozens of GPUs working in parallel, 30K+ CPU cores and 150T of memory.\n\nAgodans come from over 70 countries: It's an incredible technical creative melting pot of talents pin picked from all corners of the planet, and it happens from one of the most exciting and vibrant places in the world today - Bangkok, Thailand.\n\nYour voice will be heard, you career will make a leap, and you will be able to make a difference in a business that touches many millions in every hour of the day!\n\nResponsibilities:\nDesign, code, experiment and implement models and algorithms to maximize customer engagement and business outcomes.\nMine a big data of hundreds of millions of customers and more than 600M daily user generated events and discover actionable insights to drive improvements and innovation.\nWork with developers and a variety of business owners to deliver daily results with the best quality.\nResearch discover and harness new ideas that can make a difference.\nQualifications:\n\nThe Musts\n3+ years hands-on data science experience.\nExcellent understanding of AI/ML/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks.\nSignificant proficiency in SQL and languages like Python, PySpark and/or Scala.\nCan lead, work independently as well as play a key role in a team.\nGood communication and interpersonal skills for working in a multicultural work environment.\nGreat if you have them\nPhD or MSc in Computer Science / Operations Research / Statistics or other quantitative fields\nExperience in NLP, image processing and/or recommendation systems\nHands on experience in data engineering, working with big data framework like Spark/Hadoop\nExperience in data science for e-commerce and/or OTA\n#sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #sydney #melbourne #perth #vienna #minsk #brussels #saopaolo #toronto #vancouver #montreal #copenhagen #estonia #helsinki #paris #nice #berlin #dublin #munich #hamburg #stuttgart #hongkong #budapest #telaviv #milan #rome #tokyo #osaka #amsterdam #oslo #warsaw #krakow #bucharest #moscow #singapore #seoul #barcelona #madrid #stockholm #taipei #london #manchester #liverpool #hcmc #yokohama #jerusalem #venice #florence #zurich #geneva #basel #beijing #shanghai #ENG #IT #4 #LI-PK1\nStart your job application: click Apply Now"}, "548": {"company": "Visa Inc.", "description": "As the world\u2019s leader in digital payments technology, Visa\u2019s mission is to connect the world through the most creative, reliable and secure payment network - enabling individuals, businesses, and economies to thrive. Our advanced global processing network, VisaNet, provides secure and reliable payments around the world, and is capable of handling more than 65,000 transaction messages a second. The company\u2019s dedication to innovation drives the rapid growth of connected commerce on any device, and fuels the dream of a cashless future for everyone, everywhere. As the world moves from analog to digital, Visa is applying our brand, products, people, network and scale to reshape the future of commerce.\n\nAt Visa, your individuality fits right in. Working here gives you an opportunity to impact the world, invest in your career growth, and be part of an inclusive and diverse workplace. We are a global team of disruptors, trailblazers, innovators and risk-takers who are helping drive economic growth in even the most remote parts of the world, creatively moving the industry forward, and doing meaningful work that brings financial literacy and digital commerce to millions of unbanked and underserved consumers.\n\nYou\u2019re an Individual. We\u2019re the team for you. Together, let\u2019s transform the way the world pays.\n\nEssential Responsibilities:\nDesign and implement efficient and scalable machine learning systems\nDevelop proof-of-concept prototype with fast iteration and experimentation\nDevelop and maintain design documentation, test cases, and performance evaluation\nWorks within an agile engineering methodology and collaborative team development architecture\nBasic Qualifications\n4 years of work experience with a Bachelor\u2019s Degree or at least 2 years of work experience with an Master's degree in computer science, computer engineering, electrical engineering, mathematics, or equivalent field\nPreferred Qualifications\n8 years of work experience with a Bachelor\u2019s Degree or at least 4 years of work experience with an Master's degree in computer science, computer engineering, electrical engineering, mathematics, or equivalent field\nStrong skills in Tensorflow\nExperience with big data technologies such as Hadoop, Spark, etc.\nExperience building large scale machine learning systems\nAbility to communicate and work within a team\nTravel Requirements\n\nThis position requires the incumbent to travel for work 5% of the time.\n\nMental/Physical Requirements\n\nThis position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers, and reach with hands and arms.\n\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.\nApply Now: click Apply Now"}, "549": {"company": "AIR Worldwide", "description": "Company Description\n\nAIR Worldwide (AIR), a Verisk business, provides risk modeling solutions that make individuals, businesses, and society more resilient to extreme events. In 1987, AIR Worldwide founded the catastrophe modeling industry and today models the risk from natural catastrophes, terrorism, pandemics, casualty catastrophes, and cyber attacks, globally. Insurance, reinsurance, financial, corporate, and government clients rely on AIR\u2019s advanced science, software, and consulting services for catastrophe risk management, insurance-linked securities, site-specific engineering analyses, and agricultural risk management. AIR Worldwide, is headquartered in Boston with additional offices in North America, Europe, and Asia. To learn more about AIR, please visit us at: www.air-worldwide.com. We are proud to be a part of the Verisk family of companies!\n\nWith a history of impressive growth, an innovative culture, and offering industry-leading solutions, Verisk Analytics is an amazing place to work and make a difference. In 2018, Forbes magazine named Verisk to its World\u2019s Best Employers list and, in 2017, to its World\u2019s Most Innovative Companies list for the third consecutive year. We also earned the Great Place to Work\u00ae Certification for the third consecutive year in recognition of our outstanding workplace culture.\n\nVerisk is a leading data analytics provider serving customers in insurance, energy and specialized markets, and financial services. Using advanced technologies to collect and analyze billions of records, Verisk draws on unique data assets and deep domain expertise to provide first-to-market innovations integrated into customer workflows. We\u2019ve been delivering predictive analytics and decision support solutions to our customers for nearly 50 years, helping them protect people, property, and financial assets. At Verisk, you\u2019ll be part of an organization that\u2019s committed to serving the long-term interests of our stakeholders, including the communities where we operate.\n\nAt Verisk, you can build an exciting career with meaningful work; create a positive and lasting impact on the business; and find the support, coaching, and training you need to advance your career. Our culture of innovation means your ideas on how to improve our business will be heard. As key contributors to our success, our team members enjoy working in a business-casual, collaborative environment that offers state-of-the-art resources, advanced technologies, and an excellent benefits package.\n\nJob Description\n\nThe main responsibility of this position will be to build upon our knowledge from developing flood models for Great Britain, Germany, United States, Japan and Central Europe as we update and expand to more countries. As a hydrologist, you will use the in-house models to simulate flooding events in a stochastic framework to quantify the flooding characteristics of a selected basin or a country. You will work with other hydrologists and hydraulic engineers as well as meteorologists, climate scientists, engineers, software professionals, statisticians, and actuaries to incorporate the latest flood modeling methodologies into cutting-edge flood risk assessment software. Your contributions will help provide our clients in the insurance industry with tools and data that help them make informed decisions about flood risk and flood insurance products.\n\nMain responsibilities, but not limited to:\nDeveloping and enhancing flood hazard models and the relevant source codes.\nFormulating and implementing hydrologic models in deterministic and probabilistic frameworks.\nSimulating hydrologic responses over a wide range of spatial scales.\nFormulating and implementing a variety of hydrological analytical procedures pertaining to flood frequency analysis and hydrologic modeling.\nCollecting, managing, and analyzing various types of hydro-meteorological data for efficient integration of high-quality data into the modeling process.\nQualifications\n\nKnowledge, skills and abilities:\nExpertise in catchment hydrology and stochastic hydrology.\nExperience in hydrological model parameter estimation and calibration, data-assimilation and Bayesian methods is desirable\nGood basic knowledge of probability theory and statistics.\nAbility to gather, understand, and critically analyze relevant hydrological and geophysical data from a variety of sources.\nExperience in flood modeling for the specifics of insurance/reinsurance industry would be a significant advantage.\nSolid technical programming skills gained through practical experience (e.g., C/C++, FORTRAN, MATLAB, R, Python, etc.).\nExperience in GIS applications (e.g., ArcMap).\nProficiency with Windows and Linux operating systems, and other standard applications.\nExcellent communication and presentation skills.\nAbility to achieve goals and meet deadlines while working on multiple tasks.\nHighly motivated and self-directed in advancing complex projects.\nEducation:\nAdvanced degree in Hydrology or related field with associated professional experience\nAdditional Information\n\nVerisk Analytics is an equal opportunity employer.\n\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.\n\nhttp://www.verisk.com/careers.html\n\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\n\n</br>Apply now\nTo apply to this job, click Apply Now"}, "550": {"company": "PayPal", "description": "Minimum Qualifications:\nBS/BA degree in related field required or equivalent professional work-related experience.\n3+ years related professional experience or masters degree and 1+ year.\nExperience in online fraud or consumer risk management preferred\nResponsibilities:\nWorks on assignments that are of intermediate complexity with multiple steps in execution, and guided by generally defined processes and project requirements\nFocuses primarily on completing short-term goals of a project efficiently and effectively\nPartner with Risk Analysts and provide exceptional global solutions\nFocuses primarily on how to achieve overall analytic objectives of a project with speed and quality\nSuggests ideas for operational plans and objectives\nIdentify glitches in processes and tools and develop and execute solutions to overcome general issues and obstacles with little supervision.\nLearning in-depth analysis of alternatives and applying specialized knowledge\nSeeks improvement within defined tasks. Understands, evaluates, and executes improvement ideas from managers, stakeholders and partners\nRequirements:\nHigh proficiency in fundamental technical skills (Programming language like Java/C/C++; scripting language like Perl/Python; strong UNIX background; working knowledge of Hadoop, Map-Reduce, Hive, Pig, R; data warehouse skills)\nHas working knowledge analytic tools, processes, and methodologies to achieve the expected results with minimum supervision\nHas a good understanding of Risk business trends and directions to be able to put own work in the broad business context\nData driven, and results oriented with positive outlook\nDemonstrates effective verbal and written communication skills on a defined set of technical topics. Articulately expresses technical ideas and appropriately requests clarification when questions arise. Asks open-ended questions\nInterfaces primarily with own team to get own job done or cross-functional teams when needed.\nBe transparent and accountable\nBe data-driven and outcome-focused\nPersevere but know when to change course\nStart your job application: click Apply Now"}, "551": {"company": "GSN Games", "description": "GSN Games is looking for a Senior Data Analyst to join our team in San Francisco!\n\nWhat You\u2019ll Do:\nYou will use your big data skills to solve complex business problems within the mobile gaming domain. As a member of the Central Analytics team, the work you do will have an impact on all of our five game studios. Your relationship-building skills will come in handy as you'll be communicating the results of your analyses to our studio and executive team members.\n\nYou Will:\nWork cross-functionally with our user acquisition, advertising, game studio, finance, and data science teams to deliver actionable insights into our games, in order to further increase installs, engagement, and monetization.\nProactively perform a wide range of analyses to identify trends, issues, and opportunities across games.\nAnswer business-related questions through exploratory data analyses and ad-hoc reporting.\n\nAbout You:\n4+ years of experience in a data analyst or financial analyst.\n2+ years experience using SQL, including complex queries from multiple data sources.\nExperience creating, operating and analyzing multiple simultaneous A/B tests.\n2+ years experience applying statistical analysis to consumer behaviors (video gaming, e-commerce, consumer entertainment, etc.).\nExcellent analytic and problem solving skills, including forecasting and performance marketing analysis.\nStrong communication and presentation skills, including extensive use of chart and table tools.\nAbility to quickly prioritize and execute multiple competing projects based on business case and expected impact.\n\nBonus Points!\nExperience working with user acquisition and/or advertising data.\nFamiliarity with R, SAS, SPSS, Matlab or other statistical modeling packages.\nExperience using a programming language (Python, JavaScript, Java) to solve problems.\n2+ years within the mobile gaming domain.\nGraduate degree in a quantitative field of study.\n\nStart your job application: click Apply Now"}, "552": {"company": "IntraEdge", "description": "Data Engineer\n9920\nScottsdale,\n3/27/2019 1:46:38 PM\n\nApplication Development\nContractor - W2\n\nJob Description\nData Engineer / Lead\n\n4-5 years of experience in ETL, SQL, Python, Data Management and Spark and strong fundamentals in distributed environments\nReal project implementations with Big Data technologies based on Spark\nExperience working on Serverless technologies\nExperience implementing NoSQL technologies - Mongo or Cassandra\nExperience with AWS cloud services: Lambda, S3, Glue, Redshift, and Athena, or their open source equivalent (Zeppelin, Presto, etc)\nData storage formats - Parquet, JSON, AVRO etc.\nExperience with real-time data sources and message ingestion for processing by filtering, aggregating, and preparing the data for analysis using technologies such as Spark Streaming and Kafka, AWS Kinesis, Firehose etc.\nExperience with data pipelining\nUnderstanding of best practices within the development process\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management\nCI/CD and DevOps tools such as BitBucket/Git, Bamboo, and Maven\nAWS technologies - Cloudwatch, CloudFormation, Security (IAM)\nAWS certification\n\nJob Requirements\n\nStart your job application: click Apply Now"}, "553": {"company": "Veritone", "description": "Data Analyst\n\nWho We Are\n\nVeritone (Nasdaq: VERI) is a leading provider of artificial intelligence (AI) technology and solutions. The company\u2019s proprietary operating system, aiWARE\u2122, orchestrates an expanding ecosystem of machine learning models to transform audio, video, and other data sources into actionable intelligence. aiWARE can be deployed in a number of environments and configurations to meet customers\u2019 needs. Its open architecture enables customers in the media and entertainment, legal and compliance, and government sectors to easily deploy applications that leverage the power of AI to dramatically improve operational efficiency and effectiveness. Veritone is headquartered in Costa Mesa, California, with over 300 employees, and has offices in Denver, London, New York, San Diego, and Seattle. To learn more, visit Veritone.com.\n\nWhat You\u2019ll Do\nAccurate routing blending & configuration of data from various internal/external sources.\nDevelop multiple formulas/calculations to determine campaign efficiency.\nUse ETL software to build data maps and workflows for data transformation.\nUtilize and further develop/improve attribution and media mix models.\nCollaborate with data science on solving complex problems through machine learning.\nWork directly with clients and account managers to establish KPIs and goals/benchmarks for media campaigns. Implement direct tracking and measurement tactics for new test campaigns and make improvements to tracking elements for existing campaigns.\nRoutinely present updated reports and insights to account teams.\nAdhere to daily and/or weekly reporting deadlines for assigned account base.\nDerive meaningful insights from campaign performance reports and make optimization recommendations to the media team.\nMonitor client media schedules for accuracy & resolve discrepancies with internal teams.\nLeverage various media tools to assist media buyers in collecting research data\nPackage and report on engine outputs for SaaS customers.\nDevelop workflows and dashboards for various use cases across multiple verticals.\nWhat You'll Need\nBA or BS degree in Information Systems or related subjects.\n2 to 5 years of experience.\nMust have exceptional Excel skills with advanced knowledge of formulas.\nStrong decision making and communication skills.\nExcellent organizational skills.\nDetail-oriented with solid math skills and a high level of accuracy.\nBonus Points If\nMust have exceptional Excel skills with advanced knowledge of formulas.\nStrong analytical, creative and innovative approach to solving problems.\nExceptional ability to multitask and manage competing priorities.\nExcellent written and oral communication skills.\nExperience working with web analytics (GA, Adobe, etc.) and attribution tools\nExperience working with BI/CRM tools.\nExperience working with ETL tools (Alteryx) for data blending and transformation\nKnowledge of account services and data analytics.\nExperience with research and buying tools; specifically for digital and offline media.\nExperience client-facing and working directly with vendors.\nProficient in media fundamentals; digital/offline media planning, buying and execution.\nAble to work autonomously or collectively in a high-pressure/fast-paced environment.\nWhat Is In It For You\nA competitive compensation package.\nStock Options.\nA fully stocked kitchen, casual dress attire, catered lunch on Fridays\nFlexible Time Off.\nQuality benefits: medical, dental, vision, 401K.\nAn opportunity to be a part of the next big thing in artificial intelligence!\n#LI-BC1\n\nOur company provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics.\nApply Now: click Apply Now"}, "554": {"company": "Northwest FCU", "description": "The Senior Data Intelligence Specialist operates as a member of the Data Operations Team. Supports the entire Credit Union\u2019s analysis and data needs. The successful candidate will take ownership of understanding the organizations strategic business needs, running analysis and providing highly effective feedback information for the entire Credit Union. They will have a strong understanding of the data, and a high level of understanding of the Credit Union\u2019s needs to be able to provide information for decision making at all levels.\n\nDUTIES& RESPONSIBILITIES:\nCollaborate with stakeholders throughout the organization to identify opportunities for leveraging data to drive business solutions\nResearching, designing, implementing, and deploying scalable data analytics vision and machine learning solutions to challenge various business issues\nMine and analyze data to drive optimization and improvement of product development, marketing techniques and business strategies\nCommunicate results of analysis and ideas to key decision makers\nUnderstand the Credit Union\u2019s strategic goals to be able to provide analysis based on data exploration\nHelp the Credit Union to evolve into an analytical and data driven culture\nWork closely with other team members to develop standards, promote efficiency, and prioritize the work load\nPreform Analysis using Python and R\nDevelop reports and dashboards using the Credit Union\u2019s BI Tools\nDevelop SQL Queries for reports and dashboards\nAnalyzing relational and transactional databases to provide data analysis\nCreate documentation around processes and procedures and manage code reviews\nApply industry standards best practices to development activities\nWork in an agile environment (methodology)\nWork with data team to ensure solutions are successfully executed, within agreed upon time frames\nMentor Junior Team Members to provide expertise on statistical and mathematical concepts\nRemain current on research techniques and become familiar with state of the art tools applicable to your function\nREQUIREMENTS:\n5 - 8 years of experience manipulating data sets and building statistical models\nBachelor\u2019s degree in Analytics, Economics, Finance, Mathematics or related field\nExperience using statistical computer languages (R, Python, SAS etc.) to manipulate data and draw insights from large data sets\nSubject matter expertise in data modeling\nStrategic thinking and analytical capability\nAbility to translate complex technical topics into business solutions and strategies\nExperience working with natural language processing and machine learning libraries\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, etc.\nA drive to learn and master new technologies and techniques\nAble to understand various data structures and common methods in data transformation\nExperience writing SQL, preferably in SQL Server or Hive (Hadoop)\nExperience with a BI analysis and reporting tools, preferably IBM Cognos Analytics or Tableau\nExceptional analytical, problem solving, and time management skills required Strong attention to detail\nHighly proficient in Microsoft Office and expert level understanding of Excel\nExcellent quantitative and qualitative analysis skills\nAbility to handle multiple projects with tight deadlines and adaptable to changing priorities\nAbility to work both independently and within a team environment, to build good working relationships and effectively manage multiple tasks\nExcellent interpersonal and communication skills, oral and written\nAdvance knowledge of Financial Institutions and Systems\nExperience with Hadoop Ecosystem and Pentaho\nApply Now: click Apply Now"}, "555": {"company": "Shape Security", "description": "About Shape Security:\nWe are security and web experts, pioneers, evangelists, and elite researchers. We believe in the power of the Internet to be a positive force; our mission is to protect every website and mobile app from cybercriminals. Shape\u2019s founders fought cybercrime at the Pentagon, Google, and other leading security companies. We are backed by some of the most prominent leaders and investors in the technology industry including Kleiner Perkins, Google Ventures, and more. Come be a part of our unparalleled team that is responsible for making the Internet a safer place for everyone.\n\nJob Description:\nShape Security is seeking a driven, analytical and highly professional individual to help shape the future of what we build at Shape Security. You will enjoy working with one of the richest data sets in the world, cutting edge technology, and the ability to see your insights turned into real products on a regular basis. The perfect candidate will have a background in a quantitative or technical field, will have experience working with large data sets, and is passionate about solving tactical problems day to day while keeping an eye on long term product strategy. You are focused on results, a self-starter, and have demonstrated success in using analytics to drive the understanding, growth, and success of a product.\n\nToday, Shape identifies and stops automated attacks and fraud against web and mobile applications of the Fortune Global 2000. Tomorrow, we\u2019ll need to fight even more sophisticated adversaries, while helping human users to have ever more frictionless experience.\n\nIf you have a passion for deriving actionable insights from complex big data sets, and love to help the product team make data-driven decisions, then we\u2019d love to talk with you.\n\nResponsibilities:\n\nAnalyze large volumes of web and mobile traffic of Global 2000 organizations both on a regular and ad-hoc basis, including exploratory analysis that uncovers current customer pain and future product opportunities\nBuilding and analyzing dashboards and reports that produce meaningful insights; define, evaluate and monitor key metrics that contributes to customer success;\nPerform cohort and sensitivity analysis that helps us identify key levers that maximize customer delight\nBe a strong voice for a data-informed point of view when working with cross functional teams (product, engineering, professional service, sales)\n\nRequirements:\n\n5+ years analytical experience working with large-scale datasets.\nStrong analytical skills including the ability to manipulate, model, interpret and visualize large quantities of structured data.\nA passion to use data to help inform product decisions.\nA strong understanding of experimentation and statistical analysis.\nProficiency in SQL and in at least one major programming language (e.g. Python, Java and/or C/C++.).\nProficiency in packages/tools/frameworks for data analytics and visualization (e.g. Jupyter notebooks, Pandas, Kibana, d3.js) highly preferred.\nA scrappy yet meticulous approach, and a love for problem solving!\nStrong interpersonal skills, personable, and persistent. Self-motivated, able to work well both independently and as part of an agile team.\nDemonstrated enthusiasm and capacity to learn new technologies quickly.\nBachelor\u2019s degree in a quantitative discipline such as Computer Science, Engineering, Statistics, Economics, or Operations Research required.\nApply Now: click Apply Now"}, "556": {"company": "IntraEdge", "description": "Machine Learning Engineer 10334 Phoenix, AZ 10/29/2019 7:38:00 PM\nIT\nContractor - W2\nJob Description\n*Understand the business problem and convert that problem into the Machine Learning algorithms. *Identify the various source of data, understand its relationships, connect it up and bring the data into common platform using ETL process, and perform data exploration using python IDE, SQL queries and BI tools like Tableau. *Use BigData Stack like Spark, Hadoop, Hive, to connect it up with the huge volumes of data, different Varieties of data, relational SQL and No-SQL databases and bring to the common place to explore to discover useful hidden patterns using analytics tools and techniques. *Perform Data Exploration to get the business insights from data, by using statistical techniques like Univariate, Bivariate, Multivariate and Cross Tables analysis and correlation techniques, prepare statistics to explore and evaluate the importance of the data and its features. Perform Data Pre-Processing to address outliers, encode variables to suit to the Machine learning algorithm going to be used. *Identify Machine learning stack more suitable to the problem in hand and data identified to represent the problem. *Use the various Machine learning models For Linear Classification, use techniques like Logistic regression binary and multi class classifications, Support vector machine (Maximum margin classifier) and Kernel tricks making non-Liner to linear). *For Non-Linear Classifications use techniques like KNN K-Nearest neighbors, Using trees for classifications, Neural networks and Na\u00efve bayes classifiers (Probabilistic classifier). *Use Linear regression models to predict the continuous dependent and use clustering techniques like K-Means and hierarchical to understand non-labeled data. *Use all GLM (generalized linear models), Tree models, Random forests, xgboost, use all ensemble and stack them together in stacking methods to improve the predictability of the model. *Train, test and evaluate the developed model. *Use various techniques like K-Fold Cross validation, batch normalization, batch and Stochastic gradient descent, Optimization techniques like momentum, RMS prop, Adam Optimization and Regularization techniques Ridge & Lasso. *Use techniques to reduce variance and reduce bias of the model. *Use NLP (Natural Language processing) techniques like word2Vector, Glove, and other sequence models to include text data related features into the model. *Own and conduct A/B tests for exploring various ideas to evaluate different models developed, understand how data is changed over time using time serious analysis ARIMA (Autoregressive integrated moving average) models *Use Markov chain models to track the events and predicting the probabilities of the events happenings *Use statics techniques Chi-Squire test, t-test, ANOVA analysis of variance etc. *Use basic mathematical concepts such as Bios and Variance, Probability, P-value, correlation and PCA and other sampling techniques.\nJob Requirements\n*Understand the business problem and convert that problem into the Machine Learning algorithms. *Identify the various source of data, understand its relationships, connect it up and bring the data into common platform using ETL process, and perform data exploration using python IDE, SQL queries and BI tools like Tableau. *Use BigData Stack like Spark, Hadoop, Hive, to connect it up with the huge volumes of data, different Varieties of data, relational SQL and No-SQL databases and bring to the common place to explore to discover useful hidden patterns using analytics tools and techniques. *Perform Data Exploration to get the business insights from data, by using statistical techniques like Univariate, Bivariate, Multivariate and Cross Tables analysis and correlation techniques, prepare statistics to explore and evaluate the importance of the data and its features. Perform Data Pre-Processing to address outliers, encode variables to suit to the Machine learning algorithm going to be used. *Identify Machine learning stack more suitable to the problem in hand and data identified to represent the problem. *Use the various Machine learning models For Linear Classification, use techniques like Logistic regression binary and multi class classifications, Support vector machine (Maximum margin classifier) and Kernel tricks making non-Liner to linear). *For Non-Linear Classifications use techniques like KNN K-Nearest neighbors, Using trees for classifications, Neural networks and Na\u00efve bayes classifiers (Probabilistic classifier). *Use Linear regression models to predict the continuous dependent and use clustering techniques like K-Means and hierarchical to understand non-labeled data. *Use all GLM (generalized linear models), Tree models, Random forests, xgboost, use all ensemble and stack them together in stacking methods to improve the predictability of the model. *Train, test and evaluate the developed model. *Use various techniques like K-Fold Cross validation, batch normalization, batch and Stochastic gradient descent, Optimization techniques like momentum, RMS prop, Adam Optimization and Regularization techniques Ridge & Lasso. *Use techniques to reduce variance and reduce bias of the model. *Use NLP (Natural Language processing) techniques like word2Vector, Glove, and other sequence models to include text data related features into the model. *Own and conduct A/B tests for exploring various ideas to evaluate different models developed, understand how data is changed over time using time serious analysis ARIMA (Autoregressive integrated moving average) models *Use Markov chain models to track the events and predicting the probabilities of the events happenings *Use statics techniques Chi-Squire test, t-test, ANOVA analysis of variance etc. *Use basic mathematical concepts such as Bios and Variance, Probability, P-value, correlation and PCA and other sampling techniques.\nStart your job application: click Apply Now"}, "557": {"company": "Silicon Valley Bank", "description": "Silicon Valley Bank is the market\nleader in providing financial solutions to the world\u2019s most innovative\ncompanies, leaders and investors. Our clients are the game changers\nfueling the global innovation economy and transforming the way we live and\nwork. SVB has been an incredible growth story over the last 30 years and\ncontinues to grow and expand internationally. Come join a\ngrowing, global commercial bank at the heart of the innovation economy where\nyou will be able to help bring our clients\u2019 world-changing ideas to life.\n\nThe Enterprise Business Analytics\ngroup at SVB is responsible for providing analytical business solutions to the\nbank. We translate data into actionable analytical solutions and promote\ninformation-based decision making to support SVB's strategic goals. One\nresponsibility of the group is to create an insight foundation that is\nleveraged to develop analytical solutions and predictive modeling. In order to\ndesign and create information foundation, data scientists identify and explore\nrelevant data sources; then create business understanding of the data by\napplying data mining techniques.\n\nThe Data scientist in this role will\nbe responsible for complex data transformations and data mining efforts.\nThey will build processes for the team to be able to use insights effectively\nand efficiently.\nResponsible\nfor end to end Cards insight creation, support in Card campaign,\ndeveloping & building card related insights\nResponsible\nfor managing/maintaining Card programs i.e. Card Opportunities, Portfolio\nmanagement, Value at risk, Card Explorer, Spend program etc.\nData\nmining and developing relevant data transformation logic\nDesigning\nprocesses to integrate data from multiple sources to facilitate client\ncentric advanced analytics\nUnderstand\nand connect the dots to different aspects of Card program.\nBuild,\ndesign, and develop the insights for decision making as well as building/assisting\nthe dashboards design for Business Users.\nResponsible\nfor identifying and exploring all relevant data sources, generate the\nunderstanding, develop the logic to transforms into insights that can be\nleveraged into decision making and other needs.\nDocumenting\ndata transformation logic\nDeveloping\nefficient, scalable and repeatable processes to transform data on regular\nbasis\nCommunicating\nwith IT partners to share selected transformation processes by\nfacilitating and reviewing business requirements\nDesign,\nbuild, develop and maintain the Analytical solutions to understand Card\nClients behavior.\nDevelop\nanalytical solutions to recommend Card product team to produce meaningful\nresults.\nPartnering\nwith other data scientists/business analysts to make them familiar with\nthe transformed information so that it can be appropriately used by other\nanalysts and statisticians\nManaging\nprocesses designed and developed by the information foundation team\nUsing\nbest practices framework to ensure data quality and reconciliation checks\nare in place and are transparent to our users\nLeveraging\ncommunication skills to collaborate effectively with analysts across SVB\nEvaluating\neffectiveness of the transformation process and delivered information by\nworking with users of information\nPartnering\nwith business groups to understand the Business case/Use case to\ndevelop/design best-in-class analytical solution(s).\nAbility\nto research external insights and blend with internal insights to create\nand understanding of the market place (Clients/Prospects).\n#LI-MS1\nSolid\nunderstanding of writing and understanding of complex SQL queries\nExtensive\nknowledge and experience in Oracle SQL, PLSQL, and SAS tools/techniques\nDemonstrated\nexperience with the data mining tools SAS/Anaconda and SQL preferably\nthrough Oracle PL/SQL.\nStrong\nbackground in SAS programming and SQL coding is preferred\nExperience\ntransform business specifications and requirements into well documented\nand scripted SQL, PL/SQL processes.\nAbility\nto develop and enhance complex PL/SQL scripts, queries, and stored\nprocedures and ETL processes\nProven\nDocumentation (technical and user documentation) and Verbal and written\nCommunication skills\nGood\nunderstanding of BI Methodologies and Practice\nExperience\nwith systems integration, building system models by combining model\ncomponents and testing the integrity of modeling systems, proficient with\nmodel and systems implementation testing\nKnowledge\nof Data Governance and DQ framework is a plus\nBackground\nin data management in Banking/Finance industry is preferred\nExperience\nwith ETL and data modeling tools is a plus\nStrong\nanalytical and problem solving skills\nDemonstrated\nability to self-manage and multitask in a dynamic, ever-changing environment\nEffective\ntime management and organizational skills\nFlexibility\nto work/manage variety of projects\nBachelor/Masters\nin Computer Science, Finance, Accounting, Economics, Statistics or\noperational research\nWorking\nknowledge with Tableau is a plus\n6\nyears of experience in analytics and/or business intelligence space\nApply Now: click Apply Now"}, "558": {"company": "PayPal", "description": "We are seeking world-class problem solvers who have a passion for data and a relentless focus on execution and delivery. You will be most successful with a healthy combination of both, technical skills and business acumen. As a Data Analyst you will generate insights by conducting extensive analyses of PayPals rich data. In the process, you will develop a deep understanding of the payments business, our site functionality, further strengthen your analytic, leadership and presentation skills and gain exposure to a wide variety of functional teams within PayPal.\n\nKey Responsibilities\nUnderstand how to make data visually appealing and simple to both navigate and comprehend for end-users\nAggregate data from various sources to construct streamlined data pipelines and integrate data from multiple PayPal systems\nIdentify key metrics and build exec-facing dashboards to track progress of the business and its highest priority initiatives\nIdentify key business levers, establish cause & effect, perform analyses, and communicate key findings to various stakeholders to facilitate data driven decision-making\nWork closely across the matrix with teams like Finance, Marketing, Product, Engineering and senior executives\nLead and participate in special projects/initiatives: innovate and implement large-scale quality improvements to processes and/or systems by conducting data analysis and making recommendations, troubleshooting technical issues, and refining processes around customer support\nBasic Requirements:\nGraduated, or will be graduating, with a bachelors or masters degree in Computer Science, Math, Statistics or related field\nExperience with one or multiple of the following will be highly desirable; Python, Java, Tableau, Jupyter Notebooks, Teradata, Hadoop/Hive, Oracle, JavaScript, SQL, Airflow, Linux, Perl, PHP\nExcellent understanding of computer science fundamentals, data structures, and algorithms\nDemonstrated experience, familiarity and ease with handling large data sets and crunching numbers\nInformation Retrieval (search/recommendation/classification) experience or Human Judgment/User Interface experience\nStrong written and verbal communication skills with the ability to translate complex problems into simpler terms, and effectively influence both peers and senior leadership\nPosition Location: Varies\nApply Now: click Apply Now"}, "559": {"company": "Dematic", "description": "Company Overview\n\n\nDematic is a leading supplier of integrated automated technology, software and services to optimize the supply chain. Dematic employs over 7,000 skilled logistics professionals to serve its customers globally, with engineering centers and manufacturing facilities located around the world. Dematic is one brand under the KION Group of companies and has implemented more than 6,000 integrated systems for a customer base that includes small, medium and large companies doing business in a variety of market sectors.\n\nHeadquartered in Atlanta, Georgia, Dematic is a member of KION Group, a global leader in industrial trucks, related services and supply chain solutions. Across more than 100 countries worldwide, the KION Group designs, builds and supports logistics solutions that optimize material and information flow within factories, warehouses and distribution centers. The company is the largest manufacturer of industrial trucks in Europe, the second-largest producer of forklifts globally and a leading provider of warehouse automation.\n\nThe Role\n\n\nPosition Summary:\n\nThis is an exciting opportunity to join the Software Center of Excellence of Dematic. As part of this global team of software experts, you will help develop robust organizational capabilities in sales, design, engineering and support to deliver exceptional software to our customers.\n\nAs a specialist, you will own end-to-end implementation of analytics & IoT engagements with Dematic customers, while driving the services pipeline as well as be a key voice internally for the further development of the analytics services program. This is both a cross-functional role within the organization as well as a key customer interfacing role. A successful candidate will have demonstrated exceptional performance, innovation, creativity and insight in a similar role.\n\nKey Responsibilities (Problem Solving, Critical Thinking):\nWorks with customer end-users to define analytics & IoT solution requirements and works with internal team to concept, design and deliver solution\nWorks independently, within teams, and with multiple types of skillsets (business, data architect, other technical resources)\nPerforms business process analysis, mapping and design\nEnsures high quality delivery of software consulting services and overall client satisfaction\nDrives development and documentation of services\nDisplays depth of knowledge to customers during sales-phase while representing breadth and depth of Dematic solutions and expertise\nSupports the sales organization and drive pipeline generation of analytics consulting services\nWhat We Are Looking For\n\n\nEducation:\n\nBachelor's Degree and/or advanced degree\n\nKnowledge / Qualifications:\n\nThe qualifications for the position of advanced analytics & IoT include proven success in Client Management, Project Management, and Consultative Selling and Services Delivery. Other important areas of experience and skills include:\nExperience working with business users to concept, generate and deliver analytics solutions, dashboards and reporting\nOverall knowledge of MHE technologies and warehouse systems or similar domains is preferred\nSpecific domain experience and knowledge in the logistics and supply chain industries is a plus\nExcellent written and verbal communication skills including presentation skills and knowledge of software tools (MS PowerPoint, MS Visio)\nStrong leadership and customer engagement skills\nA willingness to travel in order to satisfy client needs\nExperience conducting requirements analysis, meeting with business stakeholders and applying solutions to customer challenges\nWorking knowledge of advanced analytic tools such as SAS, R, or Python is required\nWorking knowledge of data visualization tools such as Tableau, QlikView, or Domo is required\nWorking knowledge of BI (business intelligence) or analytics tools preferred\nWorking knowledge of Microsoft SQL Server and/or Oracle databases is preferred\nWorking knowledge of cloud based technologies is preferred\nAt least 3 years of experience in a related role\nTo apply to this job, click Apply Now"}, "560": {"company": "American Family Insurance", "description": "At American Family Insurance, we\u2019re driven by our customers and employees. That\u2019s why we provide more than just a job \u2013 we provide opportunity. Whether you\u2019re already part of our team in search of a new challenge or new to our company and ready for what\u2019s next, you\u2019re in the right place. Every dream is a journey that starts with a single step. Start your journey right here. Join our team. Bring your dreams.\n\nQuick Stats:\nJob ID:\nR13317 Data Scientist III (Open)\nSummary:\nDevelops, analyzes and models operational, economic, management, accounting and other organizational data to quantify the competitive performance of business segments, evaluate potential operational changes, and design new approaches and methodologies. Analyzes organizational data to recommend solutions to new and complex problems, develops innovative strategies, quantifies the competitive performance of the organization's operations and/or markets; models and evaluates the potential impact of changes. Applies and integrates statistical, mathematical, predictive modeling and business analysis skills to manage and manipulate complex high volume data from a variety of sources.\nResponsibilities:\n\n\nTravel Requirements\nThis position requires travel up to 10% of the time\nEducation/Licenses/Designations\n\nPreferred: Master's Degree in Mathematics, Statistics, Physics, Computer Sciences or Engineering, or related field; PhD strongly preferred\n\nSpecialized Knowledge and Skills Requirements\nDemonstrated experience providing customer-driven solutions, support or service.\nAbility to work as part of a team and to communicate effectively.\nProficiency in programming languages suitable for database access, scripting, statistical analysis, and system development. Understanding of software development best practices including source control, coding standards and testing frameworks.\nDemonstrated experience communicating complex findings in a clear and concise manor to divisional management.\nDemonstrated experience developing and managing complex projects.\nExperience shaping the strategy for projects to deliver maximum business value\nDemonstrated experience formulating, approaching, and solving complex analytical problems using a quantitative, scientific approach.\nDemonstrated experience working with large, complex datasets using big data technologies and script.\nDemonstrated knowledge and understanding of managing data to scale using data summarization, query, and analysis software and tools.\nAdditional Job Information:\n\n\nDepending on qualifications, we are open to considering candidates at the appropriate level.\n\nTop candidates will have an advanced degree (PhD or MS) in Computer Science or Computer Engineering.\n\nCandidates with experience in one or more of these disciplines preferred: NLP, Image, Video, or Speech.\n\nAdditionally, the following skills are definitely a plus: cloud computing skills (open to platform, Python coding skills, Hadoop, Hive, and Spark/SQL.\n\n\nJob Description:\n\n\nPrimary Accountabilities\nCreates business application and modeling framework, for new datasets, and discovers insights and relationships from large/complex datasets through investigative research using advanced mathematical and/or statistical techniques.\nExplores data using a variety of advanced statistical techniques to proactively identify relationships, create insights and answer business questions or guide future model development.\nBuild the hypothesis, identify research data attributes and determine best approach to address business issues.\nCombines business acumen with mathematical capabilities to build complex predictive models to support business objectives.\nBuilds complex programs for running mathematical or statistical tests on data and for understanding complex relationships across attributes.\nIncorporates findings and provides industry and competitor insights as part of model development and enhancement.\nResearches and maintains awareness of industry best practices and business strategies.\nBrings new and innovative ideas and approaches to develop business solutions.\nMonitors industry and competitor trends to determine potential impact to predictive models.\nIncorporates findings and provides industry and competitor insights as part of model development and enhancement.\nIdentifies, leverages and develops expertise in emerging technologies, open source tools, and harnesses new techniques (e.g., machine learning).\nNetworks with and contributes thought leadership to the broader external analytics community. Builds awareness of leading techniques, tools, and data resources.\nAssists with complex research or analytics projects related to large, complex business initiatives.\nInteracts with company senior leadership to inform on industry trends and emerging research topics. Serves as internal expert for new areas of analytics exploration.\nStay connected: Join our Talent Community!\n\nLI:DB1\nApply Now: click Apply Now"}, "561": {"company": "Memorial Sloan-Kettering", "description": "Company Overview\n\n\nAt Memorial Sloan Kettering (MSK), we\u2019re not only changing the way we treat cancer, but also the way the world thinks about it. By working together and pushing forward with innovation and discovery, we\u2019re driving excellence and improving outcomes. For the 28th year, MSK has been named a top hospital for cancer by U.S. News & World Report. We are proud to be on Becker\u2019s Healthcare list as one of the 150 Great Places to Work in Healthcare in 2018, as well as one of Glassdoor\u2019s Employees\u2019 Choice Best Place to Work for 2018. We\u2019re treating cancer, one patient at a time. Join us and make a difference every day.\n\nJob Description\n\n\nWe are seeking a Data Analyst for the Division of Quality and Safety at MSK. With regular accountability to the Deputy Physician-in-Chief, you will work closely with physicians and administrative leaders to consolidate, analyze, and report data from a variety of sources and systems for quality assessment and performance improvement purposes.\n\nAdditionally, you will facilitate integration and evaluation of data central to care redesign, collaborate with department quality leaders to define quality improvement opportunities, provide statistical programming, and project support for a number of ongoing/future projects and serve as a departmental subject matter expert.\n\nCurrent or upcoming projects:\nUtilize various tools and quality databases to screen, monitor, and prevent potential high-risk adverse events across the institution.\nOngoing data-driven measure development in tandem with various services for more effective quality assessment and maintenance, performance outlier analysis, and accreditation purposes.\nAbout our current team:\n\nWe focus on data analytics/reporting and application development. The team consists of developers and analysts, with two managers reporting to the Associate Director. The Data Analyst role will report Project Manager. There is a high level of collaboration amongst the team but individual project ownership is promoted as well.\n\nWhat's exciting and unique about this opportunity:\n\nWe love to see our employees grow and are supportive of learning and training for relevant certificates of interest. There is flexibility on doing work that you\u2019re passionate about. We are owners of several quality initiatives that have institution-wide reach and are enhancing the patient experience on a daily basis.\n\nYou Need:\nDegree in a quantitative field, such as biostatistics, applied mathematics, engineering, or economics.\nExcellent analytical and problem-solving skills with an ability to develop creative solutions for complex problems.\nExcellent verbal and written communication skills, with the ability to share ideas in both technical and user-friendly language.\nAble to develop effective relationships with individuals at all levels.\nAbility to develop SQL code as needed to extract and manipulate data from clinical, hospital-based, ambulatory, and claims-based databases.\nAbility analyze and visualize cancer care data with tools like R, Python, SAS, MS Reporting Services, Pandas, or Tableau\nAbility to work both independently and as part of a team to identify, measure, and address opportunities for quality improvement.\nIntellectual curiosity and ability to independently critically think.\nNice to have:\nAdvanced degree in statistics, mathematics, or related quantitative/analytical field\nExperience with Electronic Medical Records systems\nFamiliarity with common medical terminologies (e.g. ICD, SNOMED, CPT, LOINC)\nFamiliarity with national clinical quality initiatives and performance improvement measures\nExperience writing and presenting reports of statistical findings for publication or conference proceedings.\nKnowledge of a production programming language (e.g., C#, C++, Java)\n**Please include a link to your github on your resume**\n\n#LI-POST\n\nClosing\n\n\nMSK is an equal opportunity and affirmative action employer committed to diversity and inclusion in all aspects of recruiting and employment. All qualified individuals are encouraged to apply and will receive consideration without regard to race, color, gender, gender identity or expression, sexual orientation, national origin, age, religion, creed, disability, veteran status or any other factor which cannot lawfully be used as a basis for an employment decision.\n\nFederal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.\nStart your job application: click Apply Now"}, "562": {"company": "Guild Education", "description": "Guild is hiring for a Decision Scientist who will sit at the intersection of data, product, technology, business operations, and internal strategy, to help inform Guild's most interesting business needs. You will work across the company to serve as a thought partner and data expert to help drive data driven decisions, build algorithms and tools.\n\nAs a Decision Scientist you will:\nServe as the primary analytics partner for operating teams across the organization including Marketing, Enrollment, Partnerships, Retention Services and Student Operations to help teams make the best data informed decisions by deeply understanding trends, advising on best practices for collecting data, and building statistical models\nMine structured and unstructured data to identify trends and run descriptive, predictive, and prescriptive analyses\nAggregate data from disparate data sources to help identify areas for product, operations, and marketing growth and optimization\nWork with product and engineering teams to collect new data and ensure data is captured in a way that it can be used to help the business grow\nDesign, develop, and deploy a/b tests and algorithms to help better serve our students\nServe as a cross-functional consultant to inform strategic and operating business questions. This could include uncovering a problem, identifying data sources to quantify the problem, synthesizing findings and solutions, analyzing the business case and tradeoffs, and managing the implementation of recommendations.\nLead special projects as they are identified\nIn addition to working on the Decision and Data Science team, in this role you will collaborate with other Guild leaders including: Noah Yetter (Staff Data Engineer), Katie Corder-Paul (Director of Student Operations), and Christine Hettinger (Group Product Manager).\n\nYou are a strong fit for this role if you have:\n5+ years of experience in decision science, data science, analytics or a related technical role in a fast-paced business or start up environment\nProven business experience with a scripting language like Python or R, SQL (Redshift/Hive/Presto experience preferred), Excel/Google Sheets, and BI Tools (Looker a plus)\nAnalytical, intellectually curious, excellent problem-solver who is comfortable working with messy and unstructured data and translating it into strategic recommendations.\nStrong written and oral communication skills - you can build analytical and decision support models, synthesize recommendations, and create effective presentations for all audiences\nTeam player mindset, with strong interpersonal and influencing skills\nPassion for our mission \u2013 Guild is pioneering a new path for education as a benefit in a complicated and regulated space \u2013 success means quickly and effectively adapting your expertise\nSomething else? Wonderful, we're curious to learn more about you!\nAbout Guild:\n\nGuild is increasing economic mobility for working adults by partnering with the largest employers in the country to offer education as a benefit to their employees via our marketplace of nonprofit universities and education institutions. Guild's proprietary technology platform facilitates the administration of this innovative benefit and our team of coaches helps each employee navigate the path back to school, providing individualized support from day one through program completion.\n\nWe also just became the latest female-led company to hit a $1billion valuation and the only B-corp with those qualifications. Our Series D round was led by Ken Chenault, General Catalyst Partners chairman and former CEO of AMEX, and joined by Emerson Collective, LeadEdge Capital, and Iconiq.\n\nGuild Education is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\nTo apply to this job, click Easy Apply"}, "563": {"company": "Flexential", "description": "Marketing Data Scientist\n\nGeneral Description\n\nThe Marketing Data Scientist, a strategic role in Flexentials expanding marketing team, will aggregate and analyze existing intelligence and source new data to optimize go-to-market efforts and inform internal cross-functional strategic initiatives to increase the overall success rate of marketing pipeline, processes and programs. Reporting to the Sr. Director of Marketing Operations, this experienced data scientist, will have a business-first acumen, deliver data insights that enable us to develop a deep understanding of the B2B enterprise technology buyers, and the ability to discover and present actionable insights to leadership to stimulate revenue growth, maximize marketing return on investment (ROI) and enhance overall customer experience.\n\nResponsibilities\nProvide marketing team with data insights to inform strategy on customer segmentation, customer and prospect targeting for marketing programs and to inform strategic new product introductions, including the identification of upsell and cross-sell opportunities\nProvide data, information, and analysis to help business decision makers to make measurably different decisions than they would have otherwise\nFind net new insights in a creative way to find that aha moment to connect with business strategy\nUse data, analytics and business acumen to help guide strategy by identifying target market profiles and a hypothesis for Ideal Customer Profile (ICP) and propensity to buy\nWillingness to support organization wide related requests at it relates to marketing data sets\nPredisposition to hypothesize, test, revise, always working to improve and evaluate models\nUse advanced techniques that integrate traditional and non-traditional datasets and method to enable analytical solutions\nApply predictive analytics, machine learning, simulation, and optimization techniques to generate management insights and enable customer-facing applications\nParticipates in building analytical solutions leveraging internal and external applications to deliver value and create competitive advantage\nIntegrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.\nConducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.\nSupports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation.\nTranslates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions.\nSkills\nDatabase Technology: Competently and independently navigate relational data systems to produce their own datasets for analytical purposes (i.e. use T-SQL to write complex queries to retrieve data from enterprise level RDBMS systems)\nScripting: Independently craft custom scripts to tackle technical challenges that arise as part of the analysis process (i.e. write a Python script to move data between a transactional system and an RDBMS system)\nMachine learning: Strong interest in machine learning principles including statistical analysis, model creation and training and application of custom analytical models\nRequirements\nBachelors Degree in finance, analytics, data science or a related field of study\nMinimum of 5 years of experience in analytics, market insights, marketing strategy or similar role within the B2B enterprise technology space IT services preferred\nStrong understanding of marketing performance concepts and attributes, as well as corporate financial key performance indicators\nExceptional project management skills, detail orientation and complex problem-solving ability\nStrong interpersonal, verbal communication and presentation skills, with ability to tailor to varying audiences and stakeholders\nA cross-functional collaborator with the ability to relentlessly drive outcomes that benefit the business\nHigh level of proficiency in and understanding of marketing and sales force automation platforms (e.g., Marketo, SFDC), business intelligence tools (e.g., Qlik, Tableau, Domo), databases (e.g., Oracle, SQL) and Microsoft Office Suite\n\nStart your job application: click Apply Now"}, "564": {"company": "MLB.com", "description": "Senior Software Engineer\n\nReporting to: Sr. Director of Engineering, Baseball Data\n\nLocation: New York, NY\n\nLaunched in 2001 as the tech arm of Major League Baseball, MLB.com is renowned for creating experiences that baseball fans love - and we're just getting started!\n\nJob Overview:\n\nThe new Machine Learning team at Major League Baseball builds and maintains models to analyze and evaluate what's happening on the field. As part of the Baseball Data department, we leverage tracking data from individual plays and players to develop solutions using data science, machine learning, deep learning, and computer vision. While we do work on projects that may not be public, much of our work can regularly be seen on broadcasts.\n\nWe are responsible for taking projects from the initial ideation phase into data exploration and model training in shared Jupyter notebooks and into production. We use specialized toolchains that help with scheduled orchestration of ETL processes, model (re)training, and a large amount of real-time data. We are moving towards Google BigQuery as our Data Warehouse platform. We love Python, and regularly develop complex Python scripts to interact with APIs and SQL datastores.\n\nThe Software Engineer will be responsible for accelerating and solidifying the infrastructure and services upon which our work relies. This includes creating, optimizing, and scaling the data pipeline to support this work. The Software Engineer will be crucial to the Machine Learning team's ability to produce and deliver, and will interact with our team of Data Scientists and Machine Learning Engineers on a daily basis.\n\nResponsibilities:\nProduce High Impact Work - As a core member of the Machine Learning Team, you will build, evolve, and scale state-of-the-art machine learning system infrastructure powering MLB's data and ML platform. Your work will have a direct impact on our business' bottom line.\nEmploy a Broad Range of Technology - You'll have the freedom to use the right tools for the job, whether it's vanilla SQL or a distributed processing framework such as Apache Spark. We run our processes within Amazon Web Services and Google Cloud Platforms' ecosystems, so we can take advantage of their managed services such as DataProc, DataFlow and Kubeflow -- if they help us get the job done better or faster.\nLeverage Diverse Data Sources - You'll work with many data sources, including:\nPlayer tracking and pose estimation data, as well as ball tracking data which powers MLB's Statcast\nUser interactions with our MLB.tv and Video on Demand products.\nVideo clips from every pitch of every game\nBuild and Support - You will own and operate deep learning training systems, models serving systems, and dataset management pipelines. You'll embrace the DevOps mentality to build and support data applications in the cloud. You'll deploy using infrastructure as code.\nBasic Qualifications:\nExpertise in Python, specifically interacting with data APIs and automating tasks.\nExpertise in SQL.\nExperience with standard software engineering methodology, e.g. unit testing, code reviews, design documentation.\nExperience working with large (Terabyte-scale) data sets\nExperience with an MPP Data Warehouse such as BigQuery, Redshift, or Teradata\nExperience with cloud infrastructure.\nComfort in a Linux environment and with basic server administration tasks.\nSignificant experience with Data Engineering or ETL Engineering.\nPreferred Qualifications:\nPrevious experience supporting Machine Learning modeling or its product integration\nExperience with any/all of the following:\nApache Airflow\nGoogle BigQuery\nDevOps - Jenkins/Ansible/Terraform\nDocker / Kubernetes\nExposure to ML techniques and programming\nExperience in deep learning model training\nExperience with data processing and storage frameworks like Google Cloud Dataflow, Hadoop, Spark, Cassandra, Kafka, etc.\nTo apply to this job, click Easy Apply"}, "565": {"company": "Sojern", "description": "About Us:\n\nSojern's mission is to help travelers go from dream to destination by showing the right travel ad at the right time to the right person, and we use technology and our significant data advantage to make that happen.\n\nOur customers are hotels, airlines, cruise lines and tourist attractions. Sojern has delivered over $13B in traveler bookings through advertising on their behalf; Our relentless focus on driving customer value and performance has grown our customer base to more than 8500 customers and helped us become a profitable, privately-held company. In late 2018, we closed a $120M Series D funding round with Technology Crossover Ventures to further accelerate our growth.\n\nIn addition to having the upside of a Series D startup at Sojern, Sojern's work culture encourages work-life balance with traditional working hours, flexible time-off and company-wide volunteer goals. Need more convincing that Sojern is a great place to work? Check out our Glassdoor reviews!\n\nAbout the Team:\n\nThe Data Science Engineering team develops methods to optimize advertising campaigns, defines new methods for measuring campaign performance, and applies machine learning at scale with more than 5000 models in production. Example projects include:\nBayesian statistics to model conversion rates and revenue\nThompson sampling and linear programming to balance campaign objectives\nStratified sampling and power analysis to run controlled experiments\nUsing Tensorflow and XGBoost on Kubeflow to predict a traveler's propensity to convert\nAnd as a part of engineering, we own the full data product life-cycle: from analysis and prototyping to production development.\n\nThe Role:\n\nWe are looking for a Senior Data Science Engineer to drive data science impact.\n\nThe Experience We're Looking For:\nYou have hands-on experience building production-level ML and data products.\nYou have expert-level understanding of data science topics.\nYou have at least 2 years experience as a data scientist with at least 1 year of experience within the Ad Tech ecosystem.\nYou have an MS or PhD in computer science or a quantitative discipline.\nThe Skills You Bring:\nYou write production code in Python, and can reason about algorithmic efficiency.\nYou effectively communicate with data scientists, engineers and product managers.\nYou work independently to solve data science challenges.\nYou use your grit and initiative to fill in gaps and drive projects to completion.\nThe Value You Deliver:\nYou drive technical impact by making meaningful, well-designed, reusable, efficient contributions to data-driven products.\nYou mentor and participate in code/design reviews.\nYou partner with product managers to improve requirements.\nYou innovate in the context of trade-offs.\n\n\nPerks:\nOpportunities: Be part of a growing team with training and support to help you grow\nOwnership: Lead creative and challenging projects\nGive Back: We give 40 hours a year to volunteer and organize office volunteer programs with local organizations\nCulture: Strong core business values, focus on teamwork, vibrant, social and fun environment\nSnacks: Variety of snacks in the office\nMeals: Monthly catered lunches & happy hours\nCompetitive Localized Benefits\nIATA Travel Discount\nTime Off: Flexible vacation days\nAt Sojern, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\n]]>\nApply Now: click Apply Now"}, "566": {"company": "IQVIA", "description": "IQVIA is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.\n\nJob Description\n\nThe IQVIA Advanced Analytics team is one of the leading healthcare analytical teams in the world. Joining the AA team provides the opportunity to work with extremely complex data and methodologies in a fast-paced, ever-changing environment. We seek highly motivated people who truly want to make a difference in the life sciences industry. At IQVIA, we look for the very best people, and then give them meaningful work to do. we dont simply think about careers, we think about contributions.\n\nAdvanced Analytics - with departments in Philadelphia, Frankfurt, Paris, and Warsaw as well as a network of over 150 team members worldwide - is the global competence center for data science at IQVIA. Complex advanced analysis at the highest level are conceptualized and implemented to support international customers in the pharmaceutical industry - often within multinational projects. As a member of our team you can expect exciting international projects with interesting development perspectives.\n\nThe position will use large data sets to find opportunities for product and process optimization and models to test the effectiveness of different courses of action. Our data scientists have strong experience using a variety of data mining/data analysis methods, building and implementing models, using/creating algorithms and simulations. For this position, we are seeking several years of direct experience with developing algorithms and models to solve prediction problems. Awareness of various techniques available to use in predictive analytics. Using their proven ability to drive business results with their data-based insights, they will comfortably interact and work with a wide range of stakeholders and functional teams. They have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\nWhat were looking for:\nQuantitative background with advanced degrees (Master, PhD preferred) in Statistics, computer science, engineering, informatics, data science, or related field.\nIn-depth understanding of machine learning algorithms and statistical models\nAbility to manage, lead and communicate\nExperience in pharmaceutical or hospital/healthcare industry\nWhat youll be doing:\nBuild machine learning/statistical models and pipelines for solving predictive analytic tasks with electronic healthcare claims and medical records\nApply machine learning, data mining technologies in developing innovative solutions in pharmaceutical industry.\nParticipate at client meetings for complex proposals to present IQVIA advanced analytic methodologies to clients and to bring credibility for IQVIA team\nEnsure data quality throughout all stages of acquisition and processing, including such areas as data collection, normalization, transformation, embedding, visualization, etc.\nPresent study findings to clients and translate analytic outputs to business impact and recommend actions to clients to improve their business performance\nEnsure data quality throughout all stages of acquisition and processing, including such areas as data collection, normalization, transformation, embedding, visualization, etc.\nWork with IQVIA technology team to support machine-learning algorithms in big data platform to solve a variety of business problems.\nIQVIA is an EEO Employer - Minorities/Females/Protected Veterans/Disabled\n\nWe know that meaningful results require not only the right approach but also the right people. Regardless of your role, we invite you to reimagine healthcare with us. You will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve human health outcomes.\n\nWhatever your career goals, we are here to ensure you get there!\n\nWe invite you to join IQVIA.\n\nJoin Us\n\nMaking a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.\n\nForge a career with greater purpose, make an impact, and never stop learning.\n\nIQVIA is an EEO Employer - Minorities/Females/Protected Veterans/Disabled\n\nIQVIA, Inc. provides reasonable accommodations for applicants with disabilities. Applicants who require reasonable accommodation to submit an application for employment or otherwise participate in the application process should contact IQVIAs Talent Acquisition team at workday_recruiting@iqvia.com to arrange for such an accommodation.\nTo apply to this job, click Apply Now"}, "567": {"company": "Maxar Technologies", "description": "Why us?\nWe build advanced algorithms to gain analytic insights from a large range of open source and government data.\nWe enable machine learning systems, automate workflow, and design and develop custom applications for unique national-security mission.\nWe operate an end-to-end predictive analytic platform unlike any other within the US Government.\nWe provide training to expand your skills and challenges to develop them.\nOur clients missions are vital to national security, so were mission-first always.\nOur work environment is relaxed business casual.\nAt our core we believe and practice social responsibility.\n\nWhat would you be doing?\nExtracting and transforming data using programming languages such as Java and Python and associated open source data analytics libraries\nAscertaining unique ways to apply algorithms to derive specific customer data analytic results\nApplying big data analytics tools to large, diverse sets of collection data to assess risk of adverse threat activities\nExtending existing algorithms as required to support customer requirements\nApplying data science methods to create and data feeds to generate models that perform predictive analytics using a variety of approaches (such are natural language processing, association rule mining, etc.)\n\nMinimum Qualifications:\nMust have a current/active TS/SCI and be willing and able to obtain a CI Polygraph\nRequires 5 or more years of relevant experience\nRequires a Bachelor's degree in Engineering, Math, Physics, Computer Science or related field.\nExperience in at least one of these languages: R, VBA, Java, C++, SQL, Python\nDevelopment experience in a Linux/Unix/Windows environment\nOccasional local travel to government sites for customer meetings and demonstrations\nExperience conducting model feasibility research and algorithm development for machine learning\nExperience with distributed datasets and experience analyzing both relational and NoSQL data structures\nExperience working in an Agile environment,\nExperience developing and testing models\nExperience with Data Analytics\n\nDesired Skills:\nGraduate experience working with probabilistic and stochastic statistical analysis or computational intelligence\nAscertaining unique ways to apply algorithms to derive specific customer specific data analytics results\nApplying big data analytics tools to large, diverse sets of collection data to assess risk of adverse threat activities\nExtending existing algorithms as required to support customer requirements\nKnowledge of technical aspects of ISR systems\nExtracting and transforming data using programming languages such as Java and Python andassociatedopensourcedata analytics libraries\nExceptional oral and written communications\nOrganizational skills and excellent attention to detail\nCapability to work effectively in a geographically distributed development team\nStart your job application: click Apply Now"}, "568": {"company": "PayPal", "description": "Responsibilities:\n\nRisk Analytic Data Scientists are highly motivated team players who specialize in the investigation of fraud patterns and the creation of advanced proprietary fraud prevention components. Our researchers overcome challenges presented by big data, evolving fraud techniques and new payment technologies by leveraging domain expertise, story-based analytics and advanced mining algorithms. They lead the research and accompany the development of advanced components which help drive PayPal's competitive edge by providing accurate, split-second decision making capabilities in a high-risk environment.\n\nThe ideal candidates are problem solvers, equipped with strong analytical & quantitative skills suited to approach various kinds of challenges in complex environments. Adept at creative and critical thinking, they are able to deconstruct problems and transform personal insights into large scale, state-of-the-art solutions. Candidates must be quick learners with a strong sense of personal responsibility and a technical orientation.\n\nRequirements:\nBachelors Degree in Mathematics, Physics, Computer Science, Statistics, Engineering or similar.\nStrong analytical skills\nCode writing capability in any programming language (Python, R, Java, etc.)\n1-2 years related work experience\nExperience in Machine-Learning, Data Mining or Statistics an advantage\nHadoop experience (MapReduce, PIG, Hive, Spark) an advantage\nQuick-thinker, fast learner, wide general knowledge, problem solver\nTeam worker, responsible, delivery-oriented\nTo apply to this job, click Apply Now"}, "569": {"company": "PayPal", "description": "What does Success Look Like?\n\n\nIn your role as a Senior Data-Scientist, you will:\nWork with partners to translate business challenges into Data Science problems\nMine data and extract information in PayPals Big (!) Data environment\nLeverage Machine Learning algorithms to solve real-life problems\nWork with engineers and product managers to develop and deliver E2E data science driven solutions that bring real business value\nAnalyze various kinds of data to conclude actionable insights\nCarry out independent research and innovation in new content and technological domains, while supporting existing projects\nAbout You\nMasters, PhD, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.)\nProduct/Marketing data science work experience an advantage\nCode writing capability in any programming language (Python, R, Java, Scala, etc.) and familiarity with relevant ML packages\nHadoop experience (PIG, Hive, Spark)\nStrong analytical skills\nExcellent spoken and written English\nTeam worker, responsible, delivery-oriented\nStart your job application: click Apply Now"}, "570": {"company": "Sub Rosa", "description": "OVERVIEW\n\nSub Rosa is a strategy and design practice headquartered in New York\u2019s West Village. We create strategies and solutions that empower leaders and evolve organizations. Our work is grounded in Applied Empathy, a methodology created by Sub Rosa that brings insights and action together to drive change.\n\nROLE DESCRIPTION\n\nThe problems we\u2019re facing haven\u2019t been solved before. We need smart, creative and tenacious minds to help achieve our vision of automating the process of finding real time correlations and patterns in large, unstructured and disparate datasets. These insights will be used by global marketers across the Fortune 100 to inform their next great marketing decisions and creative campaigns.\n\nWe\u2019re seeking a senior machine learning engineer with a breadth of academic and/or work experience in machine learning algorithms such as SVMs, Logistic Regression, Naive Bayes, LSTM, DB Scan, k-NN, etc. In collaboration with the NLP and Data Science experts on the team, the senior machine learning engineer will choose the best algorithm for each situation, tune hyperparameters, provide relevant feature engineering and feature reduction, utilize existing tools and APIs where available and implement appropriate peer-reviewed research paper solutions when pre-existing tools are not available. Our current datasets are large social media datasets (unstructured- and semi-structured-text) that are analyzed in real-time. Future datasets may include images, video, and structured datasets of retail purchase lists, consumer marketing surveys, dynamic geolocation data, etc.\n\nYou won\u2019t find cubicles or drawn-out bureaucratic processes here. You\u2019ll be joining a quickly growing startup team with the mentality, culture and office space to match, but still embedded within a larger company that offers stable funding and organizational creature comforts such as great benefits, 401k safe harbor matching, HR, receptionist, etc. You\u2019ll have your personal choice of laptop and access to snacks, Nespresso coffee machine, sparkling water, alcoholic beverages, video game area (PS4, Switch, N64), a large fluffy white dog (most Fridays), fantastic new whiteboards and markers (team tested and approved), roof deck for BBQs and lounging, free in-house yoga classes on Wednesdays, and happy hours on Fridays. Team members regularly attend relevant industry conferences, workshops, and trainings. Optional team events are a common occurrence and have already spanned from Laser Tag at Chelsea Piers, Axe Throwing at Kick Axe, shooting pool at Fat Cats, and drinks at the Biergarten under the Highline. We take our work and our play seriously.\n\nIf this sounds exciting, we want you to join our initial core team of extremely bright developers and product strategists as we build the first prototypes and develop the commercial version of the product that will be used by brand managers, audience strategists and product managers of the world\u2019s largest advertisers.\n\nRequirements:\n\u2022 Wide range of Machine Learning (ML) expertise with algorithms such as SVMs, Logistic Regression, Naive Bayes, LSTM, DB Scan, k-NN, etc.\n\u2022 5+ years of experience building machine learning systems\n\u2022 Strong analytical and problem-solving skills\n\u2022 Strong programming skills in Python for solutions prototyping\n\u2022 Preference in working in a collaborative team development environment\n\u2022 While no academic credentials are required for this role, we expect that most candidates will have a MS/PhD/Doctorate in Computer Science or a related Machine Learning (ML) field.\n\n*Disclaimer\nAll candidates that apply are requested to take a mandatory HackerRank test online and provide up to two references. Additionally, they must have the legal right to work in the US as we are unable to provide employment visas at this time.\nTo apply to this job, click Easy Apply"}, "571": {"company": "PayPal", "description": "Responsibilities:\n\n\u2022 Provide business requirements and collaborate with internal teams on data capture strategy that will support advanced analysis and insights on sales pattern and consumer behavior \u2022 Design and implement data-driven systems that increase sales success\n\n\u2022 Explore new data sources to add signal to existing models and develop models for new sales opportunities\n\n\u2022 Define key sales performance metrics and create dashboards and reports that provide ongoing insight to business stakeholders\n\n\u2022 Perform ad hoc and in-depth analyses and then reporting/presenting insights\n\n\u2022 Surface insights on the sales conversion pipeline, customer segmentation, and customer success\n\n\u2022 Develop advanced and predictive models such as customer segmentation, lead prioritization, churn prediction and assist sales teams in using these models\n\n\u2022 Automate analyses and build analytics data pipelines via SQL and python based ETL framework\n\n\u2022 Creating forecasts using operational and statistical tools and models \u2022 Partner with regional heads of sales to develop regional sales strategy\n\nMininum Qualifications:\n\n\u2022 MS/PhD Degree in Statistics, Mathematics, Applied Mathematics, Computer Science, Operations Research, Engineering, Economics\n\n\u2022 5+ years experience in sales analytics\n\n\u2022 Experience in querying and manipulating raw datasets for analysis\n\n\u2022 Experience with visualizations, dashboards, and reports\n\n\u2022 Experience with data modeling, machine learning algorithms, and data science techniques,\n\n\u2022 Experience explaining technical concepts and analysis implications to varied audiences and translating business objectives into analyses\n\n\u2022 Experience working independently and as a member of a cross functional team\n\n\u2022 Experience with Tableau\n\n\u2022 Experience with Salesforce.com\nStart your job application: click Apply Now"}, "572": {"company": "Chan Zuckerberg Initiative", "description": "Founded by Dr. Priscilla Chan and Mark Zuckerberg in 2015, the Chan Zuckerberg Initiative (CZI) is a new kind of philanthropy that's leveraging technology to help solve some of the world's toughest challenges \u2013 from eradicating disease, to improving education, to reforming the criminal justice system. Across three core Initiative focus areas of Science, Education and Justice and Opportunity, we're pairing engineering with grantmaking, impact investing, policy work, and movement building, to help build an inclusive, just and healthy future for everyone.\n\nOur Values\n\n\nWe believe we can help build a future for everyone.\nWe aim to be daring, but humble: We look for bold ideas \u2014 regardless of structure and stage \u2014 and help them scale by pairing engineers with subject matter experts to build tools that accelerate the pace of social progress.\nWe want to learn fast, but build for the long-term: We want to iterate fast and help bring new solutions to the table, but we also realize that important breakthroughs often take decades, or even centuries.\nStay close to the real problems: We engage directly in the communities we serve because no one understands our society's challenges like those who live them every day.\nOur success is dependent on building teams that include people from different backgrounds and experiences who can challenge each other's assumptions with fresh perspectives. To that end, we look for a diverse pool of applicants including those from historically marginalized groups \u2014 women, people with disabilities, people of color, formerly incarcerated people, people who are lesbian, gay, bisexual, transgender, and/or gender nonconforming, first and second generation immigrants, veterans, and people from different socioeconomic backgrounds.\n\nThe Opportunity\n\n\nOur mission is to support science and technology that will help make it possible to cure, prevent, or manage all diseases by the end of the century. Interdisciplinary teams of physicians, biologists, computational scientists, and engineers can expand our understanding of the human body and illness \u2014 the very science behind medicine. CZI fosters collaboration between scientists and engineers, develops tools and technologies, and builds support for basic scientific research.\n\nThe ideal candidate will have a background in a quantitative or technical field and experience working with large data sets and making data-driven decisions. If you are mission-driven, entrepreneurial, and committed to building transformative technologies, we want to hear from you.\n\nMeta is a product that helps biomedical researchers discover literature that's important to their work and delivers it in real-time to their personal feeds. Meta uses artificial intelligence to organize and track over 67 million biomedical diseases, genes, proteins, techniques, researchers, journals, papers, preprints, and more\u2014including full coverage of PubMed and bioRxiv. We believe that the complexity and scale of scientific knowledge is limiting how quickly researchers can understand, navigate and quickly make powerful connections across what is know. This is one of the fundamental challenges hindering the rate of discovery in basic scientific research.\n\nAs Data Scientist for Meta, you'll be helping bring Meta to the broader community of researchers around the world. If you want to make a difference and help accelerate innovation in science, come and join us!\n\nYou will\nLeverage data to understand product, identify areas of opportunity, and execute projects to drive growth and engagement of science product users.\nDrive projects focusing on user retention, user engagement, product-market-fit and growth, and mobile usage - working closely with product, engineering, data, research, and leadership teams.\nExplore the feedback and data about the customer experience, develop metrics as-needed, and ensure prioritization is data-driven and accommodating of short-term and long-term strategies for incorporating into the end-to-end product development cycle.\nDerive deep (quantitative and qualitative) insights around product use, stability, and performance of the customer experience across a variety of touch-points and data sets.\nSupport product team with analysis to support decision making with reports and presentations.\nUse tools like Snowflake Computing, Mode Analytics, Adobe Marketing Cloud, Google Analytics, Python, R, ETL, Excel, and many other tools to work efficiently at scale.\nManage communication and alignment across multiple partner teams.\nPartner with engineering and design to implement changes in existing products that are impactful for the customer experience and ensure the measurement of the outcomes of new product features that will launch are high quality and risks are understood.\nInform, influence, and execute new quality strategies and tactics using sound analysis and impact metrics to support your positions.\nYou have\n4+ years work experience or equivalent within tech, finance, consulting or a related industry.\nExtensive quantitative or statistical analysis experience - building product intuition, solving problems using data, and providing practical business insight using data.\nAdvanced experience in analytics supporting marketing, advertising, or growth; communicating technical content and analytical insights to multiple audiences.\nAdvanced experience with SQL.\nAbility to process and analyze data sets, and interpret them to make business decisions.\nExcellent communication skills and ability to manage a project or product.\nTo apply to this job, click Apply Now"}, "573": {"company": "Alignment Healthcare", "description": "Data Scientist:\n\nAlignment Healthcare is a data and technology driven healthcare company focused partnering with health systems, health plans and provider groups to provide care delivery that is preventive, convenient, coordinated, and that results in improved clinical outcomes for seniors.\n\nWe are experiencing rapid growth (backed by top private equity firms), our Data Science team is looking for the best and brightest data scientists. Data drives the way we make decisions. We love our customers and understanding them better makes it possible to provide the best clinical outcome and care experience.\n\nThis position will play a key role in uncovering deep insights from data using advanced machine learning technologies and advanced statistical analysis, processing very large data sets using cloud-based data pipelines, variety of analytic tools, visualizations and delivering actionable healthcare insights & solutions.\n\nProblems you will work on every day will include:\nCollaborate with key business leaders to understand their business problems and come up with analytical solutions.\nBuild end-to-end data science solutions which will improve healthcare outcomes and reduce the cost for our members.\nDevelop conversational AI solutions to improve healthcare experience of our members.\nBuild customer segmentation models to better understand our customers, and tailor the clinical outcome and healthcare care experience for them.\nDevelop scalable and efficient modeling algorithms that can work in production systems.\nCollaborate with the engineering team to build end-to-end cloud based machine learning production pipelines.\nDesign and implement online experiments and experimental frameworks\nBasic Qualifications:\nMasters in Computer Science, Engineering, Mathematics, Statistics, or related field\n2+ years relevant experience in predictive modeling and analysis.\nExcellent communication, analytical and collaborative problem-solving skills\nExperience in building end to end data science solutions and applying machine learning methods to real world problems with measurable outcomes.\nDeep understanding and experience with various machine learning algorithms, including deep neural networks, natural language processing, kernel methods, dimensionality reduction, ensemble methods, HMM and graph algorithms.\nSolid data structures & algorithms background.\nStrong programming skills in one of the following: Python, Java, R, Scala or C++\nDemonstrated proficiency in SQL and relational databases.\nExperience with data visualization and presentation, turning complex analysis into insight.\nExperience in setting experimental analytics frameworks or strategies for complex scenarios.\nUnderstanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc.\nExperience with manipulating and analyzing complex, high-volume, high-dimensionality and unstructured data from varying sources\nPreferred Qualifications:\nPhD in Computer Science or related field\nHealthcare experience\nExperience in Big Data processing technologies: Hadoop, Spark, Cosmos\nExperience in Azure, AWS or other cloud ecosystems.\nExperience in NoSQL databases.\nPublished work in academic conferences or industry circles.\nDemonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic startup environment\nPosition Location:\nOrange, California\nAlignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.\n\nIf you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.\nApply Now: click Apply Now"}, "574": {"company": "ManTech", "description": "Secure our Nation, Ignite your Future\n\nJob Summary\n\nEach day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of big data solutions to promote efficient trade and travel. Further, effective big data solutions help CBP ensure the movement of people, capital, and products is legal, safe, and secure. In response to this challenge, ManTech, as a trusted mission partner of CBP, seeks capable, qualified, and versatile data scientists to help lead the development and delivery of high-quality predictive modelling solutions.\n\nAs a Senior Data Scientist on our team, you will utilize your subject matter expertise in the application of quantitative methods, machine learning algorithms, and predictive models to address complex national and homeland security challenges. You will help your team to leverage large structured and unstructured datasets to develop and operationalize models, tools, and applications that drive optimized decision making. Project tasks include data collection, mining, data and text analytics, clustering analysis, pattern recognition and extraction, automated classification and categorization, and entity resolution to implement and enhance automated risk assessment. The products we develop provide actionable insight with real and immediate impact on the safety and security of the United States, its citizens, visitors, and economy.\n\nJob Description\nLead and perform hands-on analysis and modeling involving the creation of intervention hypotheses and experiments, assessment of data needs and available sources, determination of optimal analytical approaches, performance of exploratory data analysis, and feature generation (e.g., identification, derivation, aggregation)\nCollaborate with mission stakeholders to define, frame, and scope mission challenges where big data interventions may offer important mitigations and develop robust project plans with key milestones, detailed deliverables, robust work tracking protocols, and risk mitigation strategies\nDemonstrate proficiency in extracting, cleaning, and transforming CBP transactional and mission data associated within an identified problem space to build predictive models as well as develop appropriate supporting documentation.\nLeverage expert knowledge of a variety of statistical and machine learning techniques and methods to define and develop programming algorithms; train, evaluate, and deploy predictive analytics models that directly inform mission decisions.\nExecute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching.\nBrief project management, technical design, and outcomes to both technical and non-technical audiences including senior government stakeholders throughout the model development/ project lifecycle through written as well as in-person reporting.\nRequired Qualifications\nSignificant experience in developing machine learning models and applying advanced analytics solutions to solve complex business problems\nProficiency with statistical software packages: SAS, SPSS Modeler, R, WEKA, or equivalent\nExperience with programming languages: R, Python, Scala, Java, SQL, or equivalent\nExperience constructing and executing queries to extract data in support of EDA and model development\nExperience with unsupervised and supervised machine learning techniques and methods\nExperience working with large-scale (e.g., terabyte and petabyte) unstructured and structured data sets and databases\nExperience performing data mining, analysis, and training set construction\nMasters degree in operations research, industrial engineering, mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience\nDesired Qualifications\nExperience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop)\nProficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc.\nProficiency with Supervised Machine Learning methods including Decision Trees, Support Vector Machines, Logistic Regression, Random/Rotation Forests, Categorization/Classification, Neural Nets, Bayesian Networks, etc.\nExperience with pattern recognition and extraction, automated classification, categorization, and entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation)\nExperience working in a team and deploying solutions in an iterative or agile/DevOps continuous integration and delivery environment using lifecycle management methods and tools\nExperience with visualization tools and techniques (e.g., Periscope, Business Objects, D3, ggplot, Tableau, SAS Visual Analytics, PowerBI)\nPh.D. degree preferred\nActive Top Secret Clearance\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS clearance is required as well as CBP suitability.\n\nMust be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) Background Investigation.\n\n#LI-FA1\n\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\n\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.\nApply Now: click Apply Now"}, "575": {"company": "Avlino", "description": "Job Description\n\n\nAvlino Inc. is seeking experienced data scientists to join our growing team\nof AI engineers, analysts, and quantitative developers. The role involves\nmodel construction, information extraction, prediction and finding solutions\nto large-scale problems for mission critical applications using large\nderived from a broad spectrum of domains for industry specific sectors. The\nideal candidate will have comprehensive expertise in machine learning,\ntime-series analysis modeling, statistical data analysis, and deep neural\nnetworks. Experience with dynamic programming and reinforcement learning is\na plus.\n\nDemonstrate your experience in creating real-world artificial intelligence\napplications using pulsing customer data sets!\n\nThis is a great opportunity for an experienced Data Scientist with 4+ years\nof relevant experience to work in a fast-paced environment where they can\nshare their passion for numbers and AI.\n\nResponsibilities\nDevelop, implement, and use a broad set of machine-learning models and\nquantitative techniques for prediction and classification for mission\ncritical applications.\nTo find problems in industrial and service sector applications.\nStrong background in numerical techniques, optimization, and gradient\nmethods.\nDevelopment of new machine learning algorithms and/or substantial\nmodification of pre-existing techniques.\nAnalysis of high-volume, noisy, heterogeneous real-time data.\nCollaborate with business analysts to transform customer needs into\nactionable insights.\nDesign custom end user reports that are easy to read and interpret for\nmultiple business unit audiences.\nArchitect the next generation analytical platform.\nCapable of de novo implementation of mathematical models, or to avail\nwidely used open source programming platforms and libraries (Scala, R,\npython, TensorFlow).\n\nRequirements\nMUST: Solid 5 years of experience in machine learning, statistical\nmodeling, data mining, time-series forecasting, and neural networks.\nMUST: Solid 5 years of experience working with big data technologies\ndistributed computing such as Hadoop/Spark, Map/Reduce, TensorFlow.\nMUST: Solid 5 years of experience in multiple programming languages \u2013\nC#/.NET, C++, C, Scala, Python, R, Java.\nExperience in developing or implementing enterprise class Data Analytics\nand BI solutions.\nExtremely analytical and able to solve problems independently.\nAssesses customer requirements and translate them to appropriate\ndeliverables.\nMUST: Have an analytical mind, and on point with detailed specifics.\nMUST: Education: MS/Ph.D. (Preferred) in Computer Science, Physics, or a\nrelated discipline.\nPLUS: Experience in the logistics or transportation industry.\n\nApply Now: click Easy Apply"}, "576": {"company": "MassMutual", "description": "Position Summary:\n\nMassMutuals Advanced Analytics group is seeking an exceptional, highly motivated and self-directed data scientist. In this role, you will perform data-driven research, problem solving, and algorithm development through the systematic application of mathematics, statistics and computer science as well as cutting edge data technologies. Results of this work manifest themselves in a variety of ways, including interactive visualizations, presentations, publications, web applications, predictive algorithms, and APIs.\n\nThis is an opportunity to join a small but growing high performing team with diverse backgrounds in applied math, computer science and physics that have been tasked with developing, maintaining and extracting knowledge from a strategic data asset. Our work revolves around studying fundamental and high impact business questions that directly impact the direction of the company and industry at large.\n\nOverall Responsibility:\nSet strategy and assume a leadership role in a domain of expertise\nDevelop roadmaps for projects and services, data, and technology\nOversee operations of algorithm and system deployments\nPartner with executive leadership to ensure alignment of data science initiatives and company strategy\nLead projects and research initiatives\nDevelop algorithms and predictive models, create prototype systems, visualizations, and web applications\nDesign and analyze experiments\nAssemble data sets from disparate sources and analyze using appropriate quantitative methodologies, computational frameworks and systems\nDisseminate findings to non-technical audiences through a variety of media, including interactive visualizations, reports and presentations\nMentor junior team members\n\nCandidate Requirements:\nIndustry recognized expertise\n7+ years working with data and relevant computational frameworks and systems\n7+ years developing of probabilistic models and machine learning algorithms\nProficient level of understanding in the following areas and an expert in at least one: machine learning, probability and statistics (esp. Bayesian methods), natural language processing, operations research\nExceptional problem solving skills and willingness to learn new concepts, methods, and technologies\nExpert in data analysis using R or Python (numpy, scipy, matplotlib, scikit-learn, pandas, etc.) programming languages\nKnowledge of HTML/CSS/Javascript, d3.js and web application frameworks (Flask, Django, Play!, etc.)\nKnowledge of NoSQL systems, Hadoop/map-reduce, Spark, Hbase, etc.\nExperience in database design and SQL\nAbility to work in a highly collaborative environment\nOutstanding communication skills (publication history a plus)\n\nEducation - M.S. or Ph.D. in a quantitative discipline (Computer Science, Statistics, Applied Mathematics, Electrical Engineering, Physics, etc.) is required\nTo apply to this job, click Apply Now"}, "577": {"company": "Johns Hopkins University Applied Physics Laboratory", "description": "Introduction:\nThe Johns Hopkins University Applied Physics Laboratory (APL) a national leader in scientific research and development, located midway between Baltimore and Washington, DC is seeking a Cyber Data Scientist.\nIn this position, you will employ engineering and data science skills to help operators improve and augment cyber defense by developing state of the art analytics, algorithms (including machine learning and deep learning systems) and visualizations, applying these solutions to current mission sets and clearly communicating insights and observations associated with deployment.\n\nJob Summary:\nThe Analytics Capability Group (QAC) is looking for Data Scientists that can develop innovative, cutting-edge prototype solutions to tradecraft-driven problems for DoD and IC customers by blending latest research and industry best practices. We are looking for technical professionals to help us develop and implement cyber technologies, machine learning approaches, analytics and visualizations to help bolster computer network defense missions.\nDuties:\nApply expertise in cyber, quantitative analysis, programming and machine learning techniques to process and interpret cyber data sets to our sponsors within DoD and IC. (80%)\nWork with sponsors to deploy, evaluate and iterate solutions to maximize effectiveness. (10%)\nDocument research approaches and analysis artifacts (5%)\nExplore promising new research and maintain/gain technical edge required for projects. Share approaches and methods. (5%)\n\nNote: This job summary and listing of duties is for the purpose of describing the position and its essential functions at time of hire and may change over time.\nRequired Qualifications:\nBachelor's degree in Computer Science, Mathematics, Engineering or related field\nProgramming and computer proficiency including hands-on experience developing with open source coding, analysis, database and visualization tools\nExtensive experience with data transformation/conversion - extracting, transforming, parsing, porting data into defined data structures\nStrong written and verbal communication and interpersonal skills (technical, non-technical)\nDesired Qualifications:\nMaster's degree or higher in Computer Science, Mathematics, Engineering or related field\nBasic to intermediate understanding of cyber systems and networking\nExperience with machine learning and/or deep learning techniques\nIntermediate to advanced skills in networking, data analysis, visualizations and cyber operations\nSpecial Working Conditions: Some limited travel to customer sites may be required.\n\nSecurity: Applicant selected will be subject to a government security clearance investigation and must meet the requirements for access to classified information. Eligibility requirements include U.S. citizenship.\n\nBenefits: APL offers a comprehensive benefits package including a liberal vacation plan, a matching retirement program, significant educational assistance, a scholarship tuition program for staff with dependents, and competitive salaries commensurate with skills and experience. For more information about our organization, please visit our web site at www.jhuapl.edu.\n\nEqual Employment Opportunity: Johns Hopkins University/Applied Physics Laboratory (APL) is an Equal Opportunity/Affirmative Action employer that complies with Title IX of the Education Amendments Acts of 1972, as well as other applicable laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, sexual orientation, gender identity, national origin, disability, or protected Veteran status.\nStart your job application: click Apply Now"}, "578": {"company": "Dassault Systemes", "description": "Data Analyst\n\nShare\n\nUnited States, IL, Schaumburg\nRegular\nFull-Time\n512623\n\nApply\n\nApply\n\nImagine new horizons\u2026.\nThe DELMIAWORKS Data Analyst reports to the, VP, Center of Excellence and is responsible for the research, collection, maintenance and preparation of data related to company metrics and operations with a focus on sales operations, metrics and reporting, market research and analysis, logistics, linguistics, and sales support. The Data Analyst will bring the sales, operations and technical expertise to understand and ensure the quality and accuracy of the data, to process, design and to present it in ways to enable the organization to make informed and accurate sales, marketing and business decisions.\n\nThe Data Analyst has responsibility for supporting sales operations, managing the master data set, developing reports, data models, visualizations and troubleshooting data issues to resolution. To succeed in this role requires strong attention to detail in a sales operations environment, experience as a data analyst, and a deep understanding of CRM and BI tools and reports.\n\nWhat will your job be?\nUsing DELMIAWORKS data and market data as required interprets the data, analyzes results using best practice statistical techniques and provides, metrics and metrics analysis, reports, visualizations including but not limited to reports to manage the corporate business, finance, sales, marketing, professional services and product performance, etc\nDevelop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality\nAcquire data from primary or secondary data sources and maintain databases / data systems\nIdentify, analyze, and interpret trends or patterns in complex data sets\nFilter and \u201cclean\u201d data by reviewing reports, printouts, and performance indicators to locate and correct code problems\nProcessing confidential data and information according to company guidelines\nUse statistical methods to analyze data and generate meaningful sales and business reports/presentations/visualizations using BI reporting tools\nThe research, analysis and preparation of data for special projects as required\nWork with leadership team to create a prioritized list of needs for each business segment\n\nYour key success factors\n5+ years\u2019 experience as a Data Analyst or equivalent role\nTechnical expertise regarding data models, database design development, data mining and segmentation techniques\nStrong knowledge of and experience with BI reporting packages, databases, programming languages\nPossess strong knowledge of MS Office Suite, Excel (including pivot tables), Word, PowerPoint, and Outlook with overall computer skills, etc. and preparing reports and presentations as required\nWorking knowledge of CRM systems, CRM administration experience preferred\nKnowledge of statistics and experience using statistical packages for analyzing datasets\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\nAdept at queries, report preparation, visualizations and presenting findings\nHigh-level experience in methodologies and processes for managing large scale databases\nThe ability to research, analyze and prepare data for special projects as required\nProficiency in managing multiple projects effectively, with a high degree of accuracy and in a timely manner\nBachelor of Science in Mathematics, Economics, Computer Science, Information Management, Statistics or equivalent\nSuperior professional communication skills required, both verbal and written\nAn analytical mind with inclination for problem-solving\nStrong attention to detail\nSelf-starter, ability to work with autonomy in a remote environment, able to prioritize and proactively anticipate and solve critical issues\nIndependently exercise good judgment, discretion and sound reasoning in making important decisions.\nAbility and willingness to travel 20% of the time yearly\nPluses, not required\nSQL\nemail open rates\n\nCompensation & Benefits\n\nDassault Syst\u00e8mes offers an excellent salary with potential for bonus, commensurate with experience that is above average in the local community. Benefits include a choice of plans providing comprehensive coverage for medical, dental, vision care for employee & dependents as well as employee life, short & long term disability, tuition reimbursement, immediate 401K enrollment, 401K match, 3 weeks\u2019 vacation and 8 paid holidays plus 4 floating holidays.\n\nEqual opportunity\n\nIn order to provide equal employment and advancement opportunities to all individuals, employment decisions at 3DS are based on merit, qualifications and abilities. 3DS is committed to a policy of non-discrimination and equal opportunity for all employees and qualified applicants without regard to race, color, religion, gender, sex (including pregnancy, childbirth or medical or common conditions related to pregnancy or childbirth), sexual orientation, gender identity, gender expression, marital status, familial status, national origin, ancestry, age (40 and above), disability, veteran status, military service, application for military service, genetic information, receipt of free medical care, or any other characteristic protected under applicable law. 3DS will make reasonable accommodations for qualified individuals with known disabilities, in accordance with applicable law.\n\nStart your job application: click Apply Now"}, "579": {"company": "Almo", "description": "Data Analyst\n\nJob Details\nLevel\nExperienced\nJob Location\nPhiladelphia, PA - Philadelphia, PA\nPosition Type\nFull Time\nEducation Level\nBachelor's Degree\nSalary Range\nUndisclosed\nTravel Percentage\nNone\nJob Shift\nRegular Business Hours\nJob Category\nEcommerce Channel Sales and Support\nDescription\nPosition Summary:\n\nThis position is responsible for managing several software applications including: Mozenda: Web scraping tool, Power BI; Dashboards, and Ad Hoc Sales Reporting via MS Access and Excel.\n\nWhat you will do in this role:\n\nManage Web Scraping tool \u2013 Mozenda\nCheck to ensure that Almo products are properly merchandised on customer\u2019s web site\nCreate/Manage Agents for each Customer and/or Brand(s)\nCreate/Deliver exception reporting to appropriate individuals\nBuild and deliver Sales reports as needed via MS Access or Excel\nManage MAP compliance tool \u2013 PriceSpider\nPriceSpider Maintenance\nSubmit, adjust, and monitor SKU\u2019s and MAP\nInternal Communication and Monitoring\nWork with sales team to ensure MAP compliance\nOffer best practices and strategies for MAP compliance\nMonitor and research suppressed parts\nExternal Communication and Monitoring\nMonitor communication from manufacturers/Customers with regards to MAP violation notices\nM81319\nPreferred Qualifications\nWhat we look for in a candidate:\nBachelor's degree with concentration in business, math, or economics preferred\n3-5+ years of experience in related work that aligns with the responsibilities listed above\nDemonstrated expertise with Microsoft Access, Excel, and SQL\nUnderstanding of Power BI is a plus\nDemonstrated track record of consistently meeting and/or exceeding performance expectations\nDrives performance targets to completion\nStart your job application: click Apply Now"}, "580": {"company": "Silicon Valley Bank", "description": "Silicon Valley Bank is the market leader in providing financial solutions to the world\u2019s most innovative companies, leaders and investors. Our clients are the game changers fueling the global innovation economy and transforming the way we live and work. SVB has been an incredible growth story over the last 35 years and continues to grow and expand internationally. Come join a growing, global commercial bank at the heart of the innovation economy where you will be able to help bring our clients\u2019 world-changing ideas to life.\n\nThe role: as a Senior Data Scientist in Machine Learning and Predictive Analytics with the Enterprise Business Analytics team, you will be a key contributor to development and implementation of leading edge machine learning technologies. This position will be dedicated to our Early Stage Practice (\u2018ESP\u2019) which is focused on engaging and building authentic relationships with pre-Series A founders, clients, prospects and partners. Your automated machine learning solutions will ensure our ESP prospects and clients receive best practice relationship management.\nResponsibilities include:\nDevelop and implement cutting edge machine learning solutions that provide our client facing staff with foresight and direction to optimize their prospects and client interactions\nCreate and deliver clear, compelling communications to your internal business partners that demonstrate the power of your machine learning solutions\nSeek out and implement opportunities that apply machine learning to proactively alert, advise and recommend best actions to our team members.\nBachelors degree\n5 to 8 years of experience in the quantitative analytics, machine learning and/or statistics space\nDemonstrated proficiency with SQL and at least one scripting language such as Python, R, Julia or Scala\nHands on experience using machine learning techniques and deploying them into production\nSolid success integrating machine learning solutions into systems such as CRM to automatically create alerts, triggers and recommendations for client facing staff\nStrong communication skills to collaborate effectively with business partners across the company\nPreferred:\nGraduate level education in computer science, mathematics, quantitative economics, statistics or operations research, preferred\nExperience in financial services and/or an operational role in an early or growth stage company or consulting firm to early stage companies\nKnowledge of business development, customer acquisition and sales, growth, and revenue generating strategies that drive early stage company success\nMBA\nStart your job application: click Apply Now"}, "581": {"company": "T2 Biosystems", "description": "Tracking Code\n\n462-093\n\nJob Description\n\nWe are seeking an exceptional and highly motivated individual to join our team as a Principal Scientist. This position will report directly to the Associate Director, Microbiology R&D, and is based in Lexington, MA.\n\nThe Principal Scientist will be responsible for providing technical expertise in the areas of bacterial physiology and molecular biology and will provide leadership for the construction of novel bacterial strains and the cultivation of clinically relevant pathogenic organisms. This individual will work with our Microbiology team to refine established protocols and develop methods to enable production of test samples for development of novel assays in conjunction with our Assay Development team. This role will perform hands-on execution in the laboratory.\n\nResponsibilities:\n\nProvide guidance and share technical expertise with members of the Microbiology R&D group.\nOptimize microbiological cultivation methods and processes for a broad array of microorganisms.\nDevelop, refine, and execute SOPs and work instructions in the execution of protocols required for verification and validation procedures.\nDevelop microbiological methods for titer level assignment and blood spiking to support assay development.\nDevelop, establish and execute processes for preparation of spiked blood samples to support assay verification and validation activities.\nContribute to other projects and initiatives as needed.\nSkills and Experience:\n\nPhD in Microbiology or Molecular Biology and 7+ years of experience, or MSc in Microbiology or Molecular Biology and 10+ years of experience.\nTechnical expertise in microbiology with a strong background in bacterial physiology a plus.\nProven track record of managing teams towards successful completion of projects.\nDemonstrated experience in generating bacterial strains and constructs.\nExperience in technology transfer and manufacturing procedures a plus.\nExcellent organizational, recordkeeping and communication skills.\nExperience working with a broad range of clinically relevant bacterial species.\nExperience working with pathogens in a BSL3 environment a plus.\nDemonstrated excellence with data analyses and attention to detail.\nSuccessful project management experience and demonstrated ability to achieve project timelines and milestones.\nJob Location\n\nLexington, Massachusetts, United States\n\nPosition Type\n\nFull-Time/Regular\nTo apply to this job, click Apply Now"}, "582": {"company": "Johns Hopkins University Applied Physics Laboratory", "description": "Introduction:\nThe Johns Hopkins University Applied Physics Laboratory (APL), a national leader in scientific research and development, located midway between Baltimore and Washington, DC is seeking an innovative, energetic semantic web / linked data scientist.\n\nJob Summary:\nWork with our multi-disciplinary team designing and implementing semantic web-based systems for ontology-centered knowledge representation and intelligence analysis.\n\nDuties (Listed in order of importance with the estimated amount of time spent at each task):\nWork with senior software engineers, semantic web technologists, ontologists, physicists, chemists, biologists, and related field subject matter experts to implement and deploy systems for analyzing big data within the realm of intelligence analysis. (40%)\nConceive and design innovative methods for employing semantic technologies to the counter-WMD and intelligence analysis problem sets. (10%)\nResearch and develop systems concerned with semi-automated or automated ontology construction alignment. (10%)\nIntersect semantic web / ontology based approaches with Natural Language Processing, Information Retrieval, and Data Mining techniques to make novel advancements in practical application and research of data science and analysis.(15%)\nDecompose real-world mission gaps into problems sets that can be addressed using set, information, and graph theoretic approaches. (10%)\nSupport system deployment, troubleshooting and user training. (10%)\nAuthor and present papers on current research activities. (5%)\nNote: This job summary and listing of duties is for the purpose of describing the position and its essential functions at time of hire and may change over time.\n\nRequired Qualifications:\nPh.D. or M.S. in Computer Science or similar academic discipline. Candidate must have strong understanding of core Computer Science academic theory regardless of degree. Practical experience building applications using standards and technologies falling within the semantic web stack (e.g., Jena, Sesame, Triple / Quad Stores). Proficiency with Resource Description Framework (RDF), Resource Description Framework Schema (RDFS) and SPARQL Graph Query Language, or similar technologies. Strong understanding Web Ontology Language (OWL), including the use of advanced features such as property restrictions, language profiles, consistency checking, and logical inference. Familiarity with Ontology engineering practices and modeling tradeoffs. Familiarity with and willingness to adopt upper ontology principles of Basic Formal Ontology (BFO) in systems design. Intermediate to advanced level of proficiency in object-oriented software engineering principles and including proficiency in software development using one or more modern languages such as Java and Python. Comfortable in an environment where only high-level requirements may exist in absence of a fully-defined detailed project schedule. Ability to creatively contribute towards developing new requirements by identifying customer needs and applying expertise and knowledge of available methods, tools, and concepts to those needs. Ability to own a task and take responsibility for completion with minimal supervision. Ability to clearly express oneself both orally and in writing. Must have some limited experience with integrated development environments, software architecture design and development, and software test and deployment.\n\nDesired Qualifications:\nSome familiarity with additional areas of study in the field of Intellgent Systems / AI such as knowledge discovery, Natural Language Processing, Information Retrieval, Classifiers, and Statistical Inference. Current TS/SCI.\n\nSpecial Working Conditions (travel, working in closed areas, extended hours): May require a small amount of travel within the National Capital Region to deploy production systems or attend meetings or conferences. Occasional travel out of the area for sponsor / partner engagements.\n\nSecurity: Applicant selected will be subject to a government security clearance investigation and must meet the requirements for access to classified information. Eligibility requirements include U.S. citizenship.\n\nBenefits: APL offers a comprehensive benefits package including a liberal vacation plan, a matching retirement program, significant educational assistance, a scholarship tuition program for staff with dependents, and competitive salaries commensurate with skills and experience. For more information about our organization, please visit our web site at www.jhuapl.edu.\n\nEqual Employment Opportunity:Johns Hopkins University/Applied Physics Laboratory (APL) is an Equal Opportunity/Affirmative Action employer that complies with Title IX of the Education Amendments Acts of 1972, as well as other applicable laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, sexual orientation, gender identity, national origin, disability, or protected Veteran status.\n\nApply Now: click Apply Now"}, "583": {"company": "Nyansa", "description": "Nyansa is a fast-growing innovator of advanced IT infrastructure analytics software based in Palo Alto, California. Founded in September 2013 by technology professionals from MIT, Meraki, Aruba Networks and Google, Nyansa is credited with developing the first cloud sourced, vendor-agnostic network analytics and IoT security platform, called Voyance.\n\nWe embrace simplicity and take following to heart on everything we do:\"Any intelligent fool can make things bigger, more complex, and more violent. It takes a touch of genius -- and a lot of courage -- to move in the opposite direction.\" - Einstein\n\nNyansa is looking for a data engineer to join the team that is building a new, vendor-agnostic IT network analytics service purpose built for CIOs, network operations and helpdesk personnel managing heterogeneous enterprise environments. Our product is focused on the end user experience by helping IT staff gain new insights into client access conditions, network service behavior and enterprise applications issues that impact user performance.\n\nOur current big data analytics system analyzes billions of streaming events per day using advanced algorithms. Going forward, we aim to scale the system extensively and are looking for radical ideas to achieve this.The company is well funded and provides competitive compensation package, stock options, benefits, catered lunch, and a fun work environment.\n\nWe\u2019re located within a 1 min walk from the Palo Alto Caltrain station.\n\nResponsibilities:\n\u2022 Design and develop highly scalable and available real time analytics platform using Spark, Kafka, Cassandra, and Elasticsearch for large data input streams\n\u2022 Work closely with data science and UI teams to define and implement various analytics features related to product\n\u2022 Configure, monitor, and optimize Spark and related infrastructure\n\nRequirements:\n\u2022 Strong desire to work for an early stage startup and be a part of its success\n\u2022 Strong in Map-Reduce, parallelizing computations, and identifying bottleneck computations\n\u2022 Strong in Scala and Python\n\u2022 Experience in configuring and tuning Spark and Kafka systems\n\u2022 Good understanding on Spark UI to extract useful information on application stages, and identify bottlenecks\n\u2022 B.S. or higher degree in Computer Science or equivalent\n\nPluses:\n\u2022 Experience with Cassandra, Elasticsearch, Mongo\n\u2022 Experience with Ganglia and able to correlate information from various UIs to diagnose efficiency issues\n\u2022 Experience working with AWS\n\u2022 Experience with Spray to build REST endpoints\n\nPlease Apply Directly Here --> http://bit.ly/nyansa-data-eng"}, "584": {"company": "Sweetwater", "description": "Sweetwater, the nation's largest online retailer of musical instruments & pro audio gear is looking to add a Data Science Engineer to join our growing Digital Marketing team. As a Data Science Engineer you will be accountable for processing, indexing, analyzing, testing, and reporting of large sets of historical data. You will be instrumental in designing & implementing the next generation of Sweetwater's data strategy, marrying big analytical challenges like advanced attribution, website behavior, customer purchase history, and more. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys building data systems from the ground up with a strong passion for continually optimizing and validating them. Successful candidates must be organized, analytical, and adept at working in a team environment.\n\nRequirements:\nBachelor's Degree in related field required. Masters/PhD in Statistics, Operation Research, Applied Mathematics, Economics, Computer Science, or a quantitative discipline preferred\nProven ability to concept, design and implement innovative, pioneering data-driven insights to solve highly complex business problems.\n3+ years of experience in a retail environment as a Data Scientist, Data Engineer or related field\nExpert level experience analyzing very large datasets with SQL (Redshift, Teradata, Oracle, or MySQL) and R, Python, TensorFlow, SAS, DOMO or other statistical packages\nExperience with big data tools like Hadoop, Spark, Presto, etc\nFamiliarity creating datasets and schemas with cloud technologies such as AWS S3, EC2, EMR, RDS, Redshift, Microsoft Azure, or Google Cloud\nExperience developing machine learning models and algorithms for revolutionary retail experiences\nBonus points:\nYou're a musician, play a musical instrument, or have experience in the music and/or music retail industry\nWe function best as a unified team, so relocation to our headquarters in Fort Wayne is required. As with all positions at Sweetwater, working from home is not an option. Please fill out this online application and send your resume and supplemental information to jordan_applegate@sweetwater.com\nApply Now: click Apply Now"}, "585": {"company": "Clarity Insights", "description": "Do you have a passion for working with Data? Do you love working in machine learning, real-time analytics, or Big Data? Interested in learning and utilizing different technologies without limitation? We are looking for a Data Expert that will help our clients evaluate and implement big data and advanced analytics solutions in the Cloud and on-premise. At Clarity Insights, we specialize in providing Data & Analytics expertise that result in real and measurable business outcomes. We are passionate about data, problem solving and driving value to make a difference with our clients.\n\nClarity Insights is the largest independent professional services firm focused exclusively on data analytics solutions. Our Healthcare Practice is expanding and looking to develop in multiple US Regions. Clarity\u2019s Delivery Practices have one vision: to drive better business outcomes through data and analytics. We provide data analytics advisory consulting services. We believe that nothing sells like great delivery, and are committed to our people and client delivery excellence. With continuing, aggressive growth plans for the next five years, Clarity is seeking outstanding Healthcare industry data analytics leaders to successfully qualify, propose, close and lead client solution delivery.\n\nAt Clarity Insights, the Senior Principal Data Scientist is responsible for understanding, qualifying and estimating new business opportunities from a solution perspective, supporting proposal and SOW generation, making presentations, and leading and contributing directly to client solution delivery. Typically, he/she performs the following: creates statistical models, hands on with technology such as SAS, SPSS, R, Python or similar tools. The Data Scientist is also a key leader and mentor for Clarity Insights' technical consultants at all levels, assembling and managing high performance client and internal teams, and contributing to the development of individual, Practice, and Clarity Insights' technical capabilities.\n\nAs a key Clarity Insights, Data Scientist and technical data analytics leader, the Data Scientist establishes effective, collaborative working relationships with Clarity executives, Partners, Engagement Managers, and Senior Business Analysts. This individual will also collaborate with our Service Leaders and consultants across our core delivery competencies including Data Science, Data Engineering, Data Visualization and Data Strategy.\n\nA career at Clarity Insights is different\u2014our people and culture (we are a \u201cconsultants\u2019 consulting company\u201d), our relentless client service commitment, and our specialization in data analytics\u2014set us apart. We have the data analytics expertise and scale to compete with the largest systems integration firms, and yet still provide the nimble, focused, bespoke experience of a boutique.\n\n\nFunctional Expertise\nFully understands the requirements of our client and working with big data (e.g. parallel/MapReduce algorithms, etc.)\nResponsible for creating advanced analytical models that will lead to actionable insights that allow our client to make more informed business decisions\nExperience with hypothesis or idea generation and prioritization, exploratory analysis using iterative modeling and tuning, and production integration and delivery of results to ensure adoption\nPlaying a senior role in professional work engagements and demonstrating proficiency in predictive analytics and data mining either through references or a portfolio of work\nStrong communication skills to non-analytical and analytical client team members. Ability to create and explain executive summaries of work to C-level executives\n\nBusiness Development\nBuild fully satisfied, referenceable client relationships, and actively contribute to the positive reputation of Clarity among prospects and in the market\nAssemble and lead collaborative, high-performing technical teams in business development and delivery situations\nCreate high quality technical content for introductory presentations, proposals, Statements of Work, deliverables, and other client and market-facing content\nAssist with business development activities that produce client/project wins and revenue growth\nSupport the profitability (direct revenue and expenses) of client engagements in accordance with client commitments and internal policies and rules\nAppropriately leverage and protect Clarity intellectual property in business development and delivery\nRepresent Clarity at conferences and symposiums, presenting our services\nPersonal Utilization\nPlay a valuable technical leadership role(s) in client solution delivery, including leading the client team\u2019s technical delivery performance, identifying and responding to technical delivery extension/expansion opportunities, and actively managing the client relationship and expectations\nAchieve company utilization targets\nClarity Contributions\nMentor technical employees and contribute to their individual development, and lead performance management processes for technical delivery teams\nContinuously learn about clients, target market segments, and data analytics business and technology trends, and effectively communicate/share information with colleagues\nParticipate regularly in effective technical recruiting, candidate interviewing, and employee on-boarding activities\nBuild, cultivate, and curate Clarity intellectual property that contributes to business development and client delivery performance\nAssist others in achieving business development and client delivery goals by providing leads, content, peer review, qualified client references, and other sharing that promotes success\nPublishing content and/or creating and delivering presentations that effectively promote the Clarity brand\nActively participate in and support organizational development and process improvement initiatives\nConstructively share ideas, observations, and evaluations that could contribute to Clarity\u2019s client, people, and business goals\nRequired Skills\nMinimum 10 years of recent, progressive experience and demonstrable technical expertise in enterprise-class data analytics solutions and services\nMinimum 4 years of recent, progressive experience and demonstrable expertise the Healthcare industry\nMinimum 4 years of recent, progressive experience in technical consulting leadership roles\nMinimum 2 years of recent leadership experience in enterprise-class data analytics architecture, including enterprise and solution architecture assessment/definition, and significant depth in two or more data analytics solution architecture components (i.e., data management, data integration, information delivery, and/or advanced analytics)\nA strong understanding of market-leading data analytic technology platforms, roles, and trends\nExceptional written and verbal communication skills, including experience estimating technical solution builds, and contributing to custom proposals, responses to Requests for Proposal, Statements of Work, advisory deliverables, and executive-level presentations\nRecent work references related to industry and data analytics architecture, technology, and design/engineering leadership expertise\nCompletion of a B.S./B.A. degree in Statistics, Industrial Engineering, Mathematics, Econometrics or Economics is required\nMaster's degree preferred\nTravel to the client on a weekly basis is required. Normal weekly schedule is M-TH travel to client location (U.S. based)\nWhy Clarity Insights, Why Consulting and Why Now?\n\nWe don\u2019t try to be everything to everybody all the time. We specialize in Data & Analytics and will remain a platform and tool agnostic company so you can grow technically throughout your career. It sounds ridiculous but you actually need to be 100% technical and 100% business with strategy because we don\u2019t hire non-communicative robots who have a one size fits all approach. We often could speak to a CFO or Head of Underwriting about a business or finance problem, and based on the need for real-time and affordable scalability, we can outline \u2013 in terms they can understand \u2013 why they should think about a cloud solution for big data and analytics. If we step across to the DevOps lab, we can easily pick up on a conversation about Apache committers, OSF, full stack development, microservices, containers and much more. We\u2019re not trying to boil the ocean. We want to grow from 400 people to 1700 people in 4 years to take the market an accessible set of consulting skills. We have a lot of fun together. Most people join here and stay here for the people. That said, we are popular so we do rack up some travel miles. I have a million things to share about why that may change and why that must stay the same for now, but here\u2019s a suggestion \u2013 if you LOVE Cloud Computing for Big Data and/or Advanced Analytics, Machine Learning, etc we should talk.\n\nClarity Insights is an Equal Employment Opportunity Employer. We believe in treating each employee and applicant for employment fairly and with dignity.\nGLDR\n#LI-NT1\n\nApply Now: click Apply Now"}, "586": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking a Data Scientist (Journeyman) in the role of the Maritime Safety Office.This position is to provide both digital and hardcopy maritime products, services, and data to support worldwide Safety of Navigation. Without accurate and up-to-date nautical products, military platforms are at increased risk when they conduct operations, transport personnel and deliver material. The U.S. Navy has made it clear to NGA that it will continue to require both digital and hard copy maritime products for the foreseeable future. Services procured under this contract will primarily support the production and maintenance of Maritime GEOINT at NCE facilities.\n\nResponsibilities include:\nCollect, process, and perform data analysis\nIntegrate, centralize, protect, and maintain data in a DBMS\nClean, massage, and organize data\nPerform ad-hoc analysis and present results in a clear manner\nConduct undirected research and frame open-ended industry / customer questions\nRecommend cost-effective changes to existing procedures and strategies\nCommunicate complex quantitative analysis in a clear, precise, and actionable manner using story-telling / visualization\nCreate / maintain tools to extract features from a variety of sources including raster to vector, vector to vector, text to vector, and text to database.\nWrite / maintain Python Scripts in ARCGIS to improve efficiency of the production process.\nSupport Business Processing Re-Engineering\nPerform Data Conversion/migration\nPerform Business Analytics\nWork with the Government on new production capabilities / services\nBasic Qualifications:\n3 to 10 years of programming skills with the ability to write / maintain scripts, including Python scripts and Java and familiarity of querying with SQL.\nAdvanced knowledge in data science, including the areas of data services, modeling, and analytics.\nAdvanced knowledge of geospatial data management including data type conversion; coordinate systems (latitude and longitude, UTM) and their conversions; and knowledge of projections and their properties / conversions.\nMinimum 2 years of experience working with data quality control tools including ArcGIS Data ReViewer.\nProficient with ESRI Workflow Manager WMX and TAM.\nDesired Skills:\nExperience with combining digital cartography, computer technology, GIS, cartographic and geospatial production techniques, remote sensing, photogrammetry, and digital data formats.\nAbility to clean / prune data to discard irrelevant information\nAbility to examine data from a variety of angles to determine hidden value, weaknesses, trends, and / or opportunities\nAdvanced knowledge of ESRI ArcGIS and ArcServer.\nKnowledge of database systems and architecture (ORACLE, PostgresSQL, NoSQL (MongoDB), Microsoft Access)\nAbility writing SQL\nUnderstanding cloud architecture and DevOps\nKnowledge of symbolization rules (how symbols are used to portray features)\nKnowledge of generalization rules.\nExperience working with geospatial data in a multi-user enterprise environment (i.e., versioning data)\nKnowledge of artificial intelligence, natural language processing, and machine to-machine learning.\nKnowledge of Metrics dissemination\nAbility to convert unstructured data into structured data\nSecurity Clearance: Top Secret SCI\n\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nStart your job application: click Apply Now"}, "587": {"company": "Argus Information & Advisory Services", "description": "Company Description\n\nAs one of the original innovators in lending, credit, fraud, and spend analytics, Verisk Financial integrates one of the industry\u2019s largest sets of data to help banks, financial regulators, retailers, and media companies grow their businesses. We combine data with predictive analytics to uncover new consumer and business insights and integrate this data with the most technologically advanced platforms.\n\nVerisk Financial | Argus is a leading provider of intelligence, decision support solutions, and advisory services to financial institutions across the global commerce ecosystem. Our clients include more than 50 top U.S., Canadian, and other international financial organizations, regulators, payment providers, merchants, and media. Argus is the leading source of segment-level portfolio management benchmarking data, analytics, models, and advisory services. We maximize value delivery to clients by combining proprietary data sets, cutting-edge software and analytic tools, domain expertise, and our unique results-oriented approach. Customers worldwide use our services for tailored data management solutions that include business intelligence platforms, profile views, mobile data solutions, enterprise database services, and fraud risk scoring algorithms for marketing, fraud, and risk mitigation. Our clients gain competitive advantage from our exclusive focus on leveraging global best-in-class analytics and methodologies to help achieve their business and regulatory objectives. To learn more about Argus please visit us at: www.argusinformation.com. We are proud to be a part of the Verisk family of companies!\n\nWith a history of impressive growth, an innovative culture, and offering industry-leading solutions, Verisk Analytics is an amazing place to work and make a difference. In 2018, Forbes magazine named Verisk to its World\u2019s Best Employers list and, in 2017, to its World\u2019s Most Innovative Companies list for the third consecutive year. We also earned the Great Place to Work\u00ae Certification for the third consecutive year in recognition of our outstanding workplace culture.\n\nVerisk is a leading data analytics provider serving customers in insurance, energy and specialized markets, and financial services. Using advanced technologies to collect and analyze billions of records, Verisk draws on unique data assets and deep domain expertise to provide first-to-market innovations integrated into customer workflows. We\u2019ve been delivering predictive analytics and decision support solutions to our customers for nearly 50 years, helping them protect people, property, and financial assets. At Verisk, you\u2019ll be part of an organization that\u2019s committed to serving the long-term interests of our stakeholders, including the communities where we operate.\n\nAt Verisk, you can build an exciting career with meaningful work; create a positive and lasting impact on the business; and find the support, coaching, and training you need to advance your career. Our culture of innovation means your ideas on how to improve our business will be heard. As key contributors to our success, our team members enjoy working in a business-casual, collaborative environment that offers state-of-the-art resources, advanced technologies, and an excellent benefits package.\n\nJob Description\n\nVerisk Financial is seeking an experienced Data Science professional who\u2019s excited to take on some of the world\u2019s most difficult data challenges. A Principal Data Scientist is a proven leader and mentor who loves getting their hands-on data and solving challenging problems with real-world impact. You will be able to shape how data science is done on a wide variety of problems at Verisk Financial and how we grow our data science function.\n\nWhat we are looking for:\n\nYou will have at least 5-7 years of experience in applied research and statistical modeling with a degree or higher (MS/Ph.D.) in statistics, mathematics, physics, or similar field\n\n\u00b7 A track record of creatively tackling challenging data problems\n\n\u00b7 Full understanding of common machine learning techniques and familiarity with ongoing research\n\n\u00b7 Success mentoring and growing exceptional data scientists\n\n\u00b7 Fluency with analytical programming, including libraries for cleaning, reshaping, exploring and visualizing data\n\n\u00b7 Strong knowledge of machine learning, computer science, mathematics, and statistics\n\n\u00b7 Experience with several of the following concepts: decision trees, random forests, and gradient boosting; linear regression; logistic regression; linear and non-linear dimensionality reduction using PCA, kernel methods, and dictionary learning; clustering with K-means, hierarchical clustering, and DBSCAN; autoencoders; generative models; and sequential data modeling\n\n\u00b7 Strong programming skills in Python, R, and SQL\n\n\u00b7 The ability to clearly convey complex concepts with plain language\n\n\u00b7 Demonstrated ability to produce high-quality, product-focused, scalable analysis\n\n\u00b7 Problem-solving with determination, perseverance, and grit\n\n\u00b7 You are motivated by working on hard problems with smart people\n\n\u00b7 Ability to prioritize\n\n\u00b7 Experience running or working at data-centric startups is plus\n\nQualifications\nStrong programming skills in Python, R, and SQL\n\u00b7 The ability to clearly convey complex concepts with plain language\n\u00b7 Demonstrated ability to produce high-quality, product-focused, scalable analysis\n\u00b7 Problem-solving with determination, perseverance, and grit\n\u00b7 You are motivated by working on hard problems with smart people\n\u00b7 Ability to prioritize\n\u00b7 Experience running or working at data-centric startups is plus\nAdditional Information\n\nVerisk Analytics is an equal opportunity employer.\n\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.\n\nhttp://www.verisk.com/careers.html\n\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\n\n</br>Apply now\nApply Now: click Apply Now"}, "588": {"company": "Agios Pharmaceuticals", "description": "Senior Scientist, DMPK\nLocation\n\n\nAgios Pharmaceuticals HQ\n\nJob Code\n\n914\n\n# of openings\n\n1\n\nApply Now\n\nSenior Scientist, Discovery DMPK\nAgios (agios.com) is a biopharmaceutical company committed to applying our scientific leadership in cellular metabolism to transform the lives of patients with cancer and rare genetic diseases. We are growing rapidly with an active research and discovery pipeline across both therapeutic areas. Agios has two approved oncology precision medicines and multiple first-in-class investigational therapies in clinical and/or preclinical development.\n\nPosition Overview\nAgios is searching for a talented Senior Scientist to join Discovery DMPK. The successful candidate will be primarily responsible for leading the DMPK functions for Discovery projects in Oncology, Rare Genetic Disorder, and/or metabolic immune-oncology therapeutic areas, all the way from early target validation stages to the nomination of the development compound. The incumbent will be responsible for working with various CROs on the in vitro and in vivo ADME, PK, PKPD, and TK studies and ensure timely data based decision making within the project teams. The candidate should have strong understanding of DMPK and PKPD areas applicable to animal models and translation into humans, and have demonstrated experience leading the discovery projects as the DMPK representative.\n\nKey Responsibilities:\nResponsible for leading the scientific, technical and operational efforts of the DMPK for Discovery projects.\nDirect internal and external DMPK activities, including routine studies, troubleshooting, and issue management for the given Discovery projects.\nDesigning, working with the CROs on biotransformation and transporter studies and interpretation/communication with the project teams as needed.\nParticipating in or leading the IND documentation\nResponsible quality, quantity and timelines of all DMPK and PKPD activities within the project teams\nMinimum Requirements:\nPhD in Pharmaceutical Sciences, Pharmacokinetics, Drug Metabolism, or a related field with\n6+ years\u2019 experience in the pharmaceutical industry\nStrong scientific knowledge of Drug Discovery, DMPK/ADME, biotransformation, transporters, and PKPD of NCEs\nStudy management skills are required to interface with the cross functional teams in Chemistry, Biology, Pharmacology, Cell Metabolism, and Toxicology functions\nDemonstrated expertise in DMPK and PKPD areas\nExperience working with CROs\nExcellent leadership and problem-solving skills. Team player with strong inter-personal skills.\nExcellent written and communication skills\nPreferred Qualifications:\nExperience in handling pre-clinical drug development and has the flexibility of handling both discovery and development stage projects\nHighly desirable to have experience in biotransformation of small molecules and transporters\nIND filing experience\n\nTo apply to this job, click Apply Now"}, "589": {"company": "MassMutual", "description": "At MassMutual, were passionate about helping millions of people find financial freedom and this passion has driven our approach to developing meaningful experiences for our customers. The Data Engineering team, part of the Enterprise Technology and Experience, is comprised of highly skilled, collaborative, problem solvers who are motivated to create innovative solutions that exceed the changing needs of our customers and move MassMutual and the industry forward.\n\nTo continue our cutting-edge work, we are hiring an Advanced Data Engineer to join our team.\n\nWhat great looks like for this role:\n\n\nOur ideal Advanced Data Engineer is a collaborative leader skilled in designing and constructing highly scalable data management systems. Youre also committed to data integrity, are highly analytical, and can work on multiple projects at once. Youll use your skills to develop, monitor, and manage data systems across our platform. Additionally, you will act as a mentor to junior team members and coach them on best practices and engineering standards. The team culture of working collaboratively, cross-functionally, using new technologies combined with the work/life balance provided by MassMutual are core reasons people enjoy working on the Data Engineering team at MassMutual.\n\nObjectives of this role:\nDesign, construct, install, test and maintain highly scalable data management systems.\nEnsure systems meet business requirements and industry practices.\nDesign, build, and maintain a high-performance streaming and messaging platforms to support the enterprise.\nDaily and Monthly Responsibilities:\n\nDesign, build, and maintain a high-performance streaming and messaging platforms to support the enterprise.\nCreate messaging standards for our messaging platforms.\nDevelop tools and processes to support the platform.\nCreate custom software components (e.g. specialized UDFs) and analytics applications.\nWork across departments and business units to define patterns and data needs.\nTranslate high-level business requirements into technical specs.\nBasic Qualifications:\n\nBachelors degree in computer science or engineering.\n4+ years of experience with designing and building data platforms.\n3+ years of experience with streaming/messaging platforms (Kafka, MQ, RabbitMQ, etc)\n3+ years of coding and scripting (Python, Java, Scala) and design experience.\nExpertise in tuning and troubleshooting streaming/messaging platforms.\nExperience with ELT methodologies and tools.\nStrong data integrity, analytical and multitasking skills.\nExcellent communication, problem solving, organizational and analytical skills.\nAble to work independently.\nAuthorized to work in the USA with or without sponsorship.\nPreferred Qualifications:\n\nAbility to setup and maintain a Kafka Cluster\nExperience with Spark\nExperience with designing an automating deployment process (CI/CD)\nBasic knowledge of database technologies (Vertica, Redshift, etc)\nApply Now: click Apply Now"}, "590": {"company": "PulsePoint", "description": "PulsePoint\u2122, a global programmatic advertising platform with specialized healthcare expertise, fuses the science of programmatic targeting, distribution, and optimization with the art of brand engagement. The PulsePoint platform is powered by terabytes of impression-level data, allowing brands to efficiently engage the right audiences at scale while helping publishers increase yield through actionable insights.\n\nOur organization has a strong history of utilizing machine learning, contextualization, and targeting to distribute advertising to the right consumers at the right time and create real connections across the internet. We are now taking that knowledge and expertise to solve challenges within healthcare in order to create better health outcomes through Radical Health Personalization\u2122.\n\nThe goals of the PulsePoint Data Science team:\nOptimize and validate targeting mechanisms for specific health conditions\nImprove and optimize our proprietary contextualization, and recommendation engines that handle hundreds of thousands of transactions per second, billions of times each month\nCollaborate with internal Health experts to ideate and support rapid assessment, analysis, and prototyping of ideas for achievable commercialization.\nWhat you will be tasked to do:\nResearch and develop user profiling models to enhance our clinical trial recommendation engine to leverage both online and offline data.\nCollaborate with Product teams on data-driven products to support clinical trial platform design and delivery.\nSupport and enhance the existing work on health user profiling, prediction, and targeting tools.\nContribute on future project on patient/physician identity for cross-device tracking, profiling and targeting.\nSupport existing codebases for data integration and production support for our core models.\nWhat you need to be successful in this role:\n3+ years of full-time experience working as a Statistician/ Machine Learning Engineer/ Data Scientist\nAdvanced knowledge of Big Data technologies such as Hadoop, Hive, and Impala\nAdvanced knowledge of Python using the numpy/scipy/pandas/skilearn stack\nMS/PhD in Astronomy, Physics, Applied Mathematics, Statistics, Machine Learning, Computer Science; or BS with several years of applied machine learning experience\n** All applicants must submit a code sample or a GitHub link to be considered **\n\nAt PulsePoint\u2122, data is at the core of everything we do and Data Science is a high profile and high impact team, focusing on creating innovative solutions that rely on predictive modeling and big data analytics. We are looking for \"A\" players that have a combination of drive, focus, speed, efficiency and quality to drive statistical modeling, optimization and/or machine learning. You will be given ownership and autonomy over the research and development of your projects and will be expected to execute well and on time. We work on challenging problems that will make ads matter for people with health problems. Your work will directly influence our trajectory as a company.\n\nWhat we offer:\nSane work hours\nGenerous paid vacation/company holidays\nVacation reimbursement, sabbatical, pawternity leave, marriage leave, honeymoon bonus\nComprehensive healthcare with 100%-paid medical, vision, life & disability insurance\n$2,000 annual training and development budget\nComplimentary annual memberships to One Medical, NY Citi Bike and SF Ford GoBike\nMonthly chair massages\nFree fitness classes (spin, yoga, boxing)\nGym reimbursement, local gym membership discounts\nOnsite flu shots, dental cleanings and vision exams\nAnnual company retreat\nPaid parental leave and a lot of new parent perks\nEmergency childcare credits\n401(k) Match and free access to a financial advisor\nVolunteer Time Off and Donation Matching, ongoing group volunteer opportunities\nTeam lunches, Sip & Social Thursdays, Game Nights, Movie Nights\nHealthy snacks and drinks\nAnd there's a lot more!\n\nWant to peek inside the PulsePoint\u2122 offices? Check it out here: https://www.themuse.com/profiles/pulsepoint\nApply Now: click Apply Now"}, "591": {"company": "Sojern", "description": "About Us:\n\nWant to join a company on the cutting edge of technology and travel? Want to be part of a fantastic and fun company that's revolutionising the online travel advertising space?\n\nSojern works with 93% of the Fortune 500 travel companies and has spent more than a decade analyzing the complete traveler path to purchase. We drive travelers from dream to destination by activating multi-channel branding and performance solutions on the Sojern Traveler Platform for more than 8,500 customers around the world.\n\nSojern made Deloitte's Technology Fast 500 list for the last 6 years in a row, and was recognised on the Top Company Cultures list by Entrepreneur Magazine and named a Best Place to Work by AdAge. The company is headquartered in San Francisco, with teams based in Dubai, Dublin, Hong Kong, Istanbul, London, Mexico City, New York, Omaha, Paris, Singapore, and Sydney.\n\nNeed more convincing that Sojern is a great place to work? Check out our Glassdoor reviews!\n\nAbout the Team:\n\nThe Data Science Engineering team develops methods to optimize advertising campaigns, defines new methods for measuring campaign performance, and applies machine learning at scale with more than 5000 models in production. Example projects include:\nBayesian statistics to model conversion rates and revenue\nThompson sampling and linear programming to balance campaign objectives\nStratified sampling and power analysis to run controlled experiments\nUsing Tensorflow and XGBoost on Kubeflow to predict a traveler's propensity to convert\nAnd as a part of engineering, we own the full data product life-cycle: from analysis and prototyping to production development.\n\nThe Role:\n\nWe are looking for a Manager of Data Science to drive business, process and team impact with data science, team empowerment and collaboration.\n\nResponsibilities:\nWrite production code in Python, and can reason about algorithmic efficiency.\nInspire with the way you authentically communicate with data scientists, engineers, product managers, and leadership.\nSolve data science challenges and innovate in the context of trade-offs.\nCoordinate, collaborate and delegate to make sure that products are successful.\nSolid understanding of what drives the products that you work on.\nDrive business impact by designing, architecting, implementing, and delivering data-driven products.\nEnsure your team is successful with inclusivity, mentorship, feedback, recognition, and career goals.\nPartner with product managers and engineering leadership to create clarity, positive change and improve technology strategy.\nPrioritize company and team goals ahead of your own.\nChampion diversity on the data science and engineering teams.\nServe as a multiplier helping the team be more than the sum of its parts.\nDetermination and initiative to fill in gaps and drive projects to completion.\nWhat you bring to the table:\nAt least 6 years experience as a data scientist\nAt least 2 years of experience within the Ad Tech ecosystem\nAt least 2 years of experience managing (player/coach).\nHands-on experience building production-level ML and data products.\nExpert-level understanding of data science topics.\nExperience writing code and managing reports.\nExperience applying agile methods to data science, and ideally have been a scrum master.\nMS or PhD in computer science or a quantitative discipline.\nPerks:\nOpportunities: Be part of a growing team with training and support to help you grow\nOwnership: Lead creative and challenging projects\nGive Back: We give 40 hours a year to volunteer and organize office volunteer programs with local organizations\nCulture: Strong core business values, focus on teamwork, vibrant, social and fun environment\nSnacks: Variety of snacks in the office\nMeals: Monthly catered lunches & happy hours\nCompetitive Localized Benefits\nIATA Travel Discount\nTime Off: Flexible vacation days\nAt Sojern, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\n]]>\nTo apply to this job, click Apply Now"}, "592": {"company": "Synechron", "description": "TECHNOLOGY\nSenior Data Scientist\nNew York, NY and Charlotte, NC, USA\n\nApply\n\nJob Description\n\n\nThe Data Science team is looking for a seasoned data scientist with a strong analytics, programming, and machine learning background. The ideal candidate will work closely with top tier financial services organizations to formulate solutions to complex business problems using multiple analytical tools and frameworks, including statistical analysis, natural language processing, machine learning, and deep learning. The ideal candidate will be able to identify client needs, propose effective solutions, and implement the solutions as part of a team.\n\nSynechron\u2019s collaborative culture and global network of Tier One banking clients provides an incredible environment for a data scientist to work on the most cutting-edge use cases in machine learning and artificial intelligence in finance. You will have the opportunity to work with some of the best data scientists anywhere in an environment which truly values innovation, creative thinking, and a proactive approach to problem solving. Exciting projects include building machine learning platforms for investment research, private wealth management, IPO underwriting, customer analytics, social AI, and retail and commercial banking. As a senior member of the Data Science team you will have the opportunity to lead teams and projects and to mentor junior data scientists in their development.\n\nResponsibilities\nDesign and develop scalable solutions to complex problems using statistical modeling, machine learning, Natural Language Processing, Optical Character Recognition, and deep learning;\nImplement solutions in Python in multiple environments including Spark, AWS, and Azure;\nManage junior data scientists in the implementation of machine learning solutions;\nMeet with clients to understand business use cases, identify needs, and formulate end-to-end solutions encompassing data ingestion, cleansing, modeling, and predictive and prescriptive analytics;\nManage the ingestion and cleansing of large data sets using big data tools such as Spark;\nTranslate solutions into business requirements;\nIndependently formulate new ideas for solving client problems or providing clients with new tools for growing revenue, reducing cost, improving customer acquisition and retention, and automating business processes.\n\nRequirements\n\n\nBasic Qualifications\nHold a MS or PhD degree in a quantitative discipline: computer science, applied mathematics, statistics, operations research, management of information systems, engineering, economics, social sciences or equivalent;\nProgramming skills in Python;\nPresentation skills including experience presenting complex ideas to clients and prospects;\nThe ability to independently formulate solutions to complex problems or to otherwise think of potential solutions without guidance;\n8+ years of total experience including 4+ years of experience developing machine learning systems in Python, Java, or a related programming language;\nHands on experience with data mining, machine learning, econometric analysis or equivalent;\nExperience in Hadoop or other MapReduce paradigms and associated languages such as Spark;\nExperience with Unix/Linux environment for automating processes with shell scripting.\nPreferred Qualifications\nStrong Python programming skills;\nKnowledge of deep learning and related open source libraries such as TensorFlow;\nFinancial Services experience and knowledge of the FS industry;\nDeep knowledge of Natural Language Processing;\nExperience with Spark and machine learning libraries such as MLlib;\nExperience in marketing and sales, being an innovator and disruptor is also a plus;\nBeing self-motivated, creative and collaborative;\nStrong presentation and communications skills.\n\nTo apply to this job, click Apply Now"}, "593": {"company": "Optoro", "description": "Optoro is a fast-growing technology company that is revolutionizing the retail industry. Every year, more than 15% of retail goods are returned or simply never sell. This creates tons of unnecessary waste and costs retailers billions.\n\nOur mission is to make retail more sustainable by eliminating all waste from returns. Our technology platform connects every returned item to its best home, thereby increasing profitability for retailers, giving consumers great deals, and reducing environmental waste.\n\nBacked by some of the top investors in the country - including Kleiner Perkins, Revolution Growth, and UPS - Optoro is powered by its collaborative, unconventional, and resourceful employees who love solving big problems. We are looking for individuals with similar creativity and energy to help build a lasting company focused on the triple bottom line.\n\nOptoro's Data Science team is responsible for turning our massive data resources into actionable insights that inform our products and business processes. Our team values creativity, willingness to embrace new methods and technology, and the ability to solve problems independently. The team uses a wide variety of machine learning techniques - from linear regression to deep learning to hierarchical Bayesian models - while constantly pushing the bounds on real-time experimental methods including multi-armed bandits, reinforcement learning and more! Our goal is to create a step-change increase in the world's ability to efficiently and effectively optimize returns across the entire Optoro platform. We're looking for experienced Data Scientists that are passionate about helping us to achive that goal, using any and all means necessary.\n\nResponsibilities\nDevelop models via a wide variety of machine learning techniques that have demonstrable impact on business challenges.\nManipulate complex, high-volume, high-dimensionality data from varying sources to provide insights that enhance Optoro's SmartDisposition\u2122 routing algorithm and pricing approach.\nMonitor results of deployed algorithms for accuracy, drift over time, and robustness to new data and enact methods to continuously improve models.\nDesign and execute experimental tests of business logic using multi-arm bandit frameworks, traditional A/B testing and more.\nProduce reports and data visualizations using Tableau and other tools.\nRequirements\nStrong mathematical and statistical background; B.A. (graduate degree preferred) in a relevant quantitative field (e.g. applied mathematics, statistics, physics, computer science, operations research); or equivalent work experience in a relevant role.\n4+ years in a machine learning-focused role, including data extraction and cleaning, exploratory analysis, predictive modeling, and monitoring of deployed algorithms.\nDeep understanding of data analysis, machine learning, and data communication across multiple domain areas.\nExperience with the Python statistical programming stack (NumPy, Pandas, Scikit-Learn, TensorFlow, PyMC3, etc\u2026) and deploying algorithms in production environments. We also welcome candidates who come primarily from an R background but want to migrate to Python.\nAbility to deal with ambiguity in a fast-paced, dynamic environment.\nProven experience thinking creatively about challenging, analytical problems.\nExperience with supply chain, eCommerce, microeconomic theory, NLP, Ruby on Rails, Airflow, Kafka, and PostgreSQL are all a plus!\nOptoro is an equal opportunity employer.\nApply Now: click Apply Now"}, "594": {"company": "Kareo Inc", "description": "What We Need\nA Senior Data Scientist with solid problem-solving skills to partner with the development teams.\nYour Area of Focus\nJoin a growing team of tech heads who love building things with ones and zeros\nWork in a fast-paced environment that sometimes fails fast and early, but always learns and improves\nBe unshackled by conventional thinking and allowed to use cool tech to solve hard problems\nPerform component design for a complex system or service. Considers scaling, reusability, maintainability, and performance into system or service design.\nStrong written and verbal communication skills and ability to train and mentor Junior engineers\nMake recommendations to product requirements and business solutions based on an understanding of how Kareo's products work under the hood\nWrite unit tests and integration tests for most of one's own work and ensure a high quality of deliverables\nYour Qualifications\nComputer Science Degree (or degrees) or enough experience to convince us you do not need one\nExtensive knowledge of Python or R\nAbility to understand and interpret data and programmatically make predictions\nExperience with statistical tools and visualizations techniques to extract hidden insights from large datasets\nAbility to use historical data to build models that can predict future outcomes and drive business decisions\nExperience with Microservices and CI/CD (Kubernetes is a plus)\nDeep understanding of latency, contention, computation, mutation, consistency, CAP theorem and system design trade-offs\nExperience in an UNIX environment\nExperience with SoA architectures and in SaaS products\nExtensive knowledge of RESTful APIs\nFamiliarity with relational databases such as MySQL, Oracle, and SQL Server\nExperience with data warehousing tools and technologies\nAbility to design and implement scalable big data pipelines and frameworks that can integrate external data sources and third-party APIs\nSolid experience with concurrency, multithreading, server architectures, and distributed systems\nExperience with distributed search engines like Elastic search\nStrong problem solving and critical thinking skills\nStrong attention to detail\nProcess oriented: you can teach us a thing-or-two about machine learning and real-time data analytics in high throughput environment\nDeep understanding of the inner workings of one or more programming languages and tech stack\nAbility to build REST APIs that can process and distribute data to 3rd party applications at scale\nExperience with building AI bots\nA good understanding of current industry trends and best practices\nYour Personal Characteristics\nBe Passionately Driven: We take pride in our work, inspire others to excel, and are always curious to learn more. We hold ourselves to the highest standards of quality and integrity. We work with urgency because we love what we do.\nDedicated to Customer Success: Helping our customers succeed is our number one goal and inspires every action we take. We want our customers' practices, and their patients, to thrive. We are empathetic, solution-oriented, and aligned with their needs.\nTogether We're Better:We are honest, approachable, and collaborative. We believe great teams with members that are willing to do what it takes to get the job done can accomplish more. We put the team first and win together.\nConstant Innovation: We reject the status quo. We take a unique approach and make every effort to bring clarity to a needlessly complex industry. We are creative problem solvers. And we apply the same innovative thinking to our business and healthcare as a whole. We believe in making things better.\nKareo is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\nTo apply to this job, click Easy Apply"}, "595": {"company": "Fidelity Investments", "description": "At Fidelity\u2019s Artificial\nIntelligence Center of Excellence (COE), you won\u2019t be just tinkering around the\nedges, you\u2019ll be building critical solutions that will benefit our clients for\nyears to come. We work closely with business stakeholders, collect\nrequirements and deliver high value AI/ML solutions that drive customer and\nbusiness value. Those of us who love to work with data see this as the\npinnacle of opportunities that you cannot find anywhere else in the industry.\n\nThese positions are all\nlocated in Boston, MA.\n\nThe Team\n\nThe AIML (Artificial\nIntelligence and Machine Learning) team contributes to the vitality and growth\nof the organization through researching and building complex, cutting edge and\nscalable AI algorithms, models, platforms and technologies to significantly\nimprove customer experience and drive business results. Our team of high\ncaliber scientists, mathematicians and statisticians use rigorous quantitative\napproaches to ensure that we are efficiently building algorithms and technology\nrelevant to the business or customer experience issue at hand.\nThe Expertise You Have\nMinimum Master\u2019s Degree\nin Engineering, Computer Science, Mathematics, Computational\nStatistics, Operations Research, Machine Learning or related technical\nfields.\nAdvanced knowledge in model\nevaluation, tuning and performance, operationalization and scalability of\nscientific techniques and establishing decision strategies.\nHands on experience developing\nsupervised and unsupervised machine learning algorithms (regression,\ndecision trees/random forest, neural networks, feature\nselection/reduction, clustering, parameter tuning, etc.),\nExperience in evaluating and\nmaking decisions around the use of new or existing tools for a project.\nExperience in projects involving\nlarge scale-multi dimensional databases, complex business infrastructure,\nand cross-functional teams. Three to five successfully launched ML\nprojects would be ideal.\nProgramming skills\nin Python, Spark, Scala, R or MatLab\nThe Skills You Bring\nYour solid skills in algorithm\ndevelopment and predictive modeling\nYou have deep knowledge of some\ncombination of the following:\nNatural Language Processing\n(NLP)\nDeep Learning, Neural Networks\nReal Time Event Detection and\nScoring\nTime series analysis,\nEconometrics\nRobotic Process Automation\nCloud ML\nThe Value You Deliver\n\nYou will partner with\nbusiness stakeholders to identify/prioritize top AI opportunities, create\nbusiness/technical requirements, transform large volumes of data into AI-driven\nsolutions using creative, cutting edge open source methods/technologies, lead\nML strategy and road map planning, work across teams and influence the\ndirection of external teams. The ideal candidate will combine expert AI/ML/Open\nSource/Tech knowledge with hands on experience building\nalgorithms/models/programming and outstanding business skills (revenue/cost\ndrivers, customer experience, customer journey, communication, etc.) to manage\nand deliver complex/critical projects driving significant value to Fidelity.\nCompany Overview\n\nAt Fidelity, we are focused on making\nour financial expertise broadly accessible and effective in helping people live\nthe lives they want. We are a privately held company that places a high degree\nof value in creating and nurturing a work environment that attracts the best\ntalent and reflects our commitment to our associates. We are proud of our diverse and inclusive workplace where\nwe respect and value our associate\nfor their unique perspectives and experiences. For information about working at\nFidelity, visit FidelityCareers.com.\n\nFidelity\nInvestments is an equal opportunity employer.\nTo apply to this job, click Apply Now"}, "596": {"company": "Q2 Solutions", "description": "Q2 Solutions is a leading clinical trial laboratory services organization with end-to-end laboratory services and secure, enterprise-wide biospecimen and consent management solutions. With a relentless focus on quality and innovation, Q2 Solutions uses its global experience and scientific expertise to transform science and data into actionable medical insights that help customers improve human health. A joint venture of IQVIA (formerly QuintilesIMS) and Quest Diagnostics, Q2 Solutions combines the best of each parent organization\u2019s clinical trials laboratory services capabilities to fulfill its mission of treating each sample as if a life depends on it.\n\nPURPOSE\n\nThis scientific position builds on experience, skills, and personal attributes of an accomplished bioanalytical scientist. The position involves applying laboratory skills to assist in the development and implementation of small molecule therapeutics and biomarkers.\n\nRESPONSIBILITIES\nWork under the direction of senior scientists and/or management to perform wet laboratory work in support of regulated bioanalytical method validation. May also conduct method development and troubleshooting experiments. Occasional study sample analysis may also be required.\nUphold all safety standards, guidelines, and regulatory compliance requirements\nConduct all aspects of manual and automated sample preparation\nMake and record observations, and perform calculations as required\nDocument all project work according to Q Squared and GLP processes and procedures\nBuild specialized knowledge in chromatographic and mass spectrometric techniques for career development\nPrepare and present project data and supporting information as required.\nAssist with training new Wet Laboratory staff and provide leadership to less experienced staff\nResponsible for providing clear communication with higher level Scientific, Project Management, and LCMS teams\nPrepare stock and working solutions, standards and QC samples\nWeigh reference compounds\nAssist in maintaining adequate supplies and housekeeping of laboratory areas\nParticipate in process improvement initiatives, e.g. 6S\nREQUIRED KNOWLEDGE, SKILLS AND ABILITIES\nHighly experienced in all routine laboratory procedures\nUnderstanding of development/validation of methodology\nUnderstanding of wet-laboratory sample extraction\nAbility to interact with clients, and work to objectives/timelines\nExcellent attention to detail and communication skills\nAbility to maintain clear and efficient documentation\nAbility to follow verbally communicated or draft procedures\nGeneral understanding of chromatography and mass spectrometry instrumentation\nAbility to establish and maintain effective working relationships with coworkers, managers and clients.\nMINIMUM REQUIRED EDUCATION AND EXPERIENCE\nBachelor\u2019s Degree in Chemistry or a related field with 3 years of related experience; or equivalent combination of education, training and experience in GLP laboratory environment.\nPHYSICAL REQUIREMENTS\nExtensive use of keyboard requiring repetitive motion of fingers\nExtensive use of telephone and face-to-face communication requiring accurate perception of speech\nRegular sitting for extended periods of time\nExtensive use of micropipettes requiring repetitive motion of hand and wrist\nMay be required to lift 20-pound loads on an infrequent basis\nAbility to wear PPE, as required\nWill work with general laboratory reagents and research compounds\nIQVIA is an EEO Employer - Minorities/Females/Protected Veterans/Disabled\n\nIQVIA is an EEO Employer - Minorities/Females/Protected Veterans/Disabled\n\nIQVIA, Inc. provides reasonable accommodations for applicants with disabilities. Applicants who require reasonable accommodation to submit an application for employment or otherwise participate in the application process should contact IQVIA\u2019s Talent Acquisition team at workday_recruiting@iqvia.com to arrange for such an accommodation.\n\nApply Now!\nTo apply to this job, click Apply Now"}, "597": {"company": "Esurance", "description": "Team. Culture. Community. That\u2019s Life at Esurance!\nThe Esurance Internship Program is a 12 week summer program offering students an opportunity to explore our culture, gain business expertise, and provide innovative solutions to enhance our organization. We\u2019re looking for a Data Science Intern to join our dynamic team of individuals who are committed to making insurance surprisingly painless! We\u2019re a socially conscious company that\u2019s focused on creating a diverse work environment.\n\nWhat our Data Science & Analytics Group is all about:\nEsurance has created a centralized data science & analytics (DSA) group that is responsible for helping business units make objective decisions using data. The group supports the company\u2019s overall business operations by delivering critical analytical insights and in-depth consultative analyses to senior management teams and our business partners.\nWhat we\u2019ve accomplished:\nWe have exploited our rich data repositories, industry-competitive data science tools, expertise and business SME knowledge to collaboratively build several machine learning models and applications which are used by our customers and associates on a daily basis across the range of operations of the company. Applications include accurate insurance pricing, customer lifetime value prediction, severe injury detection in Claims and prediction of customer churn.\nWhat we\u2019re working on:\nWe are building and deploying state-of-art machine learning and AI models to help our Claims, Product Pricing, Marketing, Sales and Service teams realize business value through automation, improved process efficiencies and optimal decision-making. Our recent efforts leverage deep learning expertise in NLP to take advantage of unstructured text data available in Claims reports, customer survey responses, emails and virtual chat sessions to uncover actionable insights.\nWhat you\u2019ll do:\nAs an intern of DSA, you will collaborate with some of our senior data scientists on various projects, a valuable opportunity to gain hands-on industrial experience for someone with career focus as a future data scientist. The data science intern will work closely with some senior team members with the following responsibilities:\nSupporting data science projects in data acquisition, cleaning, processing.\nResearching predictive algorithms using large amounts of structured and unstructured data.\nDesigning experiments to determine efficacy of solutions.\nProviding on-going performance monitoring of decision systems and statistical models\nFirst cohort runs from 5/18/2020 - 8/7/2020 for semesters students\nSecond cohort runs from 6/15/2020 - 9/4/2020 for quarters students\nWhat we\u2019re looking for:\nCandidates in a Masters or PhD program are strongly preferred.\nMinimum GPA: 3.4\nDemonstrate a strong interest in data science as a future career.\nExcellent knowledge of a language for statistical and scientific computing (R, Python, etc.).\nExtensive experience in data management and data scrubbing.\nStrong aptitude towards math and programming.\nAbility to communicate complex information in a way that is clear and easily understood.\nPrior exposure to machine learning techniques such as dimension reduction, regression, clustering, and classification to solve real-world problems.\n\nCompensation is nice! 12-week PAID summer internship. 40 hours per week\nYou\u2019ll be matched to a meaningful project that will build on your skills and background\nTackling complex, real-world problems, you\u2019ll have the opportunity to own your projects from start to finish, all while working as part of a team!\nAttend new hire orientation with your cohort on your first day\nProfessional Opportunities: Exposure to Esurance Executives, Work alongside skilled industry veterans and Participate in a Professional Development Course\nDevelopment Opportunities: Personal manager and mentor, Hands-on coaching and development, Exciting learning opportunities\nPersonal Opportunities: Weekly social events and lunches, A Volunteer Day (Community Service), Great location in San Francisco\u2019s Financial District, Walking distance to popular attractions\nPresenting your work: You will have two opportunities to present in front of the leadership team and your colleagues. Presentations will allow you to share what you have learned throughout your experience.\nLearn more about us:\nEsurance combines the spunk of a startup with the backing of Allstate (the largest publicly held personal lines insurer in the U.S.) to create a unique, energized, and exciting place to work.\nTo learn more about Life at Esurance, please review our Glassdoor page and see why our employees love to work for us!\nStart your job application: click Apply Now"}, "598": {"company": "PEAK6", "description": "Data Engineer, Irvine - New Startup, PEAK6 Entity\n\n\nPortland\n\nWe are looking for a technical, entrepreneurial-minded Data Engineer to help us create solutions that modernize the traditional financial services industry. You will design, develop, deploy, and maintain a number of real-time databases, data warehouse, and reports that will be the foundation of the new platform. Working alongside experienced engineers and product managers, you will build this exciting platform that will simplify, automate, and facilitate access to financial markets for all.\n\nThe role is for someone who is passionate about applying modern technology to replace monolithic and hard-to-access incumbent systems. Along the way, you'll learn about the problem space and re-imagine existing solutions. You will work on a number of back-end services and integration solutions using multiple languages and frameworks.\n\nThis is an opportunity to join a fast-paced team with the urgency of a startup and expertise of an established organization. We are a flat organization which will afford you the ability to gain access to personnel and resources necessary to execute on your vision. PEAK6 is a privately-held organization focused on delivering long-term value rather than short-term gains. This translates to a focus on bringing solutions for an industry and not bespoke products. Due to the space we innovate in, your products will process billions of transactions per day, in real-time, and power both startup and established industry participants.\n\nYou will report to the VP of Data Engineering, but work closely with everyone across the organization.\n\nThis role can be based out of Irvine or Portland.\n\nWhat you'll do all day:\nDesign, develop, deploy, and maintain the transactional and analytical databases for the platform\nThink through hard data problems and solve them for the enterprise\nDevelop and maintain a clean and consistent database and reporting environment for both internal applications and external client applications\nWrite self-documenting and well-tested code with an emphasis on sustainable development practices\nWork as a part of small, productive development team that puts an emphasis on code quality, peer reviews and strong engineering practices\nWhat you need to succeed:\nA degree in Computer Science, Computer Engineering or other demanding engineering degree (or equivalent work experience)\nAt least three years of professional experience working with databases and SQL. A strong preference for expertise in PostgreSQL.\nProfessional experience with data modeling and data warehousing\nProfessional experience with database administration. Experience architecting database solutions that involve high availability, disaster recovery, and database replication\nProfessional experience designing and developing reports for internal employees and external facing clients\nProfessional experience working as a part of a multi-person development team that utilizes automated testing, CI/CD pipelines, and peer reviews\nOne or more years of mid to senior experience is a necessity as you will be expected to follow established practices and patterns without day to day supervision\nWe are writing mostly Golang and SQL. A strong proficiency and in-depth understanding of at least one of the following core languages a must: SQL, Go, C, C++, C#, Java\nDemonstrated skills in process and algorithm design\nAbility to learn new and unfamiliar technologies quickly, as required\nExperience with Kafka, Protobufs, and reactive, multi-tenant applications a big plus\nA DevSecOps mindset and experience with cloud-native applications and infrastructure-as-code is a plus\nTo apply to this job, click Easy Apply"}, "599": {"company": "Dell", "description": "Data Scientist Product Manager\nAustin, TX\n\n\nDell provides the technology that transforms the way we all work and live. But we are more than a technology company \u2014 we are a people company. We inspire, challenge and respect every one of our over 100,000 employees. We also provide them with unparalleled growth and development opportunities. We can\u2019t wait for you to discover this for yourself as a Data Scientist Product Manager.\n\nProduct Development Management is a fast-paced environment where innovative thinking is prized. Our team focuses on the delivery of products or computer-based systems for external customers. We lead and deliver the entire lifecycle from product definition and planning through to production and release. We also oversee modifications, upgrades and maintenance of the product or product line. And to make the whole process run smoothly and seamlessly, we\u2019re experts in analytics project management, from initiation through to delivery, and liaise with other departments on technical matters. We are looking for a candidate who has a strong background in product management, data science and analytical problem-solving.\n\nResponsibilities:\nBuild best in class AI products to create value for our customers and business.\nExperience shipping successful products, including defining vision, strategy, outcome-driven product roadmaps and creating and managing backlogs\nAnalyze customer behavior and business performance to design and develop impactful analytics solutions/products.\nDrive analytics program & product management while working with cross-functional teams.\nWork with software engineering, data engineers, data scientist, architects and business to design actionable strategic products.\nLead cross-functional engagements to define problem statements, collect data, build analytical models and make recommendations.\nLead end-to-end AI product development from understanding the user requirements to successfully delivering products in production environment.\nRequirements:\n6+ years of relevant Product Management experience with at least 2+ years\u2019 experience with AI/ML\nTypically requires 12+ years of related experience in a professional role with a Bachelor\u2019s degree; or 8+ years with a Master\u2019s degree; or 5+ years with a PhD; or equivalent experience\nExperience in most big data and statistical analytic tools: Python, Hadoop (Hive), SQL and machine learning algorithms/concepts.\nExperience with lean startup or agile/Pivotal methodologies for developing products.\nHands-on analytics capabilities, expertise in analytical problem-solving techniques and frameworks and the ability to deal with large volumes of data.\nStrong communication skills, including the ability to convey analytic insights effectively to both IT and business audiences\nStrong teamwork, business acumen, and customer advocacy skills\nPreferences:\nExperience working within global teams\nExperience with large, high-volume web sites\nBenefits\nWe offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities \u2014 all to create a compelling and rewarding work environment.\n\nDell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Learn more about Diversity and Inclusion at Dell here.\nApply Now: click Apply Now"}, "600": {"company": "PayPal", "description": "Design, develop and implement advanced predictive models using advanced data mining and machine learning techniques.\nCollaborate with other data scientists and engineers to formulate innovative solutions to experiment and implement advanced data mining techniques\nWork with large volumes of data; extract and manipulate large datasets using standard tools such as Python, Hadoop, R, SQL and SAS\nAnalyze data covering a wide range of information from user profile to transaction history. Identify new risk patterns through data mining\nCommunicate complex concepts and the results of the analyses in a clear and effective manner through creative visualization\nQualification\nAdvanced degree (MS or PhD) in science or engineering field with 4+ years of relevant experience\nData Mining experience in Python, R, H2O, Scala and/or other Big Data techniques. Familiar with various Machine Learning algorithms and Statistical methods\nAbility to deal with large amount of data and fluency with SQL or SQL-like tools.\nStrong problem solving and communication skills\nHave a passion for working on big data and professional experience in data mining, statistical analysis, predictive modeling, and data manipulation.\nFinancial services or eCommerce experience a strong plus\nStart your job application: click Apply Now"}, "601": {"company": "Guidewire Software, Inc.", "description": "Guidewire\u2019s Cyence Risk Analytics products help the (P&C) property & casualty insurance industry to model new and evolving risks such as cyber. By combining internet-scale data listening, adaptive machine learning, and insurance risk modeling, Cyence Risk Analytics provides insights that help P&C customers face new risks, take advantage of new opportunities, and develop new products. To learn more about Cyence Risk Analytics, please visit https://www.guidewire.com/products/cyence\n\nWe are seeking a talented Principal Modeler to join our team. Your responsibilities as a modeler will include:\nDeveloping and implementing methodologies to quantify the impact of cyber security risk, as well as other emerging risks affecting the P&C industry\nExploring different data sources to come up with features and assumptions to enhance our set of risk models\nCalibrating, testing and validating different types of models in the insurance space\nIntegrating modeling processes in our production pipeline to feed our platform\nCommunicating technical details related to the models and their outputs to individuals from various backgrounds\nWorking together with cyber analysts, data engineers, modelers, and product managers\n\n\nWhat we are looking for:\nMaster\u2019s or PhD degree in a quantitative field (e.g. CS, Statistics, Sciences, Engineering, Economics)\nSolid statistics and predictive modeling foundations\n6+ years of experience in data analysis, feature engineering, data visualization and hypotheses testing\nExperience working different types of datasets (e.g. unstructured, semi-structured, with missing information)\nExperience in implementing parametric and non-parametric models in a production-level environment\nHigh level proficiency in Python or R, and SQL\nGood written and verbal communication skills\nAbility to think critically and creatively in a dynamic environment, while picking up new tools and domain knowledge along the way\nA positive attitude, and a growth mindset\nBonus:\nInsurance, actuarial modeling or financial modeling experience\nGeneral understanding of computer network and cybersecurity\nExperience with Cloud infrastructure (e.g. AWS), and open source data processing frameworks (e.g. Hadoop, Spark, Mongo and Cassandra)\nGuidewire exists to help property and casualty (P&C) insurers adapt and succeed at a time of accelerating change. We provide an industry platform that our customers rely upon to run, differentiate, and grow their business. Now serving 370+ customers in 30 countries, Guidewire is regarded by industry commentators as the leading vendor that has helped P&C insurers to replace aging legacy systems with modern software. Now Guidewire is intent on leading the next era of technology in P&C, industry platforms consisting of software, services and partner ecosystem and powered by the cloud.\nTo apply to this job, click Apply Now"}, "602": {"company": "Alaant Workforce Solutions", "description": "Alaant is seeking a Data Analyst in the Glens Falls, NY area for our client who partners with local healthcare organizations to provide better health care solutions to the upstate New York region. In this role you will participate in analyzing and maintaining the accuracy and integrity of the costs in medical care.\n\nJob Details:\nAnalyze and maintain the accuracy and integrity of the cost standards data.\nReview and utilize purchase and pharmacy reports, review invoices and journal entries.\nReview and analyze individual department cost structures.\nRun monthly flex budget process, review flex budget reports and assists management with questions.\nPrepare miscellaneous cost analyses.\nParticipate in and provide support on a timely basis to each performance and profitability team.\nPrepare decision support system reports as requested by directors and managers.\nRequirements:\nMust have experience in creating, producing, and organizing data using statistics and business requirements.\n3 years of Database experience\n3 years of SQL Server/R Studio\n3 years of experience creating dashboards using Excel, Powerpoint or Tableau.\nBachelor's degree in Finance, Accounting, Information Technology or related field and 2 years of related experience required.\nFor more details on this role contact:\nJaime Toolan, Senior Talent Resource Manager @ 518-689-3155, Jaime.toolan@alaant.com\n\nAlaant Workforce Solutions wants all interested applicants to know they are seeking a diverse workforce and are actively recruiting candidates in accordance with diversity, inclusion and equal opportunity policies.\n\nConnect with us on LinkedIn, Facebook, Twitter, Instagram & Glassdoor\n\nAt Alaant we believe in People First! We Care. We Listen & We Support.\n\nwww.alaant.com\n\nINDNYH\nApply Now: click Easy Apply"}, "603": {"company": "Johns Hopkins University Applied Physics Laboratory", "description": "Do you love developing creative solutions to challenging problems?\n\nAre you passionate about providing real impact to the country's toughest national security problems?\n\nAre you searching for engaging work with an employer that prioritizes continual innovation?\n\nIf so, we are looking for someone like you to join our team at APL.\n\nAs a Senior Data Scientist at APL, you will get to work with state-of-the-art hardware, software, and techniques to develop computational algorithms and statistical methods that find valuable information hidden in large volumes of data.\n\nPosition Summary:\n\n\nThe Large-Scale Analytics Group (QAS) develops software systems that incorporate machine learning (ML) algorithms on big data platforms and graph databases as well as visual analytics to find details hidden deep within large and complex data sets. We support multiple agencies within the US Government by applying innovative analytics to uncover activities such as illegal activities, international trade fraud, illicit manufacturing of weapons of mass destruction, and cybercrime. You will implement and apply computationally tractable solutions and corresponding data architectures to address the needs of our sponsors. We are seeking a confident leader, creative thinker, motivated problem solver, standout colleague, and life-long learner that wants to strengthen the safety and security of our country. You will join a hardworking team in an inclusive environment that cultivates intellectual curiosity, innovation and creativity.\n\nAs a Senior Data Scientist you will...\nDesign creative algorithms and analytic pipelines for analyzing large-scale and complex data.\nLead analysis teams and develop proposals for new research. These proposals will be for sponsor-funded projects as well as internal research.\nDevelop large-scale data architectures using technologies like Hadoop, Spark, and distributed graphs to support analytic algorithms.\nBuild creative software applications and perform analytics on complex data.\nPresent results to both JHU/APL and Sponsor leadership.\nYou meet our minimum qualifications for this position if you\nPossess an M.S. or Ph.D. in Computer Science, Information Science, Mathematics, Physics, Operations Research, or a related discipline. 5 years of experience.\nHave experience with statistics, machine learning algorithms, and general algorithm development.\nHave knowledge of modern large-scale data systems and architectures.\nPossess solid software development skills, including in an Agile environment.\nExhibit excellent social skills, the ability to work independently, excellent written and oral communications skills, and good organizational skills.\nPossess an active secret clearance or higher; or are able to obtain a secret clearance at minimum. Preference for SSBI. If selected, you will be subject to a government security clearance investigation and must meet requirements for access to classified information. Eligibility requirements include US Citizenship.\nYou'll go above and beyond our minimum requirements if you\nPossess a Ph.D. in the disciplines listed above.\nHave experience leading software development and/or analysis teams.\nHave experience clearly presenting methods and results to business or government decision-makers.\nSpecial Working Conditions: [Travel, working in closed areas, extended hours]: Some local travel to sponsor sites may be required.\n\nWhy work at APL?\n\n\nThe Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation's most critical defense, security, space and science challenges. With a wide selection of challenging, impactful work and a robust education assistance program, APL promotes a culture of life-long learning. Our employees enjoy generous benefits and healthy work/life balance. APL's campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities atwww.jhuapl.edu/careers.\n\nAPL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, disability status, veteran status, or any other characteristic protected by applicable law.\nStart your job application: click Apply Now"}, "604": {"company": "Foundation Medicine", "description": "Data Scientist\nJob Location\n\n\nBoston, MA\n\nReq Number\n\n10842\n\nDepartment\n\n\nData Strategy & Prod Dev\n\nApply Now\n\n\nABOUT FOUNDATION MEDICINE\n\nFoundation Medicine, Inc. (FMI) began with an idea\u2014to simplify the complex nature of cancer genomics, bringing cutting-edge science and technology to everyday cancer care. Our approach generates insights that help doctors match patients to more treatment options and helps accelerate the development of new therapies. Foundation Medicine is the culmination of talented people coming together to realize an important vision, and the work we do every day impacts real lives.\n\nABOUT THE JOB\n\nData Scientist I, Data Products researches, prototypes, and otherwise enables the next generation of real-world data products. In partnership with product managers, engineers, and domain experts in oncology and genomics, the Data Scientist leverages FMI\u2019s real-world data assets, including FoundationCORE and clinico-genomic database (CGDB) for efforts in analyzing real-world clinical and genomic data. Specifically, the incumbent examines clinical use cases, such as biomarker-based outcomes analyses, examining genomic predictors of clinical outcomes, clinical utility of next-generation sequencing, and the impact of diagnostics on patient care. The Data Scientist I collaborates with internal and external stakeholders to explore and develop opportunities to provide clinical decision support tools based on FMI\u2019s data assets.\n\nKey Responsibilities:\nDesign, execute and present data query results of large genomics, clinical and process datasets to identify correlating information.\nDesign and develop standardized data templates for reporting and visualization of validation study results.\nProvide insights and collaborate with other functions in building a centralized validation database to store and trace all analytical and clinical validation data.\nMaintain and expand knowledge of and access to available and meaningful data sources within and outside of FMI, and their application to product development needs.\nCollaborate with the Medical, Commercial and Product Teams to design and execute quantitative analyses of real-world oncology cohorts.\nCreate data visualizations communicating insights to a range of audiences.\nDevelop prototype data products for internal and external users, especially in the area of clinical decision support applications.\nContribute to the scaling of data product tools to FMI\u2019s customers that utilize real world data insights.\nCo-author case studies and peer-reviewed publications.\nProvide support on projects of increasing complexity, as needed.\nOther duties as assigned.\nQUALIFICATIONS\n\nBasic Qualifications:\nMaster\u2019s Degree in Statistics, Bioinformatics, Computer Science, Biomedical Engineering, Mathematics, or related field and 1+ year of work experience in the fields of data science, data analysis, biostatistics, or bioinformatics\nOR-\nPh.D. in Statistics, Bioinformatics, Computer Science, Biomedical Engineering, Mathematics, or related field with no professional work experience.\nPreferred Qualifications:\nExpertise in biostatistics and epidemiology data sources and analysis.\nExperience with the statistical analysis of analyzing clinical health data, particularly survival and outcomes analyses.\nExperience with the development of clinical decision support tools.\nExperience with the statistical analysis of genomic data (+/- other omics data types).\nKnowledge of Next-Generation Sequencing (NGS).\nFamiliarity with regulatory requirements, including those of GCP and ICH.\nHistory of successfully completing highly-independent work.\nAbility to collaborate within cross-functional teams.\nStrong interpersonal skills that include excellent skills in written and oral communication, and problem solving with other departments and colleagues.\nDemonstrating of integrity and a commitment to values held at FMI: patients, innovation, collaboration, and passion.\nDemonstrated history of successfully managing multiple initiatives and maintaining one\u2019s own workflow.\nUnderstanding of HIPAA and importance of privacy of patient data.\nFoundation Medicine is proud to be an Equal Opportunity and Affirmative Action employer and considers all qualified applicants for employment without regard to race, color, religion, sex, gender, sexual orientation, gender identity, ancestry, age, or national origin. Further, qualified applicants will not be discriminated against on the basis of disability or protected veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also FMI\u2019s EEO Statement and EEO is the Law and Supplement. If you have a disability or special need that requires accommodation, please let us know by completing this form. (EOE/AAP Employer)\nApply Now: click Apply Now"}, "605": {"company": "GreatCall", "description": "Senior Data Science Software Engineer\nLocation San Diego, CA\nApply Now\nPOSITION: Senior Data Science Software Engineer\nDEPARTMENT: Data Science & Analytics\nREPORTING SUPERVISOR: VP, Data Science & Analytics\nDIRECT REPORTS: No\nFLSA: Exempt\nEMPLOYMENT STATUS: Direct Hire\nTRAVEL REQUIREMENTS: 1-4 times per year\nSCHEDULE: Standard business hours\nABOUT THE TEAM:\nOur team uses technology to improve the wellness of people, reduce healthcare costs, and provide safety for our customers. Wearable mobile devices and sensors installed throughout homes measure daily activities of individuals. A variety of physical parameters are continually collected, aggregated, processed, and monitored. This information is augmented with data from business operations as well as trained staff in direct contact with customers. Machine learning and other algorithms are used to interpret data into meaningful trends and predictions. The system is implemented by a robust, horizontally scalable software architecture. Our technical staff includes software engineers, product designers, infrastructure professionals, data scientists, and business intelligence analysts. We work closely with product managers and other groups to understand and formulate requirements with freedom to recommend and explore solutions. We analyze data, develop and implement algorithms, and monitor results to ensure that our products function reliably to serve our customers.\nABOUT THE JOB:\nYou will be working on socially fulfilling products deeply involved in the areas of data analytics, cloud-based big data, and Internet of Things (IoT). You will be a major stakeholder in these products by analyzing data, developing predictive models, implementing algorithms in code, validating and testing performance, and presenting results. This position would be a good fit for machine learning engineers and data scientists who enjoy both developing algorithms and making them work robustly in production, or a software engineer with a thorough understanding of machine learning and experience developing it. You must be capable of complex problem solving, self-motivated, and willing to interact frequently with people possessing different skill sets across business areas.\nRESPONSIBILITIES:\n-Design, build, and optimize predictive models using machine learning and other algorithms\n-Organizing, cleansing, and verifying the integrity of data used for analyses, including sensor and mobile device data as well as business data\n-Implement modeling and data handling that can be run in production, usually as python code\n-Write code to perform online stream processing and offline batch processing from data lakes, relational databases, and other data sources\n-Perform exploratory data mining to uncover relationships and trends in data\n-Present results clearly in both written and verbal form\n-Mentor less experienced members of the team\n-Recommend enhancements to data collection in order to promote our objectives\n-Work with product managers and other business groups to formulate requirements and suggest creative solutions for analytics features and functionality\n-Uphold best practices around development processes, coding, and peer reviews\n-Fully test algorithms and code to ensure the highest level of credibility, reliability, and maintainability\nQUALIFICATIONS:\nEducation: Requires a bachelor's degree in CS, EE, Mathematics, Statistics, or other rigorous quantitative program; prefer a Master\u2019s degree or higher\nExperience:\nRequired:\n-At least 4 years of experience developing machine learning algorithms\n-At least 5 years of experience writing code in modern general-purpose programming languages\n-At least 2 years of experience writing extensive code in Python, including experience with computational libraries such as NumPy, Pandas, and scikit-learn\n-At least 3 years of experience accessing and manipulating a relational database using SQL, with some attention paid to efficiency optimization\nPreferred:\n-Experience with distributed batch processing frameworks (Spark, Hadoop MapReduce, etc.) and stream processing frameworks (Kafka Streams, Spark streaming, etc.)\n-Experience with TensorFlow\n-Experience using data visualization tools such as Tableau, Jupyter notebooks, or libraries such as matplotlib\nKnowledge/Skills/Abilities:\nRequired:\n-Excellent understanding of supervised learning (regression, SVM, neural networks, decision forests, time series prediction, etc.) and unsupervised learning (clustering, PCA, etc.)\n-Knowledge of deep learning, reinforcement learning, RNNs, and other modern AI methods\n-The ability to adeptly write core Python\n-Strong academic foundation in probability theory, statistics, and applied mathematics\n-Knowledge of software engineering good practices such as design for robustness and maintainability, Agile methods, source control, and package/environment management (e.g., Anaconda).\nPreferred:\n-Knowledge of signal processing, information theory, detection & estimation theory, Bayesian filtering, and Markov models\n-Familiarity with IoT or healthcare applications\nApply Now: click Apply Now"}, "606": {"company": "Specialized Bicycle", "description": "Are you a natural leader with the ability to bounce back and forth between strategic planning and getting into the weeds on a specific data projects? Do you have a passion for harnessing diverse datasets to drive consumer experiences and business outcomes? Are you simultaneously comfortable with statistical analysis/inference and modern deep learning and machine learning approaches? Can you combine a diverse array of data science techniques and tools to ultimately create personalized recommendation engines? If you were able to answer yes to these questions then we want to talk to you!\n\nWe are searching for a Data Scientist to join our team and be a leader that will ultimately build a modern data function for Specialized!\n\nHOW YOU'LL MAKE A DIFFERENCE\nEnd-to-end deep learning/machine learning application: data analysis and idea conceptualization, model definition and refinement, creation of proof of concept, production development and deployment.\nBenchmark, investigate, and propose newest techniques and approaches to harnessing AI for personalized recommendations.\nCreate specific algorithms to drive product and experience recommendations.\nBig data analysis and support of multiple teams, including product development and operations planning.\nDefine necessary data architecture to support application of models/algorithms and data analysis.\nWHAT YOU NEED TO WIN\nGraduate degree and/or multiple years experience in Data Science or related field (Computer Science, Mathematics, Statistics, Engineering).\nExperience with a variety of machine learning / deep learning techniques, including model development and production deployment.\nExperience with SQL/Python/R\nExperience with recommendation algorithms\nExperience with data analysis tools and techniques, particularly big data approaches\nFirst and foremost, we are riders. We share the core belief that bikes change lives. From product development and operations, to finance and marketing - every role at Specialized contributes to a culture of sustainable, global growth and innovation. We are always looking for passionate people to join the team who are interested in learning and growing far above the scope of the position. You'll be challenged in many different ways and have a tremendous amount of opportunity. All with an eye towards growing people and expanding careers.\n\nYou'll be working alongside a passionate, driven team and there are some great benefits including daily lunch rides, onsite yoga classes, and all of the bagels your heart desires on Friday mornings. Come ride with us!\n\nSee what we are up to on LinkedIn, Instagram, and most importantly, our #DogsofSpecialized.\nTo apply to this job, click Apply Now"}, "607": {"company": "MITRE", "description": "Why choose between doing meaningful work and\nhaving a fulfilling life? At MITRE, you can have both. That's because MITRE\npeople are committed to tackling our nation's toughest challenges\u2014and we're\ncommitted to the long-term well-being of our employees. MITRE is different from\nmost technology companies. We are a not-for-profit corporation chartered to\nwork for the public interest, with no commercial conflicts to influence what we\ndo. The Research & Development centers we operate for the government create\nlasting impact in fields as diverse as cybersecurity, healthcare, aviation,\ndefense, and enterprise transformation. We're making a difference every\nday\u2014working for a safer, healthier, and more secure nation and world.\n\nThe candidate should possess extensive experience analyzing\nlarge scale datasets from prominent and emerging domains as well as complex\nsocial networks using unique and innovative methodologies. The candidate should have a strong knowledge\nof data science, various programming languages, and open source\ntechnologies. Skills sought include\nUtilize\nexisting open source social media methodologies to apply specialized tools and\ncapabilities in support of the Department of Homeland Security (DHS) national\nsecurity mission\nExperience\norganizing analytic results for further analysis\nAbility to\nfind patterns in data and clearly articulate the entire analysis (e.g.,\nmethodology, results, assumptions, constraints) using various suites of tools\nExperience\nwith databases technologies (e.g., PostgreSQL, Oracle, MySQL, SQL Server,\nMongoDB, Neo4j)\nExperience\nmanipulating datasets with at least one modern programming language or business\nintelligence platform like Python, SAS, MATLAB, C , R, Java, SQL, PL/SQL\nCreatively\napply visualizations to large datasets using tools like Tableau, Power BI, or Qlik\nAbility to\nunderstand and map data relationships\nAbility to\nassess the quality of data or tool against a set of requirements\nAbility to\nprepare comprehensive written reports, presentations, and charts based on\nresearch, collection, and analysis of intelligence data\nExcellent\nwritten and verbal communication skills, adapted to a variety of audiences and\ntechnical understanding\nAdvanced and\nproven ability to:\nAssess the\ngaps between current capabilities and target business/IT needs\nAnalyze and\nalign business and technology strategies\nIdentify,\nanalyze, and recommend high-impact alternative solutions and prototypes\nRequired Business/Soft Skills\nExperience\nin a customer-facing environment\nAbility to\nleverage both MITRE and team knowledge effectively\nAbility to\nwork in a \u201cwar room\u201d environment (i.e., close quarters within an open team room\nwith multiple conversations)\nAbility to\nwork with a variety of audiences to include sponsors, vendors, and partner\ncontractors\nStrong\ncommunications and interpersonal skills\nMust have\ngood analytical, written, presentation skills\nStrong\ninterpersonal communication skills to interact with senior Government staff,\ntechnical peers, and MITRE team members\nAbility to\nwork in a dynamic fast-paced environment\nRequirement - DOD Secret or higher and DHS Suitability\nSecret or higher (preferred)\nStart your job application: click Apply Now"}, "608": {"company": "Perfect World Entertainment", "description": "The Data Scientist provides data-driven insights related to several of Perfect World\u2019s services and products, including our popular games and the global game publishing platform.\n\nHe/she identifies the opportunities that would help improve the user acquisition, retention and monetization of our games.\n\nIdeal candidates will have a deep understanding of statistics and machine learning algorithms, experience working with large datasets, and an ability to communicate actionable insights directly to non-technical audiences.\n\nKey Qualifications\n2 years of industry experience in a Data Science or Analytics role.\nExperience with visualization software.\nWorking knowledge of SQL and Python/R.\nWorking experience of Machine Learning and predictive analytics.\nFamiliarity with the Hadoop framework, including the ability to interact with data through Hive, Pig, or MapReduce preferred.\nStrong communication skills, both written and oral, and an ability to convey complex results in a clear manner.\nData Science or Analytics experience in gaming or marketing strongly preferred.\nEducation\nMajor in a quantitative field, such as Computer Science, Applied Mathematics, or Statistics, or equivalent professional experience.\nTo apply to this job, click Apply Now"}, "609": {"company": "PwC", "description": "PwC Labs is focused on standardizing, automating, delivering tools and processes and exploring emerging technologies that drive efficiency and enable our people to reimagine the possible. Process improvement, transformation, effective use of innovative technology and data & analytics, and leveraging alternative delivery solutions are key areas of focus to drive additional value for our firm.\n\nThe AI Lab focuses on implementing solutions that impact efficiency and effectiveness of our technology functions. Process improvement, transformation, effective use of technology and data & analytics, and leveraging alternative delivery are key areas to drive value and continue to be recognized as the leading professional services firm. AI Lab is focused on identifying and prioritizing emerging technologies to get the most out of our investments.\n\nTo really stand out and make us ?t for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\n\nAs an Associate, youll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nInvite and provide evidence-based feedback in a timely and constructive manner.\nShare and collaborate effectively with others.\nWork with existing processes/systems whilst making constructive suggestions for improvements.\nValidate data and analysis for accuracy and relevance.\nFollow risk management and compliance procedures.\nKeep up-to-date with technical developments for business area.\nCommunicate confidently in a clear, concise and articulate manner - verbally and in written form.\nSeek opportunities to learn about other cultures and other parts of the business across the Network of PwC firms.\nUphold the firms code of ethics and business conduct.\n\nJob Requirements and Preferences:\nBasic Qualifications:\n\nMinimum Degree Required:\nBachelor Degree\n\nRequired Fields of Study:\nComputer and Information Science, Computer and Information Science & Accounting, Operations Management/Research, Statistics, Accounting, Electrical Engineering\n\nMinimum Years of Experience:\n1 year(s) or 0 years with MS degree\n\nPreferred Qualifications:\n\nAdditional Educational Preferences:\n\nMaster Degree or equivalent (including MBA) with specialization or experience in machine learning, machine reasoning, natural language processing, or data mining unstructured data analytics in corporate or academic research environments.\n\nPreferred Knowledge/Skills:\n\nDemonstrates some abilities and/or a proven record of success, as both an individual contributor and team member through:\nDeveloping AI algorithms and solutions;\nProgramming (especially python) to enable rapid prototyping and implementation of solutions;\nDemonstrating experience in accounting and auditing and ability to understand business context and integrate artificial intelligence and advanced analytics levers for solutions;\nDemonstrating ability to articulate and clearly communicate the solution scope, timeline and benefits with clients;\nDemonstrating experience eliciting high-level business requirements and creating detailed functional specs as well as other documentation, such as requirement traceability matrices, work-flow diagrams and use-cases;\nDemonstrating ability to develop working relationships with all relevant parties, particularly at the senior management level;\nDemonstrating proven academic credentials with publications in journals and conferences; and,\nDemonstrating ability to work in a global collaborative team environment and proficient verbal and written English communication skills.\nDemonstrates some knowledge and/or abilities in:\nUnderstanding machine learning/deep learning, knowledge representation and reasoning, natural language understanding and natural language generation in corporate or academic research environments;\nUnderstanding Artificial Intelligence: Natural language understanding, natural language generation, knowledge representation and reasoning, and deep learning;\nUnderstanding Cloud based open source and solution deployment: docker container, kubernetes, Postgres, neo4j, mongodb, Drools and DevOps methodology; and,\nUnderstandingUI/UX frameworks such as Django, Flask, or equivalent.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nStart your job application: click Apply Now"}, "610": {"company": "Software Resources, Inc.", "description": "Software Resources has an immediate long term contract job opportunity for a Data Scientist with a major corporation in Orlando, FL.\n\nDescription:\nRelevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, or software engineering.\nAn ideal candidate for the Lead Machine Learning Scientist role should have practical experience, a love of experimentation, and a passion for the problem we're trying to solve. In this position, you will play a central role in developing Client ways to leverage machine learning and statistical analyses. You'll use a mixture of supervised and unsupervised techniques to generate and test hypotheses and turning your results into actionable, impactful insights. You will be exposed to and incorporate a variety of statistical and machine learning techniques such as logistic regression, experimental design, generalized linear models, mixed modeling, CHAID/decision trees, neural networks and ensemble models.\n\nWhat You'll Do:\n\" Knowledge of statistical concepts such as regression, time series, mixed model, Bayesian, clustering, etc., to analyze data and provide insights.\n\" Conduct statistical analysis and build time series models using linear regression, ARIMA, DLM, VAR, and VECM. Responsible for creating and implementing AI, machine learning and deep learning algorithms to solve business problems. Design project specific custom model architectures, preprocessing and postprocessing pipelines and training and evaluation procedures. Deploy machine learning and deep learning models from prototype stage to production ready, highly scalable applications capable of real-time and batch inference. Develop models to derive information from text using natural language processing like parts of speech, named entity recognition, constituency parsing, and dependency parsing. Automatically summarize text, classify text, extract sentiment and infer latent topics from text data to predict company performance.\nResearch, prototype, and develop core machine learning and statistical analyses for commercial strategy data including revenue and capacity data.\nMix supervised and unsupervised methods to train classifiers.\nLeverage cloud-based technologies to collate and pre-process model input data.\nWork closely with our team to validate and improve experiment results.\nAbout You:\nYou're adaptable, driven, and have at least a BS in Computer Science, Statistics, Mathematics, Applied Mathematics, or a related field.\nYou're a leader: you can accomplish things on your own, but you also bring out the best in people around you.\nYou have 3+ years of experience in architecting, implementing, and evaluating machine learning and/or image processing approaches for unique datasets.\nYou're proficient in Python and common machine learning frameworks\nYou're familiar with cloud computing technologies and conducting experiments on cloud-based datasets (e.g. Amazon EC2, Amazon S3, Docker, Snowflake).\nYou have strong written and verbal communication skills to share findings with the rest of the team.\nPluses:\nMS/Ph.D. in a relevant field.\nDemonstrable experience as a primary developer for production Client solutions.\nProficiency in machine learning and statistics theory, as well as knowledge of recent advances in deep learning.\nRequired Education:\nBS Computer Science or Math\n\nDon't delay. Join the Software Resources team today!\nSoftware Resources specializes in connecting talented IT professionals with challenging job opportunities that transform jobs into careers.\nTo meet our clients hiring needs, we continuously source talented IT Professionals with all levels of expertise and in all disciplines. We offer world class major medical, dental and vision benefits, 401(k) with match, short term disability, Life Insurance and AD&D. You, our future employees, can make a tremendous difference to our company and our clients. Please apply to this job and experience the Software Resources difference. You can view all of our jobs at https://www.softwareresources.com/careers/\n\nCompany Overview\nSoftware Resources is a national staffing and recruitment firm delivering the best candidates to our clients and the best jobs to our candidates since 1992.\nWe are a certified woman owned business in business to place contract, contract-to-hire, and direct-hire talent in Technology (IT, creative, marketing), finance, accounting, and executive-level positions. We serve many vertical markets including Entertainment/Media, Cruise Industry/Leisure travel, Hospitality, Government, Personal Care, Professional Services, Energy/Utilities, Security, and Financial Services.\n\nHeadquartered in Lake Mary, FL in the Orlando metro area, we have branches and sales professionals across the US. Wherever you're located and whatever the need, count on Software Resources to provide exceptional candidates who are fully vetted and ready to go. Call (800) 774-8036 or visit us online at https://www.softwareresources.com/ and leave the recruiting to us!\n\nApply Now: click Apply Now"}, "611": {"company": "Shape Security", "description": "About Shape Security\n\nWe are security and web experts, pioneers, evangelists, and elite researchers. We believe in the power of the Internet to be a positive force; our mission is to protect every website and mobile app from cybercriminals. Shape\u2019s founders fought cybercrime at the Pentagon, Google, and other leading security companies. We are backed by some of the most prominent leaders and investors in the technology industry including Kleiner Perkins, Google Ventures, and more. Come be a part of our unparalleled team that is responsible for making the Internet a safer place for everyone.\n\nPosition Summary\n\nWe are looking for a Big Data Engineer that will work on the storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.\nResponsibilities\nSelecting and integrating big data frameworks required to provide requested capabilities\nBuild analysis pipelines as well as visualization dashboards\nMonitoring performance and iterate the solution fast\nSkills and Qualifications\nExperience with Cloud-based service and development environment, such as AWS or GCP\nProficiency with programming languages such as Python and Java\nProficient understanding of distributed computing principles\nGood knowledge of Big Data querying databases, such as BigQuery, BigTable and MongoDB\nTo apply to this job, click Apply Now"}, "612": {"company": "Quantlab", "description": "We are seeking high caliber Quantitative Research Interns for our Houston office to contribute to the day-to-day activities of our research teams. Dive into challenging, results-oriented projects. Work in close collaboration with our researchers to solve problems in areas including mathematical modeling, algorithmic trading and computational development. Enjoy an informal and intellectually stimulating environment. Potential for successful internships to lead to full-time employment upon graduation.\n\nWhat you\u2019ll do:\n\nBased on your interests, skills, and the needs of our teams, you\u2019ll be matched with projects in one of the following tracks:\n\nCore Research Track\n\nImmersing yourself into very large data sets for model estimation and event studies is only half the battle. You may also be challenged to design and prototype algorithmic trading strategies.\n\nData Science Track\n\nJoin us in a data exploration and predictive science journey this summer! We are looking for curious data scientists who love to discover information hidden in vast amounts of data and are excited to help us make smarter decisions to deliver even better products to our trading environment. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems.\n\nStrategy Management Track\n\nUsing powerful analytic tools, dive into the details of market data to develop cutting-edge market research. You will also collaborate with senior traders, technologists and quantitative researchers to develop new ideas for our automated trading strategies.\n\nWhat you\u2019ll have:\nCurrently pursuing a Bachelor\u2019s, Master\u2019s or PhD in Physics, Pure or Applied Math, Statistics, Electrical, Chemical or Mechanical Engineering, Computer Science, or Industrial Engineering/Operations Research\nComputational research and/or development experience\nAbility to adapt to change quickly and to make the most of a collaborative environment\nApplied experience in C++/Python/R (preferred) and other languages\nSkill in mathematical methods and modeling\nAn innate need to decompose and understand complexities\nEagerness to grapple with hard-to-solve problems\nStrong written and verbal communication skills\nAlso helpful, but not required:\nPast internship or job experience in finance and/or a quantitative research role\nAdvanced coursework in algorithms, network programming, operating systems, compilers\nAbout Our Summer Internship Program\n\nProjects\n\nYou will be teamed with experienced researchers who will guide you through projects relevant to quantitative trading. You will work in small teams to understand the challenge, while receiving feedback throughout the project. At the end of the summer, you will give a presentation highlighting some of your work to leaders at Quantlab and your fellow interns.\n\nLearning\n\nYou will also take classes & training sessions that will introduce you to the trading industry. The goal of our education program is to provide you the basic industry knowledge to better understand the work we do.\n\nPerks\n\nYou are invited to participate in many Quantlab social activities, including pro sports games, company parties, and other outings in the Houston area.\n\nWho we are:\n\nQuantlab is a quantitative trading firm where Technology and Scientific Research are central to our business and key to our success. Founded in 1998, Quantlab is a pioneer in quantitative algorithmic trading. Behind our success is our people. We hire some of the smartest and most passionate programmers and quants in the world.\n\nThe firm is privately held with headquarters in Houston, and offices in Boston, Chicago, Denver, New Jersey, New York, Austin, and Amsterdam. We are 1 part Wall Street, 2 parts software development firm, 3 parts Los Alamos National Laboratory, and 4 parts Tony Stark's garage.\n\nWhy you should work with us:\n\nQuantlab is constantly pushing the boundaries of technology, from high performance computing clusters attached to petabytes of storage, to ultra-low latency hardware, to highly optimized operating systems. Team members at Quantlab enjoy the collaborative and results driven atmosphere. We follow the mantra of \u201cwe can do it better.\u201d Quantlab attracts very talented people who bring innovative and interdisciplinary solutions to trading. Our casual environment has an entrepreneurial spirit that encourages creativity, agility, and continuous improvement. Quantlab is a place \u201cwhere the best get better.\u201d\n\nQuantlab is not accepting unsolicited resumes from search firms. Only search firms with valid, written agreements with Quantlab should submit resumes in response to Quantlab\u2019s posted positions. All resumes submitted by search firms to Quantlab via e-mail, the Internet, personal delivery, facsimile, or any other method without a valid written agreement shall be deemed the sole property of Quantlab, and no fee will be paid in the event the candidate is hired by Quantlab.\nApply Now: click Apply Now"}, "613": {"company": "Bill.com", "description": "About Bill.com\n\nBill.com is a leading provider of cloud-based software that simplifies, digitizes, and automates complex, back-office financial operations for small and midsize businesses. Customers use the Bill.com platform to manage end-to-end financial workflows and to process payments, which totaled over $70 billion for fiscal 2019. The Bill.com AI-enabled, financial software platform creates connections between businesses and their suppliers and clients. It helps manage cash inflows and outflows. The company partners with several of the largest U.S. financial institutions, more than 70 of the top 100 U.S. accounting firms, and popular accounting software providers. Bill.com has offices in Palo Alto, California and Houston, Texas. For more information, visit www.bill.com or follow @billcom.\n\nMission: We are looking for a talented, enthusiastic and dedicated data science leader to join Bill.com\u2019s Risk Management team. The incumbent will be responsible for managing junior data scientists as well as leading key projects associated with predictive fraud detection, transaction risk modeling and loss mitigation at Bill.com. This position requires a person who has experience with developing machine learning models and performing analytics preferably in risk domain.\nProfessional Experience/Background to be successful in this role:\nMinimum 5 years of industry experience in data science\nAn advanced degree (M.S., PhD.), preferably in Statistics, Physical Sciences, Computer Science, Economics, or a related technical field\nStrong track record of performing data analysis and statistical modeling using SQL, SAS or similar tools\nMastery of a wide range of Machine Learning techniques, tools, and methodologies with a demonstrated capability to apply them to a broad range of business problems and data sources\nMachine Learning techniques include clustering, classification, regression, decision trees, neural nets, anomaly detection etc.\nAbility to clearly communicate complex results to technical experts, business partners, and executives\nComfortable with ambiguity and yet able to steer analytics projects toward clear business goals, testable hypotheses and action-oriented outcomes\nDesirable to have experience solving problems related to risk using data science and analytics\nExperience with implementation of Machine Learning models\nPrior team management and payment risk experience is a plus\nCompetencies (Attributes needed to be successful in this role):\nFunctional/Technical Expertise\nThought leadership/People leadership\nLearning Abilities/Tech Savvy\nCommunication\nTeam Player\nBill.com Culture:\n\u25cf Humble \u2013 No ego\n\u25cf Fun \u2013 Celebrate the moments\n\u25cf Authentic \u2013 We are who we are\n\u25cf Passionate \u2013 Love what you do\n\u25cf Dedicated \u2013 To each other and the customer\n\nStart your job application: click Apply Now"}, "614": {"company": "Sojern", "description": "*** Please note: This is a 12+ month PT Internship, 20 hours per week ***\n\nAbout Us:\n\nWant to join a company on the cutting edge of technology and travel? Want to be part of a fantastic and fun company that's revolutionising the online travel advertising space?\n\nSojern works with 93% of the Fortune 500 travel companies and has spent more than a decade analyzing the complete traveler path to purchase. We drive travelers from dream to destination by activating multi-channel branding and performance solutions on the Sojern Traveler Platform for more than 8,500 customers around the world.\n\nSojern made Deloitte's Technology Fast 500 list for the last 6 years in a row, and was recognised on the Top Company Cultures list by Entrepreneur Magazine and named a Best Place to Work by AdAge. The company is headquartered in San Francisco, with teams based in Dubai, Dublin, Hong Kong, London, Mexico City, New York, Omaha, Paris, Singapore, Sydney and Istanbul.\n\nNeed more convincing that Sojern is a great place to work? Check out our Glassdoor reviews!\n\nThe Role:\n\nThe Analyst & Data Science Intern role will focus on gaining an understanding of the online advertising ecosystem and use data to drive customer performance, operational efficiencies and company margin. An Analyst & Data Science Trainee will play a critical role within the Operations team by ensuring Sojern's clients' programmatic campaigns are structured and optimized in a way to drive optimal performance for Clients and Sojern. The intern will also have the opportunity to work cross functionally with Product, Engineering and Data Science. Upon completion of the program, interns who develop the necessary skill set will have the opportunity to apply for available full-time Data Science positions.\n\nIf you thrive in a fast-paced, innovative and collaborative environment, and are excited by the idea to make impactful data-driven decisions every day, then Sojern is the place for you!\n\nResponsibilities:\nManage Sojern Clients' programmatic campaigns by combining audience segmentation, bidding, delivery and pricing strategies to extract optimal conversion based performance by leveraging Sojern's travel data.\nSolve real client challenges by utilizing data mining and visualization to identify and implement new solutions.\nHave an opportunity to collaborate with the Product, Engineering and Data Science teams on a capstone project at the end of the internship.\nCollaborate with the global analyst team on automation projects and best practices.\nWhat you bring to the table:\nCurrent Graduate or Undergraduate student working towards a degree in data science, data analytics, statistics, or a related field.\nExperience with SQL and the Python Data Science toolkit (e.g. Jupyter, Pandas, Scikit-learn, Numpy).\nAbility to commit to 20 hours a week during normal business hours.\nCoursework covering topics such as sampling, hypothesis testing, regression, and Bayesian statistics.\nAbility to commit to the 12+ month program depending on current year in school.\nPerks:\nOpportunities: Be part of a growing team with training and support to help you grow\nOwnership: Lead creative and challenging projects\nGive Back: We give 40 hours a year to volunteer and organize office volunteer programs with local organizations\nCulture: Strong core business values, focus on teamwork, vibrant, social and fun environment\nSnacks: Variety of snacks in the office\nMeals: Monthly catered lunches & happy hours\nAt Sojern, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\n]]>\nStart your job application: click Apply Now"}, "615": {"company": "Novetta", "description": "Are you passionate about solving challenging problems?\nDo you thrive being a critical part of an elite team of like-minded people?\nHow would you like for your next career move to take you to the next level?\n\nIf any of this sounds appealing, look no further.\n\nJob Description:\n\nNovetta is seeking a skilled Senior Data Engineer to support a fast paced, innovative project supporting our client in the field of data science and AI/Machine Learning.\n\nBasic Qualifications:\n5+ years of data engineering or data management experience\nProficiency with major data sciences tools such as SQL, Python, R, and Git\nDemonstrated experience with cleaning, management, optimizing performance and processing large volumes of data\nDesired Skills:\nExperience with machine learning, with statistical modeling, time-series forecasting, and/or geospatial analytics\nExperience with Hadoop, Spark, or other parallel storage/computing processes\nSecurity Clearance:\nAn active TS/SCI w/Poly clearance\nSo, what does Novetta do?\n\nWe focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.\n\nOur culture is shaped by a commitment to our Core Values:\nIntegrity: We hold ourselves accountable to the highest standards of integrity and ethics.\nCustomer Mission Success: Customer mission success drives our daily effortswe strive always to exceed customer expectations and focus on mission success beyond contractual commitments.\nEmployee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.\nInnovation: We believe that innovation is critical to our success that discovering new and more effective ways to achieve customer mission success is what makes us a great company.\nGET A REFERRAL BONUS FOR THE GREAT PEOPLE YOU KNOW!\nWith our amazing referral program, you could be eligible to earn\noutstanding rewards for referring qualified new hires to Novetta.\n\nNovetta is an equal opportunity/affirmative action employer.\nAll qualified applicants will receive consideration for employment without regard to sex,\ngender identity, sexual orientation, race, color, religion, national origin, disability,\nprotected veteran status, age, or any other characteristic protected by law.\nApply Now: click Apply Now"}, "616": {"company": "Demandbase", "description": "The world's largest and fastest-growing companies such as Accenture, Adobe, DocuSign and Salesforce rely on Demandbase to drive their Account-Based Marketing strategy and maximize their B2B marketing performance. We pioneered the ABM category nearly a decade ago, and today we lead the category as an indispensable part of the B2B MarTech stack. Our achievements and innovation would not be possible without the driven and collaborative teams here at Demandbase. As a company, we're as committed to growing careers as we are to building word-class technology. We invest heavily in people, our culture and the community around us, and have continuously been recognized as one of the best places to work in the Bay Area.\n\nThe Senior Data Engineer will work in all aspects of engineering including technical design, architecture, implementation, quality assurance, deployment, and operations. You will be responsible for scaling our machine learning pipeline, including requirements, architecture, design & development. You will establish the ins and outs of building a highly available, scalable, distributed, and robust system that uses all the modern cloud computing paradigms, techniques and tools.\n\nTo apply for the role, you should possess strong analytical, design, and problem diagnosis skills. You like thinking \"outside the box\", are not afraid of ambiguity, get excited about difficult challenges, and are a motivated self-starter. You are a strong team player and thrive in a startup environment where flexibility is essential and delivering rock solid, customer focused solutions is paramount.\n\nResponsibilities:\nCore responsibilities will be to help scale large scale machine learning models\nOwn and drive processing of tens of petabytes of unstructured and structured data\nProvide leadership to the data science and engineering teams in terms of big data processing\nEnable machine learning systems to become more real-time in terms of decisions but also large scale data ingestion\nWorking with the latest open source technology on highly distributed, scalable products\nRequirements:\nBachelor of Science or Master's in Computer Science\n6+ years of experience as a Software Engineer in a huge data environment\nExperience working with terabyte level, real-time datasets\nMust have built applications in the past (at the start/mid-career point)\nMultiple large scale distributed systems or data platforms, including Spark, Flink, Kafka, Dataflow, BigQuery, BigTable, Dataproc, etc.\nExperience with Scala and/or Java and Python\nExperience building large scale crawlers, using Nutch, Gora, MapReduce, HBase, Elasticsearch, etc.\nStrong algorithm & data structure knowledge\nExcellent communication skills and the ability to work well in a team\nKnowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations\nStrong customer focus, ownership, urgency and drive\nWhy join us...\nBe part of a rapidly-growing, pre-IPO company\nOpportunity to extend our ABM leadership position and fast-track innovation behind AI-powered Account-Based Marketing solutions\nDrive the next generation of intelligent CRM technologies and invent how Artificial Intelligence, product design, and applications converge\nWork with a world class team of engineers, PMs, data scientists, sales and marketers\nHave the flexibility of a start up with the security of a sizable, well-funded organization (we recently closed a $65M round of funding)\nAbout Demandbase...\n\nDemandbase is the leader in Account-Based Marketing (ABM) and an indispensable part of the B2B tech stack. The company offers the only end-to-end ABM platform that helps B2B marketers identify, win and grow the accounts that matter most. The biggest and fastest growing companies in the world, such as Accenture, Adobe, DocuSign, GE, Salesforce and others rely on Demandbase to drive their ABM strategy and maximize their marketing performance. The company has been named to the JMP Securities list \"The Hot 100: The Best Privately Held Software Companies,\" the Deloitte Fast 500 and named a Gartner Cool Vendor for Tech Go-To Market. In 2019, Demandbase executives authored the definitive book on ABM, Account-Based Marketing: How to Target and Engage the Companies That Will Grow Your Revenue. For more information, please visit www.demandbase.com or follow the company on Twitter @Demandbase.\n\nBenefits...\n\nOur benefits include 100% paid for Medical, Dental and Vision for you and your entire family, short-term/long-term disability, life insurance, flexible vacation policy, 401k, commuter benefits, free snacks, catered lunch every Friday, chair massages, weekly yoga and much more!\nTo apply to this job, click Easy Apply"}, "617": {"company": "Hilton Corporate", "description": "Job Summary\n\nHilton is creating a best-in-class data & analytics department that will lead a connected ecosystem of data, technology, tools, techniques, people and processes. This innovative data & analytics function will drive advanced analytics and actionable insights to help drive Hilton's performance.\n\nWhat will I be doing?\n\nThe Data Science Team serves as internal advanced analytics elite consultants to key functions across Hilton's business, bringing predictive and prescriptive analytics through ML/AI. The team consists of data scientists, advanced analytics modelers, and data engineers, working closely with other DNA teams, Pricing and Revenue Management teams, as well as Product partners.\n\nWorking with the Sr. Director, Data Science, the Manager, Data Scientist, will be working with other Pricing scientists and directly influencing the creation and delivery of advanced Pricing and Revenue Management solutions/services. You will be responsible as a key resource for defining and recommending data science algorithms thru a service architecture framework.\n\nMore specifically, you will:\nWork closely with business, technology, and data science teams to gather, analyze and understand business requirements. This includes translating activities and business goals into analytical models and algorithm codes for application in a production scale environment.\nPerform analysis on existing as well as new data sets to identify and foster innovative advanced analytics opportunities.\nDocument, develop, code, and test data science modules into scalable solutions in a big data environment.\nWork with multi-functional teams to access data elements, understand the data being analyzed, and identify improvement opportunities for data ingestion process.\nFacilitate and identify repeatable testing and measurement strategies from results produced by analytics models/algorithms.\nProvide insights and solutions regarding data storage and optimization.\n\nWhat are we looking for?\n\nWe are looking for problem solvers, who are passionate about data and who love to have the opportunity to create improvements to data management. We believe success in this role will demonstrate itself through the following attributes and skills:\nSelf-starter, well organized, and a confident teammate willing to take ownership of responsibilities with a high level of positive energy and drive\nExcellent time management and project management skills that contribute to leading multiple priorities, working well under time constraints and effectively handling concurrent demands to prioritize responsibilities\nEffective communicator, collaborator, influencer and solution seeker across a variety of opinions\nAccountable individuals, who take ownership of projects, effectively communicate results and recommend improvements\nStrong communicators, both verbally and in writing, who effectively communicate at all levels of the organization\nTo fulfill this role successfully, you should demonstrate the following minimum qualifications:\nTwo (2) years of experience in data science, linear/integer and non-linear optimization, and/or applied statistics\nOne (1) year of hands-on experience in architecting, developing and implementing advanced analytics models, machine learning algorithms for scalable environments\nAdvanced programming skills in Python and/or R (and their related data science, machine learning, and visualization libraries)\nExperience with CPLEX, Gurobi, or comparable optimization suite\nExposure to Spark/Scala, Java, C/C++, SQL\nIt would be helpful in this position for you to demonstrate the following capabilities and distinctions:\nPhD Doctorate Degree in Data Science, Operations Research, Computer Science, Engineering, or related technical fields\nOne (1) year of experience in a full life-cycle analytics code development, deployment, and maintenance efforts involving distributed data sets\nExperience in pricing science and revenue management methods\nHands-on experience in statistics, machine learning, artificial intelligence, natural language processing, deep learning\nExperience in ETL management, SQL/no SQL platforms, Apache products (NiFi, KafKa) and data warehousing technologies (Snowflake, Redshift)\nWhat will it be like to work for Hilton?\n\nHilton is the world's leading global hospitality company, spanning the lodging sector from luxurious full-service hotels and resorts to extended-stay suites and mid-priced hotels. For nearly a century, Hilton has offered business and leisure travelers the finest in accommodations, service, amenities, and value. Hilton is dedicated to continuing its tradition of providing exceptional guest experiences across its global brands. Our vision to fill the earth with the light and warmth of hospitality unites us as a team to create remarkable hospitality experiences around the world every day. And, our amazing Team Members are at the heart of it all!\n\nEOE/AA/Disabled/Veterans\n\nStart your job application: click Apply Now"}, "618": {"company": "LeanData Inc.", "description": "LeanData is revolutionizing enterprise Sales and Revenue Operations to help businesses accelerate their sales velocity and make the most of their marketing spend. This is a great opportunity to work with a fast-growing, venture-funded company focused on creating products to get customers to revenue more quickly.\n\nWe are looking for a rock star Data Analyst with a track record for delivering data-based insights and impact. You are highly organized and have a background analyzing customer data, are able to communicate your findings and recommendations, and have an ability to drive actionable insights. You are comfortable with technical environments, work well with ambiguity, and are able to develop a deep understanding of product capabilities to drive your hypotheses, analyses, and recommendations.\n\nThis is your opportunity to join a red-hot technology company and make a real impact. Benefits include competitive compensation, equity, healthcare, and flexible vacation.\n\nResponsibilities:\nWork with cross-functional teams to help deliver data-driven insights\nUnderstand LeanData product to drive product-driven insights\nDesign and evaluate scalable approaches to deliver ongoing product and customer analytics\nWork with the Product, Engineering, and Customer teams to deliver product monitoring metrics\nCollaborate with the Product and Customer teams to make quantitative, evidence-based decisions\nDefine analytics roadmap to balance long term insights with short term data needs and questions\n\nQualifications:\n3 - 5 years of enterprise data analyst work experience\nProven experience collaborating with cross-functional teams\nStrong ability to driver user insights and understand user experience and behavior\nA self-motivated, curious learner who enjoys learning new systems\nSolution-oriented with ability to drive toward actionable insights and results\nExcellent oral and written communication skills\nResourceful, detail-oriented, and highly organized problem solver\nSelf-starter who thrives under ambiguity in a fast-paced, deadline-oriented startup environment\n\nTo apply, please send in your resume\n\nWe\u2019re passionate about revenue operations and simplifying the B2B sales process to improve sales and marketing collaboration and help companies achieve their revenue goals more quickly. Our solution has been built to support any sales and marketing strategy, including\naccount-based approaches. We are backed by Tenaya Capital, Shasta Ventures, Sapphire Ventures, Felicis Ventures, Industry Ventures, Correlation Ventures, and the Funders Club.\n\nOnly apply if you are qualified and highly motivated.\nNo relocation offered.\nPrincipals only, no recruiters.\nTo apply to this job, click Apply Now"}, "619": {"company": "Rocketrip", "description": "When was the last time you were planning a business trip and really tried to save your company money? If your company allowed you to stay in a fancy hotel, would you ever volunteer to stay at an Airbnb or at a friend's house? How about flying coach instead of business class? The vast majority of employees optimize for comfort and convenience, spending at the high end of their company policy limits, because, well, why not? So how can a company get its employees to care about expenses without implementing draconian policies, creating friction and frustrating employees? How can a company motivate its employees to save?\n\nThe answer is Rocketrip. We're a NYC-based startup that rewards business travelers for cost-sensitive behavior. It's a win-win: companies save, while employees cash in with real rewards.\n\nThe Role:\n\n\nWe are seeking a Data Engineer who can operate within our engineering organization and help take our data strategy to the next level. The Data Engineer will be able to design, code and provide architecture solutions for the team, including but not limited to ETL, data warehousing, and data integration. The right candidate for this role is someone who is passionate about technology and interacting with product owners, thrives in ambiguity, and is focused on delivering exceptional results with great teamwork skills in a scrappy, startup environment. The candidate will have the opportunity to influence and interact with fellow engineers beyond their team.\n\nResponsibilities:\n\n\nDesign and development of ETL and data pipeline solutions for complex business problems to load Data Warehouse.\nData Stewardship - own or support the data definitions and lineage across our organization.\nCreate a data integration plan and build data integrations between systems.\nFigure out the best way to share information and build the tech needed to execute.\nMentoring - help teach other team members about data architecture and also be a consultant for developers who need help with data.\n\nRequirements:\n\n\nAt least 3 years of relevant experience.\nExperience working with data warehouses, including data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools and environments like RDS, MySQL, Python, Pyspark, Airtable, Talend.\nExperience developing, deploying, and testing in AWS.\n\nHere at Rocketrip, we...\nAre in growth mode where all work has impact.\nOffer great benefits, including medical, dental and optical.\nGive all employees free membership to One Medical.\nProvide access to a 401k plan and offer matching.\nBelieve it's important to rejuvenate and offer a \"take what you need\" vacation policy.\nEncourage employees to spend the holidays exploring, relaxing, or with loved ones by closing our offices during the last week of December.\nRegularly huddle up as a company to share goals, learnings and celebrate!\nHave a dog-friendly office.\nProvide access to gym membership and Citibike discounts.\n\nFounded in 2013 and headquartered in New York City, Rocketrip is aiming to revolutionize business travel by introducing the motivation to save. We're a group of tech innovators who looked at the current state of business travel, became frustrated by the antiquated employee and employer experiences, and decided to do something big about it. Our team is focused on utilizing technology, design and data to align employee and company interests.\n\nRocketrip is backed by a renowned set of investors and advisors, including Google Ventures, Bessemer Venture Partners, Canaan Partners, Genacast Ventures, and Y Combinator.\n\nApply Now: click Apply Now"}, "620": {"company": "VillageMD", "description": "Why VillageMD?\n\nVillageMD is changing the trajectory of healthcare by empowering primary care physicians to make informed decisions and engage patients in meaningful ways. We work with thousands of clinicians and healthcare disruptors across the country to build and contribute to our platform to improve patient health while driving down the cost to deliver it.\n\nWe are a mission-oriented organization and are thrilled about the work that we do every day. We're transparent, collaborative, and relentless in pursuit of our mission, all while doing so with humility and a low ego. We believe that diverse backgrounds and experiences create the best opportunity for innovation and the community that we are creating is greater than any individual.\n\nWe've built our technology using the best of cloud and open-source technologies to create an open, data-first platform that is enriched with analytical models and modernly connected to internal and external apps. These apps drive clinical decision support, patient engagement, and other facilitators of innovative, information-enriched health experiences.\n\nData Engineers at VillageMD build distributed components, pipelines, and tools that enable our organization to make analytical, data-driven decisions. We're in a unique position to impact everyone in primary care from independent, family-owned practices to world-class health systems. We aggregate, process, and deliver rich datasets to improve the effectiveness of primary care for our doctors and patients.\n\nWhat are examples of work that Data Engineers have done at VillageMD?\nBuilt and implemented a data profiling tool to reverse engineer data schemas from new data sources facilitating normalization of the data into our data model\nCreated a summary data platform supporting our presentation layer that allows clinicians and operators in our practices to pinpoint interventions on-demand to patients most in need\nAnalyzed and designed the best ways to expand our data model to incorporate more data that's mission critical\nWhat will make you successful here?\nStrong analytical and technical skills\nA real passion for problem solving and learning new technology\nVision to balance speed and maintainability in solution design\nThe ability to handle multiple, concurrent projects\nCrafting and implementing requirements, keeping projects on track, and engaging partners\nChallenging the status quo to improve our processes and tools\nCommunicating complex technical details in meaningful business context\nA low ego and humility; an ability to gain trust by doing what you say you will do\nWhat you might do in your first year:\nOwn ten projects to design and implement best-in-class data processing enabling clean data flow directly to our data model and on to our presentation layer\nWork with analytics, engineering and operations to design and implement a new analytics product that supports improving patient health\nDesign a new concept within our data model to meet a new operational or analytical need\nThe following experience is relevant to us:\n5+ years of full-time experience including extensive experience with healthcare data\nAbility to understand and design relational data structures required\nVery strong capabilities manipulating data using SQL\nKnowledge of, and/or willingness to learn, non-relational data structures and other technologies (e.g. Postgres, Redshift, Cassandra, MongoDB, Neo4j, S3, etc.)\nExperience or willingness to learn building information pipelines utilizing Python or Java a plus\nBS/MS in computer science, math, engineering, or other related fields is required.\nTrack record of successfully executing projects with multiple partners\nWhat can we offer you?\nCompetitive salary, bonus, and health benefits\nPaid gym membership\nFun, fast-paced, startup environment (with snacks)\nPre-tax savings on commute expenses\nRemote flexibility\nA highly-collaborative, conscientious, forward-thinking environment that welcomes the impact you can make from Day 1.\nA clear link between our daily work on products and services and the improved quality of healthcare that this work facilitates for patients.\nAt VillageMD, we see diversity and inclusion as a source of strength in transforming healthcare. We believe building trust and innovation are best achieved through diverse perspectives. To us, acceptance and respect are rooted in an understanding that people do not experience things in the same way, including our healthcare system. Individuals seeking employment at VillageMD are considered without regard to race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nStart your job application: click Easy Apply"}, "621": {"company": "Dassault Systemes", "description": "Machine Learning Engineer\n\nShare\n\nUnited States, MA, Waltham\nRegular\nFull-Time\n512074\n\nApply\n\nApply\n\nMachine Learning Engineer \u2013 SOLIDWORKS xDesign\nWaltham, MA\nImagine new horizons\nDassault Syst\u00e8mes, the 3DEXPERIENCE Company, provides business and people with virtual universes to imagine sustainable innovations. Its world-leading solutions transform the way products are designed, produced, and supported. Dassault Syst\u00e8mes\u2019 collaborative solutions foster social innovation, expanding possibilities for the virtual world to improve the real world. The group brings value to over 190,000 customers of all sizes, in all industries, in more than 140 countries.\nDassault Syst\u00e8mes SOLIDWORKS is looking to hire a Machine Learning developer who will be located in Waltham and will work with the rest of the team in developing new and cutting-edge innovative ideas.\n\nWhat will your role be?\nCollaborate with fellow team members to better understand problems faced by SOLIDWORKS users while executing their daily tasks\nApply previously gained experience within Machine Learning as it applies to CAD solutions in developing future and innovative product ideas\n\nThe challenges ahead\nSupport SOLIDOWORKS and their pursuit of developing the innovation of the solution by investing more in the field of machine learning as it applies to CAD\nBe a part of the xDesign team, the first machine learning based functionality within SOLIDWORKS, as they work to expand the product group and support future releases of more machine learning based functions\nWork with R&D to continue to improve the overall performance, ease of use, and total user experience by applying machine learning principles to ongoing software development\n\nYour key success factors\nB.S. minimum required, MS preferred \u2013 Computer Science, Engineering, Mathematics, etc.\n1 to 3 years of experience in machine learning and artificial intelligence\nGood understanding of design, CAD, optimization and simulation technologies\nSoftware development experience in one or more programming languages: C, C++, JavaScript, Python, R, Matlab\nAbility to work independently and/or within a collaborative team structure\nPositive, self-motivated individual with high level of enthusiasm and willingness to learn and incorporate coaching and instructions into daily tasks and assignments\nHighly organized with critical attention to details\nAbility and willingness to self-teach new and advance software functions; initial coaching and instruction will be provided, but we want someone who goes after knowledge\nPossess new technology curiosity and a history of self-technical education\nStrong communication skills in written and spoken English.\n\nCompensation & Benefits\n\nDassault Syst\u00e8mes offers an excellent salary with potential for bonus, commensurate with experience that is above average in the local community. Benefits include a choice of plans providing comprehensive coverage for medical, dental, vision care for employee & dependents as well as employee life, short & long term disability, tuition reimbursement, immediate 401K enrollment, 401K match, 3 weeks\u2019 vacation and 8 paid holidays plus 4 floating holidays.\n\nEqual opportunity\n\nIn order to provide equal employment and advancement opportunities to all individuals, employment decisions at 3DS are based on merit, qualifications and abilities. 3DS is committed to a policy of non-discrimination and equal opportunity for all employees and qualified applicants without regard to race, color, religion, gender, sex (including pregnancy, childbirth or medical or common conditions related to pregnancy or childbirth), sexual orientation, gender identity, gender expression, marital status, familial status, national origin, ancestry, age (40 and above), disability, veteran status, military service, application for military service, genetic information, receipt of free medical care, or any other characteristic protected under applicable law. 3DS will make reasonable accommodations for qualified individuals with known disabilities, in accordance with applicable law.\n\nStart your job application: click Apply Now"}, "622": {"company": "Berg Health", "description": "NO AGENCIES - PLEASE!!!\n\nPosition Summary:\n\nThe Digital Health team is seeking a highly motivated, meticulous and detail-oriented individual for a multi-disciplinary team. The candidate will be instrumental in analyzing and making inferences from healthcare big data and must be goal oriented and should have strong background in statistics, epidemiology and possess some programming skills. The candidate should also be a quick learner, flexible and able to adapt to needs of the project.\n\nResponsibilities:\nExecution of meticulous and well thought out data analysis for building predictive algorithms on healthcare big data\nDevelopment and execution of data analysis protocols to support company's discovery pipeline\nDetailed documentation of data analysis methods and findings\nPresentation of scientific results internally and externally\nPreparation and submission of scientific manuscripts for review and publication\nOther duties, as assigned\nQualifications:\nRequires a Ph.D. in Statistics, Epidemiology, Public Health, Data Science or related field\nExperience working with healthcare claims, pharmacy and electronic medical record data (EMR) is a highly desirable.\nStrong skills in statistics and study design.\nProficiency in R and ability to work in Linux environment are required\nExperience with SQL, Hadoop, Python is preferred\nProven experience in applying Data Science methodologies to extract, process and transform data from multiple sources\nProven ability to find creative, practical solutions to complex problems.\nExcellent communication and interpersonal skills combined with superior and proven track record of technical and organizational skills.\nAbility to multitask and work in a team-oriented environment\n\nApply Now: click Apply Now"}, "623": {"company": "Penske Logistics", "description": "Position Summary:\n\nThe Staff Data Scientist will be a key role in the Data Science and Analytics team tasked with providing technical leadership for the establishment of enterprise wide capabilities in data engineering and predictive analytics. The Staff Data Scientist will typically work on 3-5 large projects concurrently that have organization-wide impact. In addition to these projects, the Staff Data Scientist will provide technical consultation, advice and training on all major on-going Data Science and Analytics projects. As and when required, the Staff Data Scientist will also act as a project manager where vendors, suppliers and consultants are engaged on key strategic and emerging technology initiatives.\n\nMajor Responsibilities:\n\nIdentifying Analytics Opportunities\n\n\u2022 Identify business opportunities or problems to improve productivity and generate cost savings\n\n\u2022 Help in the development of business case with clear ROI to communicate and prioritize projects to senior leadership\n\nLead Data Science Projects\n\n\u2022 Lead the translation of business requirements into technical solutions\n\n\u2022 Identify appropriate techniques and algorithms for building model; Create, test and deploy model\n\n\u2022 Ensure organization wide adoption of solution\n\nTechnical Guidance on Analytics Projects\n\n\u2022 Advise analytics teams on technical concepts, including but not limited to ML algorithms, hyper tuning and scripting\n\n\u2022 Help with training effort and development of data engineering and data science associates in new technologies (ETL/various AWS services).\n\nProject Management\n\n\u2022 Ensure the creation of project plans, milestone charts and communication plan for key strategic initiatives\n\n\u2022 Conduct regular stakeholder and executive meetings to provide on-going communication and status\n\nLead technology change in Data Engineering and Analytics\n\n\u2022 Evaluate new technologies and determine if and how they can be applied\n\n\u2022 This will include evaluating and recommending new technology and services to enable a modern, flexible and state of the art unified data platform.\n\nQualifications:\n\n\u2022 Master's Degree required; preferred concentrations in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field.\n\n\u2022 PhD preferred in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field.\n\n\u2022 7 years of experience along with a PhD in a related field OR 10 years of experience along with a Master\u2019s degree in a related field required.\n\n\u2022 Experience Required in both Data Science and Data Engineering disciplines:\n\n- Data Science: Designing and building machine-learning applications using both structured and unstructured datasets is required. Practical experience programming using Python, R or other high level scripting languages is required. Demonstrated experience with one or more machine learning techniques including logistic regression, decision trees, and random forests and clustering is required.\n\n- Data Engineering: Experience with modern data infrastructure in designing data pipelines and ETLs is required. Knowledge of Big Data tools, frameworks, cloud architecture in a public cloud environment is required. Experience with both traditional on-premise Business Intelligence/Data Warehouse and Data Warehouse in the cloud.\n\n\u2022 Ability to collect and analyze complex data.\n\n\u2022 Advanced skill in machine learning, statistical modeling, SQL, and database concepts required.\n\n\u2022 Intermediate skill in statistical computing packages (e.g., R), and scripting languages (e.g., Python) required.\n\n\u2022 Regular, predictable, full attendance is an essential function of the job\n\n\u2022 Willingness to travel as necessary, work the required schedule, work at the specific location required, complete Penske employment application, submit to a background investigation (to include past employment, education, and criminal\n\nhistory) and drug screening are required.\n\nPhysical Requirements:\n\n-The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\n\n-The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines.\n\n-While performing the duties of this job, the associate may be required to stand, walk, and sit. The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms. The associate must be\n\nable to occasionally lift and/or move up to 25lbs/12kg.\n\n-Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus.\n\nAbout Penske Logistics\n\nPenske Logistics is a wholly owned subsidiary of Penske Truck Leasing. With operations in North America, South America, Europe and Asia, Penske Logistics provides supply chain management and logistics services to leading companies around the world. Penske Logistics delivers value through its design, planning and execution in transportation, warehousing and freight management. Visit www.PenskeLogistics.com to learn more.\nTo apply to this job, click Apply Now"}, "624": {"company": "Demandbase", "description": "The world's largest and fastest-growing companies such as Accenture, Adobe, DocuSign and Salesforce rely on Demandbase to drive their Account-Based Marketing strategy and maximize their B2B marketing performance. We pioneered the ABM category nearly a decade ago, and today we lead the category as an indispensable part of the B2B MarTech stack. Our achievements and innovation would not be possible without the driven and collaborative teams here at Demandbase. As a company, we're as committed to growing careers as we are to building word-class technology. We invest heavily in people, our culture and the community around us, and have continuously been recognized as one of the best places to work in the Bay Area.\n\nWe are a group of talented individuals with deep expertise in the domain area of business applications and building large complex systems with simple user interfaces. We also have deep expertise in big data technology such as IR, NLP, and large graphs and utilize the best technology to provide innovative and novel products to frustrated end-users in the enterprise.\n\nAs a Senior Big Data Engineer, you will be responsible for building out all aspects relating to the Demandbase Data ecosystem and moving products from R&D into production scale. A successful Senior Data Engineer will possess a natural curiosity about data, strong work ethic, and clear technical leadership ability. Understanding of the ad ecosystem and the large scale data problems that come with it are going to be the root of your every day work.\n\nYou will be both hands-on and strategic\u2014with both a broad ecosystem-level understanding of our market space and the ability to work closely with engineering, data science and product teams to deliver software in an iterative, continual-release environment. This is a high-visibility position involving close collaboration across many functional groups as well as interaction with executive stakeholders.\n\nWhat you'll be doing...\nWork with internal stakeholders to design and develop components in the next generation of Demandbase's core Data Products\nIntegration and conflation of multiple 1st and 3rd party data sources to build a key component in the core of our data platform\nWrite clear documentation to convey plans and technical architecture\nEnsure all new and modified code and pipelines are tested and of the highest quality at delivery time\nBuild out new pipelines as part of an ever-evolving set of requirements for the core data asset as our business needs grow\nEnsure high reliability of all maintained product offerings by building reporting and monitoring mechanisms into our infrastructure.\nWhat we're looking for...\nBS or Masters in Computer Science and 3+ years of working experience\nWorked in a start-up (less than 150 employees) within the past 4 years is a strong plus\nProven experience with Hadoop or Spark or other large-scale data processing platforms\nProven experience processing and aggregating over billions to trillions of rows\nStrong software design and development experience, preferably in Scala or Java or other compiled languages\nStrong experience with Apache Parquet, Avro, or similar technologies\nDeep desire for data is a must; this position lives in data\nUnderstanding of cookies, mobile web traffic, and user behavior is a strong plus\nUnderstanding of cloud infrastructure (preferably AWS) is a strong plus\nProven ability to solve problems using state of the art technology\nProven ability to innovate when necessary, but not reinvent the wheel\nAbility to define standards and best practices for teams\nAble to handle ambiguous delivery goals and turn them into concrete output\nAbility to suggest technical direction when necessary to solve problems\nHands on and not afraid to wear multiple hats\nPassion for career growth\nAbout Demandbase\n\nDemandbase is the leader in Account-Based Marketing (ABM) and an indispensable part of the B2B tech stack. The company offers the only end-to-end ABM platform that helps B2B marketers identify, engage, close and measure progress against best-fit accounts. The biggest and fastest growing companies in the world, such as Accenture, Adobe, DocuSign, GE, Salesforce and others rely on Demandbase to drive their ABM strategy and maximize their marketing performance. The company has been named to the JMP Securities list \"The Hot 100: The Best Privately Held Software Companies,\" the Deloitte Fast 500 and named a Gartner Cool Vendor for Tech Go-To Market. In 2019, Demandbase executives authored the definitive book on ABM, Account-Based Marketing: How to Target and Engage the Companies That Will Grow Your Revenue. For more information, please visit www.demandbase.com or follow the company on Twitter @Demandbase.\n\nBenefits:\n\nOur benefits include 100% paid for Medical, Dental and Vision for you and your entire family, 100% paid for short-term and long-term disability, 100% paid for life insurance, 401k, flexible vacation policy, commuter benefits, free snacks, catered lunch every Friday, and much more!\nApply Now: click Easy Apply"}, "625": {"company": "Pivotal Software", "description": "LOCATION: Remote (home based) with some travel to New York, Washington DC, Boston.\n\nAbout Us VIDEO\n\nFounded in 2013, Pivotal Software, Inc. combines our leading cloud-native platform, tools, and methodology to empower the world's largest organizations to adapt to change and build great software. Our technology unleashes developer productivity, while fulfilling our mission to transform how the world builds software.\n\nYou\n\nAs a data scientist on Pivotal's Data Science team, you'll be working on a wide variety of data problems for a diverse range of clients. You will often be asked to learn new technologies and domains on the fly. You should be comfortable working under deadlines and making tough decisions. Consequently, you will frequently have to balance achieving an immediate goal with scalability and productionalizability.\n\nThe role offers room for personal and professional growth, and you won't be working in isolation. Data Science at Pivotal is an encouraging and supportive team, where ideas and challenges are addressed collaboratively. We're looking for the kind of person who will try and solve a problem on their own first, but isn't afraid to ask for help or say \"I don't know.\"\n\nUs\n\nThe Data Science team at Pivotal is primarily a consulting practice; we are tool agnostic, working with our customers to solve real world problems. Our customers, like us, are cross-disciplinary. We service engagements with use cases running from customer churn to optimization to detecting fraud and misconduct. We are not just doers, we are also educators and enablers.\n\nYour Day\n\nWhile there is no such thing as a \"typical day\", these are activities we frequently find ourselves doing:\nWorking with clients to uncover and frame new opportunities for data science. Clients often come to us without a clear understanding of what we can do, so this is our chance to open their eyes to new possibilities for their businesses.\nExploring client datasets, looking for actionable insights we can present.\nEngineering features, training models, tuning hyperparameters and evaluating the results. We emphasize rigor, because data science done right at this stage leads to models that shine in production.\nTaking the models we build into production. This is an exciting stage for anyone who likes collaborating with engineering teams and seeing their model become real when users interact with it.\nHelping our clients develop their internal data science practices, from hiring and recruiting to data capturing, so that they can be successful when we hand off the project.\nRequired Skills / Experiences\nClear and empathetic communicator. You'll be the one sharing your insights with clients and stakeholders at check-ins, documenting your work, and even explaining your model to client data teams as part of a handoff. As such, communication and empathy are essential parts of your toolkit.\nAdvanced knowledge of statistical modeling and/or machine learning methods. These are the tools we need to go from analysis to prediction.\nStrong programming skills. Left to our own devices most of us work in Python, but learning the client's tech stack is an important part of the job.\nStrong exploratory data analysis skills. Every engagement starts with an investigation of the data, and thorough EDA saves us a lot of headaches in the long run.\nSome travel is expected, depending on location and skillset. We mostly work out of the Pivotal office closest to the client, but sometimes we have to be on site for an extended period of time.\nAt least a bachelor's degree in an analytical or technical field. This could be applied mathematics, statistics, computer science, operations research, economics, etc. Higher education welcome and encouraged.\n\nThis role will support US government clients that require US citizenship. Given this, US citizenship is required for you to apply.\nDesired Skills / Experiences\n2+ years of work in a data-centric field (data science or data engineering).\nExperience with relational databases.\nExposure and experience working in a Linux environment.\nYou have a specialization in an area like NLP, optimization, or image processing.\nHands-on experience working in a distributed computing environment or proven theoretical understanding of parallelism.\nPivotal is an Equal Employment Opportunity employer that will consider all qualified applicants, regardless of race, color, religion, gender, sexual orientation, marital status, gender identity or expression, national origin, genetics, age, disability status, protected veteran status, or any other characteristic protected by applicable law.\nStart your job application: click Apply Now"}, "626": {"company": "Pactera", "description": "Looking fora Data Scientis/Architect who has 8 yrs of exp in data design, data modelling, data flow, analytics in supply chain domain.\n\nHere\u2019s the detail JD:\nExpert programming skills in Python, R\nExperience in writing code for various Machine learning algorithms for classification, clustering, forecasting, regression, Neural networks and Deep Learning\nHands-on experience with modern enterprise data architectures and data toolsets (ex: data warehouse, data marts, data lake, 3NF and dimensional models, modeling tools, profiling tools)\nStrong knowledge of Supply Chain domain, preferably in the hi-tech industry\nStrong problem solving and abstract thinking skills\nKnowledge of data architecture and design patterns and the ability to apply them\nAbility to conceptualize and articulate ideas clearly and concisely\nExcellent communication, presentation and interpersonal skills\nApply Now: click Easy Apply"}, "627": {"company": "LiveRamp", "description": "ABOUT LIVERAMP\n\nLiveRamp is the trusted platform that makes data accessible and meaningful. Our services power people-based customer experiences that improve the relevance of marketing and allow consumers to better connect with the brands and products they love. We thrive on solving the toughest technical and customer challenges, and we're always looking for smart, compassionate people to help us blaze a trail.\n\nMission: LiveRamp makes it safe and easy to connect the world's data, people, and applications.\n\nABOUT THIS JOB\n\n\nThis role will facilitate roles and responsibilities associated with being an Analyst on an Analytics team.\n\nThe 'ideal candidate' for the role:\nIs proficient with data visualization tools/software such as Tableau (preferred), Stata, or R\nCan replicate existing Tableau work products and also suggest design improvements\nHas a sense for good design and exceptional attention to detail\nIdeally has some familiarity with marketing data, dsp logs, web logs data ..etc.\nIs a quick learner and independent worker who is comfortable asking for help\nCan work self-guided and in a largely autonomous fashion\nRESPONSIBILITIES\nGather requirements, extract and analyze data in support of multiple programs within the organization\nLead reporting and related activities, be knowledgeable about data types, data taxonomy, and have an understanding of data management\nIdentify new approaches to challenge the status quo with how to introduce, evaluate, and implement emerging Information Technology Infrastructure trends\nSupport development dashboards, providing data analysis, data requirements, analysis of data interaction between systems, design of dashboard layout and mapping data to produce accurate reporting\nPlan and coordinate activities related to data needs for various programs\nQUALIFICATIONS\n2-4 years of recent experience in a business analyst or data analyst role. Preferably experience in the digital advertising industry or related field\nExperience with Data Analysis\nAbility to operate comfortably and effectively in a fast-paced, highly cross-functional, rapidly changing environment\nExperience with business problem identification, data collection and preparation, modeling, and problem solving\nSolve routine problems of limited scope and complexity by following established practices or establishing new procedures\nAbility to work effectively across business teams and engineering partners to meet the data needs of the business, translating business needs into analytical requirements\nBachelor's Degree preferred in an engineering or analytic related discipline\n1-2+ years job experience working with Big Query or Google Cloud Products\n1-2+ years job experience utilizing Python in a productional environment\nNICE TO HAVE\nRecent proven experience developing data visualizations, dashboards, and reporting in Tableau (or a similar reporting tool)\nExperience with Tableau preferred\nComfortable working with modern data technologies. Familiarity with database modeling and data warehousing principles\nSQL required: Python, or Java/Scala preferred\nComfortable with advanced analytics tools such as Pandas, R, and Spark a plus\nFamiliarity with data science exploration, analysis, feature selection, model development, and evaluation a plus\nEMPLOYEE BENEFITS\nFood. Enjoy catered meals, boundless snacks, and the occasional food truck.\nFun. We host events such as game nights, happy hours, camping trips, and sports leagues.\nPeople. Work with talented, collaborative, and friendly people who love what they do.\nHealth and Saving. Receive the benefits of comprehensive health, dental, vision and disability insurance along with a 401k matching plan.\nLocation. Work in the heart of San Francisco \u2013 the best city in the world, and take advantage of our commute.\nLiveRamp is an affirmative action and equal opportunity employer (AA/EOE/W/M/Vet/Disabled) and does not discriminate in recruiting, hiring, training, promotion or other employment of associates or the awarding of subcontracts because of a person's race, color, sex, age, religion, national origin, protected veteran, disability, sexual orientation, gender identity, genetics or other protected status. Qualified applicants with arrest and conviction records will be considered for the position in accordance with the San Francisco Fair Chance Ordinance.\nApply Now: click Easy Apply"}, "628": {"company": "Remedy BPCI Partners, LLC.", "description": "This role will report to our VP, Data Science.\n\nWhat will you do?\nWork closely with cross-functional business, product, analytics and BI teams to understand and capture requirements to be supported by data pipelines to better enable analytical and BI efforts.\nIdentifying, designing, and implementing process improvements: automating & streamlining, processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuilding the infrastructure & data pipelines required for optimal extraction, transformation, and loading of data from a wide variety of data sources using python, SQL and AWS \u2018big data\u2019 technologies.\nDevelop, adhere to, and be a proponent for data warehouse development standards, including ETL standards and best practices.\nBecome expert on projects to help strategize plans of attack in terms of technology and team education.\nEnsure that all security procedures within their area of responsibility are carried out to achieve compliance with security policies and standards.\nEnsure control objectives are implemented for all data movement processes, implement change control for production data, establish and follow proper incident management procedures.\nLeading multiple initiatives across both ongoing and innovative work.\nProvide continuous mentoring to junior resources.\nWe are looking for someone with:\n7+ Years of hands-on experience designing, building, and automating data flows in cloud environments.\nExperience building and migrating data pipelines, transformations, and catalogs using cloud native and open source tool.\nExperience AWS data warehousing and technologies including Redshift, Aurora, Athena, Glue, EMR, S3, RDS, Lambda, SQS, SNS, Kinesis, CFT.\nExperience with data warehouse schema design, data modeling, and query optimization.\nExperience with relational databases, NoSQL Databases or MPP systems.\nSelf-starter with a proven track record of fully understanding the scope, asking the right questions, and end-to-end ownership to meet upon agreed timelines.\nFull commitment to quality, efficiency, and ability to proactively anticipate, foresee and suggest necessary improvements and possible shortcomings.\nTeam oriented focus with ability to develop code in alignment with an Enterprise Architecture.\nStrong experience mentoring junior colleagues.\nExcellent written and verbal communication skills.\nBachelor\u2019s degree in Computer Science or a related field is preferred.\nOur benefits include but are not limited to:\nPaid Time Off\n401(k) Savings Plan with match\nMedical, Vision & Dental\nPre-Tax Commuter Benefits\nParental Leave\nGym Reimbursement\nTuition Reimbursement\nAbout Us\n\nRemedy Partners delivers software and services that enable payers, employers and at-risk providers to organize and finance healthcare delivery around a patient's episode of care. For healthcare providers, Remedy Partners\u2019 software, analytics and administrative services support bundled payment contracts with Medicare and Commercial Insurers, often through shared-risk partnerships. For payers, Remedy Partners empowers the development of bundled payment contracting programs and guides development of bundled payment networks. Remedy Partners presently delivers its services to partners at more than 1,000 healthcare locations nationwide.\nApply Now: click Apply Now"}, "629": {"company": "Comtech Safety & Security Technologies", "description": "Data Analyst Windows/UNIX\nSeattle, WA\nwww.Comtech911.com\nABOUT THE OPPORTUNITY:\nThe MSAG Data Analyst position\u2019s primary responsibility is to support carrier service providers with address validation issues. The analyst works in a collaborative team environment and is responsible for Comtech address data, vendor outreach to resolve addressing issues by auditing and resolving fallout in a 911 customer-critical address data set. The analyst will also process data using Oracle SQL and other database tools, loading data into an Oracle database, validating address datasets, and preforming fallout resolution. The analyst\u2019s overall objective is to ensure that Comtech\u2019s address validation maintains the highest accuracy, which is used in routing 911 calls.\nMajor Duties and Responsibilities:\nThe data analyst will be responsible for increasing the accuracy of the database, including:\nResolve data inconsistencies, conflicts, inaccuracies, and other fallout of subscriber data.\nProvide reporting and feedback to team regarding address data inconsistencies.\nIdentify and create methods for proactively identifying potential fallout.\nIdentify data inconsistencies and conflicts in address data sets.\nIdentify and perform detailed analysis of all data sources for each application and subject area.\nWork towards aggressive timelines to maximize data accuracy.\nProvide the data mapping and associated transformation rules for each data item.\nWork with internal teams to learn and support 911 specific business processes.\nKnowledge & Skills:\nMust be able to work in both Windows desktop and Unix command line environments.\nMust have advanced experience with MS Office, specifically Excel and Access.\nMust have experience using databases and tables to perform analysis and reporting required.\nRequire strong experience using Oracle, mySQL, or other RDBMS.\nFamiliarity using geographic data sets and GIS a strong plus.\nFamiliarity with addressing and maps a strong plus.\nExperience & Other Requirements:\n4-year college degree or equivalent required.\nMinimum 2 years data analysis experience required.\nExhibit strong verbal and written communication skills.\nDisplay high levels of self-motivation.\nAbility to self-direct and take ownership required.\nCritical, creative, and conceptual thinking abilities required.\nAbility to manage multiple tasks and function as part of a team required.\nComtech is an Equal Opportunity Employer \u2013 M/F/Veteran/Disability/Sexual Orientation/Gender Identity\nTo apply to this job, click Easy Apply"}, "630": {"company": "Catalent Pharma", "description": "Job Description\n\n\nPosition Overview:\n\nCatalent hires people with a passion to make a difference to the health of millions of people globally. Your expertise, coupled with Catalent\u2019s advanced technologies and collaboration with thousands of innovative pharmaceutical, biotech and healthcare companies, will help bring life-enhancing products to the people you know and love. Your talents, ideas and passion are essential to our mission; to develop, manufacture and supply products that help people live better, healthier lives. Interested in learning more about life at Catalent? Start here\n\nPosition Summary\n\nCatalent is looking to recruit a Scientist, Process Development to join our growing team in Bloomington, In.\n\nA Scientist in Process Development has primary roles to design, execute and analyze laboratory and pilot scale experiments for process development and scale-up of processes for the expression of biologics/biopharmaceuticals. Bioprocesses can be in mammalian cell culture bioreactors, protein purification operations like chromatography and filtration, drug product process development and/or drug product formulation.\n\nThe Scientist in Process Development is responsible for leading development work for projects in order to develop robust processes that scale effectively to GMP manufacturing as needed. The Scientist in Process Development will also apply technical knowledge to develop robust processes or assays, designing, executing and interpreting internal and external client experimental plans including DOE, troubleshooting experiments. The Scientist in Process Development will guide Assistant and Associate Scientists with troubleshooting and experimental design, acting as project lead, including preparing and presenting data to clients informally and formally, with support of Senior or Principle Scientists as necessary. They will maintain necessary documentation in a lab notebook, authoring and reviewing technical reports, and supporting process transfer into manufacturing by providing written and oral communication of the process, training of manufacturing associates, review and approval of documentation, and on-floor support.\n\nIn concert with Catalent\u2019s Patient First philosophy, the Process Development Scientist ensures the manufacturing processes can be ran successfully, and that the quality of final product delivered to patients is consistent with expectations.\n\nThe Role\nScientist will have complete knowledge of varied aspects or a single specialized aspect of a discipline and some knowledge of principles and concepts in other disciplines\nApplies technical and functional knowledge to conduct experiments/research in assigned area\nMay act as a technical resource within own work group/project team\nWorks independently to solve problems of moderate scope\nActively participates, suggests solutions to problems\nThe Candidate\nBachelor\u2019s degree in science field with 5-7 years of experience OR\nMaster\u2019s degree in science field with 2-4 years of experience OR\nPhD in science field with 0-2 years of experience\nCatalent\u2019s standard leadership competencies that are used to interview and for Performance & Development:\nLeads with Integrity and Respect\nDelivers Results\nDemonstrates Business Acumen\nFosters Collaboration and Teamwork\nChampions Change\nEngages and Inspires\nCoaches and Develops\nPosition Benefits\nPotential for career growth within an expanding team\nDefined career path and annual performance review & feedback process\nCross functional exposure to other areas of Catalent\nMedical, Dental, Vision, and 401K are all offered from day one of employment\n19 days of paid time off annually + 7 paid holidays\nCatalent offers rewarding opportunities to further your career! Join the global drug development and delivery leader and help us bring over 7,000 life-saving and life-enhancing products to patients around the world. Catalent is an exciting and growing international company where employees work directly with pharma, biopharma and consumer health companies of all sizes to advance new medicines from early development to clinical trials and to the market. Catalent produces more than 70 billion doses per year, and each one will be used by someone who is counting on us. Join us in making a difference.\n\npersonal initiative. dynamic pace. meaningful work.\nVisit www.catalent.com/careers to explore career opportunities.\n\nCatalent is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, sexual orientation or gender identity. If you require reasonable accommodation for any part of the application or hiring process due to a disability, you may submit your request by sending an email, and confirming your request for an accommodation and include the job number, title and location to DisabilityAccommodations@catalent.com. This option is reserved for individuals who require accommodation due to a disability. Information received will be processed by a U.S. Catalent employee and then routed to a local recruiter who will provide assistance to ensure appropriate consideration in the application or hiring process.\n\nNotice to Agency and Search Firm Representatives: Catalent Pharma Solutions (Catalent) is not accepting unsolicited resumes from agencies and/or search firms for this job posting. Resumes submitted to any Catalent employee by a third party agency and/or search firm without a valid written & signed search agreement, will become the sole property of Catalent. No fee will be paid if a candidate is hired for this position as a result of an unsolicited agency or search firm referral. Thank you.\nTo apply to this job, click Apply Now"}, "631": {"company": "Genomic Health", "description": "Genomic Health, a subsidiary of Exact Sciences is seeking an exceptional individual with strong statistical skills to participate in the development of genomic biomarker assays that help cancer patients and their physicians make better treatment decisions. The Data Scientist II will directly support more senior personnel in pursuit of all Nonclinical Biostatistics (NCB) efforts across our various internal customer groups. In particular, these efforts will support Process Engineering, New Technologies development, and R&D efforts across multiple projects.\n\nAdditional responsibilities may include but are not limited to: relevant study support for Assay Development and the Development Lab work (e.g., initial data display and analysis), Analytical Chemistry/Analytical Sciences, Commercial Lab support and data monitoring, and clinical data QC for clinical studies. The candidate will interact with more senior staff of NCB and under their direction/supervision, establish close working relationships with our internal customer groups.\n\nRESPONSIBILITIES / DUTIES:\n\n\u2022 Primary responsibility will be to support the NCB staff and our internal customers in the development of any and all assigned projects, including but not limited to:\nNew Technologies and their evaluation\nProcess monitoring subsystems\nGHI Commercial Lab data monitoring and QC\nTable formation and development of descriptive statistics as required\n\u2022 Support will consist of but will be limited to:\nCode development in SAS, R, or Python as directed\nData review under the guidance of the NCB designated technical lead\nProcess improvement and automation\nProcess troubleshooting under the direction of the NCB designated technical lead\n\u2022 Secondary responsibilities will include when appropriate, direct support for our customer base, and under some supervision provide statistical guidance and advice with respect to initial analyses, data visualization, and tabularization.\n\nQUALIFICATIONS:\n\n\u2022 MS or Ph.D. in Biostatistics / Statistics\n\u2022 A minimum of 2 (Ph.D.) or 6 (MS) years of relevant work experience in industry or academia\n\u2022 Sound knowledge of theoretical and applied statistics\n\u2022 Experience in analyzing high dimensional data, designing/performing DOE studies\n\u2022 Statistical process control, analytical method development, and validation\n\u2022 Good written and oral communication skills\n\u2022 Able to integrate and apply feedback in a professional manner\n\u2022 Able with direction to prioritize and drive to results with a high emphasis on quality\n\u2022 Ability to work as part of a team\n\u2022 Experience with Machine Learning, and Deep Learning frameworks desirable\n\nPHYSICAL REQUIREMENTS:\n\n\u2022 Use of computer, and or telephone for long periods of time may be necessary.\n\u2022 Considerable periods of time may be spent concentrating and or analyzing data\n\u2022 Considerable periods of time may be spent communicating verbally and in various written forms including presentation material and email with other people\n\u2022 At times, stress may be experienced.\n\u2022 Standing or sitting for long periods of time may be necessary\n\u2022 Some lifting (greater than 25 pounds) may be necessary; Facilities, Materials and Engineering employees occasionally must lift at least 50-75 pounds.\n\u2022 May be exposed to hazardous materials, tissue specimens and instruments with moving parts, lasers, heating and freezing elements, and high-speed centrifugation (GENERALLY LABORATORY & CUSTOMER SERVICE EMPLOYEES ONLY)\n\n#LI-CB1\n\nWe are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to age, color, creed, disability, gender identity, national origin, protected veteran status, race, religion, sex, sexual orientation, and any other status protected by applicable local, state or federal law. Applicable portions of the Company\u2019s affirmative action program are available to any applicant or employee for inspection upon request.\n\nPhysical Requirements\n\n\u2022 Use of computer, and or telephone for long periods of time may be necessary.\n\u2022 Considerable periods of time may be spent concentrating and or analyzing data\n\u2022 Considerable periods of time may be spent communicating verbally and in various written forms including presentation material and email with other people\n\u2022 At times, stress may be experienced.\n\u2022 Standing or sitting for long periods of time may be necessary\n\u2022 Some lifting (greater than 25 pounds) may be necessary; Facilities, Materials and Engineering employees occasionally must lift at least 50-75 pounds.\n\u2022 May be exposed to hazardous materials, tissue specimens and instruments with moving parts, lasers, heating and freezing elements, and high speed centrifugation (GENERALLY LABORATORY & CUSTOMER SERVICE EMPLOYEES ONLY)\n\nCompany Profile:\n\n\nGenomic Health is a global provider of genomic-based diagnostic tests that address the overtreatment of cancer, one of the greatest issues in healthcare today. Our goal is to improve the lives of people with cancer by providing personalized, biological information that helps them get the right treatment at the right time, and to avoid unnecessary treatments and their side effects. In this way, our work is truly life, changing.\nOur Oncotype IQ Genomic Intelligence Platform is a portfolio of diagnostic tests that help physicians and patients answer specific and critical treatment questions throughout the cancer journey\nWe currently offer Oncotype tests addressing breast, colon, prostate and lung cancers and hundreds of thousands of patients from over 90 countries have benefited from our tests.\nThe Oncotype DX breast cancer test is considered standard of care in the US and is included in all major international clinical guidelines for breast cancer treatment.\nWe are expanding our portfolio of tests to include additional liquid- and tissue-based tests through clinical research and internal product development as well as strategic partnerships.\nJoin the Genomic Health Team, and have the unique opportunity to make a difference in the lives of patients with cancer, while developing your career potential. We embrace our unique culture characterized by our Core Values of Community, Truth Seeking, Being Ahead of the Curve and Winning to be the best in the world at what we do. We maintain competitive total rewards programs designed to satisfy our employees\u2019 work life and personal life needs.\n\nAll qualified applicants will receive consideration for employment without regard to race, sex, gender identity, color, religion, national origin, protected veteran status, or on the basis of disability.\n\nApply Now: click Apply Now"}, "632": {"company": "Assurance Careers", "description": "About Assurance\nAt Assurance we are disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosystem. We are rapidly growing as we expand our product offerings and global footprint, and this growth continues to present new and exciting challenges as we push our industry into its future. We eliminate waste throughout the industry and calculate the complex into simple, valuable solutions to improve people's lives. We are humble, driven, and committed to improving the lives of millions.\n\nAbout the Position\nAs we build the future of consumer insurance in a modern age, data is at the core of everything that we do. The role requires team members who are adept at using large data sets to find opportunities for optimization and can leverage appropriate models to test the effectiveness of different courses of action. Our team uses a variety of data mining and analysis methods, a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Team members must be very comfortable writing production-ready code to include testing and maintenance infrastructure, and able to put models and analysis into production with no support from engineering (we own our stack end to end). At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise.\nTo be successful in this role, you must possess the following:\nProficiency in either Python or R, and expertise in SQL.\nExperience working with AWS or another cloud-based computing platform.\nExperience and working knowledge of data infrastructure, pipelines, and advanced data manipulation.\nExperience with BI tools like Tableau or Looker (preferred), or any other industry tool such Qlik, PowerBI, Spotfire, etc.\nExcellent communication ability \u2013 you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.\nBusiness Acumen \u2013 you are always eager to understand how the business works, and more specifically, how your work impacts the business.\nEnthusiastic yet humble \u2013 you are excited about the work you do, but you are also humble enough to embrace feedback \u2013 you don\u2019t need to be the smartest person in the room.\nThe following additional experience is desired:\nExperience retraining a model within a few days or update a model within one day.\nCapable of performing an in-depth analysis and summarizing findings in one day.\nComfortable having conversations with our executive team and non-technical team members to distill down their needs and to deliver actionable insights.\nAbout You\nYou have a proven ability to drive business results with data-based insights and are comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. You\u2019re capable of getting data for analysis on your own, without reliance on engineering, and you can build professional dashboards as standalone software products and tools. We\u2019re growing at a rapid pace, so it\u2019s important that you embrace the opportunity to blaze your own trail. You thrive in a fast-paced environment where priorities can shift rapidly as we corner opportunity. You can work independently, with little oversight or guidance.\nIf this sounds like a good fit for you, give us a shout, we\u2019d love to chat!\nStart your job application: click Apply Now"}, "633": {"company": "Pactera", "description": "Job title: Data Analyst\nLocation: Hartford CT\nOne of leading companies in the healthcare industry is now hiring a hands-on Data Analyst with 5+ years\u2019 experience as one of those roles of data modeling, data analysis and even data architect and experience of OLTP and OLAP system design.\nShould be working with multiple data sources including Salesforce or Dynamics. Must be able to work with business and data sources independently to understand data availability and business insights that can be driven.\nExperience of owning & managing all changes to the models, solution designs, and architecture documentation; determining database structural requirements by analyzing client operations, applications, and programming; reviewing objectives with clients; evaluating current systems;\nExtensive experience in Relational Data Modelling, Dimensional Data Modelling, Logical/Physical Design, ER Diagrams, Forward and Reverse Engineering ERWIN diagrams, analyzing data sources and creating interface documents;\nProficient in data mart design and creation of cubes using dimensional data modeling \u2013 identifying Facts and Dimensions, Star Schema and Snowflake Schema;\nExperience in SQL and good knowledge in SQL/SAS programming and experience of ETL tool of SSIS and reporting tool of SSRS;\nGreat communication and a passion for driving insights from data, working with developers\u2019 analysts and business, writing or reviewing functional specs as needed etc.\nStart your job application: click Easy Apply"}, "634": {"company": "PA Consulting", "description": "Do you crave a collaborative organization where your contributions will make a strong impact?\n\nDo you want to develop products in the latest cloud-based technologies building ecosystems rather than creating client-facing slides?\n\nAre you ready to roll up your sleeves and embrace a work culture that\u2019s insanely passionate and committed to bringing the latest advanced analytics to life?\n\nThe Data Science & AI group at PA Consulting is your dream community. As part of the fastest growing innovation practice within PA Consulting, you will work with the latest advanced analytics, machine learning, and big data technologies to generate actionable insights from data and develop innovative data products. We focus on Life Science, Healthcare, Energy & Utilities and CPG sectors and work with various data sets, from social media to public health data. Our domain focus is broad and covers everything from computer vision and NLP, recommender engines, classification and clustering algorithms, linear programming and optimization.\n\nJob Requirements\n\n\n\u2022 2-5 years professional experience as a data scientist, software engineer or statistical modeler\n\u2022 Master\u2019s degree from top tier university in Computer Science, Statistics, Economics, Physics, Engineering, Mathematics, etc.\n\u2022 Expertise in machine learning algorithms and methods\n\u2022 Strong understanding and application of statistical methods\n\u2022 Experience writing production level code in one of the following: Python, Java, C++, C\nPreferred:\n\u2022 Experience working with database systems (e.g. SQL, NoSQL, MongoDB, Postgres, ect.)\n\u2022 Experience working with big data distributed programming languages, and ecosystems (e.g. S3, EC2, Hadoop/MapReduce, Pig, Hive, Spark, etc)\n\u2022 Experience building scalable data pipelines and with data engineering/ feature engineering.\n\u2022 Webscraping leveraging Beautifulsoup, Selenium, Scrapy, etc\n\u2022 Experience with front end (UI), HTML5, JavaScript, CSS, R Shiny, Tableau\n\u2022 Experience leveraging ML techniques to build recommender systems, NLP engines, computer vision algorithms, etc..\n\nAbout PA Consulting Group\n\n\nBringing Ingenuity to Life: We\u2019re an innovation and transformation consultancy that believes in the power of ingenuity to build a positive-human future in a technology-driven world. Our diverse teams of experts combine innovative thinking with breakthrough-technologies to progress further, faster.\n\nWith a global network of FTSE 100 and Fortune 500 clients, we\u2019ll offer you unrivalled opportunities for growth and the freedom to excel. Combining strategies, technologies and innovation, we turn complexity to opportunity and deliver enduring results, enabling you to build a lasting career.\n\nIsn\u2019t it time you joined us?\n\nWe are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class. VEVRAA Federal Contractor\n\nApply Now: click Apply Now"}, "635": {"company": "QuantumBlack", "description": "Analytics\nSenior Data Scientist - QuantumBlack\n\nBoston\n\nApply Now\n\nQualifications\n\nMSc or PhD level in the field of Computer Science, Machine Learning, Applied Statistics, Mathematics\nExperience in statistical modelling and machine learning techniques\nProgramming experience in at least two of the following languages: R, Python, Scala, SQL\nExperience in applying data science methods to business problems\nExperience in applying advanced analytical and statistical methods in the commercial world\nGood presentation and communication skills with the ability to explain complex analytical concepts to people from other fields\n\nWho You'll Work With\n\n\nAs a Senior Data Scientist at QuantumBlack in Boston you will work with other Data Scientists, Data Engineers, Machine Learning Engineers, Designers and Project Managers on interdisciplinary projects, using Maths, Stats and Machine Learning to derive structure and knowledge from raw data across various industry sectors.\n\nWho you are\n\nYou are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritizing impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.\n\nWhat You'll Do\n\n\nYou will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally.\n\nYou will influence many of the recommendations our clients need to positively change their businesses and enhance performance.\n\nRole responsibilities\nWork on complex and extremely varied data sets from some of the world\u2019s largest organisations to solve real world problems\nDevelop data science products and solutions for clients as well as for our data science team\nWrite highly optimized code to advance our internal Data Science Toolbox\nWork in a multi-disciplinary environment with specialists in machine learning, engineering and design\nAdd real-world impact to your academic expertise, as you are encouraged to write \u2018black\u2019 papers and present at meetings and conferences should you wish\nAttend conferences such as NIPS and ICML as one global team as well as Data Science retrospectives where you will have the opportunity to share and learn from your co-workers.\nWork with one of the largest and most advanced data science teams, support the Lead Data Scientists to develop data science products\nWhat you\u2019ll learn\nHow successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines\nBuild products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations\nBe able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.\nBest practices in software development and productionize machine learning by working with our Machine Learning Engineering teams which optimize code for model development and scale it\nWork with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualizations\nUsing new technologies and problem-solving skills in a multicultural and creative environment\nYou will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.\nReal-World Impact\u2013 No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.\nFusing Tech & Leadership\u2013 We work with the latest technologies and methodologies and offer first class learning programs at all levels.\nMultidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.\nInnovative Work Culture\u2013 Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.\nStriving for Diversity\u2013 With colleagues from over 40 nationalities, we recognize the benefits of working with people from all walks of life.\nOur projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimizing a Formula1 car\u2019s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture:\nHealthcare Efficiency\u2013 We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.\nEnvironmental Impact\u2013 We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.\nProduct Development\u2013 We worked with the CEO of an elite automotive organization to reduce the 18-month car development timeframe by improving processes, designs and team structures.\nVisit our Careers site to watch our video and read about our interview processes and benefits.\n\nMcKinsey & Company is an equal opportunity employer.\n\nIndustries\nHigh Tech\n\nFunctions\nTechnology\n\nApply Now\nshare this job\n\nJob Skill Group - CSS Associate\nJob Skill Code - SPDS - Specialist, Data Science\nFunction - Technology\nIndustry - High Tech\nPost to LinkedIn - Yes\nPosted to LinkedIn Date - Sun Sep 08 20:00:00 GMT 2019\nLinkedIn Posting City - Boston\nLinkedIn Posting State/Province - Massachusetts\nLinkedIn Posting Country - United States\nLinkedIn Job Title - Senior Data Scientist - QuantumBlack\nLinkedIn Function - Consulting;Information Technology;Science\nLinkedIn Industry - Computer Software;Information Technology and Services;Management Consulting\n\nTo apply to this job, click Apply Now"}, "636": {"company": "Verisk Analytics", "description": "Company Description\n\nISO, a Verisk business, has been a leading source of information about property/casualty insurance risk since 1971. For a broad spectrum of commercial and personal lines of insurance, ISO provides statistical, actuarial, underwriting, and claims information and analytics; compliance and fraud identification tools; policy language; information about specific locations; and technical services. ISO serves insurers, reinsurers, agents and brokers, insurance regulators, risk managers, and other participants in the property/casualty insurance marketplace. To learn more about ISO please visit us at: www.verisk.com/iso. We are proud to be a part of the Verisk family of companies!\n\nWith a history of impressive growth, an innovative culture, and offering industry-leading solutions, Verisk Analytics is an amazing place to work and make a difference. In 2018, Forbes magazine named Verisk to its World\u2019s Best Employers list and, in 2017, to its World\u2019s Most Innovative Companies list for the third consecutive year. We also earned the Great Place to Work\u00ae Certification for the third consecutive year in recognition of our outstanding workplace culture.\n\nVerisk is a leading data analytics provider serving customers in insurance, energy and specialized markets, and financial services. Using advanced technologies to collect and analyze billions of records, Verisk draws on unique data assets and deep domain expertise to provide first-to-market innovations integrated into customer workflows. We\u2019ve been delivering predictive analytics and decision support solutions to our customers for nearly 50 years, helping them protect people, property, and financial assets. At Verisk, you\u2019ll be part of an organization that\u2019s committed to serving the long-term interests of our stakeholders, including the communities where we operate.\n\nAt Verisk, you can build an exciting career with meaningful work; create a positive and lasting impact on the business; and find the support, coaching, and training you need to advance your career. Our culture of innovation means your ideas on how to improve our business will be heard. As key contributors to our success, our team members enjoy working in a business-casual, collaborative environment that offers state-of-the-art resources, advanced technologies, and an excellent benefits package.\n\nJob Description\nLeads a team of diverse team of data scientists\nCoaches team members, and manages team development; knowledge transfer to team members.\nPartner with project managers, directors, and other internal project leaders.\nActively supports innovation, and the integration of new methods and technologies.\nSupports and/or tests new methodologies, software and data sources for continual improvement of quantitative solutions.\nUtilizes statistical, mathematical, and machine learning theory and methodologies to design analytic architecture and solutions.\nSupports and/or implements techniques to create high-performing models that comply with regulatory and privacy requirements and address business objectives and client needs.\nExecute and monitor project plans for timely project completion; supporting all stages of the analytic pipeline.\nSupports and/or participates in the creation of lucid documentation and reports (technical and non-technical) for internal and external clients.\nPresents analysis ideas, progress reports and results to internal managers, project owners, and executives.\nQualifications\nGraduate-level degree with concentration in a quantitative discipline such as statistics, mathematics, economics, operations research, computer science or aligned discipline. MS or higher preferred.\n7+ years of insurance experience, focusing on the personal lines.\nTeam-oriented with a track record of building strong internal and external unit partnerships.\nLead cross-functional projects using advanced data analysis techniques.\nStrong logical, evidence-based problem solving, and critical thinking skills that support innovative, creative solutions.\nProficient across the stages of the data analytic pipeline, from ETL to results communication, supporting knowledge transfer for team growth.\nBreadth and depth in the areas of feature engineering and selection methodologies, and machine learning methodologies.\nExperience using statistical computer languages (e.g. R, Python, SLQ), and with the management of large, complex datasets.\nExcellent verbal and written communication, and presentation skills (technical and non-technical)\n#LI-YD1\n\nAdditional Information\n\nVerisk Analytics is an equal opportunity employer.\n\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.\n\nhttp://www.verisk.com/careers.html\n\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\n\n</br>Apply now\nStart your job application: click Apply Now"}, "637": {"company": "MassMutual", "description": "Since 1851, MassMutuals commitment has always been to help people protect their families, support their communities, and help one another. This is why we want to inspire people to Live Mutual.\n\nWere people helping people.\n\nA career with us means you will work alongside exceptional people and be empowered to reach your professional and personal goals. Our employees are the foundation of what makes MassMutual a strong\n\nstable and ethical business. We seek and value unique and varied perspectives and experiences because we believe we are stronger when all voices are heard.\n\nWe invite you to bring your bright, innovative ideas to MassMutual as we continue to help millions of Americans rely on each other.\n\nTogether, were stronger.\n\nWhat great looks like in this role\n\nOur ideal Advanced Data Analyst candidate is proficient in data management and has a strong analytical capability. The incumbent will use own skills to provide subject matter expertise and complete in-depth data analysis, which contribute to the strategic efforts of the team. Youre also detail-oriented and adaptable. The team culture of working collaboratively, cross-functionally, using new technologies for data driven decision making\n\ncombined with the work/life balance provided by MassMutual are among the core reasons people enjoy working at MassMutual.\n\nDescription\n\nMassMutual continues to expand its data analytics capabilities and we are looking for an experienced and highly motivated individual with strong analytics background to join our Data Analytics team within the Enterprise Technology Experience organization! Data plays a key role at MassMutual, and as such, our Data Analytics team plays a critical role in MassMutuals success. In this role, you must be proficient in data management,\n\nhave a strong analytical capability and be able to partner with stakeholders to understand their needs. You will use your skills to provide subject matter expertise and complete in-depth data analysis, which contribute to\n\nthe strategic efforts of the team. The team embodies a culture of working collaboratively, cross-functionally, and using new technologies all in support of a culture of.\n\nObjectives of the role\nParticipate with various teams to define and understand data requirements\nProvide subject matter expertise on the data needs for project deliveries, scope, acceptance, installation and deployment.\nDaily and monthly responsibilities\nReview and coordinate with business application teams on data delivery requirements.\nDevelop estimation and proposed delivery schedules in coordination with development team.\nDevelop sourcing and data delivery designs.\nReview data model, metadata, and delivery criteria for solution.\nWork with data partners to develop/ enhance data to gain required insights\nDesign and develop dashboards and reports to visualize analysis results using BI tools\nContribute to the design, development and completion of project deliverables.\nComplete in-depth data analysis and contribution to strategic efforts\nComplete understanding of how we manage data with focus on improvement\nBasic Qualifications\nBachelors degree.\n4+ years of data analysis working with business data initiatives.\nKnowledge of SQL and use in data access and analysis.\nExperience with R and Python.\nKnowledge of Business Intelligence tools such as MicroStrategy, Looker, Tableau, etc\nBasic knowledge of database technologies (Vertica, Redshift, etc.).\nProficient in data management including data analytical capability.\nExcellent verbal and written communications, high attention to detail.\nPresentation skills in demonstrating system design and data analysis solutions.\nAuthorized to work in the USA with or without sponsorship now or in the future.\nPreferred Qualifications\nMasters degree in computer science or engineering.\nFamiliar with agile project delivery process.\nAbility to manage diverse projects impacting multiple roles and processes.\nCandidate should be able to troubleshoot problem areas and identify data gaps and issues.\nAbility to adapt to fast changing environment.\nExperience designing and implementing automated ETL processes.\nStrong organizational skills and ability to effectively prioritize multiple tasks.\nStart your job application: click Apply Now"}, "638": {"company": "Juvo", "description": "Juvo was founded with an overarching mission: to establish financial identities for the billions of people worldwide who are creditworthy, yet financially excluded. In partnership with mobile network operators, Juvo's proprietary Identity Scoring technology uses data science, machine learning and game mechanics to create an identity-based relationship with anonymous prepaid users, opening up access to otherwise unattainable mobile financial services.\n\nSince emerging from stealth in September 2016, Juvo has increased its global reach five times over, from 100 million to 500 million, and has steadily grown its operations and employee base worldwide with 100 employees today. To date, Juvo has enabled over 400M transactions in 25 countries and 4 continents, with 1M active subscribers a day. Juvo's mobile operator partners include Telefonica, Millicom, Sprint, Deutsche Telekom and Cable & Wireless.\n\nIn 2017, Juvo completed a $40 million USD Series B funding round with funding from Samsung NEXT and top-tier VCs including NEA, Wing Venture, and Freestyle Capital. Early investors in the company include the former CEOs of AT&T Wireless, NYSE, Sprint, Telefonica International and Vodafone Group. Juvo is frequently profiled in top tier tech and business press and our proprietary technology, Identity Scoring, is award winning.\n\nAbout the Job\n\nWe are looking for a talented Senior Data Scientist with a minimum of seven years of experience to help Juvo convert user data into personalized credit scores. You will play a central role not only in ensuring Juvo's success, but improving the financial landscape of millions, if not billions of people. As you lead key Data Science and platform initiatives, you will play a major role in the planning and construction of Juvo's technical stack.\n\nQualifications\nMS/PhD in a quantitative field e.g., Physics, Astronomy, Chemistry, CS, Math or have worked in Data Science, Quantitative Research or Software Development for 7 years.\nComfortable in Unix computing environments and have a handful of your favorite BASH tricks. You are fluent in one or more of the following programming languages: Python, Scala, R, Java.\nFamiliar with distributed computing frameworks such as Hadoop, Spark, Hive.\nYou know your way around AWS and regularly use one or more of their services e.g., S3, EC2, EMR, Redshift, DynamoDB, Kinesis, etc.\nYou like working in a fast-paced collaborative environment where the mantra is to push to master, make sure it makes sense...and doesn't break!\nPerks & Recreation\nWork towards a mission that matters \u2013 join us in creating the YES economy\nCompetitive cash and equity compensation\nGreat medical/dental/vision benefits, with dependent coverage\nPre-tax commuter benefits\n401(k) available\nPaid holidays and flexible paid time off\nMonthly reimbursement for internet or mobile phones\nConveniently located office in the Financial District of San Francisco\nFully stocked kitchens with organic and healthy snacks\nWeekly catered lunch\nYour choice of the best and newest tech (Apple products, Sennheiser Noise Canceling headphones, Stand-up desks, etc)\nEmployee discount on Samsung products (Samsung is an investor)!\nJuvo is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Juvo is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation.\nTo apply to this job, click Apply Now"}, "639": {"company": "Varen Technologies", "description": "At Varen, our performance is measured by the success of our clients, and our reputation for service, superior quality, objectivity, integrity and results. Our reputation is everything to us as we are committed to being a trusteisor to our nations decision makers in a day in age that demands acute attention to detail in a fast-paced environment. Varen is sed adveking to add the sharpest technical professionals who share our passion for ensuring the mission success of our customers at all times.\n\nPOSITION DESCRIPTION:\n\n\nVaren is seeking candidates with analytics expertise to help realize a program that measures organizational drivers of success and focuses on data driven decisions. The candidate(s) shall support the analytics team in identifying and developing actionable insights through problem definition, application of statistical models, and analysis against existing and future data. They will collect and convey information about language acquisition, maintenance and testing to improve the language and learning function at an Enterprise level. This foreign language related data will be displayed in the Personalized Language Dashboard and the upcoming Language Lifecycle tool. This team will provide language analytics using innovative research methodologies and tools to enable stakeholder decisions, increase the quality and effectiveness of Learning Enterprise (LE) products and services, establish relationships between the LE and mission execution, implement data collection and data visualization tools, and produce internal/external reporting.\n\nREQUIRED EXPERIENCE:\n\nDemonstrated experience designing and conducting research to answer key business questions, to include structured interviews, focus groups, and surveys.\nDemonstrated experience identifying metrics of relevance to leadership and aligned with organizational strategy.\nDemonstrated experience deriving insights from data and presenting conclusions to non-technical audiences.\nDemonstrated experience identifying and obtaining datasets needed to answer key business questions.\nDemonstrated experience visualizing data and conveying complex research findings in both written and oral formats to stakeholders at all levels.\nDESIRED EXPERIENCE:\n\nFamiliarity with Sponsors data systems as they relate to foreign language acquisition and maintenance, human resources (HR) or learning.\nExperience leveraging programming languages to script the extraction, formatting and transformation of data from a wide variety of organizational systems.\nDemonstrated experience working in a learning environment.\nDemonstrated experience working across Sponsor units effectively in support of an end goal.\nCLEARANCE REQUIREMENT:\n\nTS/SCI clearance in JPAS is required\n\nStart your job application: click Apply Now"}, "640": {"company": "GMMB", "description": "Are you up for a meaningful challenge? Do you aspire to use your creativity to drive social change?\n\nThen come join our team of sharp, passionate and (sometimes) quirky activists. In our 35+ years, we\u2019ve helped elect presidents; improved education; fought for stricter regulations on tobacco, supported clients to improve health interventions like vaccines and clean water in the developing world; fought to bring health coverage to all Americans; and brought people together to improve the lives of individuals, families, communities and nations.\n\nOur mission: to create real and lasting change in the world. And between our D.C. home base, Seattle and San Francisco offices, you\u2019ll find all the know-how and drive to create advocacy campaigns that deliver real results.\n\nWe are\u2026political strategists, data scientists, issue experts, social and digital strategists, comms and advertising gurus, designers, writers, media planners and multi-media producers.\n\nYou are\u2026a Data Engineer who knows how to:\nSupport, maintain, and develop key pieces of the data infrastructure\nBuild tools to help GMMB teams improve their reporting and strategy\nAssist in the administration of our data systems and tools\nBuild pipelines to load information into database and reporting tools\nProject manage requests made to the data team from clients/internal teams\nWork collaboratively with the campaign technology team to support data infrastructure\nSupport internal projects by automating various data flows and processes as needed\nDevelop reporting dashboards with data visualization tools\nWrite technical documentation\nOnboard/train other team members in data science best practices\nYou have\u2026\nExtensive experience working with data in Python or R; familiarity with building predictive models in chosen programming language Python or R\nExtensive experience working with data visualization tools (Tableau, Google Data Studio, Shiny, Dash or D3)\nExperience automating pipelines and data flow across an organization\nExperience working in the various flavors of SQL (we use Redshift and PostgresSQL)\nFamiliarity with Git version control system\nExperience working with external APIs\nStrong organizational and project management skills; experience writing technical documentation\nIntermediate skills in MS Office including Word, Outlook and PowerPoint; advanced skills in Excel\nA passion for progressive causes and is not afraid to question the status quo (we encourage it!)\nA desire to learn new skills and stay up-to-date with emerging technologies\nThe ability to thrive in a high pressure, fast paced environment with shifting priorities\nFlexibility to work evenings and weekends - because we're a client services firm so sometimes that's when our clients need us\nStrong interpersonal skills and can work collaboratively across teams\nA meticulous eye for detail and exceptional organization skills\nIt\u2019s a bonus (not required) if you have\u2026\nExperience working in marketing, advertising or politics\nExperience working with GIS data\nExperience working with a *nix environment\nExperience working with Docker containers\nExperience with web crawlers/scrapers (Scrapy, Selenium)\nFamiliarity with full-stack web development (React, Django) including unit testing\nFamiliarity with AWS/Google Cloud\nFamiliarity with 2D Design software (Adobe Creative Suite, Inkscape, Gimp)\nGMMB is an equal opportunity employer. All applicants are considered without regard to race, color, religion, national origin, sex, sexual orientation, gender identity or expression, age, disability, marital status, veteran status or any other discriminatory factors prohibited by law.\nTo apply to this job, click Apply Now"}, "641": {"company": "Proofpoint", "description": "It's fun to work in a company where people truly BELIEVE in what they're doing!\n\nWe're committed to bringing passion and customer focus to the business.\n\nThe Role\n\nDo you have a passion for applying machine learning to hard problems in new application areas? Do you keep up with the latest on GANs, ResNets, CNNs, RNNs, and Deep Reinforcement Learning but have also mastered the classics like SVM and Random Forest? Are you looking for the opportunity to work with a great team that combines algorithm design, software engineering, and domain knowledge into products that are first of their kind? If so, we are looking for you. We need a Data Scientist who will work on analyzing data from malicious actors to help uncover cyber threats. Your primary focus will be applying your skills in various areas like anomaly detection, graph mining, clustering, and predictive analytics to help us build groundbreaking services that would revolutionize the industry.\n\nWe are a fast-paced, high-energy team where you will be given the opportunity to make a significant impact. The team has a solid engineering culture that values the craftsmanship of writing great software, enjoys learning, and solving big problems.\n\nYour day-to-day\nFeature engineering, building and optimizing classifiers, applying machine learning and deep learning expertise\nBlending data from disparate sources, mining the resulting data lake to build models\nContributing tested code to the team\u2019s git repo and working with engineering to implement models efficiently\nProcessing, cleansing and verifying integrity of data used for analysis\nConducting ad-hoc analysis and innovation around data visualization\nWhat you bring to the team\nExcellent understanding of machine learning algorithms, processes, tools and platforms including:\nSupervised methods - Na\u00efve Bayes, Logistic Regression, SVM, ConvNet, LSTM, Siamese Networks, etc.\nUnsupervised methods - K-means, DBSCAN, T-SNE, Spectral Clustering, SOM, LSH, etc.\nToolkits - numpy, scipy, scikit-learn, tensorflow, pytorch, keras, genism, vowpal wabbit, etc.\nPython proficiency\nGreat communication skills, ability to explain predictive analytics to non-technical audience\nProficiency in data exploration techniques and tools, e.g. SQL, Hive, etc.\nExcellent statistics, linear algebra, and optimization skills\nMS in Statistics, Machine Learning, Applied Physics or Computer Science (or technical degree with commensurate industry experience). PhD preferred\n#LI-JL3\n\nIf you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!\nStart your job application: click Apply Now"}, "642": {"company": "Fareportal Inc.", "description": "(We are unable to sponsor for this role or in the future)\n\nAt Fareportal, we create the technology that is driving innovation in the travel industry - one of the world's fastest-growing sectors. Our employees are the core of our organization and together we're revolutionizing the way people book travel.\n\nOur portfolio of brands including CheapOair and OneTravel receive over 100 million visitors annually and drive over $4 billion in annual revenue.\n\nIn addition to competitive pay and benefits, generous time off, and frequent company-wide social events, Fareportal provides employees with an environment that nurtures diversity, creativity, and success. Our open and Agile workspace gives our employees the time and space for collaboration, brainstorming, and research and development. At Fareportal, you'll be challenged, rewarded, and motivated to work effectively day in and day out.\n\nWe are looking for a machine learning engineer to join our team. You will be handling hundreds of millions of events per day, responsible for creating and supporting machine learning models that will drive our business.\n\nMachine Learning Engineers is at the heart of how Fareportal works and they are part software engineer and part machine learning / data scientist. You will focus on creating and supporting large scale models that we deploy to power our recommendation, pricing or other systems.\n\nThe ideal candidate will participate in the design and implementation of the entire model pipeline, from project ideation, figuring out which data to capture and store, coming up with features, to creating the final model.\n\nWe are passionate about making data-driven decisions and you will have the opportunity to shape the team's direction and create large impact.\n\nOur team loves Python and Scala (and is not afraid of Functional Programming) and we strongly encourage DevOps approaches.\n\nResponsibilities:\nSupport our data modeling efforts to ensure we are capturing the data needed to improve our modeling\ncapabilities.\nCreate features for our feature store\nBuild machine learning models\nUse a variety of techniques including predictive modeling, recommendation engines, revenue\nmanagement, conversion rate optimization, and site and user experience optimization.\nOur ideal candidate:\n\nWho You Are\nYou are smart and love to build systems that are well tested as well as flexible\nYou like being around smart people who will challenge you on a daily basis.\nYou love to ramp up on new technologies to build awesome things with us!\nPassionate about working with large unstructured and structured data sets and developing new\napproaches to relevance problems\nRequirements\nBachelor in Computer Science, Software engineering, Data Science or related disciplines (we are open to exceptions) - Only May 2020 Undergraduates\nGood knowledge of one of: Python or Scala\nSolid understanding of object oriented or functional programming concepts\nFamiliarity with version control concepts\nGood knowledge of machine learning\nGood knowledge of Pyspark\nGood knowledge of software engineering best practices\nStart your job application: click Easy Apply"}, "643": {"company": "Earnest", "description": "Earnest empowers people to live better lives\n\nWe're an accomplished team of design, math, finance and technology geeks who noticed some issues in our financial system and decided to do something about it. We created a company that combines data science, streamlined design, and technology to:\nBuild more affordable products\nBring them to more people\nEngage through more human experiences\nAs a Senior Data Scientist, you will report to the Head of Data and work on full stack-data science. Our modelers and engineers partner and own everything from data sourcing/ETL to model creation/testing and model deployment/maintenance. You will do compelling modeling and also work on state-of-the-art engineering.\n\nTeam Philosophy:\nEveryone on the team is considered and treated as a Senior, so you are given a lot of ownership over the projects you're working on. With this in mind, we expect you to write code that is well tested, modular, and maintainable. We frown at instances of destructive firefighting, caused by badly designed architecture or mismanaged projects.\nWe like learners. Hence, we create an environment where Data Scientists learn the skills and abstraction patterns of Software Engineers and Data Engineers learn the iterative model development workflow seen in Machine Learning. Expect an environment where you will be always learning and challenged to work with tools, languages, frameworks that are outside of your area of expertise.\nTools, Frameworks, and Languages you will work with:\nMachine Learning: We use state-of-the art open source tools and frameworks. The problem domain is constrained to tabular, time-series, and NLP data.\nLanguages: Python, SQL, R (occasionally you will also work with Node.js or Scala)\nStorage: Postgres, Redshift, S3\nCompute: Spark, Athena, EC2\nWorkflow Management: Airflow\nMisc: Looker, Github, Jira, Splunk, PagerDuty\nResponsibilities\nCreatively use new and existing data to increase the efficiency of our underwriting infrastructure\nWork with engineers to design machine learning solutions that operate quickly and effectively at scale. You will be involved in deploying models within Python microservices.\nMake recommendations to the executive and cross-functional teams that would help improve Earnest operations.\nWrite tooling or expand on existing internal frameworks (e.g., feature-generator repo).\nIdeal backgrounds and expertise:\n3+ years of industry experience developing machine learning models from inception to business impact.\nStrong programming skills - Python preferred (though open to R for candidates that have very strong background in the language).\nIntermediate to advanced knowledge of SQL and ability to wrangle data from many different data sources.\nDeep experience with ML/DL toolkits: Tensorflow, scikit-learn, XGBoost, Numpy, Scipy, Pytorch, PySpark.\nYou've earned a degree in Machine Learning, Statistics, Optimization, Physics, or related field, with experience building production-ready ML models and systems.\nFamiliarity with building inferential models (GLM, LMER), simulation techniques (MCMC), and hypothesis testing.\nUnderstanding of traditional relational databases (PostgreSQL, MySQL) and distributed systems (Redshift, BigQuery, Spark, Apache Hadoop)\nNice to Have:\nDomain experience developing software for Fintech, Banking, or related Consumer Financial Services companies\nKaggle Ranking (this can help speed up the interview process)\nAn active Github or Medium profile\nEarnest Perks & Benefits:\nHealth, Dental, & Vision benefits plus savings plans\nEmployee Stock Purchase Plan\n401(k) plan to help you save for retirement plus a company match\nTuition reimbursement program\n$1000 flight on each Earnie-versary to anywhere in the world and 25 days of annual PTO\nEarnest provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, sexual orientation, disability, genetics, gender identity or expression, or veteran status. Qualified applicants with criminal histories will be considered for the position in a manner consistent with the Fair Chance Ordinance.\nTo apply to this job, click Apply Now"}, "644": {"company": "Remitly", "description": "At Remitly, we help immigrant communities around the world send over $6 billion a year to their loved ones. Sending money is faster, easier, and costs less with our all-digital money transfer platform. Our vision is to transform the lives of immigrants and their families by providing the most trusted financial service products on the planet. At Remitly, your work has a direct and positive impact on people around the globe. Your work matters, every day.\n\nWe are looking for an exceptional Machine Learning Engineer to join our global ML team to work on data products that underpin our business. Our ML team currently builds systems that set our FX rates for customers, detect bad actors using our product, and forecast volume to inform our currency trading strategy. This role will focus on the Pricing space where you will develop models that are used to price tens of millions of dollars worth of volume in real time every day.\n\nIn this role, you will:\nBuild production systems that set FX rates for customers in real time.\nBe a subject matter expert in Pricing and Treasury, and a thought leader with respect to pricing choices throughout Remitly. In this capacity you will partner with Economists, Analysts, and Engineers to build the strategies and products that power our pricing engine.\nProvide insightful statistical and econometric analysis that extracts value from complex datasets and achieves targeted outcomes.\nHave a significant impact on Remitly's bottom line. Your work will impact our customer facing product and dictate the exchange rates customers receive on transactions every day. As an exceptional business thinker, you will also provide analytical expertise and judgement to other teams including Treasury and Marketing.\nYou are:\nCustomer centric. Your models will be directly impacting the economics of everyday life for immigrants and their families. As a senior team member in this space, this role requires a high degree of empathy and commitment to our customers to ensure model outputs align with our cultural values.\nOutcome oriented. All models start and end with a business problem. You enjoy seeing and measuring the results of your work and are excited to build products with a large impact to the company.\nEconomically minded. We approach many problems from a microeconomic perspective. You enjoy finding the simplest form for a problem and aligning your underlying models with business intuition and economic theory.\nEnergetic. You continually exhibit high energy and an ability to stay positive under pressure. We should be a self-starter, able to work independently, as well as work in a team-oriented and fast paced environment.\nCurious. You ask why, and you question every assumption. If you've ever said \"oh, I just did it that way because [Important Person] said so,\" you won't do well here. We need you to probe assumptions, question the status quo, and follow up on unexpected data results.\nConfident in your data and ideas. You can explain the method to your analysis and validate your results. Once the data supports your ideas, you're willing to advocate your recommendations to any stakeholder that needs to buy-in (fortunately for you, we're happy to rally behind your great idea).\nSuccessful candidates should have:\nAn MS or PhD in Computer Science, Economics, Statistics, Applied Mathematics or a related area\n6+ years of work experience building production ready systems, with at least 4+ years applying statistics and machine learning that resulted in data-driven business impact.\nSolid knowledge of both the theory and application of ML algorithms.\nProficiency with systems design and data processing. Candidates should have hands on experience with Python, ML libraries (e.g., scikit-learn, scipy, numpy, matplotlib, pandas etc), and SQL. Experience with AWS, Scala, Spark, and Hadoop are also sought but not necessary.\nStrong knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.\nAbility to present complex concepts in a clear narrative that influences stakeholders to take action.\nYou are curious, love to continuously improve and exhibit the aptitude to learn quickly.\nYou love making a difference.\nTo apply to this job, click Easy Apply"}, "645": {"company": "Adavance2", "description": "About the position\nAdvance2 is a fast-growing marketing optimization tech startup. We\u2019re bringing the world of marketing optimization to the next level leveraging Machine Learning. Advance2 automates data collection, model building, insights extraction and optimization of our clients\u2019 business.\nWe are looking for a Data Scientist to be part of the Product Development team. You will be working alongside a small cross-functional team of Engineers and Data Scientists. You will enjoy designing, developing and deploying to production data-based approaches to solving difficult business and product problems.\nThe Data Scientist will be responsible for leveraging their expertise in data processing, statistical modeling, ML, and AI to build product solutions at scale.\nYou will thrive in this role of you love problem-solving, analytical thinking and combining doing math on the whiteboard with coding.\n\nResponsibilities\nDesign, develop and deploy Machine Learning algorithms to production.\nCollaborate with Software Engineers to streamline and optimize model building and deployment.\nPartner with Product Managers to help prioritize and deliver product features.\nApply Machine Learning and Artificial Intelligence expertise to build prototypes and translate them into product features.\nContribute in creating a data-driven approach to complex business problems in the company.\nQualifications\nM.A./M.S. or Ph.D. degree in Statistics, Mathematics, Economics, Physics, or Engineering\n3+ years of experience in building predictive models using statistics and/or Machine Learning at scale.\nExperience with extracting and delivering causal relationship findings from predictive models.\nWorking knowledge of Python and related data science libraries (NumPy, Pandas, Scikit-learn, SciPy).\nMedia/Agency experience is a plus.\nExperience with data visualization is a plus.\n\nAbout Advance2\nAdvance2 is the next generation AI-driven marketing optimization platform. We help our clients continuously optimize their marketing budget with a holistic approach by leveraging Machine Learning and automation.\nWhile advanced Machine Learning algorithms are often perceived as black-boxes, we strive to bring a human touch to our AI engine, conveying the thought process underlying the AI recommendations with the help of advanced visualizations."}, "646": {"company": "SAGE Therapeutics", "description": "General Scope and Summary\n\nSage Therapeutics is searching for an experienced Associate Director, Pharmacovigilance Scientist (AD, PV Scientist) that is a creative, resourceful and integrative thinker. The person in this role works closely with the Global Safety Lead (GSL) and with the VP of Drug Safety and Pharmacovigilance and provides pharmacovigilance and signal detection expertise through contributions to clinical and post market pharmacovigilance deliverables and activities. Effective communication skills will be key as this role provides an excellent opportunity for close collaboration with colleagues from other functions such as Clinical Development, Clinical Operations, Regulatory Affairs and Medical Affairs. The AD, PV Scientist will provide scientific/clinical expertise, strategic input, and support for deliverables and activities associated with signal management activities, safety and benefit-risk evaluations for assigned products, management of potential safety issues for assigned products, evaluation of databases for safety signals, and drafting of responses to regulatory inquiries on product safety issues including oversight of aggregate reporting for all products within the product group,\n\nRoles and Responsibilities\nOverseeing aggregate reporting, clinical trial activities, signal management, literature review, and ad hoc regulatory responses for assigned product group\nLead product safety surveillance activities for assigned product(s)during all phases of the product life-cycle\nReview study protocols, statistical analysis plans and other clinical study-related documents\nReview standard design of tables, figures, and listings for safety data from clinical studies\nManage updates to Investigator Brochure, Company Core Safety Information and other Reference Safety Information\nSignal detection, evaluation, and management\nImplement signal detection strategy approved by GSL and VP of Drug Safety and Pharmacovigilance\nReview adverse event data, literature, and other safety-relevant data for the purpose of signal detection\nPrepare review of potential safety signals for GSO and VP of PVRM\nProvide safety contents for risk management plans\nAssisting in the successful implementation, execution and maintenance of safety processes and systems that conform to the companys business strategy, industry standards and compliance with global regulations\nExperience, Education and Specialized Knowledge and Skills\n\nMust thrive working in a fast-paced, innovative environment while remaining flexible, proactive, resourceful and efficient. Excellent interpersonal skills, ability to develop important relationships with key stakeholders, good conflict management and negotiation skills, ability to analyze complex issues to develop relevant and realistic plans, programs and recommendations. Demonstrated ability to translate strategy into action; excellent analytical skills and an ability to communicate complex issues in a simple way and to orchestrate plans to resolve issues and mitigate risks.\n\nBasic Qualifications:\nAdvanced degree (RN, PharmD, NP, PhD, MD, MPH, NP, DVM with specialty board certification)\nMinimum of 6 years pharmacovigilance experience, including experience in aggregate safety reports and safety signal management.\nPreferred Qualifications:\nExpertise in the following; Argus Safety Database, MedDRA, Sharepoint, Microsoft Office, Excel\nSound clinical acumen and decision making\nA proactive and innovative approach and a flexible, hands-on nature that works with a high sense of urgency.\nAbility to review, synthesize and analyze and communicate (verbally and in writing) complex safety data and clinical/pharmaceutical information\nExpertise in international regulations governing drug safety (US and EU) for pre and post-marketing\nDemonstrated leadership and collaborative skills necessary to influence across functions and earn credibility across a complex and rapidly growing organization.\nLevel will be commensurate upon experience and qualifications.\nExcellent oral and written communication skills\nPrior experience contributing to the development (process improvement, training, etc.) of a drug safety would be desirable\nEmbrace our core values: Put People First, Do Big, Be Accountable, Grow through Learning and Change, and Work Fun\nExcitement about the vision and mission of Sage\nEmployment Type:\nEmployee\nNumber of Openings:\n1\nJob ID:\nR000382\n#Biotechnology #Careers #ThisIsSage\n\n\nAll qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.\n\nEEO is the Law\n\nEEO is the Law - Poster Supplement\nTo apply to this job, click Apply Now"}, "647": {"company": "SocialCode", "description": "About Us:\n\nSocialCode combines audience data, insights, creative and measurement to drive superior performance for leading brands. We offer an integrated technology and service solution that transforms consumer and brand data into highly effective planning, media activation and measurement for a variety of leading Fortune 500 and emerging brands. Our deep expertise in people-based media, advertising, and e-commerce platforms like Facebook, Google, and Amazon drives superior business results and actionable insights about customers and prospects.\n\nThe Role:\n\nWe're looking to hire a Data Engineer to help to further develop our analytics platform for audience and campaign data. The ideal candidate has a passion for data and big data technology, and will be joining a team of seasoned data engineers to take that passion to the next level!\n\nHow You Can Make An Impact:\nCollaborate with other engineers to produce a robust, highly performant data pipeline including data ingestion, transformation, aggregation, and storage of data for analysis and modeling.\nOrchestrate complex workflows to accommodate a range of large-scale data sets from our clients and partners across several targeted verticals.\nPartner with our data scientists to deliver production-ready models that operate at scale to power superior advertising performance.\nDevelop the experience and know-how to keep our data pipeline operations on rails.\nRequirements:\nBachelor's or Master's degree in Computer Science (or related field) or equivalent experience\nMinimum of 2 years experience in software engineering, including at least 1 year working with big data tooling\nIdeal Candidate:\n\nExperience in:\nBig data tech including Spark, Hadoop, and HDFS\nCloud-based analytics environments (such as Qubole or DataBricks)\nWorking within the AWS platform or Google Cloud Platform\nPython or equivalent high-level language\nWorkflow management tools such as Airflow, AWS Step Functions, or Oozie\nDomain experience highly desirable in the following areas:\nComputational advertising and/or marketing technologies\nIngesting and transforming large-scale data sets (both in batch and streaming fashion)\nExcellent leadership, written and verbal communication, analysis, design, development, and collaborative problem-solving skills\nWHAT WE OFFER\nCompetitive salary + Quarterly bonus eligibility\nFull benefits (Medical, Dental, FSA/HSA) + 401(k) & pension\nContinuing education dollars + Sabbatical program\nCasual dress + Catered Lunch + In-office snack surplus\nTo apply to this job, click Easy Apply"}, "648": {"company": "MITRE", "description": "MITRE is a trusted operator of federally funded research and development centers and we\u2019re on a mission to make the world a safer place\u2014for all of humanity, today and in the future. To deliver on our mission, we need the world\u2019s best talent and leaders\u2014groundbreakers and partnership-builders on a global scale in areas like healthcare, artificial intelligence, critical infrastructure resiliency, pandemic management, and cybersecurity. In return, we have the privilege of backing you with thousands of technical experts in diverse fields, a culture of innovation and knowledge sharing, access to data and resources uniquely available to MITRE through our wide-ranging partnerships across government, industry and academia.\nThe MITRE\nNaval Division delivers innovative concepts, technologies, and methodologies\nenabling current and future Naval superiority.\nRisk takers skilled in machine learning and deep learning will find a\nhome at the Naval Division where their skills will push the boundaries of\nmilitary data analytics and artificial intelligence. This position requires creative problem\nsolving through novel applications of machine learning algorithms using MATLAB,\nPython, IDL (interactive data language), or other scripting languages and tools. The ideal candidate will enjoy working with\ndiverse teams on a variety of problem sets in a dynamic environment.\n\nKey\nFunctions include:\nPerforming\ncomplex data analysis using supervised and unsupervised machine learning\nApplying\ndeep technical knowledge in the latest data science technologies including data\ngeneration, augmentation techniques, semantic segmentation\nApplying\nartificial intelligence algorithms using neural networks\nLeveraging\nthe collective wisdom of the government, academia, industry, and other FFRDCs\nto create transformational impact, and help advance the field by sharing our\nresearch via publications and professional conferences.\nContributing\nto the technical work program of one or more projects and providing technical\nguidance and quality products\n\nMinimum Qualifications:\nBS and 5 years related experience\nApplicants selected for this position\nwill be subject to a government security investigation and must meet\neligibility requirements for access to classified information or applicants who\nare eligible for security clearances\nRequired Qualifications:\nKnowledge of signal processing, detection and estimation theory, stochastic processes, numerical methods, linear algebra, applied statistics, probabilistic reasoning, graphical models, etc.\nStrong software development skills with experience using analytical software tools such as Python, C/C /C#, or MATLAB.\nBroad understanding of the technologies and capabilities of machine learning and deep learning\nFamiliarity with style-transfer learning, unsupervised learning, training sets, and inference models\nDeep working knowledge of data engineering tools and technologies\nObtain and maintain a Secret level security clearance\nOne or more of the preferred qualifications\nPreferred Qualifications:\nMaster's or PhD in Computer Science, Mathematics, or Physics or related field\nAbility to produce quantitative analysis benchmarking the performance of machine and deep learning algorithms/approaches against state-of-the-practice methods.\nHands-on experience applying machine/deep learning libraries such as SciPy, Scikit-Learn, TensorFlow, Torch, Keras, Spark, etc.\nExperience with neural network design and implementation including, but not limited to, generative adversarial networks and deep neural networks\nExcellent written, oral, and interpersonal communications skills\nObtain and maintain a Top Secret level security clearance\n\nStart your job application: click Apply Now"}, "649": {"company": "Improbable", "description": "Improbable believes in a future where new, virtual worlds will augment human experience and become as meaningful, lasting and rich as the physical world.\n\nOur platform, SpatialOS, lets developers transcend the limits of regular computation, allowing swarms of servers running in the cloud to cooperate in order to simulate worlds far larger and more complex than any single server could. The team in Arlington, VA is focused on applying our technology to solve real world problems within Government and Industry.\n\nAt Improbable, you are surrounded by people who want to improve everything and everyone around them, and who compel you to improve yourself. We\u2019re motivated by the fulfilment of solving hard problems to achieve something profound and transformative.\n\nYour Mission\n\nis to build innovative, product-oriented solutions leveraging and contributing to our R&D effort around probabilistic techniques. We are growing our applied science capability to enable our federal customers to better understand their most challenging problems. Our applied scientists are delivery focused, working in diverse technical teams to design, build, deploy and evaluate models and simulations. You will work with customers to deliver new solutions to some of the most important challenges we face today.\n\nWe\u2019ve already built a team of 15 highly experienced engineers, and scientists; now we\u2019re moving onto the next chapter of our growth. We offer competitive salaries, full benefits, training, progression, equity and a chance to be a \"founder\" of a strategically important new office.\n\nOverview of our products here\n\nYou can read about the engineering culture of the division here.\nResponsibilities\nPrototype models, iteratively designing robust models that meet the needs of the client\u2019s use case.\nCritically assess the type and quality of customer data and work with them to appreciate their toughest problems, define modelling assumptions and capture uncertainty.\nWork closely with our customers to develop a strategy to extract the maximum possible value from the available data\nCollaborate with engineers to build models in production environments.\nBe involved throughout customer interaction from project scoping to final delivery\nWork independently or with our research team to develop a modelling strategy to sit at the core of a data-led simulation-based approach to problem solving\nTake ownership of ensuring and demonstrating the reliability of the models that we create\n\nAdditionally you will drive thought leadership within the company and help our clients to understand their data needs and design their data strategies. This involves keeping up-to-date with a diverse body of cutting-edge research, designing and prototyping pioneering new technical approaches and rapidly developing expertise in new subject areas to support new bids and projects.\nCompetencies\nStrong background and experience in delivery of technical, data-rich projects ideally for external clients.\nDegree in a scientific or mathematical field, ideally with a computational element\nPragmatic coding ability - with fluency in at least one relevant programming language and the openness to learn and adapt to a variety of languages. We use Python, Pandas, R and many related tools and libraries.\nEnthusiastic about continuously improving and rapidly developing new competencies.\n\nThe following would be advantageous, but isn't essential\nBayesian methods\nEffectively communicating and visualising analysis of rich data sets\nProbabilistic programming. You can see our early open-sourced work here.\nWorking with real, complex data\nEffectively communicating with clients in person, in writing and with visualisation\nOur office is currently located in Arlington, VA with travel to client sites across N. Virginia\n\nEqual Opportunity\nThe best ideas are often the least expected and require new ways of thinking; that\u2019s why our teams at Improbable are made up of an incredible range of talented people. Improbable is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, childbirth, related medical conditions and lactation), sexual orientation, gender identity, gender expression, national origin, marital status, age, protected veteran or disabled status, genetic information, or any other legally protected status.\nApply Now: click Apply Now"}, "650": {"company": "National Debt Relief", "description": "Who We\u2019re Looking For:\n\nNational Debt Relief (NDR) is currently seeking an inquisitive, highly motivated, and creative Data Scientist who is passionate about helping customers get out of debt. The ideal candidate will have hands on experience transforming unique data into amazing products. At scale.\n\nAt NDR you will have access to an enormous amount of high-value business activity data including unstructured and semi-structured records around the sales process as well as post sales customer activity. You will participate in the end-to-end processes of machine learning, from proof of concept to deploying models in production. You will be asked to experiment, and conduct research work geared towards new product development.\n\nMeet some of our team members!\n\nPrincipal Duties and Responsibilities:\nWork with large, complex datasets and solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct end-to-end analysis that includes data gathering and requirements specification, data processing, analysis, and deployment to production.\nResearch and develop models to improve the quality of NDR user facing products; example application areas include lead scoring and end-user behavioral modeling.\nMake business recommendations with effective presentations of findings at multiple levels of the business through visual displays of quantitative information.\nDevelop processes and tools to monitor and analyze model performance and accuracy\nInteract cross-functionally with a wide variety of leaders and teams and work closely with Engineers and Product Managers to identify opportunities for improvement.\nBe fiercely competitive and maintain a sense of urgency, creativity, and curiosity for how to continue to improve internal and customer facing processes.\nQualifications:\nBA/BS in a quantitative discipline (Computer Science, Statistics, Bioinformatics, Math, Physics, Engineering) or an equivalent practical skillset.\nIndustry experience writing code (e.g., Python, Pytorch, SQL) and taking ML models/ algorithms to production.\n3+ years of expertise using advanced machine learning algorithms and statistics: clustering, decision tree learning, ensemble methods, regression, etc. on large data sets as well as a strong understanding of their real-world advantages/drawbacks. The successful candidate will have regularly used Python and SQL to extract data, design ETL flows and derive insights.\nA love for data - this is what we do. We are looking for people who are excited about different and unique data sets, and all the ways that they could be used to improve our business.\nDemonstrated skill in selecting the right statistical tools given a data analysis problem.\nExcellent written and verbal communication skills for coordinating across teams\nStartup experience while not essential is preferred.\nWhat We Offer:\n\nWe believe in a team-first culture, full of rewards and recognition for our employees. We are dedicated to our employees\u2019 success and growth within the company, through our employee mentorship and leadership programs.\n\nOur extensive benefits package includes:\nGenerous Medical, Dental, and Vision Benefits\n401(k) with Company Match\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\n10 weeks Paid Parental Leave\nPre-tax Transit Benefits\nDiscounted Gym Membership\nCiti Bike Annual Membership Discounts\nNo-Cost Life Insurance Benefits\nVoluntary Benefits Options\nASPCA Pet Health Insurance Discount\nAbout National Debt Relief:\n\nNational Debt Relief is one of the country\u2019s largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we\u2019re all about helping our customers through a tough financial time in their lives with education and individual customer service.\n\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\n\nNational Debt Relief is a certified Great Place to Work\u00ae!\n\nNational Debt Relief is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other status protected by law.\nStart your job application: click Apply Now"}, "651": {"company": "Coinbase", "description": "Location: San Francisco, CA\n\n\nCoinbase has built the world's leading compliant cryptocurrency platform serving over 30 million accounts in more than 100 countries. With multiple successful products, and our vocal advocacy for blockchain technology, we have played a major part in mainstream awareness and adoption of cryptocurrency. We are proud to offer an entire suite of products that are helping build the cryptoeconomy, and increase economic freedom around the world.\n\nThere are a few things we look for across all hires we make at Coinbase, regardless of role or team. First, we assess whether a candidate demonstrates our values: Clear Communication, Positive Energy, Efficient Execution, and Continuous Learning. Second, we look for signals that a candidate will thrive in a culture like ours, where we default to trust, embrace feedback, disrupt ourselves, and expect sustained high performance because we play as a championship team. Finally, we seek people with the desire and capacity to build and share expertise in the frontier technologies of crypto and blockchain, in whatever way is most relevant to their role.\n\nAt Coinbase, our vision is to build an open financial system for the world, and to get there we'll need to continually learn from our data. Data scientists are focused on this critical step of converting data into learnings.\n\nYou'll spend part of your time working directly with product teams \u2014 engineers, designers, and product managers \u2014 to ensure we're focused on the biggest opportunities and interpreting our data correctly. And you'll spend the other part of your time with the Data team building analytics models and systems that help scale our insights more broadly, both throughout the company and directly in the product.\n\nWhat you'll be doing:\nMeasure business performance, develop core metrics and create dashboards to track and understand them.\nWork with product and engineering teams to design experiments for new product ideas, and analyze the results to provide actionable recommendations.\nPerform deep analyses and build models to understand customer behavior, and extract key insights that impact product decisions.\nSynthesize data learnings into compelling stories and communicate them throughout Coinbase.\nAct as a strategic partner to product and engineering leaders to help prioritize opportunities and inform product strategy.\nPrototype new analytics & machine learning models that improve both our insights and the product directly.\nWork across multiple subject matter experts to drive new data initiatives, automation of reports, establish best practices and mentor junior members in the team.\nLead analytics projects to completion.\nWork with the broader Data team to find ways to scale our insights through better systems and automation.\nWhat we look for in you:\nDemonstrate our core cultural values: clear communication, positive energy, continuous learning, and efficient execution.\nUnderstanding of statistical concepts and experience in applying them.\nExperience in data analyses using SQL.\nExperience in at least one programming language (e.g. R, Python, Java, Ruby, Scala/Spark, or Perl).\nBe able to independently create plans for analytics projects and build collaboration within the team.\n(For Senior Data Scientist)BA / BS degree or equivalent practical experience. 5+ years relevant experience, or MS degree, 3+ year or PhD degree in related fields + 2 years.\nNice to haves:\nBe able to proactively manage prioritization of work and deliver work with great quality and influence the broader team in creating leverage.\nPrevious experience working with financial services data is a plus.\nExperience with Looker, Tableau or other business intelligence platform.\nDomain experience in product, marketing or growth analytics.\nExperience manipulating large amounts of structured and unstructured data.\nCoinbase is committed to diversity in its workforce and is proud to be an equal opportunity employer and to review all of our job postings to minimize biased language. Coinbase does not make hiring or employment decisions on the basis of race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other basis protected by applicable local, state or federal law. Coinbase will also consider for employment qualified applicants with arrest and conviction records in a manner consistent with San Francisco's Fair Chance Ordinance and similar local laws.\nTo apply to this job, click Easy Apply"}, "652": {"company": "C3.ai", "description": "C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai\n\nC3.ai is looking for a Data Scientist (Federal) to solve challenging, novel, and large-scale enterprise problems for Federal clients. In this capacity you will represent C3.ai as a technical expert and help our team to frame problems, choose appropriate machine learning algorithms, and identify opportunities to leverage the C3.ai Suite.\n\nRecent examples of successful engagements include predictive maintenance on oil and gas equipment and aircraft subsystems, supply chain optimization, manufacturing yield optimization, chronic disease prevention, customer spend prediction, and equipment lifetime optimization.\n\nQualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve results at large-scale.\n\nThis role requires US Citizenship or US Permanent Residence.\n\nYour Responsibilities:\nBecome an expert in the C3.ai Suite and associated tools to teach, enable, and assist C3.ai customers to build their own applications.\nDesign and deploy machine learning pipelines for C3.ai's federal customers.\nCollaborate with data and subject matter experts from C3.ai and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.\nRequirements:\nUS Citizenship or US Permanent Resident\nBachelor's degree\nStrong understanding of machine learning algorithms & principles (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning), and their application\nStrong background in mathematics, statistics, and computer science\nExcellent programming skills in Python\nAbility to drive a project and work both independently and in a team\nSmart, motivated, can do attitude, and seeks to make a difference\nExcellent verbal and written communication\nPreferred\nMS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred.\nActive Department of Defense (DoD) security clearance (Secret or higher)\nExcellent programming skills in JavaScript. Experience with Java and Scala is a plus.\nExperience with deep learning, natural language processing, computer vision, or reinforcement learning\nA portfolio of projects (GitHub, papers, etc.)\nC3.ai provides a competitive compensation package and excellent benefits.\n\nC3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.\nTo apply to this job, click Apply Now"}, "653": {"company": "LiveRamp", "description": "ABOUT LIVERAMP\n\n\nLiveRamp (NYSE: RAMP) is the leader in data connectivity, helping the world's largest brands use their data to improve customer interactions on any channel and device. We thrive on mind-bending technical challenges and value entrepreneurship, humility, and constant personal growth.\n\nABOUT THIS JOB\n\n\nDo you love working with smart people who inspire you to be better and work harder every day? Do you want to join a high growth business and work with some of the world's biggest data sets? Do you want the freedom and responsibility necessary to continuously improve our measurement solutions? Then come join us!\n\nThis role will be based in Boston, MA as part of our rapidly growing Data Science consultancy team and may require some travel.\n\nROLE OVERVIEW\n\n\nBeing a part of the Data Science Consulting Team, you will work to deliver our data science solutions to a wide range of external clients including some of the largest platforms, retailers, and brands across the globe. Focusing on the measurement of advertising effectiveness, you will lead pre-sales meetings to learn first-hand our clients' requirements as well as build and deliver appropriate solutions to effectively improve advertising strategies. You will build long-term relationships with LiveRamp's partners while closely collaborating with Product Management and Strategic Partnership Teams.\n\nYou'll be encouraged to think outside the box and use the most appropriate tools for the job utilizing the latest offerings from Google Cloud Platform.\n\nRESPONSIBILITIES\nIdentify and implement bespoke data science solutions for our partners\nDeliver our offline sales measurement product for US clients\nBe a subject matter expert for clients on measurement methodologies and statistics\nBuild and evolve long-term relationships with counterpart teams of clients\nMake suggestions to improve current workflows and products\nSupport our commercial teams as an SME for LiveRamp's Data Science & Measurement offerings\nYOU WILL HAVE\n3-5 years of experience as a data scientist, measurement expert or statistician\nThorough understanding of statistics\nPrevious commercial or research experience in campaign measurement or A/B testing\nExperience leading client relationships\nUnderstanding of experimental design\nHands-on experience in Python and SQL\nThe ability to communicate complex analytical information clearly to non-analytical audiences\nBachelor's Degree in a numerate discipline (e.g. Maths, Science, Computing)\nInterest in digital marketing\nBONUS POINTS FOR\nExperience of advertising effectiveness measurement\nKnowledge of a wide range of Machine Learning algorithms\nPrevious consulting experience\nExperience with Cloud Compute technologies\nUnderstanding of software development best practices\nKnowledge of digital marketing\nPre-sales experience\nEMPLOYEE BENEFITS\nStock. Every employee is a stakeholder in our future.\nFood. Enjoy catered meals, boundless snacks, and the occasional food truck.\nFun. We host events such as game nights, happy hours, camping trips, and sports leagues.\nPeople. Work with talented, collaborative, and friendly people who love what they do.\nHealth and Saving. Receive the benefits of comprehensive health, dental, vision and disability insurance along with a 401k matching plan.\nLocation. Work in Boston, MA and take advantage of our commuter benefits.\nLiveRamp is an affirmative action and equal opportunity employer (AA/EOE/W/M/Vet/Disabled) and does not discriminate in recruiting, hiring, training, promotion or other employment of associates or the awarding of subcontracts because of a person's race, color, sex, age, religion, national origin, protected veteran, disability, sexual orientation, gender identity, genetics or other protected status. Qualified applicants with arrest and conviction records will be considered for the position in accordance with the San Francisco Fair Chance Ordinance.\nStart your job application: click Easy Apply"}, "654": {"company": "Union Bankshares", "description": "Requisition Number 19-0552\nPost Date 11/26/2019\nTitle Senior Data Modeler & Analyst\nLocation Innsbrook VA\nCity Glen Allen\nState VA\nDescription Position Description:\n\nThe Senior Data Modeler/Data Analyst is a critical role in translating business needs into the information required to deliver solutions. The role will be a key leader across multiple projects working with Data Architects in understanding architectural directions,\ngathering and analyzing business requirements, and developing the appropriate data structures. In addition, the role will have significant influence in Data Governance and Enterprise shared data initiatives. This position will play a key role in the transition\nfrom traditional reporting to a more dynamic, real-time analytics environment ensuring a foundation to deliver information to internal consumers at all levels in the organization.\n\nPosition Accountabilities:\n\n\u2022 Consult, facilitate understanding and translate data requirements into logical, physical and semantic layer models across the analytical data environment.\n\u2022 Ensure data structures are designed for flexibility to support future business needs.\n\u2022 Profile and analyze source system data to determine data relationships, design constructs, consistency and quality.\n\u2022 Enable and lead analytics user community in the understanding, location and selection of appropriate data sources to achieve key business goals\n\u2022 Ensure that data designs follow architectural best practices and appropriate business rules\n\u2022 Facilitate data integration, conformity, data quality, integrity and consolidation\n\u2022 Be an advocate for best practices while balancing business value and reasonable practicality\n\u2022 Create and Maintain critical data documentation and metadata that allows data to be understood and leveraged as a shared asset.\n\u2022 Set the strategy and repeatable process for maintaining the Enterprise Data model using automated tools.\n\u2022 Analyze and evaluate data definition and modeling environment providing key recommendations for improvement. Assist in defining data modeling standards, and foundational best practices.\n\u2022 Identify gaps and opportunities with regard to data governance and data ownership, and provide recommendations for improvements incorporating best practices.\n\u2022 Facilitate understanding of high quality data management discipline throughout the corporation\n\u2022 Work with the Data Governance lead to enhance/establish data stewardship and data quality management programs.\n\u2022 Develop and maintain relationships across IT and across the business with special focus on roles that are heavy consumers of data for analytical purposes; anticipate customer needs and proactively develop solutions\n\nOrganizational Relationship:\n\nThis position reports to the Director of Data Warehousing & Analytics.\nRequirements Position Qualifications\n\nEducation & Experience:\n\n\u2022 A Bachelor\u2019s Degree in a technology area of study; preferably in Computer Science, MIS or Analytics\n\u2022 7+ years equivalent work experience in Information Technology\n\u2022 5+ years in a structured IT organization with a strong PMO, a variety of methodologies, and strong technical environment management disciplines\n\u2022 5+ years of experience in Data Analysis, Data Architecture and/or Data Warehousing; preferably in a shared or enterprise data environment\n\u2022 5+ years direct experience in Data Modeling and Data Solution Development\n\u2022 2+ years of experience in banking and/or financial services\n\u2022 Deep experience in logical, physical and semantic data modeling\n\u2022 SQL Query development skills for analyzing and profiling data\n\u2022 Experience with multiple SDLC methodologies \u2013 Waterfall and Agile\n\nKnowledge & Skills:\n\n\u2022 Excellent communication, leadership and collaboration skills\n\u2022 Competency with some leading data profiling tools (such as SQL, BI tools, etc)\n\u2022 Experience with Enterprise Data Warehouse initiatives including Data Model development, Semantic/Data Access Layer Development, Reporting and Dashboard Creation; developing solutions for shared data usage\n\u2022 Experience with a Data Modeling tool (such as Erwin) and in developing processes to manage data model development, principles, and standards\n\u2022 Experience with a commercially available industry focused data model preferred\n\u2022 Exposure to and understanding of Analytical Architectures\n\u2022 Consulting and Facilitation Skills\n\u2022 Advanced decision making and problem solving skills\n\u2022 Business acumen, knowledge and professionalism\n\u2022 Strong analytical, problem solving, and work management skills\n\u2022 Customer-focused ability to communicate across all levels of the organization\n\u2022 Proactive Leadership style; self-starter and strong attention to detail\n\u2022 Proficient in MS Office (Word, Excel, Access, PowerPoint, MS Project, Visio, SharePoint)\n\nWe are proud to be an EEO/AA employer, Minority/Female/Disability/Veteran.\n\nWe maintain a drug-free workplace.\n\nApply Now: click Apply Now"}, "655": {"company": "Opcity", "description": "The home search starts online, but the real estate industry is often optimized for in-person, one-on-one service. That's a fantastic experience once you connect with the right professional, but finding the right fit isn't always a smooth process. Opcity built a nationwide real-time data and technology platform combining cutting edge deep learning, business analytics and human intuition with the latest web, mobile and digital telephony technologies to enable our team of professionals, and thousands of real estate agents and brokers, to make sure we connect every home buy with the right agent at the right time so more time is spent finding a home and less time finding the perfect agent.\n\nWhat Are We Looking For:\nDuties & Responsibilities:\n\u00b7 Support all areas of the business with analysis and reporting\n\u00b7 Drive insights through rigorous analytics on business performance and cohesive, well laid out presentation of the data and recommendations\n\u00b7 Create dashboards with KPIs for a variety of stakeholders\n\u00b7 Drive organizational change through a period of high growth, building the systems and infrastructure to support that growth.\nRequirements:\n\u00b7 Three to five as an analyst, preferably in a fast-paced environment\n\u00b7 Excellent proficiency in Excel and SQL\n\u00b7 Experience using tableau or similar data visualization tool\n\u00b7 Highly analytical with proven, great communication skills\n\u00b7 We are looking for an experienced analyst who can define and own analyses, driving to answers that consider the full context of the business and communicate their analysis and findings to all levels of the organization.\n\nWhat We Offer:\n\u00b7 Working with a highly-motivated team with a proven track record of success that also has a lot of FUN!\n\u00b7 Casual work environment, rewards and recognition and fun events\n\u00b7 Competitive pay\n\u00b7 Medical, Vision, Dental, Disability and Life Insurance plus Flexible and Dependent Care Spending Accounts\n\u00b7 Investment in growing your career and providing you opportunity to have an immediate and massive impact in a growing company with a revolutionary business model\n\n\n\n*No relocation is provided for this vacancy, local candidates preferred. Must be eligible to work in the U.S. for any employer.\nDiversity is important to us, therefore, Opcity/Realtor.com is an Equal Opportunity Employer regardless of age, color, national origin, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, marital status, status as a disabled veteran and/or veteran of the Vietnam Era or any other characteristic protected by federal, state or local law. In addition, Opcity / Realtor.com will provide reasonable accommodations for otherwise qualified disabled individuals.\nStart your job application: click Apply Now"}, "656": {"company": "SurveyMonkey", "description": "About SurveyMonkey\n\nSurveyMonkey (NASDAQ: SVMK) is a leading global survey software company on a mission to power the curious. The company's People Powered Data platform empowers over 17 million active users to measure and understand feedback from employees, customers, website and app users, and the market. SurveyMonkey's products, enterprise solutions and integrations enable 350,000+ organizations to solve daily challenges, from delivering better customer experiences to increasing employee retention. With SurveyMonkey, organizations around the world can transform feedback into business intelligence that drives growth and innovation.\n\nSurveyMonkey is a place where the curious come to grow. By embedding inclusion into our processes, policies, and culture, we are building a workplace for our 1,000+ employees across North America, Europe, and APAC where people of every background can thrive. We've won multiple awards and received recognition for our forward-looking policies, including extended parental and bereavement leave, vendor benefits standards, and Take 4 sabbaticals. SurveyMonkey was recognized by Great Place to Work\u00ae and FORTUNE as a top workplace in 2018 and 2019, and the company has also won numerous awards as a leader in global survey software, including being named among CNBC's Disruptor 50 and the Forbes Cloud 100.\n\nOver the past two years we've become a public company and expanded our platform with enterprise-grade features in privacy, security and compliance, putting SurveyMonkey on the path to rapidly expand our presence within the Fortune 500. We have ambitious goals to grow our international footprint as well, and every member of our troop plays a critical role in driving this growth and transformation. It's an incredible time to join the company and be a part of our next chapter!\n\nThe Role\n\n\nWe are looking for a seasoned machine learning and data mining expert to join our data science team to lead the execution of groundbreaking R&D projects.\n\nAs a senior member of the Data Science team, the successful candidate will play a leading role in deriving key insights from large amounts of our people-powered data, suggest and implement new product features, and make improvements in existing models for better user experience. He/She will work on developing machine learning algorithms and systems, and need to be capable of implementing and utilizing intelligent tools and technologies. He/She will help internal constituents to achieve extraordinary value for our customers. This role also involves technical leadership and mentorship of data scientists and machine learning engineers. Furthermore, you'll be instrumental in developing & growing a team of data scientists, and have the opportunity to set technical directions and establish team culture.\n\nRequirements\nExpertise in machine learning model development, including data preprocessing, feature engineering, classification and prediction model development, and model deployment.\nStrong programming skills, expert knowledge of algorithms, and data structures (Python preferred).\nPrior experience and continued interest in mentorship and technical development of junior data scientists.\nExcellent problem-solving, critical thinking, creativity, organizational, design, and interpersonal skills.\nAbility to work well with all levels of engineers.\nConfirmed ability to handle multiple projects with strict deadlines.\nPrior experience in partnering with product and engineering teams to solve problems and identify trends and opportunities.\nExcellent customer experience intuition; demonstrate success in inventing innovative and user-friendly products.\nPreferred Qualifications\nMaster's or PhD in Computer Science or a data-driven physical science, or equivalent, plus 4 or more years of relevant industry experience.\nIndustrial data-mining / analytics experience including applied techniques in data mining, machine learning, natural language processing (NLP) or graph mining preferred.\nExpert knowledge of Airflow, Pytorch/Tensorflow, Scikit-learn and Pandas is a plus.\nApply Now: click Apply Now"}, "657": {"company": "PlanGrid", "description": "ACS is looking for a Machine Learning Scientist to join our Central Machine Learning team.\n\nAs a Machine Learning Scientist, you will be responsible for delivering AI models for groundbreaking automation features for the construction industry. Your work will enable Autodesk customer to deliver safer projects, on budget & on time. As a part of Construction IQ team, our ML offering for the construction industry, you will be joining a team with a track record of delivering industry-first AI solutions.\n\nWe are looking for someone comfortable working with both cutting edge deep learning techniques and leading customer sessions. ML Scientists on our teamwork shoulder to shoulder with product managers, UX designers, engineers, and legal to identify new opportunities and deliver production quality ML features. As the central machine learning team @ ACS, we are responsible for scaling machine learning to multiple product teams and work on a wide variety of ML problems. i.e., the work is never dull.\nResponsibilities\nTrain/develop production-ready Machine Learning Models to power smart features in Autodesk products\nWork with Autodesk customers and leadership to identify high impact areas for automation and application of machine learning\nOwn the end to end process for machine learning deliverables. From defining the project scope to model deployment\nContribute to engineering best practices for the machine learning team\nWork with data annotators to build datasets for model training\nKeep current with the latest trends and technologies to anticipate future development needs and requirements\nCollaborate closely with various product groups throughout the company and across multiple geographic locations to deliver outstanding solutions\nWork with cross-functional teams like Engineering, Project Management & User Experience\nTeam player, and responsible for owning and delivering your part\nAbout You\nBS/MS/Ph.D. in Computer Science, Statistics, Engineering, or related field\n2+ years of experience with machine learning, with a strong engineering background\nExperience with Deep Learning techniques\nExperience with one or more open-source Deep Learning frameworks (e.g. Pytorch, Keras, Tensorflow, etc.)\nProficiency in Python, SQL\nFamiliar with engineering best practices\nExperience with Computer Vision\nExperience with deploying and managing machine learning models in a production environment\nExperience with building Big Data infrastructure and AWS/Terraform\n\n\nPlanGrid, an Autodesk company, builds simple, beautiful software that construction teams love to use. As part of Autodesk Construction Solutions (ACS), whose mission is to seamlessly connect the office, trailer and the field across the entire construction project lifecycle, PlanGrid\u2019s mobile-first solutions empower general contractors, subcontractors, owners and architects to provide fast, accurate information to the field. With unparalleled adoption by field workers, PlanGrid is used on projects as the single source of truth for all construction data \u2014 including drawings, photos, and other critical documents. As a result, critical workflows are streamlined, efficiency is improved and field teams can take on more work and get more done. PlanGrid\u2019s software and other Autodesk Construction Solutions products enable a complete data set to move seamlessly through each phase of a building\u2019s lifecycle \u2014 from design and preconstruction to construction, turnover, and operations. PlanGrid is used on more 1.5 million construction projects in 100+ countries.\n\nJoin us as PlanGrid and ACS advance Autodesk\u2019s leadership in construction.\n\nAs part of GDPR compliance procedures, we have posted our Recruiting Privacy Notice on our website. Please also note that the advertised position is an opportunity with Autodesk, Inc. (https://www.autodesk.com/), as Autodesk recently acquired PlanGrid. Processing of your personal information as part of the job application process, and as part of Autodesk employment should a candidate be hired, will be handled by Autodesk pursuant to Autodesk\u2019s Candidate Privacy Statement, available at: https://damassets.autodesk.net/content/dam/autodesk/www/content/careers/autodesk_candidate_privacy_statement.pdf.\n\nStart your job application: click Apply Now"}, "658": {"company": "Knowesis Inc.", "description": "Job Description:\n\nKnowesis is looking for personnel to support the United States Special Operations Command Preservation of the Force and Family (USSOCOM POTFF) program in identifying and implementing innovative, valuable solutions across the Special Operations Forces (SOF) enterprise aimed at improving the short and long-term well-being of SOF warriors and their families.\n\nDuties and responsibilities may include, but are not limited to: \u2022 Enter, clean, and conduct basic data manipulation and analysis.\u2022 Build and disseminate databases and spreadsheets designed to record POTFF related programmatic data.\u2022 Provide consultation and assistance to supported units and POTFF staff to identify opportunities and methods for capturing data relating to POTFF programs and initiatives.\u2022 Prepare reports and presentations that accurately convey data trends and associated analysis.\u2022 Enter and analyze data within government systems.\nRequired Experience:\nProficient with the suite of Microsoft Office programs, including Word, Excel, and Access.\nPrior experience using statistical software application such R, Tableau, or other data visualization software.\nPossess excellent communication skills, presentation skills,and shall be highly detail oriented.\nA certification, documented experience and heavy interest in Human Performance or Sports Science is preferred.\nA qualified candidate will:\nWork in consultation with POTFF program staff and the Government\u2019s POTFF biostatistician.\nServe as the analytical lead in support of program manager.\nBe able to use statistics and data visualization techniques to provide an accessible way to see and understand trends, outliers, and patterns in data.\nBe able to read, write, and speak English fluently and clearly in order to effectively communicate with all personnel for which they will interact.\nPossess sufficient initiative, interpersonal relationship skills and social sensitivity such that they can relate constructively to a variety of contacts from diverse background.\nA certification or documented experience with Human Performance is preferred.\nEducation: Bachelor\u2019s Degree in quantitative science, social science or related discipline (Bachelor\u2019s Degree in Sports Science with minor in a quantitative science may be acceptable).\n\nClearance Type: Secret or ability to obtain Secret Clearance\n\nPosition Location: Client site on Joint Base Lewis McCord.\n\nBenefits\n\nAbout Knowesis\nFounded in 2007, Knowesis Inc. has been providing data driven decisions and solutions to federal healthcare clients from day one. Our core capabilities include analytics and information management, planning and operations, and communication and engagement strategies. Knowesis\u2019 highly qualified, customer-focused professionals are committed to providing information and advice to enable client success through holistic, thorough, thoughtful, and aligned approaches. Our clients leverage these capabilities to support data driven decisions for their key business functions. Knowesis is dedicated to earning the loyalty of clients and staff through work ethic, collaboration, and humility. Our intent is to be a positive impact to our clients, team, and community.\n\nKnowesis is Service Disabled Veteran Owned (SDVO) (CVE certified) and Small Disadvantaged Business (SBA certified 8a) with offices in San Antonio, Texas and Fairfax, Virginia. We offer a highly competitive compensation and benefits package inclusive of medical, dental, and paid time off.\nFor more information about working with Knowesis, please visit our website at http://www.knowesis-inc.com.\n\nKnowesis is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. Knowesis will consider all qualified applicants for employment without regard to race, color, religious creed, national origin, ancestry, age, sex, sexual orientation, genetic information, physical or mental disability, veteran or marital status, or any other class protected by law. To comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability, Knowesis will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the Company would result.\n\nKeyword: Data Scientist\nFrom: Knowesis Inc.\n</br>Apply now\nTo apply to this job, click Easy Apply"}, "659": {"company": "Stanley Black & Decker", "description": "Title\nLead Data Scientist\n\n24-Sep-2019\n\nBusiness\nUS - Corporate\n\nState/Country/Province\nConnecticut\n\nNo. of Positions\n1\n\nJob Description\nLead Data Scientist\n\nStanley Black and Decker (SBD) is committed to deep and ongoing investment in Data & Analytics capability. SBD believes that advanced analytics using massive data, while already important to our business, will increasingly become fundamental \u2013 even transformational \u2013 to the value we deliver to our customers and shareholders.\nSBD is seeking a Lead Data Scientist who will be responsible for collecting data and developing insights related to innovative new business initiatives at Stanley Black & Decker focused on the digital enablement of work sites and the Internet of Things.\n\nEssential Job Functions\nLeverage big data and data science to discover patterns and solve strategic & tactical business problems using massive structured and unstructured data sets across multiple environments\nDevelop analytic capabilities (e.g. models and processes) that drive better outcomes for both customers and the company\nDrive the collection, cleansing, processing and analysis of new and existing data sources.\nBuild, test, and deploy predictive models and/or machine learning algorithms on large static and/or streaming data sets\nReport findings by creating useful and appropriate data outputs and visualizations tailored for the intended audiences\nLearn & stay current on analytics developments in one or more business domains: Internet of Things, Manufacturing, Supply Chain, Forecasting, Marketing and Sales, Pricing, etc.\nLearn & stay current on developments in one or more analytics domains: Optimization, Machine Learning, Deep Learning / AI, Simulation, etc.\nGenerate innovative ideas, establish new research directions, shape and execute the information strategy in support of technical projects and new product developments\nWork with and support other team members, management, and partners\nEssential Skills & Experience\nAdvanced degree (MS/PhD) in a relevant technical field (e.g., Computer Science, Mathematics, Applied Mathematics, Statistics, Operations Research, Industrial Engineering, Econometrics) with 5+ years\u2019 experience in related data science, analytics, and model building roles\nExperience working with large complex data sets, real time/near real time analytics, and distributed big data platforms (Hadoop & MapReduce and/or Cassandra/Spark)\nStrong practical knowledge of analytical techniques and methodologies such as machine learning/supervised and unsupervised techniques, segmentation, mix and time series modeling, response modeling, lift modeling, experimental design, neural networks, data mining and optimization techniques\nStrong knowledge of analysis tools such as Python, R, MATLAB, Spark or SAS. R/Spark on Hadoop or Cassandra preferred.\nStrong background in applying statistical machine learning techniques to predictive modeling and experience with Machine Learning libraries (via R, H2O, Python, Spark, etc.)\nProficiency in programming in Python, R, SQL, JavaScript, Java/Scala/Ruby and shell scripting\nProficiency in consuming REST based API (with JSON payload) is a plus.\nFluency in big data platforms including Hadoop, MapReduce, Hive, Spark, PIG\nFamiliarity with Cloud based HaaS/PaaS solutions such as AWS EMR, MS Azure.\nA strong understanding of data profiling and data cleansing techniques\nNatural curiosity and a strong passion for empirical research and problem solving\nStrong written and verbal communications skills; comfortable communicating with senior levels of both business and technology leadership\nCompetencies\nDepth in relevant field(s) for data science, including:\nStatistical Analysis & Modeling\nMachine Learning Algorithms & Techniques\nDeep Learning / Neural Networks\nOptimization Techniques\nUnderstanding Business Problems\nData Wrangling & Exploration\nProblem Solving Mindset\nClear Communication\nTechnical Fluency\n#Elu#LI-JF1\n\nAll qualified applicants to Stanley Black & Decker are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran\u2019s status or any other protected characteristic.\n\nRequisition Number\n65459BR\n\nFunction\nInformation Management\n\nCity\nNew Britain\n\nEEO Statement\nAll qualified applicants to Stanley Black & Decker are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran\u2019s status or any other protected characteristic.\n\nFeatured Category on SBD Careers\nData & Emerging Technology (IT, Data Science, Data Analysis)\nApply Now: click Apply Now"}, "660": {"company": "C Space", "description": "Are you passionate about applying your expertise in data science to unlock insights and solve commercial business challenges? If you're excited about making a big impact in a high-growth area of a client-centric agency that serves some of the world's biggest brands as partners in leveraging the power of customers, this role could be for you.\n\nC Space is hiring a Director of Data Science to work closely with our internal teams and clients to help companies integrate the customer into their business. We are looking for someone who can lead thinking in an area which is becoming increasingly important to our business. You'll be driven to deliver impact, with an ability to motivate and inspire team members to do the same.\n\nC Space is a customer agency. Our mission is to make business more human. We create rapid insight and business change by solving problems from the customer's perspective for 200+ of the world's best-known brands. Our promise to our clients is 'Customer Inspired Growth' and to be effective at this we need to combine art AND science, human stories AND robust data to build confidence and unlock insights. That's why your impact in this role will be so critical to our success.\n\nWhat You'll Do\n\nIn this position, you'll play a lead role pioneering data-analytics work with some of the world's largest brands. Our clients are looking for solutions to their business problems that allow for a broad range of data as input. You will work closely with various teams of researchers, consultants and clients to scope, lead, and execute various projects that could involve statistical modeling, machine learning \u2013 supervised and unsupervised \u2013 to support AI-driven solutions, as well as ETL projects. This includes:\nAdvocate for the role Data Science can play in helping our clients with their biggest business problems and in amplifying the voice of the customers we work with\nCollaborate with internal and external client stakeholders to determine appropriate proof points, specify, build, and use data structures to support an analysis plan\nWork with clients to determine how to best marry and leverage data to produce confidence in decision-making\nScope problems from a technical perspective with data scientists, business analysts, and statisticians, and eventually create a practical execution plan\nLead the vision, execution, and successful maintenance of C Space's new suite of modern data & analytics reporting tools (R Mark Down, Periscope Data, Tableau, etc.) to support internal and/or client work\nBuild, mentor and train a growing data & analytics team, including showcasing and celebrating the great work coming out of the team\nSupport business development and delivery efforts to help grow the data & analytics business and/or expand existing lines of data & analytics business\nDeliver presentations to clients and high-level stakeholders that communicate logical, compelling and cohesive stories using data\nPromote a culture of continuous education - keeping abreast of emerging analysis techniques and market trends, bringing new ideas from outside the business to the work you're doing with C Space colleagues and clients\nDesired Skills and Experience\nAn integrative education and/or experiences that bring together not only technical disciplines, but also knowledge of human beings through the social sciences and humanities\n6+ years of professional experience in economics, math, computer science, statistics, natural science, physics or other quantitative discipline, coupled with experience working with or as a part of a high functioning engineering or data science team\nA proven ability to lead the merging of technical and non-technical considerations and stakeholders into a satisfying and innovative offering\nExperience leading and managing a team of data scientists, product or business analysts\nExperience working across functions to communicate the value of the data and analytic team's work, and tailor the output of analyses to meet client needs\nAn ability to think through and articulate the required stack to answer a business question, including applicable survey research\nComprehensive knowledge of modern data science and product/web analytics tools and techniques, with excellent coding skills (e.g., in Python or R).\nAbility to utilize SQL or other database packages required for data query\nExperience with: Quantitative methods, structural equation modeling, Complex, Multilevel, and Longitudinal Research Models, Applied Multivariate Statistics, Modern Regression.\nWhile others may see you as an expert, you have a rare ability to make the complicated simple and your outstanding communication skills mean that you're able to explain complex concepts to people who won't be as data-savvy as you\nYou're able to excite and inspire people about the power of data and its ability to generate game-changing insights when handled the right way\nThere's no such thing as a typical C Spacer. What C Spacers thrive on is a growth mindset. We're a growing, always-changing business, often reinventing ourselves to keep pace with the fast-changing world of our clients. So we're looking for people who are excited about change and who challenge the status quo. We need people who share our passion for the role customers can play in solving business problems - people who want to disrupt the way things traditionally have been done.\n\nWe're focused on building a learning culture where it's safe to experiment, take risks and do things differently. That means we need people who aren't afraid to speak up and share an alternative perspective yet are humble and self-aware enough to admit they don't know everything. Collaborators, self-starters, creative problem-solvers.\n\nWe're always challenging ourselves to be better, more human, more impactful. 20 years since launch, we still think of our business as a 'work in progress' where we're focused on getting better every day. If you share that philosophy when you think about your own personal development, we might be a good match.\n\nAbout C Space\n\nOur clients call us their customer agency.\n\nOur mission is to make business more human. We create rapid insight and business change, putting customers at the heart of companies and solving problems from the customer's perspective. We keep our clients relevant by building real, ongoing relationships with customers that in turn help them deliver superior experiences, launch successful products and build loyalty. Our customized approaches are tailored to specific business needs and include online insight communities, immersive storytelling, data and analytics, activation events, innovation projects and business consulting. We do this for many of the world's best-known brands \u2013 like Bose, Walmart, Jaguar Land Rover, Mars, Samsung, IKEA and more \u2013 to create \"Customer Inspired Growth\".\n\nWe are passionate about our people and proud of our culture. We co-created a set of values to ensure that we are delivering fantastic work, continuing to learn and developing and building a high-performance culture which creates opportunities for those who work here:\nI've got this: taking responsibility, doing what we say we will\nOnly accept awesome: delivering high quality work that we are proud of and has impact\nShow the love: celebrating successes and ensuring everyone has a voice\nDo what scares you: challenging ourselves, taking risks and learning more\nTell it like it is: being honest and freeing ourselves from \"office politics\" and \"hidden agendas\"\nOpen up and listen: listening first and fully before we respond or react\nFind what fascinates: being passionate about the world and our clients' worlds\nWe before me: putting the team first\nLeave your mark: everyone has an opportunity drive change in our business and for our clients\nInterested? We look forward to receiving applications from people with diverse backgrounds \u2013 talented, creative people with their own voice, ideas and perspectives.\n\nTo learn more, visit www.cspace.com or follow us on Twitter @CSpaceGlobal and Instagram @c_spaceglobal. C Space is a part of DDB, a division of Omnicom Group Inc.\n\nHeadquartered in Boston, C Space also has offices in New York, San Francisco and London.\n\nC Space is proud to be an affirmative action and equal opportunity employer. All qualified applicants will receive consideration for employment at C Space without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law.\nStart your job application: click Apply Now"}, "661": {"company": "Clearwater Analytics", "description": "About Clearwater Analytics\u00ae\n\nClearwater Analytics\u00ae is a global SaaS solution for automated investment data aggregation, reconciliation, accounting, and reporting. Clearwater helps thousands of organizations make the most of investment portfolio data with cloud-native software and client-centric servicing. Every day, investment professionals worldwide trust Clearwater to deliver timely, validated investment data and in-depth reporting.\n\nClearwater aggregates, reconciles, and reports on more than $3 trillion in assets across thousands of accounts daily for our Fortune 500 clients.\n\nDESCRIPTION\n\nThe Innovation Center at Clearwater Analytics solves significant problems with new technology and techniques. The Innovation Center explores and uses machine learning, RPA, blockchain and any other technology that creates step-change for our clients, markets and employees. Clearwater's system is used by some of the world's largest technology firms, fixed income asset managers, and custodian banks. These firms rely on Clearwater's ability to solve difficult, seemingly impossible problems. Clearwater's Innovation is a key driver of those solutions.\n\nClearwater is looking for talented individuals who thrive on solving problems and developing new skills. We offer a competitive compensation package, exposure to cutting-edge financial market issues & information, business casual workplace, beautiful surroundings and work-life balance.\n\nResponsibilities\nDeveloping a solution to a problem in a way that hasn't been done before that has had dramatic positive results\nChanging the technical direction of a team through persuasion, leadership, and force of will onto a better path\nLeading a community of interest in a technology or domain that is not a standard part of the enterprise, but whose adoption would significantly impact the company for the better\nDemonstrating the ability to decompose problems to their root causes and then follow an engineered approach to finding appropriate solutions\nUnderstand machine learning requirements from product, engineering and data science to create machine learning technical specifications\nBuild platform for machine learning model training, batch evaluation, automated re-training, continuous monitoring and deployment in a micro-service architecture\nInteract with data, compute and serving infrastructure for shipping machine learning models\nBuild visibility into machine learning and system performance and optimize if necessary\nREQUIREMENTS\n5+ years of software development experience\nIndustry engineering experience with machine learning projects\nExperience in data analysis, engineering and statistical modeling\nExperience with AWS\nExperience with machine learning libraries like pyTorch, TensorFlow, Keras, Sagemaker\nFamiliarity in data-oriented programming such as Spark, Python, R, Hadoop, SQL with solid understanding of query performance and tuning\nKnowledge of Clojure and Java\nA demonstrated pattern of continuous improvement of both self and team\nVery strong problem solving skills\nDesired Experience and Skills\nBachelor's degree in Computer Science or related field is a plus\nWhat we offer:\n\n\nHeadquarters in the heart of downtown Boise\nBusiness casual atmosphere in a flexible working environment\nTeam focused culture that promotes innovation and ownership\nAccess to cutting edge investment reporting technology and expertise\nContinual learning, professional development and growth opportunities\nCompetitive salary and benefits package; including health, vision and dental\nAdditional benefits including PTO, 401(k) with 4% employer match\nStart your job application: click Apply Now"}, "662": {"company": "Nurx", "description": "Nurx is looking for a Data Scientist who loves answering complex business and health questions through data. This is a rare opportunity to help build a data-driven culture from the ground up and impact the lives of millions by helping reinvent the healthcare system. We're building a system to support delivery of medical care in a modern and truly empathetic way.\n\nThis is a hybrid role in which you will run deep analyses on structured and unstructured data and also build and maintain ETLs to fetch data into the Nurx warehouse. You will be asked to work with your peers to determine the best algorithm to solve any given problem, and be able to create your own data structures to execute the solution.\n\nOn this team, you'll work closely with Product, Operations, Finance, Marketing and Engineering. You'll be reporting to the Head of Data & Research and will engage with all aspects of Nurx to discover insights on how to drive operational efficiency, help plan for staffing, and most importantly, increase our ability to better our patient's health.\n\nWhat you'll do:\nDeliver the insights necessary to help Nurx scale its Operations and Medical teams.\nIdentify, track, and report regularly on key operational performance metrics.\nBuild intuitive dashboards to empower other team members with actionable data.\nPerform Data Cleansing, Data Mining and Data Modeling to analyze trends, and create forecasts in order to help Nurx understand more about its patients.\nPerform quantitative analysis, and ad-hoc reports to support key operations decisions, including staffing plans, process optimizations, and personnel performance management.\nTake an active role in key strategic decision making and analytics across the company.\nFlex into other areas of the organizations to help drive data driven decision making. Assist the Product, Finance, and Engineering teams derive key insights as needed.\nEngage with stakeholders to understand business problems and translate their questions into insights and easily digestible summaries.\nA bit about you:\nMinimum of 3+ years of experience in data science, business intelligence / consulting / investment banking / healthcare / public health or related experience.\nBachelor's Degree in: Math, Finance, Economics, Statistics, Data Science, Physics or related field.\nProven experience with Data Collection via ETLs and an understanding of data warehouse organization.\nExperience with machine learning tools and techniques such as clustering and classification.\nExperience with statistical modeling, and forecasting.\nProven ability to write, optimize and execute complex SQL queries.\nStrong comfort level with manipulating complex data structures in Python, R, Scala, or other programmatic data analysis languages.\nExpertise in A/B testing is ideal. Bonus points if you've used and understand Splunk, Looker, or Mode.\nAnalytical mindset, with the ability to focus on a problem, ask insightful questions, and gain expertise quickly.\nCompetent understanding of statistical principles (eg. statistical significance).\nAbility to derive meaning from raw data in order to influence product decisions and direction.\nNice to Haves:\nPrior experience with or interest in distributed data store environments.\nPassionate about improving the state of healthcare in the United States and beyond.\nAbout us:\n\nAt Nurx, we're creating a future where healthcare is easily accessible and affordable for everyone and building software that empowers people to be in control of decisions about their own health.\n\nOur platform enables doctors to give patients personalized care at lower costs and prescriptions delivered straight to their door. We are committed to disrupting the healthcare system and increasing access to healthcare for millions across the country, starting with birth control and PrEP.\n\nBenefits:\nTalented and collaborative team who will both support and challenge you.\nMarket competitive salary and equity.\nMedical, dental, commuter, wellness, and engineering technology benefits.\n401(k) retirement plan.\nPaid holiday, vacation, and sick leave.\nTake what you need vacation (and we really mean it!).\nThis position is full-time and based in San Francisco, CA.\nApply Now: click Apply Now"}, "663": {"company": "NetApp", "description": "33643\n\nAre you data-driven? We at NetApp believe in the transformative power of data \u2013 to expand customer touchpoints, to foster greater innovation, and to optimize operations. We are designed for simplicity, optimized to protect, created to embrace future opportunity, and open to enrich choice. We are the data authority for hybrid cloud, and we are helping our customers realize the full potential of their data.\n\nWe\u2019ve built a Data Fabric for a data-driven world \u2013 to simplify and integrate data management across the resources that are best for the business. With the Data Fabric, our customers can harness the power of cloud data services, build cloud infrastructures, and modernize storage through data management.\n\nBy harnessing the power of hybrid cloud data services, customers gain the freedom of choice to securely manage and move data \u2013 anywhere, on any cloud. Only NetApp can help organizations deliver data-rich customer experiences when they rapidly test and deploy new applications that easily use data and services regardless of where they reside or in what form.\nJob Summary\nNetApp\u2019s Cloud Operations and Engineering Services team provide enablers for a world class engineering team using data to support decisions. We are looking to apply Machine Learning and Artificial Intelligence to identify new opportunities for technical issue reduction, productivity gains, leverage assets, and automation. The ideal candidate has a solid data science background who actively listens and collaborates well with engineers, service owners, and leaders to create value out of the data ensuring short- and long-term needs are met. You are savvy with exploring and visualizing data, uncovering relationships and outliers, developing and evaluating statistical models, machine learning algorithms, and data modeling techniques, etc.\nResponsibility\nDesigns, develops, and implements data management systems of analytic frameworks for the business\u2019s data.\nUses analytical rigor and statistical methods to analyze large amounts of data, extracting actionable insights using advanced statistical techniques such as data analysis, data mining, optimization tools, and machine learning techniques and statistics (e.g., predictive models, LTV, propensity models).\nAble to work with large data (structured and unstructured), and be proficient in extracting relevant feature data from relational and non-relational databases\nConstantly innovating by building new features; improving modeling techniques to boost model performance; maintaining and refining the processes and procedures for building high-end analytic modeling solutions.\nInteracting with business teams ensuring effective working relationships, translates business requirements into quick prototypes and building data-fueled solutions that drive the business closer to its overall goals and objectives.\nFormulates new and creative ideas for leveraging the business\u2019s vast collection of data in the databases\nAssures the data is available, meaningful, and visible.. Where needed applies data cleansing.\nWriting coherent reports and presentations on high-end analytical projects.\nConstructs forecasts, recommendations and strategic/tactical plans based on applying data science techniques to business data.\nConsistent exercise of independent judgment and discretion in matters of significance.\nEngages with service owners, engineers, and managers to VP level as part of shaping and implementing initiatives delivering results.\nJob Requirements\nSelf-motived, team player. Dependable with a strong work ethic.\nBelieves in automated testing, and is able to develop modular, layered software that performs well and is easy to understand.\nDemonstrated ability to think strategically about business, product, and technical challenges.\nStrong programming (such as Scala, Spark, Hadoop MapReduce), and statistical modeling skills (like Python or R) and Machine learning (ML) techniques include clustering, classification, regression, decision trees, neural nets, support vector machines, genetic algorithms, anomaly detection, association rules, sequential pattern discovery, and text mining\nProficiency in the use of statistical packages\nExperience in software design and development.\nHas experience and/or interest in refactoring legacy systems to use more modern technology.\nStrong oral and written communication skills.\nAbility to work collaboratively with other engineers and have strong influencing and leadership skills.\nAbility to handle multiple tasks concurrently with competing deadlines.\nAptitude for troubleshooting and resolving issues even in unfamiliar environments.\nAbility to work on complex issues that require a detailed analysis of a variety of factors.\nAbility to work collaboratively within a team -- yet the ability to work independently, as well.\nAbility to develop longer-range project plans and schedules to complete complex projects or new product development.\nExperience in an environment that included revision control and project lifecycle tooling (Agile preferred).\nAbility to perform well in very dynamic environment.\nEducation & Experience\nThe successful candidate will possess 3+ years minimum of experience in data science or data engineering on an Enterprise SaaS solution, platform, marketplace, or other software-led product in an agile B2B environment, and 5+ years of experience overall.\nAdvanced degree in Computer Science, Statistics, Applied Mathematics or other analytical or quantitative-based field.\nDeep mastery of a wide range of ML techniques, tools, and methodologies with a demonstrated capability to apply them to a broad range of business problems and data sources.\nExperience with text mining, NLP and Deep Learning packages.\nExperience with implementing and shipping predictive data and analytics products.\nProficiency in SQL, Python/R and experience with MapReduce frameworks.\nExperience with Asset Management, Services Management or Operational software a plus.\nSuperb communication skills for both oral and written communication; ability to communicate confidently across all levels inside and outside of the organization.\n\nSo get ready to tap into the data visionary within, and join us as we accelerate digital transformation and empower our customers to change the world with data!\n\nIf you ask a NetApp employee why they work here, the answer is inevitably the same: the people. At NetApp, our culture is at the heart of what we do. We place importance in trust, integrity, teamwork, and caring above all else. NetApp is a place where people are empowered to make a difference. Empowered to innovate. Empowered to collaborate. Empowered to help ourselves and others be data-driven and change the world. We take care of each other, our customers, our partners, and our communities simply because it\u2019s the right thing to do.\n\nWe work hard but also recognize the importance of work-life balance for our employees because what\u2019s important to them is important to us! Recently we implemented Family First, which encourages employees to take paid time off to bond with a new child (through birth or adoption) or to care for a family member with a serious health condition. Our volunteer time off program is best in class, offering employees 40 hours of paid time off per year to donate their time with their favorite organizations. We provide comprehensive medical, dental, wellness and vision plans for you and your family. We offer educational assistance, legal services, and access to discounts and fitness centers. We also offer financial savings programs to help you plan for your future.\n\nJoin us and see what empowerment can do.\n\nEqual Opportunity Employer Minorities/Women/Vets/Disabled\n\nNearest Major Market: Durham\nNearest Secondary Market: Raleigh\nJob Segment:\nDatabase, Scientific, Medical, Engineer, Product Development, Technology, Engineering, Healthcare, Research\n\nApply now \u00bb\n\nStart your job application: click Apply Now"}, "664": {"company": "Southern California Edison", "description": "Job Description\nENERGY FOR WHATS AHEAD\n\nAre you looking to make a difference in your career? Were working on smarter grids, cleaner energy and tools to help people manage energy more efficiently.\nAbout Transmission and Distribution\n\nSouthern California Edisons (SCE's) Transmission and Distribution Organizational Unit (T & D) is responsible for planning, engineering, constructing, operating, and maintaining transmission and distribution facilities throughout the 50,000-square-mile territory. T&D is the steward of roughly $19 billion in assets that safely and reliably deliver electricity to 14 million residents via SCEs 5 million customer accounts.\nPosition Overview\n\nThe Senior Data Scientist Advisor is responsible for leading the modeling of complex analytical problems, discovering insights, and identifying opportunities using statistical, algorithmic, mining, and visualization techniques. In addition to advanced analytical skills, the senior advisor will be responsible for developing business requirements and coordinating with groups in and outside of the Transmission and Distribution group. You will be responsible for developing, presenting, and communicating results. You will also be responsible for leading and mentoring other Data Scientists.\nTypical Responsibilities:\nLead data scientists on developing models that meet or exceed business requirements.\nGenerate advanced analytical approaches using predictive modeling, optimization and simulation abilities.\nApply statistical and pattern recognition techniques to perform description, prediction, and optimization.\nDevelop and implement tools for data acquisition, extraction, transformation, management, and manipulation of large and complex data sets. Explore, model, mine, and experiment with data to answer critical business issues. And, generate and communicate business insights.\nQualifications\n\nMinimum Qualifications\nBachelors in a quantitative discipline such as Statistics, Mathematics, Engineering, Computer Science, or information sciences such as business analytics or informatics.\nTen or more years of experience in Predictive Modeling or Machine Learning or Statistical Modeling or Data Mining.\nProficient with R and Python.\nDesired Qualifications\nMS or PhD in a quantitative discipline such as Statistics, Mathematics, Engineering, Computer Science, or information sciences such as business analytics or informatics.\nExperience in leading and mentoring junior team members and guiding them on data science and advanced analytics (machine learning, predictive analytics) development.\nIn-depth industry/business knowledge in Electric Utility industry.\nProficiency with SQL and/or SAS.\nStrong Leadership skills and experience.\n\nComments\nCandidates for this position must be legally authorized to work directly as employees for any employer in the United States without visa sponsorship.\nRelocation may apply to this position.\nSouthern California Edison, an Edison International (NYSE:EIX) company, serves a population of approximately 15 million via 5 million customer accounts in a 50,000-square-mile service area within Central, Coastal and Southern California. Join the utility leader that is safely delivering reliable, affordable electricity to our customers for over 125 years.\n\nSCE is a proud Equal Opportunity Employer and will not discriminate based on race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or any other protected status.\n\nL1-EA1\nTo apply to this job, click Apply Now"}, "665": {"company": "Credit Karma", "description": "Credit Karma is a mission-driven company, focused on championing financial progress for our more than 100 million members in the U.S., Canada and U.K. While we're best known for pioneering free credit scores, our members turn to us for tips as they work on their financial goals, including helping them monitor their credit, identity monitoring, searching for credit cards, shopping for loans (car, home and personal), filing their taxes with Credit Karma Tax and growing their savings* -- all for free. Credit Karma has grown significantly through the years: we've added more than 70 million members in the last five years alone and now have more than 1,100 employees across our offices in San Francisco, Charlotte, Los Angeles, Leeds, London and soon Oakland.\n\nCredit Karma\u2019s fast growing Data Sciences team is seeking an expert Senior Data Scientist. This role will allow a motivated individual to make a significant impact across the organization by delivering the most relevant content to our users and by helping drive accelerated revenue growth.\nBanking services provided by MVB Bank, Inc., Member FDIC\nWhat the job entails\nPartner with stakeholders across the organization to identify high-impact opportunities to leverage our extensive data to better serve our users.\nDrive the creation of comprehensive datasets encompassing user profiles and behaviors, and incorporating a wide variety of signals and data types.\nAssess the potential usefulness and validity of new statistical approaches and data sources.\nBuild complex predictive models to substantially improve and continuously optimize user engagement and revenue generation.\nRapidly develop proof-of-concept prototypes to prove out hypotheses.\nReach across multiple functions, such as Product Management and Data Engineering, to implement the models into production and to monitor their performance.\nMotivate and mentor other data scientists to grow their skills and careers.\nOur ideal candidate\nAdvanced Degree (Ph. D./MS) in Statistics or a related quantitative discipline.\n6+ years of experience building and implementing complex models in a fast-paced corporate environment, ideally dealing with problems relevant to revenue, product, and/or marketing.\nExperience with advanced modeling techniques, such as collaborative filtering, matrix factorization, time series analysis, and mixed-effect models, and learning techniques such as boosting and random forests.\nExpert knowledge of R, Python, and SQL, or similar industry standard tools used for large-scale data analysis and modeling.\nExperience with Machine Learning and Big Data technologies such as Map/Reduce, Hadoop, Hive, and Spark is a big plus.\nProgramming experience in Scala, Java, or C++, and familiarity with UNIX command line and core tools would be very helpful.\nRecent experience with a consumer facing online company and/or prior exposure to consumer financial products is highly desirable.\nSelf-motivated, results oriented, enthusiastic, and a creative thinker.\nEqual Employment Opportunity\nCredit Karma is committed to a diverse and inclusive work environment. We believe that such an environment advances long-term professional growth, creates a robust business, and supports our mission of championing financial progress for everyone. We offer generous benefits and perks with a single eye to nourishing an inclusive environment that recognizes the contributions of all and fosters diversity by supporting our internal Employee Resource Groups. We\u2019ve worked hard to build an intensely collaborative and creative environment, a diverse and inclusive employee culture, and the opportunity for professional growth.\nAs part of the Credit Karma team, your voice will be heard, your contributions will matter, and your unique background and experiences will be celebrated. Credit Karma is also proud to be an Equal Opportunity Employer. We welcome all candidates without regard to race, color, religion, age, marital status, sex (including pregnancy, childbirth, or related medical condition), sexual orientation, gender identity or gender expression, national origin, veteran or military status, disability (physical or mental), genetic information, or any other protected characteristic. We prohibit discrimination of any kind and operate in compliance with the San Francisco Fair Chance Ordinance.\n\n#LI-AG1\nStart your job application: click Apply Now"}, "666": {"company": "Proofpoint", "description": "It's fun to work in a company where people truly BELIEVE in what they're doing!\n\nWe're committed to bringing passion and customer focus to the business.\n\nThe Role\n\nDo you have a passion for applying machine learning to hard problems? Do you keep up with the state of the art in deep learning, clustering, and model explainability, but know when to fall back on simple, battle-tested approaches like logistic regression, DBSCAN, and k-nearest neighbors? Are you cuckoo for cuckoo graphs (or any other graphs, for that matter)? If so, Proofpoint's Analytics and Intelligence team is looking for you!\n\nOur team combines algorithm design, software engineering, and domain knowledge into first-of-their-kind security products leveraging massive email, SaaS, and threat intelligence data sets. Your primary focus will be applying your skills in areas like anomaly detection, graph mining, clustering, generative analytics, and of course classification, to build groundbreaking new services that protect people from malware, phishing, social engineering, and other cyber attacks.\n\nWe're a fast-paced, high-energy team where you'll be given the opportunity to have a significant impact. The team has a solid engineering culture that values the craftsmanship of writing great software, enjoys learning, and thrives on solving big problems.\n\nYour day-to-day\nWork with product management, engineering, and UX from problem definition to first hypothesis to final delivery\nTrawl massive data sets \u2013 mail flow with billions of messages per day, browser and SaaS activity for millions of users, an intelligence graph with trillions of data points \u2013 for insight into cybersecurity\u2019s biggest challenges\nBlend information from disparate sources to build and optimize classification, regression, and clustering systems\nConduct ad-hoc analysis and innovation around data visualization and information design\nMentor and uplevel junior data scientists\nWhat you bring to the team\nAdvanced degree in computer science, statistics, or applied math, or real-world experience in security research and data science\nThe rigor and precision of a scientist, with an artist\u2019s intuition and flair\nExperience applying ML algorithms and techniques to living, breathing data\nAn abiding interest in data science trends, from the mainstream to the bleeding edge\nA history of building scalable processes to collect, manipulate, and analyze massive volumes of data\nFamiliarity with mature data science toolchains like Python\u2019s (NumPy, SciPy, Pandas, scikit-learn, PyTorch, Gensim, etc.)\nIf you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!\nTo apply to this job, click Apply Now"}, "667": {"company": "Shutterfly", "description": "The Data Scientist will be responsible for designing and directing experiments and observational studies to optimize our marketing efforts. This role requires an individual with a strong ability to communicate and collaborate across functional teams, in addition to outstanding analytical and critical thinking skills. The role will have a strong focus on experimental design.\n\nResponsibilities:\nDirectly impact resource allocation decisions by designing and directing experiments and observational studies\nPartner with the marketing and business strategy teams to define and test hypotheses that answer critical business questions\nPerform deep-dive statistical analysis on large, complex, multi-dimensional datasets.\nDevelop and contribute to a base of understanding that allows us to make optimal resource allocation decisions\nQualifications:\nAdvanced degree (MS, Ph.D.) in quantitative fields, and 2-3 years of experience with a range of techniques, tools, and methods related to data mining and statistical analysis\nStrong ability with a statistical language such as R, Python or SAS, and hands-on experience using a variety of analytical methods\nExperience with or strong working knowledge of experimental design concepts, regardless of industry/discipline\nHands-on experience with SQL, working knowledge of database design\nFamiliarity with internet marketing data collection methods and marketing technology, including search marketing, social marketing, and ad serving platforms\nCreative mind with strong communication and interpersonal skills; talented with simplifying abstract business issues and large amounts of data into actionable analyses; must be able to interact with diverse groups of technical and non-technical people\nTrack record of contributing to successful end-to-end analytic solutions (clarifying business objectives and hypotheses, communicating project deliverables and timelines, and informing action based on findings)\nStrong desire to articulate business recommendations based on analytical work\nThis position is full-time and based in Redwood City, CA\nStart your job application: click Apply Now"}, "668": {"company": "DICK'S Sporting Goods - Corporate", "description": "Description\n\nThe core data science team at Dick's Sporting Goods is seeking a data scientist to support product teams within the technology organization. The team builds end-to-end machine learning solutions that drive business value in all parts of the organization. A few examples of projects that the team is currently working on are demand forecasting, search algorithm optimization, supply chain optimization, and visual search. We are looking for diverse teammates with strong technical skills who also have a passion for learning and deploying the latest machine learning algorithms. An ideal candidate will have a knowledge base in search algorithms, NLP, and/or forecasting.\n\nThe Role You'll Play:\n\n\n\nMachine Learning Applications & Analyses\nApply machine learning and data mining techniques to extract actionable insights from large-scale, high-dimensional data.\nBuild end-to-end algorithmic solutions that focus on improving the customer's experience both in-store and on our website.\nCompile data from disparate data sources leveraging both qualitative and quantitative data to build holistic views of customer's experience.\nCommunicate and present complex analyses and models to all levels of leadership across the organization.\nClient Liaison\n\nWork with a variety of business units throughout the organization to help translate their requirements into specific analytical deliverables.\nContinue to improve and advance communications and collaborations amongst the various analytics teams and business units.\nTraining\nLead or support formal and/or informal training for team members on the various tools used for team members within the analytics team or client teams.\n\nQualifications\n\nEducation\nMaster's Degree Preferred In: Statistics, Computer Science, Operations Research, Engineering, Mathematics, Economics, or other quantitative fields\nAdditional experience will be considered in lieu of an advanced degree.\n\n\nExperience/Technology\n\nStatistics / Machine Learning with applications in R or Python.\nPractical experience with SQL or a SQL-like language.\nCreating visualizations and presentations for non-technical users.\nBonus Points\nPublication in top conferences or journals\nExperience applying machine learning techniques in a retail environment\nExperience with Kubernetes based systems such as Kubeflow\nExperience with any of the following: search algorithms, NLP, or time-series forecasting\nExperience in a deep learning framework such as Tensorflow or PyTorch\n\nTo apply to this job, click Apply Now"}, "669": {"company": "Mojio", "description": "Position Title: Data Scientist\nLocation: Campbell, California or Vancouver, Canada\n\nAt Mojio, we're connecting the cars of today for the journeys of tomorrow. Backed by leading investors including Amazon, Bosch and Deutsche Telekom, Mojio is driving the global adoption of its connected car technology via its growing portfolio of customers, including T-Mobile and Vivint in the US, Deutsche Telekom in Europe and Telus in Canada. With more than 10 billion miles worth of real-world driving data processed to date, we have created one of the largest and fastest-growing big data pools in the automotive industry. If you're interested in joining us on our mission to give every vehicle a voice, apply now!\n\nThe Opportunity\n\nYou will work on awesome data science and AI problems including:\nCreating data algorithms for new product features around connected car such as predictive maintenance, driving scoring, etc.\nCreating insights and analytics based around Mojio's partners growing numbers of vehicles, users and trips.\nSupport data processing that contributes to the growing use of anonymous data that can provide value to users and the larger ecosystem\nData science around data for users, vehicles and mobility as a service.\nAI processing for both batch solutions (end of trip, night time) or online streaming (while driving) dataset types\nDrive efficient and leading-edge solutions to create deep learning and other derived insights from time-based data as well as video and image feeds\nContribute to the strategic direction around big data and leading-edge AI/analytics in the connected car space\nProviding solution while maintaining privacy and security requirements.\n\nWho You Are\n\nPreferred Qualifications:\nMinimum 2 years for industry experience.\nMasters or PhD in Computer Science with preferably a focus on data science/AI\nExperience with big data processing for analytics and/or AI\nExperience with Azure or AWS cloud systems\nExperience with efficient processing of large data systems with technologies like Spark, Neural Networks, TensorFlow etc.\nKnowledge of Scala is a big plus.\nExperience with streaming data either time-series data or media\nOther job requirements:\nAbility to work with a distributed team to creating great collaborative solutions\nAn open mind to new opportunities and new solutions that have not been done before\nGood architectural knowledge to provide platform and efficient solutions rather than one-off snowflakes.\nStrong interest in connected car, autonomous and the future of transportation.\nCoding skills in one or more of: C/C++, C#, Python, Java, R as well as higher level frameworks such as Spark, Storm, NoSQL, Hadoop/HBase, etc.\nOur Perks and Benefits\nCompetitive salary, bonus and options package\nExcellent benefits (health, dental and vision)\nLifestyle Savings Account\nFree lunches provided three days per week and two days lunch stipend\nOur kitchen is always stocked with healthy (and some not-so-healthy) snacks\nEducation Tuition Program\nTeam outings\nFree Mojio for your car (obviously!)\nPhone bill reimbursement and many more!\nAll qualified applicants will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, gender identity, sexual orientation, or on the basis of disability.\n\nPosted positions are not open to third party recruiters/agencies and unsolicited resume submissions will be considered free referrals.\nTo apply to this job, click Easy Apply"}, "670": {"company": "Science 37", "description": "Science 37 is accelerating the research and development of breakthrough biomedical treatments by bringing clinical trials to patients' homes. Backed by venture investors such as Glynn Capital, Google Ventures, Redmile Group, dRx Capital and Lux Capital, we are seeking a razor-sharp Data Scientist eager to make an impact within a mission-driven organization changing the world of clinical research.\n\nAs part of the Science 37 Tech team, you will collaborate with motivated, energetic, and entrepreneurial individuals working together to achieve Science 37's mission of changing the world of clinical research through patient-centered design. You will have a hands-on role with the architecture and development of NORA\u00ae (Network Oriented Research Assistant), the technology that enables Science 37's groundbreaking Metasite\u2122 clinical research model and collaborates with Product, Data, Clinical Operations, and other relevant stakeholders to define study specific NORA requirements.\n\nResponsibilities\n\nDuties include but are not limited to:\nUnderstand business stakeholders' needs and translate those into a data insights program with solutions for each stakeholder\nDeliver on data analytics and insights by planning and performing end-to-end analysis: including aggregating and processing data, exploring data, building and validating predictive models, and presenting to business.\nAnalyze our existing data model/structure and provide recommendations to the Tech team for optimization to support our data strategy\nDesign and implement statistical algorithms and predictive analysis\nExplain data analytics and data science findings and machine learning models to internal and external stakeholders\nWork with Data Analysts, Product Managers and Software Engineers to gather data insight requirements, set goals and influence the product roadmap.\nMinimum Qualifications\nB.S. or M.S. in computer science, Mathematics, Statistics, Physics, Economics or equivalent experience\n4+ years of industry experience in predictive analysis and modeling, data analysis and science\n3+ years of industry experience in data analytics\nKnowledge of data engineering, database architecture and ETL process\nExperience building ML models\nProficient in either Python or R or both.\nExperience using ML libraries such as scikit-learn, caret\nKnowledge of machine learning frameworks and toolsets\nExperience writing and optimizing SQL\nExperience using data visualization tools.\nExperience presenting data findings\nPreferred Qualifications\nPhD in computer science, Mathematics, Statistics, Physics, Economics, Bio-Engineering/Science field\n6+ years of industry experience in predictive analysis and modeling, data analysis and science\n4+ years of industry experience in data analytics\nProven ability to tackle business problems with data science solutions\nExpert programming skills in Python and/or R\nProficient programming skills in Javascript or JAVA\nAbility to develop analytic plans for data modeling process\nAbility to accurately determine correlations\nExperience with AWS data technologies such as Redshift, S3, Data Pipeline\nExperience with Tableau\nSkills and Competencies\nAbility to think critically\nAbility to translate business problems into data questions, create solutions and drive results\nAbility to aggregate and analyze data from multiple data sources and build a holistic view\nAbility to build clear visualizations to explain complex ideas and analysis result to executives and business unit leaders\nAbility to provide guidance to other program and project managers\nAbility to resolve conflicts and negotiate agreement\nAbility to proactively identify impediments in project/program delivery and craft solutions.\nAbility to set metrics for the project and program for performance and goals.\nCapabilities\nStrong written and oral communication skills\nReporting\nThe incumbent is required to work under the guidance and direction of the VP, Engineering with little to minimal supervision.\nDirect Reports\nNo direct reports\nScience 37 values the well-being of its employees and aims to provide team members with everything they need to succeed. Enjoy healthy catered lunches, snacks and beverages, and top-notch equipment such as the latest Macbook Pro, 4k monitors, and adjustable standing desks. Submit your resume to apply!\nApply Now: click Easy Apply"}, "671": {"company": "The Buffalo Group", "description": "Data Scientist\nUS Citizenship and a current TS/SCI clearance are required for the position.\n\nJob Description: Candidate will provide support to the Department of the Army Intelligence Information Services (DAIIS) Open Source Intelligence (OSINT) Team and assist in its requirement to answer enduring/ standing requirements and ad hoc Requests for Information for publicly available information that answer worldwide intelligence requirements. The intent of this program is to provide intelligence consumers access to publicly available information on the networks on which they operate so that analysts spend less time conducting searches and building queries on the internet and more time conducting all-source intelligence analysis. Candidates will provide data management functions in the form of data governance, data architecture, data warehousing, data quality management, metadata management, data security management, data development management, data operations management, data refinement, integrated data services, data transformation services, data discovery services, data tradecraft services, advanced data analytics, and technology pursuit. Candidates will continuously identify new sources of publicly available information using multiple sources including websites, databases, and email distribution lists\n\nRequired Skills:\nAbility to collect, process, analyze and report large amounts of quantitative and qualitative data, and identify trends anomalies with minimal supervision\nAbility to Evaluate performance management and formulate recommendations for senior leadership with minimal supervision\nAbility to explain mathematical formulas and statistical findings to non-technical users and decision makers\nExtract business insights from analysis of data and communicate (orally, written, or visually) those insights to business leaders\nProficiency in Microsoft Excel (e.g Pivot Tables and Pivot Charts, Multiple criteria Lookups, Nested logical/IF formulas, etc...), and Microsoft PowerPoint\nProgramming experience with Python for data analysis (e.g. Pandas, NumPy, matplotlib, etc...); particularly in processing and analysis of different sources of quantitative and qualitative data\nHoned presentation and product demo skills\nWork cross functionally\nMatch analytic solutions to business needs\nInput and manipulate data using a dashboard (e.g. Tableau, SharePoint, etc.) visualization system\nBasic programming and scripting experience with JSON is not mandatory, but is considered a plus\nBachelor\u2019s degree is required\nThe Buffalo Group is an Equal Opportunity Employer\nTo apply to this job, click Apply Now"}, "672": {"company": "Attune", "description": "Company Description\n\nRunning a small business is hard. Getting insurance for your small business is even harder. It takes forever, the process is antiquated, and one wrong decision can be disastrous.\n\nAt Attune, we\u2019re changing small business insurance in a big way.\n\nAt the forefront of the insuretech industry, we are rebuilding small business\u2019s access to insurance from scratch, making it instant, easy, and safe. How? Instead of requiring that a business answers hundreds of questions (seriously), our sophisticated platform aggregates the necessary data from different sources, and then uses incredibly advanced analytics to create tailored products that can be delivered in mere minutes, not days or weeks.\n\nWe are at the beginning of our journey and are looking for innovators who are curious and excited to drive change.\n\nBacked by Two Sigma, AIG, and Hamilton Insurance Group, we have the horsepower and partners to make a big impact. Unlike other start-ups, Attune has the funding, expertise, and support to modernize and move quickly. If you are energized by making the complex, simple; the time consuming, easy; and the antiquated, tech-enabled, we want you on our team.\n\nDisrupting an industry through data, technology and speed isn't easy \u2013 but the challenges we\u2019ll tackle together are some of the most rewarding you\u2019ll experience in your career.\n\nJob Description\n\nYou'll join a growing analytics team that drives Attune\u2019s business model forward by solving some of the most complex analytical problems in the industry. You will partner with the actuarial, underwriting, claims, product, revenue and customer service functions within Attune to frequently test new hypotheses, implement learnings and create edge.\n\nResponsibilities include:\nWorking on initiatives like: improving insurance risk predictions, analyzing drivers of claims, understanding user engagement patterns, finding the best potential customers to contact, reducing load on our customer service team, and identifying abnormal broker behavior\nCreating new predictive models in insurance pricing, pricing elasticity, reserving, claims analytics and etc.\nExploring new datasets to see how they can add value to the business\nHelping to incorporate analyses and models into daily workflows for other departments\nContributing to our ETLs, internal web applications, and BI dashboards\nDoing quick ad-hoc analyses and supporting engineers to troubleshoot issues\nQualifications\nExperience working in an statistics, analytics or data focused role\nExperience with predictive modeling in general\nFamiliarity with advanced statistical analysis methods (e. g., bayesian statistical modeling, hierarchical modeling and etc) in addition to machine learning regression/classification/clustering techniques\nWorking knowledge of bayesian software language (STAN, JAGS, or OpenBUGS) a plus\nWe are flexible about what tools you've worked with, but comfort in either Python or R is a must, as is basic SQL.\nWe don't require experience with deep learning or with tools for working with massive data sets\nProperty Casualty insurance experience and knowledge is a plus, but not a must\nTraits for success:\nYou enjoy working with programmers and other data scientists to constantly improve the integrity and automation of your work. You are frequently sharpening your software skills.\nYou are well organized and can handle many unrelated requests without losing track of them.\nYou are quick with numbers and back-of-the-envelope calculations.\nYou have strong written and verbal communication skills.\nYou are a hands-on problem solver who is comfortable with ambiguity and loves a fast-paced environment.\nYou have strong interpersonal skills and are capable of building relationships to drive success.\nAdditional Information\n\nWhat we offer you:\nAn opportunity to change the small business landscape.\nA great working environment that lives continuous improvement and encourages sharing ideas and taking risks to find better ways of doing things.\nA culture that promotes great relationships both inside the office and outside through activities in our community and company sponsored intramural clubs and events.\nEquity compensation.\nMedical, dental, and vision from day one and 401(k) matching.\nFully stocked kitchens with free snacks & drinks.\nAttune Insurance Services, LLC is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, or protected Veteran status.\nTo apply to this job, click Apply Now"}, "673": {"company": "DICK'S Sporting Goods - Corporate", "description": "Description\n\nThe core data science team at Dick's Sporting Goods is seeking a data scientist to support product teams within the technology organization. The team builds end-to-end machine learning solutions that drive business value in all parts of the organization. A few examples of projects that the team is currently working on are demand forecasting, search algorithm optimization, supply chain optimization, and visual search. We are looking for diverse teammates with strong technical skills who also have a passion for learning and deploying the latest machine learning algorithms. An ideal candidate will have a knowledge base in search algorithms, NLP, and/or forecasting.\n\nThe Role You'll Play:\n\n\n\nMachine Learning Applications & Analyses\nApply machine learning and data mining techniques to extract actionable insights from large-scale, high-dimensional data.\nBuild end-to-end algorithmic solutions that focus on improving the customer's experience both in-store and on our website.\nCompile data from disparate data sources leveraging both qualitative and quantitative data to build holistic views of customer's experience.\nCommunicate and present complex analyses and models to all levels of leadership across the organization.\nClient Liaison\n\nWork with a variety of business units throughout the organization to help translate their requirements into specific analytical deliverables.\nContinue to improve and advance communications and collaborations amongst the various analytics teams and business units.\nTraining\nLead or support formal and/or informal training for team members on the various tools used for team members within the analytics team or client teams.\n\nQualifications\n\nEducation\nMaster's Degree Preferred In: Statistics, Computer Science, Operations Research, Engineering, Mathematics, Economics, or other quantitative fields\nAdditional experience will be considered in lieu of an advanced degree.\n\n\nExperience/Technology\n\nStatistics / Machine Learning with applications in R or Python.\nPractical experience with SQL or a SQL-like language.\nCreating visualizations and presentations for non-technical users.\nBonus Points\nPublication in top conferences or journals\nExperience applying machine learning techniques in a retail environment\nExperience with Kubernetes based systems such as Kubeflow\nExperience with any of the following: search algorithms, NLP, or time-series forecasting\nExperience in a deep learning framework such as Tensorflow or PyTorch\n\nStart your job application: click Apply Now"}, "674": {"company": "Systems & Technology Research", "description": "STR is a government research contractor specializing in advanced research and development for defense, intelligence, and homeland security applications. We pride ourselves in developing cutting-edge technologies with significant and immediate impact on our national security. Our product is our staff; we prioritize cultivating a team of driven and talented scientists and engineers that together culminate into a premier company.\n\nEvery Analyst a Scientist - One of our primary goals is to empower intelligence analysts to be able to study their data like scientists. The tools we develop focus on streamlining intelligence analysis through integrated algorithms and software that provide insight into the geopolitical landscape for use in operational intelligence missions around the world.\n\nThe Role:\n\nAs a Data Scientist, you will live by our motto that \u201cData is Destiny.\u201d You will work with a diverse collection of massive datasets, including social media, structured and unstructured text, geospatial, time series, and imagery data. You will design, test, and validate statistical tests and machine learning models in support of cutting-edge problems in the national security space. Your expertise as a data scientist will aid a diverse team of researchers to build state-of-the-art tools and technologies that are deployed to extract and enrich intelligence used by analysts. If you would like to help intelligence and defense analysis keep pace with modern machine learning and software techniques, then this role is for you!\n\nWho you are:\nA degree in a scientific field such as Statistics, Mathematics, or Computer Science\nExperience in statistical modeling including performance evaluation and uncertainty quantification\nProficiency with a scientific programming language, preferably Python, and familiarity with Numpy, Pandas, and/or Scikit-learn packages\nExperience in grooming sparse, incomplete, and noisy datasets\nMotivated collaborator and an excellent communicator of ideas to both technical and non-technical audiences\nUS citizen and willing to obtain a U.S. Security Clearance\nEven better:\nMS or PhD in a scientific field such as Statistics, Mathematics, Computer Science, or Data Science or 2+ years of relevant work experience\nFamiliarity with handling and analyzing data at scale, for example using Hadoop, Dask, Spark, and MapReduce\nWorking knowledge of data store tools such as SQL and Elasticsearch, and experience interacting with databases\nExperience with deep learning and neural network training, testing, and evaluation with fluency in Tensorflow or PyTorch\nSpecialized expertise in a data-rich field such as time-series analysis, graph analytics, geospatial analysis, image processing, or Bayesian programming\nActive U.S. Security Clearance\nCompensation:\nCompetitive salary\nComprehensive benefits (Medical, Dental, Vision, Disability, Life)\n401k company match\nCompetitive and flexible paid time off\nContinued higher education reimbursement\nProfit sharing (Additional match to 401k)\nPhone reimbursement plan\nAnd more!\nSTR is dedicated to fostering a diverse and inclusive workforce where all employees, regardless of race, ethnicity, gender, neurodiversity, or other personal characteristics, feel valued, included, and empowered to achieve their best. We recognize that each employee\u2019s backgrounds, experiences, and perspectives are essential for providing our customers with innovative solutions to challenging national security problems. STR\u2019s commitment to attracting, retaining, and engaging talented and diverse professionals is demonstrated by our participation, sponsorship, and support in local and national minority organizations.\n\nApplicants must be US Citizens.\nTo apply to this job, click Apply Now"}, "675": {"company": "Tuft & Needle", "description": "THE JOURNEY TO YOUR DREAM JOB COULD BE JUST A CLICK AWAY\u2026\nIn 2012, Tuft & Needle(tn.com) revolutionized the mattress space by turning the focus to the customer with always-honest pricing, an insistence on high-quality products, and world-class customer experience. We started our journey with two software engineers and a dream and today we have grown to a team of more than 175 talented people, working each day to bring the world premium sleep products at an honest cost.\n\nAs a Data Scientist, you'll be an important part of the company's decision-making process. You will help us understand how things are related to each other, which approaches are working, and which aren't. You'll also help us maintain our data-infrastructure. This includes our reporting and data management, as well as automated statistical and machine learning tools.\n\nTogether, we are radically reshaping how we think about sleep, mattresses, and shopping - and we\u2019re just getting started. Want to join us?\n\n*Open to remote opportunity\nRESPONSIBILITIES:\nWrite programs to automate analyses and data wrangling\nBuild machine learning models to forecast and understand customer behavior\nMaintain and improve reporting in Looker, Metabase, and R\nExplain analyses and discoveries with articles and presentations\nREQUIREMENTS:\nStrong knowledge of statistics and inference\n2+ years writing and maintaining code\n2+ years working with SQL\nExperience communicating statistical concepts to a broad audience\nPREFERRED EXPERIENCE:\nProgramming in R and/or Python\nManaging and organizing a large codebase\nExperience with Bayesian Methods\nDeep experience in some part of statistics (Ex: time series analysis, experimental design, multivariate analysis, natural language processing, etc.)\nInterest in functional style programming\nInterest in causal inference\nYOU CAN SLEEP BETTER WHEN YOU WORK AT T&N\nOur people \u2013 You will be working alongside some of the most talented, supportive, savvy individuals out there\u2026 people we are so proud to work with. Together, we are shaking things up in the mattress industry and delivering an experience for clients that they would never expect.\nOur product \u2013 Each team member receives a great bundle of products for themselves. You will too if you join the team! Your friends and family will also have access to a great product discount.\nOur benefits - We offer comprehensive health benefits for you, eligible partners and dependents, paid maternity & paternity leave, 401k with a match, a generous vacation plan, and so much more.\nTuft & Needle is proud to be an equal opportunity employer. We will not discriminate against any applicant or employee on the basis of age, race, color, creed, religion, sex, sexual orientation, gender, gender identity or expression, medical condition, national origin, ancestry, citizenship, marital status or civil partnership/union status, physical or mental disability, pregnancy, childbirth, genetic information, military and veteran status, or any other basis prohibited by applicable federal, state or local law.\nYour experience is important to us. If you have any questions with your application, please contact our Candidate Experience Team at talent@tuftandneedle.com\nApply Now: click Apply Now"}, "676": {"company": "FORMA THERAPEUTICS", "description": "PositionOverview:\n\nFORMA Therapeutics, Inc. (Watertown, MA) is a patient-focused, Cambridge-area, private biotechnology corporation dedicated to the discovery and advancement of life-saving therapies to patients across multiple therapeutic areas. While advancing multiple novel small molecule therapies discovered at FORMA in ongoing Phase I and Phase II clinical trials\nfor diverse indications in oncology, hepatology and hematology, FORMA remains committed to the cutting-edge discovery of novel chemical matter for clinically relevant disease targets.\n\nWe are seekinga passionate laboratory scientist with the experience to design, implement and run both biochemical and cellular assays. This position is a key leadership role in the Lead Discovery and Optimization Group, which is a pivotal team responsible for assay development, High Throughput Screening, DNA-Encoded library selections& hits-to-leads\nsupport for FORMA\u2019s diverse pipeline. The ideal candidate will be able to help evolve FORMA\u2019s hit identification and hits-to-lead endeavors through embracing novel assay technologies, enhancing overall process and actively drive internal and external partnerships.\n\nRequirements:\nPh.D. or Masters Degree in Biochemistry and/or Cell Biology with industry experience\nDemonstrated experience in Assay Development, Automation, Biochemistry, Cell Biology\nStrong leadership in the Lead Discovery and Optimization group, responsible for assay design, high-throughput screening (HTS), and hit-to-lead program support\nHands-on execution of mechanistic assays (e.g. Determination of Ki, Kd, drug residence times, slow/irreversible binding and mode of inhibition from catalytic and binding studies)\nExperience with high throughput data management, data flow, analysis and visualization (e.g. ABase, Genedata, Spotfire, Vortex)\nFamiliarity with robotic automation\nResponsible for establishing, monitoring and maintaining a stable and productive environment through Quality Control, preventative maintenance and standard operating procedures\nResponsible for setting and maintaining the highest scientific standards, developing skill-based competence, providing flexible project support as well as coaching and mentoring team members to maximize their potential\nDemonstrated ability to collaborate with cross-functional teams in Medicinal Chemistry and Biology\nExtensive hands-on experience in biochemical and/or cellular assays (384 or 1536 plate format), associated assay technologies and instrumentation for drug discovery is a must\nKey Attributes:\nExcellent scientific depth with a strong understanding of all facets of automation and technology\nSolid organizational skills applied to defining and optimizing workflows for maximum efficiency\nConsistently demonstrates teamwork skills and has experience coaching and mentoring others\nStrong ability to evaluate processes and drive the implementation of effective change\nExcellent cross-functional collaboration, communication, and interpersonal skills\nHighly self-motivated and able to work efficiently and productively in a rapidly-growing fast-paced company\nFORMA Therapeutics is focused on the discovery, development and commercialization of transformative medicines that will make a difference for patients in need. A fully-integrated biopharmaceutical company, FORMA\u2019s validated, proprietary R&D engine combines deep biology insight, chemistry expertise and clinical development capabilities to create differentiated drug candidates with best-in-class or first-in-class potential. FORMA has delivered high-value clinical candidates to its partners and generated a broad proprietary portfolio of programs, ranging from pivotal to preclinical-stage, with the potential to provide profound patient benefit in hematology, oncology, and metabolism indications. www.formatherapeutics.com\nTo apply to this job, click Apply Now"}, "677": {"company": "Reddit", "description": "The front page of the internet,\" Reddit brings over 330 million people together each month through their common interests, inviting them to share, vote, comment, and create across thousands of communities. Come for the cats, stay for the empathy.\n\nWe are looking for a Staff Data Scientist to work with our Ads team. You will work closely with engineers and product owners from our Ads team to understand how our data can be used to tell a compelling story to brands. In addition to strong analytical skills, this person has a solid business acumen and understanding of what is important to advertisers.\n\nResponsibilities:\nServe as a thought-partner for Product Managers and Engineering Managers in influencing the ads roadmap and strategy by identifying opportunities through deep-dive analyses and/or modeling.\nDeeply understand ad auctions and how bid densities affect CPMs, CPCs and revenue\nDevelop familiarity with managed/reserved, takeover and self-serve environments and specific interplays amongst those ads.\nHelp improve the team's understanding of ads targeting, ads pacing, frequency capping, underdelivery and other aspects related to ads delivery.\nDevelop models to improve ads performance and advertiser ROI\nWork with cross-functional stakeholders and partners including PMs, Engineers, Solution Engineers and Sales.\nWhat We Can Expect From You:\nMasters degree or above in a quantitative major (e.g., mathematics, statistics, economics, finance, computer science)\n5+ years of experience in quantitative analytical roles, preferably for a consumer-facing service/app\n2+ years of experience in online advertising\nProficiency with statistical analysis and programming languages (e.g., R / Python)\nTo apply to this job, click Easy Apply"}, "678": {"company": "Kensho", "description": "At Kensho, we hire talented people and give them the autonomy, support, and resources needed to build cutting edge technology and products for our parent company, S&P Global. As a result, we produce technology that is scalable, robust, and solves the challenges of one of the world\u2019s largest, most successful financial institutions.\n\nAs a Machine Learning Engineer, you will be responsible for tackling a wide range of problems from natural language processing to timeseries prediction. You will move beyond the theoretical confines of academia and apply your tradecraft to build machine learning systems on real world data. In this role you will constantly collaborate and work with groups of engineers. Our machine learning team is responsible for delivering ML-based solutions from problem framing, to prototyping, to production application.\n\nAre you looking to make impactful, scalable contributions that could transform the way people think about data? If so, we would love to help you excel here at Kensho. We take pride in our team-based, tightly-knit startup Kenshin community that provides our employees with a collaborative, communicative environment that allows us to tackle the biggest challenges in data.\nYou Will\nYou will conduct original research on large proprietary and open source data setsIdentify, research, prototype, and build predictive products\nYou will build cutting-edge models for understanding vast amounts of textual dataWrite production code\nYou will write tests to ensure the robustness and reliability of your productionized models\nYou will work closely with software engineers to build incredible systems\nWhat We Look For\nYou have at least one core programming expertise, such as python (NumPy, SciPy, Pandas), MATLAB, or R\nYou have experience with advanced machine learning methods\nYou possess strong statistical knowledge, intuition, and experience modeling real data\nYou have a stellar ability to communicate even the most complicated methods and results to a broad, often non-technical audience\nYou demonstrate effective coding, documentation, and communication habits\nSeveral of the following terms should hold deep meaning for you: LSTM, lookahead bias, bagging, boosting, stacking, information retrieval, batch norm, entity recognition, bootstrapping, Glorot initialization, Kullback-Leibler divergence, GLOVE, SMAPE, HMM, MAP, exponential family, VC dimension, EM, L1, TD(Lambda)\nHow You Can Really Get Our Attention\nYou have 3+ years of experience being a major machine learning contributor at a top company, hedge fund, or university\nYour github/kaggle profile shows a project or problems you\u2019ve tackled\nYou have the ability and credibility to lead a team\nTechnologies You Will Use\nPython and specifically Numpy, SciPy, Pandas, scikit-learn\nNeural network packages like TensorFlow and Keras\nML packages like LightGBM and XGBoost\nOpenFST\nElasticsearch\nBenefits & Perks\nAt Kensho, we pride ourselves on providing top-of-market benefits, including:\nMedical, Dental, and Vision insurance - 100% company paid premiums\nUnlimited Paid Time Off\n18 weeks of 100% paid Parental Leave (paternity and maternity)\n401(k) plan with 6% employer matching\nGenerous company matching on donations to non-profit charities\nUp to $20,000 tuition assistance\nPlentiful snacks, drinks, and regularly catered lunches\nDog-friendly office (CAM office)\nIn-office gyms and showers (CAM, DC) or Equinox membership (LA, NYC)\nStipend towards commuter or gym reimbursement\nBike sharing program memberships\nCompassion leave and elder care leave\nMentoring and additional learning opportunities\nOpportunity to expand professional network and participate in conferences and events\nAbout Kensho\n\nKensho uses machine learning, artificial intelligence, natural language processing and data visualization techniques to solve some of the hardest analytical problems and create breakthrough financial intelligence solutions for our parent company, S&P Global.\n\nKensho was founded in 2013 by Harvard & MIT alums and was acquired by S&P Global in 2018 for $550M, the largest FinTech AI acquisition ever. Kensho continues to operate as a startup in order to maintain our distinct, independent brand and to promote our breakthrough, innovative culture. Our team of Kenshins enjoy a dynamic and collaborative work environment that runs autonomously from S&P, while leveraging the unparalleled breadth and depth of data and resources available as part of S&P Global.\n\nAs Kenshins, we pride ourselves on maintaining an innovative culture that depends on diversity and inclusion. We are an equal opportunity employer that welcomes future Kenshins with all experiences and perspectives.\n\nKensho is headquartered in Cambridge, MA, with offices in New York City, Washington D.C. and Los Angeles.\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.\nStart your job application: click Apply Now"}, "679": {"company": "Pharmaceutical Product Development", "description": "The Senior Data Scientist at PPD executes\nadvanced analytics modeling based on exploratory data analysis from complex and\nhigh-dimensional data sets through application of statistics, machine learning,\nprogramming, data modeling, simulation, and/or advanced mathematics to\nrecognize patterns, identify opportunities, and generate valuable predictive\nbusiness insights in support of innovative business decisions. Supports\norganization leadership through data-driven decision validation and support.\nEffectively collaborates with cross-functional\nstakeholders to identify questions and business challenges and determine\nplans of action in order to effectively define, design, and develop\nmachine learning models and algorithms to derive insights into each\nproblem.\nGenerates and tests hypotheses and analyzes and\ninterprets the results.\nNavigates large, complex data sets for data mining,\nprofiling, and curation, and natural language processing (NLP), as well as\nidentifies related data that is fundamental to successfully applying\npredictive and machine learning techniques.\nDesigns, develops and programs methods, processes, and\nsoftware programs to consolidate, cleanse, and analyze unstructured,\ndiverse data sources to recognize patterns, identify opportunities, and\ngenerate actionable business insights and solutions.\nDesigns, develops, and evaluates predictive models and\nalgorithms that lead to optimal value extraction from the data in order to\nsupport business process improvements and solve business challenges.\nIdentifies meaningful insights from large data and\nmetadata sources in support of continuous improvement efforts and business\nprocess upgrades through exploratory data analysis.\nEffectively communicates and guides stakeholders\nthrough the machine learning process; Interprets and communicates findings\nand solutions from analysis and experiments to a broad audience, including\nbusiness leadership.\n#GD\n#PPDHP\nLI-NA1\nEducation and Experience:\nBachelor's degree or equivalent and relevant formal\nacademic / vocational qualification\nPrevious experience that provides the knowledge,\nskills, and abilities to perform the job (comparable to 5 years).\nKnowledge, Skills and\nAbilities:\n\nStrong working knowledge of application of statistics,\nprogramming, data modeling, simulation, and advanced mathematics to\nbusiness questions for data analysis\nDemonstrated skills with exploratory data analysis\ntechniques involving structured and unstructured data, machine learning\n(e.g. decision trees, neural networks, clustering, classification,\nBayesian networks), model validation techniques, and data visualization\ntechniques\nIn depth knowledge in one or more of the following\ntechnical areas: Snowflake, AWS EMR, Python, Spark, R, Shiny, jupyter, and\nassociated packages and libraries from numpy, pandas, SciPy or NLTK\nThorough knowledge of and exposure to cloud\narchitectures across NoSQL, lambda functions, kafka, sagemaker,\ntensorflow, etc.\nProficiency with the following data science approaches:\ndata engineering, pipelining and wrangling tools, data visualization and\nmodeling tools, and mathematical approaches to imperfect data\nSubstantial knowledge of data management approaches\nsuch as relational databases, data schemas, object stores, column stores,\ntriple stores, graph stores, and/or document stores\nProven ability to deliver accurate work products in a\ncross-functional matrix environment spanning data warehousing, data\nmodeling, and data analytics while managing multiple competing priorities\nSound analytical skills and demonstrated proficiency in\ndeveloping detailed analysis, models, plan calculations, and tools\nSolid executive presence with ability to communicate\neffectively and influence at all levels\nDemonstrated creativity in identifying non-traditional\ndata sources in addition to rigorous application of leading analytic\ntechniques\nPPD values the health and well being\nof our employees. We support and encourage individuals to create a healthy and\nbalanced environment where they can thrive.\nBelow is listed the working environment/requirements for this role:\nAble to communicate, receive, and\nunderstand information and ideas with diverse groups of people in a\ncomprehensible and reasonable manner.\nAble to work upright and stationary\nfor typical working hours.\nAbility to use and learn standard\noffice equipment and technology with proficiency.\nAble to perform successfully under\npressure while prioritizing and handling multiple projects or activities.\nVery limited travel (under 5\")\n#GD\nTo apply to this job, click Apply Now"}, "680": {"company": "Revel IT", "description": "Scientist. We have a number of Scientist contract roles available that will be responsible for initiating, directing and executing scientific research, development and manufacturing process strategies to support new and existing products. These individuals will investigate the feasibility of applying a wide variety of scientific principles and concepts to potential inventions, products and problems. He or she will also plan and execute laboratory research.\n\nAdditional Responsibilities:\nMaintains broad knowledge of state-of-the art principles and theories.\nMakes contributions to scientific literature and conferences.\nServes as an in-house and outside consultant.\nMay act as a spokesperson for corporate scientific affairs and advise top management.\nParticipates in development of patent applications.\nPromotes and participates in the professional development of scientists and laboratory facilities.\nUses professional concepts to contribute to the development of product or process principles and to achieve objectives in creative and effective ways.\nConducts research and development activities for products, methods and/or processes.\nProjects are assigned with defined scope and goals. Direction is provided by more senior scientists, management or project leader.\nParticipates in efforts to define new components, products or processes and identify technical challenges.\nMakes suggestions to improve work processes.\nCreates potentially patentable components for systems, reagents or processes.\nPlans and executes assigned projects; utilizes thorough technical and theoretical understanding of numerous techniques.\nAnalyzes data, evaluates results, forms conclusions and provides/implements process or document improvements.\nApplies advanced scientific knowledge to projects.\nExecutes experiments; participates in experimental design.\nUtilizes DOE where appropriate.\nParticipates in cross functional technical team activities.\nShares knowledge and expertise with others.\nParticipates in project planning, process updates and contributes to experimental design.\nPrepares and delivers presentations of project results to own or other groups.\nApplies advanced technical writing skills to produce reports and documents.\nMonitors work to ensure quality, and continuously promote Quality First Time.\nKnowledge, Skills, and Abilities:\nPh.D. degree in Science with entry level experience, or Master's degree with 3+ years, or Bachelors with 8 years relevant experience.\nDemonstrates potential for technical proficiency, scientific creativity, collaboration with others and independent thought.\nStrong understanding of scientific principles and concepts.\n#revelitjobs\nApply Now: click Easy Apply"}, "681": {"company": "Outreach", "description": "About The Team\n\nData is at the core of Outreach's strategy. It drives our customers and ourselves to the highest levels of success. We use it for everything from customer health scores and revenue dashboards, to operational metrics of our AWS infrastructure, to helping increase product engagement and user productivity through automated natural language understanding, to predictive analytics and causal inference via experimentation. As our customer base continues to grow, we are looking towards new ways of leveraging our data to save our customers time and improve their sales efficiency.\n\nThe mission of the Data Science team is to accelerate the success of our internal and external customers through trustworthy data analysis and experimentation. As a member of the team, you will be on the ground floor, working directly with the VP of Data Science to define and implement our strategy for delivering data products. You will be responsible for delivering models, data-driven functionality, and end-user features based on these models that will be deployed into production, as well as analyzing the data to produce actionable insights.\nYour Daily Adventures Will Include\nPlaying key role in designing and developing machine learning, NLP, and recommendation algorithms.\nWorking with internal and external customers to understand their pain points and brainstorm solutions\nDesigning A/B testing experiments and doing end-to-end data analysis to understand user experience and propose improvements.\nWorking alongside experienced engineering, design, and product teams to help deliver new customer-facing features and products.\nOur Vision of You\n2+ years experience in Data Science\nYou have experience of building production ML systems, and deep knowledge of modern ML algorithms\nYou have experience working with distributed data processing frameworks such as Spark.\nYou have experience using ML frameworks such as Tensorflow, SparkML, and Scikit-Learn.\nYou have a deep understanding of algorithms and evaluation methods used in production-grade ML systems.\nYou have strong programming skills in at least one object oriented programming language (Java, Scala, C++, Python, etc.)\nYou understand the entire lifecycle of machine learning product development, from inception to production\nYou are hands on, able to quickly pick up new tools and languages, and excited about building things and experimenting\nYou go above and beyond to help your team\nYou are honest, admit mistakes, and own fixing them\nYou are a motivated and talented craftsperson: always looking to sharpen and adapt your skills\nYou have a MS degree in Computer Science, Statistics, or a related field, or equivalent industry experience. PhD degree and publication track record at conferences such as KDD, SIGIR, WWW, ICML, NIPS, ACL, CIKM, RecSys, etc. are preferred.\nWhy You\u2019ll Love It Here\n\n\u2022 100% medical, dental, and vision coverage for full-time employees\n\u2022 Unlimited PTO (and people actually use it!)\n\u2022 401k to help you save for the future\n\u2022 Company-organized and personal paid volunteer days to support the community that supports us\n\u2022 Fun company and team outings because we play just as hard as we work\n\u2022 Diversity and inclusion programs that promote employee resource groups like OWN (Outreach Women's Network)\n\u2022 A parental leave program that includes not just extended time off but options for a paid night nurse, food delivery, gradual return to work, and the Gottman Institute's Bringing Home Baby course for new parents\n\u2022 Employee referral bonuses to encourage the addition of great new people to the team\n\u2022 Plus, unlimited snacks and beverages in our kitchen\nStart your job application: click Apply Now"}, "682": {"company": "Strivr", "description": "At the intersection of technology, science, business and sports, STRIVR offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.\n\nSTRIVR was founded in 2015 out of Stanford University\u2019s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon and Fidelity to innovate and elevate employee development.\n\nMore than just content inside a headset, immersive learning provides realistic, high-impact experiences driven by L&D experts, instructional designers, data scientists, and immersive content specialists. STRIVR offers the only end-to-end solution available today, bringing together the software, hardware, content and services needed to deliver effective training at scale.\n\nRecognized by Fast Company\u2019s Most Innovative Companies for 2019, we take pride in our passion for innovation and we use that energy to fuel our work. Our culture thrives on teamwork, grit, transparency and impact, and celebrates every win. It\u2019s an exciting time to join our fast growing team!\n\nAt STRIVR, our Data Science team develops cutting-edge techniques to improve people\u2019s performance in the real world based on their experiences in the virtual world. As a Data Scientist at STRIVR, you will be laying the foundations of how users\u2019 performance is evaluated in immersive learning environments and will be at the forefront of defining approaches to immersive analytics.\n\nYour responsibilities:\nDevelop new ways to measure user behavior and to evaluate performance in the virtual environment\nIdentify research areas, develop and implement approaches , and communicate insights in a compelling narrative\nBuild forecasting models to predict real-world performance based on behavior in the immersive environment\nDevelop optimization models to customize the training flow for each user based on their behavior\nIncorporate your research outcomes into standard analytics offering\nYour skills:\n5+ years of industry experience as a Data Scientist\nAn advanced degree in a quantitative field (e.g Economics, Statistics, Sciences, Engineering)\nExperience developing and implementing in-depth approaches, including statistical and econometric analyses\nExperience designing and training machine learning models\nProficiency with Python (or R), and SQL. Familiarity with Javascript and HTML is a plus.\nStrong communication skills. Presentation skills is a plus.\nPassion for using data to improve immersive experiences\nApply Now: click Easy Apply"}, "683": {"company": "PwC", "description": "PwC Labs is focused on standardizing, automating, delivering tools and processes and exploring emerging technologies that drive efficiency and enable our people to reimagine the possible. Process improvement, transformation, effective use of innovative technology and data & analytics, and leveraging alternative delivery solutions are key areas of focus to drive additional value for our firm.\n\nThe AI Lab focuses on implementing solutions that impact efficiency and effectiveness of our technology functions. Process improvement, transformation, effective use of technology and data & analytics, and leveraging alternative delivery are key areas to drive value and continue to be recognized as the leading professional services firm. AI Lab is focused on identifying and prioritizing emerging technologies to get the most out of our investments.\n\nTo really stand out and make us ?t for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\n\nAs a Director, youll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nArrange appropriate assignments and experiences to support others learning and development.\nSeek out different ways to use current and relevant technological advances.\nAnalyse marketplace trends - economical, social, cultural, technological - to identify opportunities and create value propositions.\nDeploy methods to keep up with, and stay ahead of, new developments and ideas.\nOffer a global perspective in stakeholder discussions and when shaping solutions/recommendations.\nDrive and take ownership for developing networks that help deliver what is best for stakeholders.\nProactively manage stakeholders to create positive outcomes for all parties.\nUphold the firms code of ethics and business conduct.\n\nJob Requirements and Preferences:\nBasic Qualifications:\n\nMinimum Degree Required:\nBachelor Degree\n\nAdditional Educational Requirements:\n\nIn lieu of a Bachelor Degree, 12 years of professional experience involving technology-focused process improvements, transformations, and/or system implementations.\n\nMinimum Years of Experience:\n10 year(s)\n\nPreferred Qualifications:\n\nDegree Preferred:\nMaster Degree\n\nPreferred Fields of Study:\nEngineering, Economics, Statistics, Mathematical Statistics, Mathematics, Operations Management/Research, Computer and Information Science\n\nPreferred Knowledge/Skills:\n\nDemonstrates thought leader-level abilities with, and/or a proven record of success directing efforts in the following areas:\nUnderstanding statistical or numerical methods application, data mining or data-driven problem solving;\nDemonstrating thought leader level abilities in the use of statistical modelling, algorithms, data mining and machine learning algorithms;\nUnderstanding business development such as client relationship management and leading and contributing to client proposals;\nDemonstrating proven delivery within a number of large scale projects;\nDemonstrating ownership of architecture solutions and managing change;\nCommunicating project findings orally and visually, to both technical and executive audiences;\nDeveloping people through effectively supervising, coaching, and mentoring staff;\nLeading, training, and working with other data scientists in designing effective analytical approaches taking into consideration performance and scalability to large datasets; and,\nManipulating and analyzing complex, high-volume, high-dimensionality data from varying sources.\nDemonstrates thought leader-level abilities with, and/or a proven record of success directing efforts in the following areas:\nDemonstrating thought leader-level abilities in commonly used data science packages including Spark, Pandas, SciPy, and Numpy;\nLeveraging familiarity with deep learning architectures used for text analysis, computer vision and signal processing;\nDeveloping end to end deep learning solutions for structured and unstructured data problems;\nDeveloping and deploying A.I. solutions as part of a larger automation pipeline;\nUtilizing programming skills and knowledge on how to write models which can be directly used in production as part of a large scale system;\nUnderstanding of not only how to develop data science analytic models but how to operationalize these models so they can run in an automated context;\nUsing Data visualization software such as tableau and qlikview in addition to web visualization libraries;\nDemonstrating proven ability with NLP and text based extraction techniques; and,\nUsing common cloud computing platforms including AWS and GCP in addition to their respective utilities for managing and manipulating large data sources, model, development, and deployment.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nTo apply to this job, click Apply Now"}, "684": {"company": "Divvy", "description": "About the Company\n\nAt Divvy, Our vision is to become the financial nervous system of every small-to-medium business in America. Our FREE one-stop-shop financial SaaS platform enables businesses to spend smarter by providing instant insight and transparency into company-wide spend and the ability to easily manage it; all in real-time! (+ many more features!)\n\nWith over 3,000 clients, extreme monthly growth, $240 million in venture capital raised from top investors, and 250+ mission-driven employees, we\u2019re well on our way.\nWhat You'll Be Doing\nDesigning and implementing data science infrastructure to support inference in a production application environment ( eg. building out Spark, Kafka/Pulsar, Postgres, analytical database like Snowflake environments)\nApply your expertise in deep learning, quantitative analysis, data mining, and the presentation of data to see beyond the numbers to increase revenue and improve our competitive position\nPartner with Product and Engineering teams to solve problems and identify trends and opportunities\nInform, influence, support, and execute our product decisions and product launches\n\nThe Data Scientist Analytics role has work across the following four areas:\nData Infrastructure and architecture\nDesigning and implementing data science infrastructure to support inference in a production application environment ( eg. building out Spark, Kafka/Pulsar, Postgres, analytical database like Snowflake environments)\nAutomating analyses and authoring pipelines via python\n\nLeadership\nInfluencing product teams through presentation of data-based recommendations\nCommunicating state of business, experiment results, etc. to product teams\nSpreading best practices to analytics and product teams\nMentoring and leveling up data scientists and analysts\n\nProduct\nForecasting and setting product team goals\nDesigning and evaluating experiments\nMonitoring key product metrics, understanding root causes of changes in metrics\nBuilding key data sets to empower operational and exploratory analysis\nEvaluating and defining metrics\n\nExploratory Analysis\nProposing what to build in the next roadmap\nUnderstanding ecosystems, user behaviors, and long-term trends\nIdentifying new levers to help move key metrics\nBuilding models of user behaviors for analysis or to power production systems\nQualifications\nMultiple years of experience doing the following: Designing and implementing data science infrastructure to support real-time inference in a production application environment ( eg. building out Spark, Kafka/Pulsar, Postgres, analytical database (snowflake, redshift, etc.) infrastructure)\nMentoring and leveling up data scientists and analysts\nAutomating analyses and authoring pipelines via python\nInfluencing product teams through presentation of data-based recommendations\nCommunicating state of business, experiment results, etc. to executives\nSpreading best practices to analytics and product teamsDesigning and evaluating experiments\nEvaluating and defining metrics\nInfluencing product feature roadmap with data\nUnderstanding ecosystems, user behaviors, and long-term trends\nBuilding models of user behaviors for analysis or to power production systems\nTotal Rewards\nAt Divvy we\u2019ve been intentional in designing scalable benefits, rewards, and perks that meet our workforce where they are while managing expectations as we scale. Just as pay parity was foundational for us in base salary, and remains our commitment and priority, our total rewards programs reflect our commitment to inclusivity and access for all.\n\nAt Divvy, you\u2019ll enjoy:\n\u2022 Employer contribution to health insurance premiums for all Full Time employees (minimum 60% independent of individual or family coverage selected)\n\u2022 Stock option grants for Full Time employees (new hire, promotion, evergreen)\n\u2022 Unlimited PTO\n\u2022 401K\n\u2022 $100 Divvy Uses Divvy each month (for personal use and engagement with our product)\n\u2022 $1000 Divvy Travel annually on your anniversary date of hire (take time to recharge)\n\u2022 Earn rewards by saving on business or personal travel with Divvy Travel powered by TripActions\n\u2022 Complimentary well-stocked kitchen and break rooms\n\u2022 Paid parental leave for Full Time employees (12 weeks for birthing/adoptive parents, 6 weeks for non-birthing parents)\n\u2022 Onsite services to make life easier (dental, vision, wellness, auto services, hair cuts, wellness, financial education, annual flu shots)\n\u2022 New 150,000 sq ft headquarters under construction with anticipated move-in summer 2020 (includes 2,000 sq ft Rogue and Peloton activated fitness facility with locker room, bike/ski storage and work room, full size outdoor basketball court, cafe, learning and development center, and continued support of gender neutral restrooms)\n\nPerks are nice, but perks don\u2019t make a company or individual successful - the work does. At Divvy, we\u2019re building the financial nervous system of business - faster, better, smarter, and the work compels us to show up each day for our customers and our teams while feeling well supported in our benefits.\n\n**We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.**\nStart your job application: click Apply Now"}, "685": {"company": "Applied Information Sciences", "description": "Now Hiring a Data Engineer\n\n\nAs a Data Engineer, you will use cutting edge cloud and data technologies to power the mission of our clients and have the ability to join our team of Data and Cloud professionals and accomplish what others only dream of. Must have the ability to commute to Houston, Texas.\nAbility to apply your skills in Azure Cognitive Services, Azure PaaS, data science, data analytics, and data warehousing to pioneer Azure cloud and data services within the DoD, bringing Azure Big Data services to IL4 & IL5.\nWork in a team using cutting edge technologies to solve challenging business problems and build solutions\nInteract directly with our client(s) to understand their needs and meet, or exceed their expectations by meeting delivery deadlines\nWork in an agile environment with participation in daily stand-ups/scrum\nDesign, write, test, troubleshoot, and document application code\nProvide mentorship to junior Developers\nLearn new technologies and be aware of industry standards, best practices, and trends.\nProfile of Success\nBachelor's degree in a related field and six years of experience\nDeep knowledge of data ingestion strategies and understanding of the V-dimensions of data (velocity, volume, variety, veracity)\nExtensive experience with the Azure storage technologies (Azure Data Lake, Azure SQL Data Warehouse, Azure SQL Database)\nExtensive experience with Azure data movement and transformation capabilities (Azure Data Factory, Data Lake Analytics, Data Bricks, Stream Analytics)\nProven experience developing Big Data solutions in the Azure space\nSQL Server 2014+ experience.\nComfortable with Microsoft SQL data technologies (SSAS/SSIS/SSRS)\nProven ability to work with clients to understand requirements and envision data ingestion solutions\nPossess DoD Directive 8140 security certification\nDesirable Skills\nMicrosoft related certifications such as the MCSD/MCSE\nExperience with Hadoop-based technologies (HDInsight, Spark, Hive, Pig, Scala, etc.)\nExperience with visualization tools such as Power BI or Tableau\nAbout AIS\n\n\nAIS, Dedicated to Our People\n\n\nAIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee\u2019s success; however, they define it.\n\nIt\u2019s our dedication to community that has committed us to become a 100% employee-owned company. Our employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology.\n\nWe hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today.\n\nWe Invest in Individuals Committed to Innovation\n\n\nAIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals. We are looking for:\nSmart people with a passion for technology\nStrong technical capabilities with a consultancy mindset\nClose involvement with local technical communities\nA willingness to think outside of the box to provide innovative solutions to clients\nAbility to solve challenging technical business problems\nSelf-directed professionals\nOur Core Values\nClient Success\nContinued Learning and Technical Excellence\nStrong Client Relationships\nCitizenship and Community\nReady to Be Part of the AIS Team?\n\n\nIf AIS sounds like the kind of place you\u2019d like to grow into your dream job, take the first step and click on the button below to apply.\n\nOur application process is quick and easy:\nAfter applying, you\u2019ll hear from an AIS Talent Associate via email and/or phone\nNext, one of your future peers will conduct a technical assessment to evaluate your capabilities\nThen, you\u2019ll have an opportunity to meet our team\nIf your skill sets and qualifications align with our core capabilities, we\u2019ll extend an offer for you to join our AIS Team!\n\nApplied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status or any other basis covered by law. Employment decisions are based solely on qualifications merit, and business need.\nStart your job application: click Apply Now"}, "686": {"company": "Fareportal Inc.", "description": "(We are not sponsoring for this role or in the future)\n\nAt Fareportal, we create technology that is driving innovation in the travel industry - one of the world's fastest-growing sectors. Our employees are the core of our organization and together we're revolutionizing the way people book travel.\n\nOur portfolio of brands including CheapOair and OneTravel receive over 100 million visitors annually and drive over $4 billion in annual revenue.\n\nWe are looking for a Lead Machine Learning Engineer/Data Scientist to join our team. You will be handling hundreds of millions of events per day, responsible for creating and supporting machine learning models that will drive our business.\n\nMachine Learning Engineers is at the heart of how Fareportal works and they are part software engineer and part machine learning / data scientist. You will focus on creating and supporting large scale models that we deploy to power our recommendation, pricing or other systems. The ideal candidate will participate in the design and implementation of the entire model pipeline, from project ideation, figuring out which data to capture and store, coming up with features, to creating the final model.\n\nWe are passionate about making data-driven decisions and you will have the opportunity to shape the team's direction and create large impact.\n\nOur team loves Python and Scala (and is not afraid of Functional Programming) and we strongly encourage DevOps approaches.\n\nResponsibilities:\nLead a team of machine learning engineers, data scientist, data engineers\nSupport our data modeling efforts to ensure we are capturing the data needed to improve our modeling capabilities.\nCreate features for our feature store\nBuild machine learning models\nUse a variety of techniques including predictive modeling, recommendation engines, revenue management, conversion rate optimization, and site and user experience optimization.\nOur ideal candidate:\n\nWho You Are\nYou are smart and love to build systems that are well tested as well as flexible\nYou like being around smart people who will challenge you on a daily basis.\nYou love to ramp up on new technologies to build awesome things with us!\nPassionate about working with large unstructured and structured data sets and developing new approaches to relevance problems\nYou like to share your knowledge and guide other fellow data scientist and engineers\nRequirements\n5+ years' experience developing, maintaining, and testing machine learning models.\nA strong technical advocate with a background in Java, Scala, or Python. Preferably familiar with Jupyter notebook environments and Spark or pySpark.\nStrong understanding of the machine learning tooling for either Python or Scala (e.g. Pandas, XGBoost, Spark)\nStrong understanding of machine learning\nNice to have\nExperience with CI/CD infrastructure and a strong supporter of unit / integration testing\nApply Now: click Easy Apply"}, "687": {"company": "Revel IT", "description": "Data Analyst. We have a contract need (or contract-to-hire) for a Data Analyst who will utilize industry standard tools and query languages to lead the collection, analysis and understanding of data within operational data repositories, data warehouses and Business Intelligence solutions. The role will act as a data and Business Intelligence subject matter expert and work closely with business stakeholders to collect requirements and map out short and long-term plans for data and Business Intelligence solutions.\n\nEssential Functions:\n40%: Lead and participate in cross-functional teams to transform business needs into requirements for data and business intelligence solutions.\n20%: Create data dictionaries, metadata, and/or ad-hoc reporting to document findings and share understanding of clients' data assets.\n10%: Work with business partners and IT teams to research and analyze data quality issues and identify and prioritize solutions.\n20%: Analyze and develop data models to ensure that data structures appropriately support business requirements.\n10%: Proactively identify opportunities to use business intelligence solutions to better support business management and/or improve efficiency of tools.\nRequirements\nEducation Level: Bachelor's Degree in Computer Science, MIS, Information Management, Engineering or related technical field of study\n6+ years of IT experience in a data management, Business Intelligence, or data quality role.\nAdvanced experience developing requirements for operational reporting systems, data warehouse systems, reports, and dashboards.\nAdvanced experience in Metadata Management/Data Dictionary management.\nAdvanced SQL skills is required; Experience with Oracle PL/SQL is a plus.\nExperience integrating and transforming structured and unstructured data using tools such as Informatica.\nExperienced using a variety of reporting, data analysis, and data visualization tools, such as Tableau, SAP BusinessObjects, SAS, custom dashboards.\nExceptional ability to visually present and communicate data, analyses and findings.\nExperience with a variety of software development methodologies (Waterfall, Agile, etc) will be a plus.\nMust be skilled at translating technical terms for a non-technical audience, and non-technical terms for a technical audience.\nAdvanced experience creating and managing enterprise data models\nAdvanced experience presenting and communicating findings/recommendations to cross-functional teams and/or leadership.\nMust possess strong data analysis, debugging and problem solving skills and a demonstrated ability to identify root causes.\nBusiness acumen and ability to understand complex business processes in a fast-paced environment.\nAbility to coach and develop less experienced personnel.\nAbility to take lead role in small projects or smaller efforts of larger projects.\nRevel IT (formerly known as Fast Switch) is one of the fastest-growing, privately held, IT Staffing companies in the nation. Our client base includes 32% of the Fortune 25.\n\nWe have major offices in Dublin, OH, Phoenix, AZ, Los Angeles, CA, and Austin, TX and are rapidly expanding into new markets from coast to coast.\n\nOur reputation is one of straight talk, creative solutions, aggressive pricing, and flawless execution ... outperforming the giants of our industry every day. We embrace the strategy inferred in Winston Churchill's famous quote, \"The short road to ruin is to emulate the methods of your adversary.\" At Revel IT, we are constantly asking ourselves, \"Is there a better way?\" Almost every day, we answer, \"Yes.\" #revelitjobs\nTo apply to this job, click Easy Apply"}, "688": {"company": "PwC", "description": "PwC Labs is focused on standardizing, automating, delivering tools and processes and exploring emerging technologies that drive efficiency and enable our people to reimagine the possible. Process improvement, transformation, effective use of innovative technology and data & analytics, and leveraging alternative delivery solutions are key areas of focus to drive additional value for our firm.\n\nThe AI Lab focuses on implementing solutions that impact efficiency and effectiveness of our technology functions. Process improvement, transformation, effective use of technology and data & analytics, and leveraging alternative delivery are key areas to drive value and continue to be recognized as the leading professional services firm. AI Lab is focused on identifying and prioritizing emerging technologies to get the most out of our investments.\n\nTo really stand out and make us ?t for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\n\nAs a Manager, youll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nPursue opportunities to develop existing and new skills outside of comfort zone.\nAct to resolve issues which prevent effective team working, even during times of change and uncertainty.\nCoach others and encourage them to take ownership of their development.\nAnalyse complex ideas or proposals and build a range of meaningful recommendations.\nUse multiple sources of information including broader stakeholder views to develop solutions and recommendations.\nAddress sub-standard work or work that does not meet firms/clients expectations.\nDevelop a perspective on key global trends, including globalisation, and how they impact the firm and our clients.\nManage a variety of viewpoints to build consensus and create positive outcomes for all parties\nFocus on building trusted relationships.\nUphold the firms code of ethics and business conduct.\n\nJob Requirements and Preferences:\nBasic Qualifications:\n\nMinimum Degree Required:\nBachelor Degree\n\nAdditional Educational Requirements:\nIn lieu of a Bachelor Degree, 12 years of professional experience involving technology-focused process improvements, transformations, and/or system implementations.\n\nMinimum Years of Experience:\n5 year(s)\n\nPreferred Qualifications:\n\nDegree Preferred:\nMaster Degree\n\nPreferred Fields of Study:\nAnalytics, Artificial Intelligence and Robotics, Business Analytics, Computer and Information Science, Computer Engineering & Accounting, Management Information Systems, Mathematics\n\nCertification(s) Preferred:\nPMI Certified, Agile Certified Scrum Master\n\nPreferred Knowledge/Skills:\nDemonstrates extensive knowledge and/or a proven record of success in applied subject matter such as IT, finance, accounting, energy or health care role emphasizing data analytics, including the following areas:\nUnderstanding of NoSQL (Graph, Document, Columnar) database models, XML, relational and other database models and associated SQL;\nUnderstanding of ETL tools and techniques, such as tools like Talent, Mapforce, how to map transformation and flow of data from a source to a target system;\nPerforming in development language environments: e.g. Python, Java, Scala, C++, R, SQL, etc. and applying analytical methods to large and complex datasets leveraging one of those languages;\nApplying statistical modelling, algorithms, data mining and machine learning algorithms problem solving;\nManaging business development such as client relationship management and leading and contributing to client proposals;\nDelivering and tracking successfully large-scale projects, including ownership of architecture solutions and managing change;\nLeading, training and working with other data scientists in designing effective analytical approaches taking into consideration performance and scalability to large datasets;\nManipulating and analyzing complex, high-volume, high-dimensionality data from varying sources;\nDemonstrating proven ability with NLP and text based extraction techniques;\nDeveloping data science analytic models and simultaneously operationalizing these models so they can run in an automated context; and,\nUnderstanding of machine learning algorithms, such as k-NN, GBM, Neural Networks Naive Bayes, SVM, and Decision Forests. Demonstrates extensive abilities and/or a proven record of success in the application of statistical or numerical methods, data mining or data-driven problem solving, including the following areas:\nUnderstanding of NoSQL (Graph, Document, Columnar) database models, XML, relational and other database models and associated SQL;\nUnderstanding of ETL tools and techniques, such as tools like Talent, Mapforce, how to map transformation and flow of data from a source to a target system;\nPerforming in development language environments: e.g. Python, Java, Scala, C++, R, SQL, etc. and applying analytical methods to large and complex datasets leveraging one of those languages;\nApplying statistical modelling, algorithms, data mining and machine learning algorithms problem solving;\nManaging business development such as client relationship management and leading and contributing to client proposals;\nDelivering and tracking successfully large scale projects; including ownership of architecture solutions and managing change;\nLeading, training and working with other data scientists in designing effective analytical approaches taking into consideration performance and scalability to large datasets;\nManipulating and analyzing complex, high-volume, high-dimensionality data from varying sources;\nDemonstrating proven ability with NLP and text based extraction techniques;\nUnderstanding of not only how to develop data science analytic models but how to operationalize these models so they can run in an automated context; and,\nUnderstanding of machine learning algorithms, such as k-NN, GBM, Neural Networks Naive Bayes, SVM, and Decision Forests.\nUtilizing and applying knowledge commonly used data science packages including Spark, Pandas, SciPy, and Numpy;\nDemonstrating familiarity with thorough learning architectures used for text analysis, computer vision and signal processing;\nUtilizing programming skills and knowledge on how to write models which can be directly used in production as part of a large scale system;\nUtilizing and applying knowledge of technologies such as H20.ai, Google Machine Learning and Deep learning;\nApplying techniques such as multivariate regressions, Bayesian probabilities, clustering algorithms, machine learning, dynamic programming, stochastic-processes, queuing theory, algorithmic knowledge to efficiently research and solve complex development problems and application of engineering methods to define, predict and evaluate the results obtained;\nDeveloping end to end deep learning solutions for structured and unstructured data problems;\nDeveloping and deploying A.I. solutions as part of a larger automation pipeline;\nUtilizing programming skills and knowledge on how to write models which can be directly used in production as part of a large scale system;\nUsing common cloud computing platforms including AWS and GCP in addition to their respective utilities for managing and manipulating large data sources, model, development, and deployment; and,\nVisualizing and communicating analytical results, using technologies such as HTML, JavaScript, D3, Tableau, and PowerBI.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nTo apply to this job, click Apply Now"}, "689": {"company": "AstraZeneca", "description": "Sr. Data Scientist/Principal Data Scientist, Oncology\n\nThe Machine Learning and AI team in AstraZenecas Oncology Data Science group is where we develop and apply sophisticated algorithms and techniques to solve the hardest problems in oncology drug discovery and development. The team uses their scientific, quantitative, and problem-solving skills to work on a broad range of challenges across the whole oncology portfolio, working collaboratively with other scientists across a range of disciplines to scope, define, and deliver projects that both advance the state of the art in data science and accelerate the delivery of innovative medicines to patients.\n\nNOTE: This position can be filled in either GAITHERSBURG MARYLAND OR WALTHAM, MASSACHUSETTS\n\nAs a Senior Data Scientistor Principal Data Scientist, you will play a key role on the front line in this rapidly growing team working to extract insight from complex biomedical data. You will develop your leadership skills and apply and develop your expertise in rigorous quantitative data science to provide solutions to a variety of data science problems, researching, recommending and delivering novel methodologies to solve the problems that matter to the oncology pipeline.\n\nExamples of projects the team works on include developing machine learning models for digital biomarkers, patient risk stratification for clinical trials, new algorithms for survival analysis, approaches to quantitatively analyse wearable data, linking of medical imaging data with omics and longitudinal outcomes to identify and/or validate new drug targets, and much more!\n\nThe level of the position will be determined by the candidates experience, skills and education.\n\nTypical Accountabilities\n\nFor our Sr. Data Scientist you will typically be accountable for:\nProviding advanced data science and machine learning expertise to AstraZeneca projects, researching and recommending data science solutions, and appropriately communicating with non-technical stakeholders.\nCollaborating in a multidisciplinary environment with world leading clinicians, data scientists, biological experts, statisticians and IT professionals.\nPublishing your work to ensure that AstraZeneca drives the data science agenda in the pharmaceutical industry.\nFor our Principal Data Scientist you will additionally be accountable for:\nDeveloping novel data science and machine learning solutions where off-the-shelf methodologies do not fit.\nLeading small (2-3 person) data science projects of defined scope.\nCoaching/mentoring junior data scientists and others to drive the development of data science as an AZ capability.\nEducation, Qualifications, Skills and Experience\n\nEssential for our Sr. Data Scientist\nMSc degree in rigorous quantitative science (such as mathematics, computer science, engineering)\nPractical software development skills in standard data science tools (such as R or python)\nKnowledge of range of mathematical and statistical modelling techniques, and drive to continue to learn and develop these skills.\nDesirable\nPhD degree in rigorous quantitative science (such as mathematics, computer science, engineering)\nExperience within the pharmaceutical industry\nOutstanding communication, business analysis and consultancy\nEssential for our Principal Data Scientist\nMSc degree in rigorous quantitative science (such as mathematics, computer science, engineering)\nExtensive hands-on experience applying data science tools in practice.\nPractical software development skills in standard data science tools (such as R or python)\nExtensive knowledge of mathematical modelling and statistical modelling techniques and drive to continue to learn and develop these skills\nOutstanding communication, business analysis and consultancy\nDesirable\nPhD degree in rigorous quantitative science (such as mathematics, computer science, engineering).\nExperience within the pharmaceutical industry.\nIn-depth experience of working in a global organization with complex/geographical context\nTo apply to this job, click Apply Now"}, "690": {"company": "OSI Engineering", "description": "JOB DESCRIPTION:\nSummary\nAs the Data Scientist on the Experience Research Team you will bring the power of our data to our team.\nThe analytics you deliver will strategically advance how Client ideates, builds, measures, and improves its own products.\nYou will use your quantitative skills to analyze disparate user data sources (e.g., NPS, Social Media, Behavioral data, Product feedback, User reported data) to present comprehensive views of user experience.\n\nWhat Success Looks Like in the Role\nYou inspire those around you to be obsessed with data and the stories you can tell. You love turning data into insights. You thrive when people take-action on the insights you provide. You work effectively cross-team and you understand the importance of building strong relationships and earning trust and credibility. You have successfully helped this organization harness the power to tell our own stories with our own data.\nIdeal years of Experience: 3-5 years\n\nResponsibilities\nDesigns, develops and programs methods, processes, and systems to consolidate and analyze unstructured, diverse \u201cbig data\u201d sources to generate actionable insights and solutions to support our own programs.\nInteracts with product and teams to identify questions and issues for data analysis and experiments.\nDevelops and codes software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources.\nIdentifies meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments.\nBe an internal leader in basic statistics including descriptive statistics, correlation and regression.\n\nMust have skillsets:\n\u2022 3+ years work experience\n\u2022 Strong quantitative analytical skills; with statistical analysis competence in techniques such as correlation, regression, KPI metric development, segmentation modeling and algorithms\n\u2022 Fluent in either Python or R, able to query data using SQL, has experience working with cloud based computing platforms and big data tools.\n\u2022 Experience in data mining, advanced data manipulation, machine learning and statistical analysis.\n\u2022 Experience with data visualization and communication projects using software like Tableau\n\u2022 Strong verbal and written communication skills to present analysis and insights including trends and opportunities to stakeholders and the business\n\u2022 Believes in eating one's own dog food and using that experience to drive the creation of exceptional customer facing products\n\u2022 High standard of detail, excellence, professionalism, and role model behavior\n\u2022 Master\u2019s Degree in Business Analytics, Data Analytics, or Data Science, with a BA/BS in Economics, Finance, Management, Marketing or Social Science\n\nCONTACT INFORMATION:\nAlan Bui\nAlan@OSIengineering.com\n408-550-2800 x 106\nOSIJOBS\nStart your job application: click Easy Apply"}, "691": {"company": "Regeneron", "description": "Known for its scientific and operational excellence, Regeneron is a leading science-based biopharmaceutical company that discovers, invents, develops, manufactures, and commercializes medicines for the treatment of serious medical conditions. Regeneron commercializes medicines for eye diseases, high LDL-cholesterol, atopic dermatitis and a rare inflammatory condition and has product candidates in development in other areas of high unmet medical need, including rheumatoid arthritis, asthma, pain, cancer and infectious diseases.\n\nThe Molecular Profiling group is looking for a talented data scientist with experience in genomic data analysis and algorithm development. The scientist will analyze preclinical and clinical data to support target and biomarker discovery & validation, as well as develop statistical and computational methods to advance our understanding of complex biological systems.\nDevelop computational methodologies to integrate and model multi-modal data to help address the gap in understanding new molecular biology.\nWork with leadership to identify novel therapeutic targets and biomarkers via mining proprietary pre-clinical and clinical data.\nDevelop data analysis pipelines and establish data analysis best practices for emerging genomic technologies.\nCollaborate with colleagues in research to design experiments and define data analysis plans.\nCommunicate results with collaborators, refine analysis based on feedback.\nPrepare clear, concise and easy-to-understand presentations and documentations for collaborators, senior management and government agencies.\n#LI-GP1\n\nRequirements:\nPhD + 0-3 years minimum in computational biology, biomedical engineering, bioinformatics, applied mathematics, or related quantitative field, with a track record of high quality publications\nExperience in analysis, interpretation, and visualization of sequencing data (e.g. bulk/single-cell RNA-seq, CRISPR screening)\nExpertise in statistical data analysis and algorithm development\nHigh proficiency in analytical and programming tools such as Python and R, and their associated packages for statistics, modeling and visualization\nHands-on experience in machine learning, predictive modeling, and/or image analysis is highly preferred\nFamiliarity with Unix/Linux, shell scripting, SGE clusters, AWS environment\nProven problem-solving skills and collaborative nature in fast-paced environment.\nAbility to work both independently and collaboratively\nExcellent communication and presentation skills\nThis is an opportunity to join our select team that is already leading the way in the Pharmaceutical/Biotech industry. Apply today and learn more about Regenerons unwavering commitment to combining good science & good business.\n\nTo all agencies: Please, no phone calls or emails to any employee of Regeneron about this opening. All resumes submitted by search firms/employment agencies to any employee at Regeneron via-email, the internet or in any form and/or method will be deemed the sole property of Regeneron, unless such search firms/employment agencies were engaged by Regeneron for this position and a valid agreement with Regeneron is in place. In the event a candidate who was submitted outside of the Regeneron agency engagement process is hired, no fee or payment of any kind will be paid.\n\nRegeneron is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability status, protected veteran status, or any other characteristic protected by law.\n\n#LI-GP1\nTo apply to this job, click Apply Now"}, "692": {"company": "Opcity", "description": "The home search starts online, but the real estate industry is often optimized for in-person, one-on-one service. That's a fantastic experience once you connect with the right professional, but finding the right fit isn't always a smooth process. Opcity built a nationwide real-time data and technology platform combining cutting edge deep learning, business analytics and human intuition with the latest web, mobile and digital telephony technologies to enable our team of professionals, and thousands of real estate agents and brokers, to make sure we connect every home buy with the right agent at the right time so more time is spent finding a home and less time finding the perfect agent.\n\nWe are looking for a self-starting data scientist to tackle some of the most interesting problems in the real estate space. As a Data Scientist here at Opcity/ Realtor.com you will help define and build the Opcity/ Realtor.com recommendation system from the ground up. You will have the freedom to test and explore the data where any decision will have an immediate visible impact.\nAn ideal candidate should be able to tackle a new problem space with minimal guidance. They should have the drive and ability to meet with relevant stakeholders, understand and model relevant data, and effectively communicate with an engineering team to put models into production. They should also be demonstrated lifelong learners and team players; willing to take advice and fill gaps in their knowledge when required.\nData Scientist Responsibilities\nWork with Data Scientists, Product Managers, and all other relevant stakeholders to frame a problem, both mathematically and within the business context\nConstruct and fit statistical, machine learning, or optimization models\nPerform exploratory data analysis to gain a deeper understanding of the problem\nWrite production modeling code; collaborate with Software Engineers to implement algorithms in production\nAnalyze experimental and observational data; communicate findings; facilitate launch decisions\n\nData Scientist Experience and Skills\nM.S. or Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, or other quantitative field or a B.A./B.S. with 3+ years professional or research experience\nProficiency with SQL\nProficiency with Python\nMatching and recommendation algorithms\nEnd-to-end experience with data, including querying, aggregation, analysis, and visualization\nFamiliarity with Bayesian techniques\nPassion for solving unstructured and non-standard mathematical problems\nWillingness to collaborate and communicate with others to solve a problem\n\nDiversity is important to us, therefore, Opcity/Realtor.com is an Equal Opportunity Employer regardless of age, color, national origin, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, marital status, status as a disabled veteran and/or veteran of the Vietnam Era or any other characteristic protected by federal, state or local law. In addition, Opcity/Realtor.com will provide reasonable accommodations for otherwise qualified disabled individuals.\nTo apply to this job, click Apply Now"}, "693": {"company": "Fareportal Inc.", "description": "(We are not sponsoring for this role now or in the future)\n\nPeople are at the core of Fareportal. We are one of the fastest growing travel technology companies in the world; our portfolio of travel brands, including flagship product CheapOair, receives over 100 million visitors annually.\n\nWe are seeking an Business Intelligence Analyst to extract and present meaningful data in order to understand our customers and drive opportunities to enhance customer experience and drive conversion. The ideal candidate will be responsible for performing data analysis and reporting to support strategic objectives. The right person will have a proven history of proactively addressing unasked questions through data and presenting solutions to top management in order to improve systems and processes.\n\nResponsibilities:\nAnalyze customer data from a variety of sources using database querying tools\nVisualize data and generate insights to help improve the business\nSupport a wide variety of departments and product teams\nCollaborate with the Product Owner to identify data sources of truth to support business decisions\nInterface with entire IT Chapter (data science, BI, IT operations, IT engineering, IT Security)\nEfficiently manage the backlog and delivery of analytical projects\nEstablish processes and SLA for Development & IT Chapters\nCreate and monitor real-time performance dashboards for key business metrics\nImplement alerting systems to quickly identify issues, notify stakeholders, and coordinate to resolve the issues.\nRequirement\nBA degree, Computer Science, Information, engineering\nMinimum 2-3 years' work or internship experience with business or data analysis\nData modeling, Statistical Analysis, Sensitivity analysis (Mathematical modeling)\nCritical thinking and problem solving skills\nUnderstanding of database structure, design, query languages (e.g. SQL), Advance Excel Skills\nRelational databases and querying such as Microsoft SQL Server, Oracle Database, or MySQL\nExperience with visualization and dashboard tools such as Power BI or Tableau\nA Plus\nStrong PowerPoint presentation skills\nExperience with BI Reporting tools such as Tableau, PowerBi, Business Objects, and/or Microstrategy\nUnderstanding of Google Analytics\nExperience with Python or R\nApply Now: click Easy Apply"}, "694": {"company": "NICE inContact", "description": "Data Science Intern\nLocation: Salt Lake City, UT\n\nPrimary Purpose\n\nAs our Data Science intern, you\u2019ll wrangle data to support research and development projects as part of NICE inContact's analytics platform. You\u2019ll work closely with the Natural Language Understanding Team and be mentored by a Senior Computational Linguist for the duration of your internship.\n\nMajor Functions/Responsibility\nBuild scripted tools to support proprietary NLU development for business insights\nPrepare data from multiple sources for analysis, including \u201cnoisy\u201d data\nProvide computational linguist stakeholders with statistics and data samples upon request\nAnalyze data for quality and general interpret-ability by non-technical audiences\nProvide peer review to other coders on the team\nEducation Requirement:\n\nCompletion of upper level courses in Computer Science or Linguistics with knowledge of Python\n\nExperience Requirement:\nKnowledge of Python\nCompletion of projects demonstrating strong analytical skills and problem solving abilities\nFast learner\nExcellent communication skills\nAbility to work independently on Engineering tasks once requirements are established\nExperience Preferred:\nNatural language processing experience\nExperience with Git or Jupyter\nKnowledge of Pandas\nComputational or Theoretical Linguistics\nForeign language proficiency\nThis job description is not intended to be all-inclusive, and employees will also perform other reasonable related business duties as assigned by immediate supervisor and other management as required.\n\nThis organization reserves the right to revise or change job duties as the need arises. This job description does not constitute a written or implied contract of employment.\n\nABOUT NICE inContact: NICE inContact makes it easy and affordable for organizations around the globe to provide exceptional customer experiences while meeting key business metrics. NICE inContact provides the world\u2019s #1 cloud customer experience platform, NICE inContact CXone\u2122, combining best-in-class Omnichannel Routing, Workforce Optimization, Analytics, Automation and Artificial Intelligence on an Open Cloud Foundation. NICE inContact is a part of NICE (Nasdaq: NICE), the worldwide leading provider of both cloud and on-premises enterprise software solutions.\nStart your job application: click Apply Now"}, "695": {"company": "Ericsson-Worldwide", "description": "Date: Nov 12, 2019\n\nEricsson Overview:\n\nEricsson is world\u2019s leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.\n\nUsing innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planet\u2019s greatest challenges.\n\nWe are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have the freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.\n\nJob Summary:\n\nResponsibilities:\nPartner with Ericsson\u2019s machine intelligence (MI) team to prioritize and answer the most important questions where machine learning and AI breakthroughs will have material impact\nUse your experience in analytics tools and scientific rigor to produce actionable insights. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical model, deep learning, reinforcement learnings and other machine learning systems\nCollaborate with business leaders, subject matter experts, and decision-makers to develop success criteria and optimize new products, features, policies, and models\nMentor junior data scientists on technologies, methodologies and best practices\nDevelop methodologies, standards/best-practices and systems for reusable MI assets across Ericsson businesses\nDevelop and nurture MI communities within Ericsson and its ecosystem in the areas of expertise\nCollaborate with others on the best way to document and present the findings and experiments of the data analysis, including benchmarking against (de-facto) industry standards and baselines, to the stakeholders\nCollaborate with product development teams to industrialize the findings\nCommunicate key results to senior management in verbal, visual, and written media\nEngage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MI\u2019s needs\nPresent and be prominent in Machine learning related forums and conferences, e.g., presenting papers, organizing sessions and be a Panelist\nTechnologies we use and teach:\nR, Python\nHive and other Bigdata family\nStatistics (Frequentist/Bayesian methods, experimental design, causal inference)\nShiny/D3/Tableau, etc.\nKey Qualifications and Education:\nBS, MS, or PhD in Computer Science, Mathematics, Physics, Economics, or related field\n3 to 5 years\u2019 experience and knowledge in Statistics, e.g., hypothesis formulation, hypothesis testing, descriptive analysis and data exploration.\nDemonstrated skills in Machine Learning, e.g., linear/logistics regression discriminant analysis, bagging, random forest, Bayesian model, SVM, neural networks, etc.\nStrong Programming skills in various languages (C++, Scala, Java, R)\nStrong skills in the use of current state of the art machine learning frameworks such as Scikit-Learn, H2O, Keras, TensorFlow, and Spark\nAbility to clearly communicate complex results to technical and non-technical audiences\nVersatility and willingness to learn new technologies on the job\nAdditional Skills a Plus:\nCertification: Machine Learning MOOCS\nFamiliarity with Linux/OS X command line, version control software (git), and general software development\nExperience in programming or scripting to enable ETL development\nFamiliarity with relational databases\nPrevious industry experience or internships in product related analytics\nIndependent research experience\nDISCLAIMER: The above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of employees assigned to this position. Therefore employees assigned may be required to perform additional job tasks required by the manager.\n\nWe are proud to be an EEO/AA employer M/F/Disabled/Veterans. We maintain a drug-free workplace and perform pre-employment substance abuse testing.\n\nEricsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, protected veteran status, union membership or genetics information. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact.\n\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development.\n\nEricsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, gender identity, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, protected veteran status, union membership or genetic information.\n\nEricsson will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by Ericsson or (c) consistent with Ericsson\u2019s legal duty to furnish information.\n\nEmployee Polygraph Protection Act Notice - Employers are generally prohibited from requiring or requesting any employee or job applicant to take a lie detector test, and from discharging, disciplining, or discriminating against an employee or prospective employee for refusing to take a test or for exercising other rights under the Act. For more information, visit https://www.dol.gov/whd/regs/compliance/posters/eppac.pdf.\n\nEricsson is an equal opportunity employer and is committed to providing reasonable accommodation for qualified disabled individuals during the application and hiring process. Ericsson will make modifications or adjustments to the job application or interview process that will enable a qualified applicant to be considered for a position. If you require an accommodation due to a disability, please contact Ericsson at hr.direct.dallas@ericsson.com or (866) 374-2272 (US) or (877) 338-9966 (Canada) for further assistance.\n\nPrimary country and city: United States (US) || || Plano || ServEng\nStart your job application: click Apply Now"}, "696": {"company": "Assurance Careers", "description": "About Assurance\nAt Assurance we are disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosystem. We are rapidly growing as we expand our product offerings and global footprint, and this growth continues to present new and exciting challenges as we push our industry into its future. We eliminate waste throughout the industry and calculate the complex into simple, valuable solutions to improve people's lives. We are humble, driven, and committed to improving the lives of millions.\n\nAbout the Position\nAs we build the future of consumer insurance in a modern age, data and machine learning are at the core of everything that we do. The role requires team members who take insights, actions, and models from our data scientists and translate that into software products that enable business optimization. We currently have more than 40 models in production and are doing about 5 million real-time predictions per day. Our team uses a variety of data mining and analysis methods, uses a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Our ML Engineers design and build the prediction services that makes this development possible with no support from engineering (we own our stack end to end). At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise.\nTo be successful in this role, you must possess the following:\nA drive to move fast and deliver business value.\n4+ years of backend software engineering in a team environment.\nExperience writing and debugging complex database queries and code.\nAbility to quickly learn new technologies to help the team explore new solutions.\nExcellent communication ability \u2013 you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.\nBusiness Acumen \u2013 you are always eager to understand how the business works, and more specifically, how your work impacts the business.\nMentorship of others \u2013 you raise the bar on coding standards and providing meaningful feedback on code changes.\nEnthusiastic yet humble nature \u2013 you are excited about the work you do, but you are also humble enough to embrace feedback \u2013 you don\u2019t need to be the smartest person in the room.\nThe following additional experience is desired:\nExperience with writing production-level Python.\nUnit and integration testing.\nUse of cloud technologies (AWS, GCP, Azure).\nParticipate in agile methodologies (daily standup, sprint planning, retros).\nProfiling and performance tuning of production code a bonus.\nDirect experience with using ML libraries like sklearn, or Spark ML in a production environment a huge bonus!\nWe\u2019re changing the world of consumer insurance and financial services everyday through the power of Machine Learning and Data Science \u2013 join us on the journey!\nStart your job application: click Apply Now"}, "697": {"company": "Esquire Recruiting", "description": "Senior Marketing Data Analyst | Real Estate-Property Management | Chicago, IL Our highly successful real estate asset management firm is hiring an experienced Senior Marketing Data Analyst in their Chicago HQ office. will hold responsibility for the development and management of reporting for global marketing trends, channel performance for both traditional and digital environments, financial analysis, and vendor performance in support of the marketing department, asset management, supporting departments and BX. This role will manage preferred partner (vendor) relationship and participate in the vetting and selection of these partners in support of the Marketing Director. The Sr. Marketing Data Analyst will report on financial performance of marketing spend and ROI as well as manage accounting and GL related procedures. Our client is offering a very competitive salary (to $85,000), plus bonus and comprehensive benefit package.\n\nSend resume and cover letter to: shay@esquire-recruiting.com\n\nBenefits:\n\nExcellent Benefit Package\n\nCompensation:\nTo $85,000 plus bonus\nResponsibilities:\nProvide reporting in a timely and accurate manner to marketing director, asset managers, executive leadership and other key stakeholders as may be determined.\nCommunicate analyses to key stakeholders within LivCor so that informed key strategic decisions may be made.\nManage reporting of marketing channel performance as related to cost per lead, cost per lease, conversion performance, and channel selection.\nExtract, analyze, and report on digital marketing performance though Google Analytics, digital marketing reports and systems, and data site-crawl tools.\nDevelop and support the marketing department budget structures and general support of annual asset budget review, analysis, and adjustment.\nManage day to day accounting processes as related to marketing department managed GLs including, but not limited to, chart of accounts mapping, reclassing of expenses, and relationship management with external accounting team.\nMaintain marketing department reporting structures and tools including, but not limited to, Oracle PBCS, Real Page BI, Rentlytics, Siteimprove, and Google Analytics.\nRetrieve and analyze financial and operational data from, Oracle PBCS, Rentlytics, Real Page BI, Yardi, YieldStar, OneSite, Axiometrics, and other sources as may be determined.\nMaintain subject matter expertise in topics including, but not limited to, digital marketing, website analytics, website structure support, industry standard technologies, etc.\nManage a platform, reporting, and action strategy for online reputation management at a portfolio, operating partner, and other grouped levels.\nDevelop productive working relationship with primary customer/end user of information to include the asset managers, department heads, operating partners and other key stakeholders.\n\u00b7Perform special ad hoc projects and analysis on a frequent basis.\nPlay primary role in management of marketing preferred technology providers as well as supporting the marketing director in the analysis and vetting of new and alternative preferred technology providers and vendors.\nManage the tactical deployment of preferred vendor systems and initiatives across assets and various operating partners.\nDevelop and manage vendor performance reporting.\nSome travel required. Travel would be oriented around vendor relationships and industry related conferences/knowledge acquisition opportunities\nRequirements (Required):\nA minimum of three (3) years\u2019 work experience in data analysis and digital/traditional marketing.\nThorough understanding of digital marketing technologies, IP targeting, re-targeting, GEO fencing, email campaigns and digital nurturing campaigns\nStrong analytical skills with a deep knowledge of and mastery of Excel.\nA strong work ethic, the strength to thrive in a dynamic and demanding work environment and an ability to meet critical deadlines.\nExcellent oral and written communication skills as well as design-oriented report development experience.\nRequirements (Preferred):\nPrior marketing agency experience and/or multifamily marketing management.\nPrior experience with real estate budgeting/forecasting processes and systems.\nExperience working at a publicly traded real estate, institutional financial services, or public/private equity firm preferred. In addition, experience in REIT performance metrics and reporting preferred.\nWork Hours: 9:00 to 5:00\nApply Now: click Easy Apply"}, "698": {"company": "Gusto", "description": "Gusto is looking for experienced data scientists with expertise in building and deploy predictive models and algorithms in order to help us grow, prevent fraud, control financial risk, and deliver products that help our customers build great places to work.\n\nThe Data Science team leverages Gusto's data to deliver data-informed insights for our customers and guide product direction and decision-making. We operate full-stack, conducting analyses, prototyping and deploying predictive models and statistical tools both for internal use and for our customers. Here are a few areas where we contribute today:\nRisk and Fraud - Gusto processes >$10B of payroll annually, so preventing fraud on our platform is critical for our survival. We also expedite payments for many of our customers, and with new features like Flexible Pay, we gives employees the freedom to choose their own pay schedule and get paid as soon as the next day for the hours they've already worked. We work with our Risk teams to build and deploy models for fraud prevention and underwriting our payment programs.\nGrowth - We work with our Marketing, Sales and Growth teams to help, from predictive models of lead and customer value to providing upsell and cross-sell recommendations.\nGreat Places to Work - Gusto pays hundreds of thousands of employees as small businesses all over the US. We are working with our Product teams to leverage this valuable payroll, benefits and HR data to build features that help our customers build great places to work.\nHere's what you'll do day-to-day:\n\n\nBuild and deploy models and data products to support growth, prevent fraud, control risk and delight our customers.\nEnhance and contribute to the team's core analysis and modeling systems and libraries\nIdentify new opportunities to leverage data to improve Gusto's products and help our business\nPresent and communicate results to stakeholders across the company\nHere's what we're looking for:\n\n\nAt least 5 years experience conducting statistical analyses on large datasets, ideally in a business context (can supplement with academic experience where appropriate)\nExperience applying a variety of statistical and modeling techniques using Python, R or another statistical modeling language, as indicated by familiarity with many of the following techniques - generalized linear modeling, regularization, ensemble models (e.g., random forest, gradient boosting), Bayesian analysis methods\nStrong programming skills - comfortable with all phases of the data science development process, from initial analysis and model development all the way through to deployment\nExcellent communication skills - able to effectively deliver findings and recommendations to non-technical stakeholders in a clear and compelling fashion\nPhD or Masters plus equivalent experience in a quantitative field\nExperience applying predictive modeling to fraud, credit or growth problems is a plus.\nAbout Gusto\n\n\nOur customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto.\n\nGusto is a modern, online people platform that helps small businesses take care of their teams. On top of full-service payroll, Gusto offers health insurance, 401(k)s, expert HR, and team management tools. Today, Gusto offices in Denver, San Francisco, and New York serve more than 100,000 businesses nationwide.\nApply Now: click Apply Now"}, "699": {"company": "OSI Engineering", "description": "JOB DESCRIPTION:\nSummary\nWill work alongside RnD staff to extract, process, plot and interpret data collected from variety of chemical and sensor experiments. Data may also come from deployed sensor networks.\n\nRequired Skillsets\n\u2022 Seeking 1-5 years of experience in Data collection and analytics\n\u2022 BS or equivalent in CS, Electrical Engineering, Data Sciences. Candidates should have a range of courses on statistics, SPC and databases\n\u2022 Comfortable with python programming\n\u2022 Experience with JMP and interpreting / working with Matlab\n\u2022 Experience with Excel and Powerpoint would be desirable\n\u2022 A team player\n\nCONTACT INFORMATION:\nSandra Montes\nSandra@OSIEngineering.com\n220.2800 x 108\nOSIJOBS\nApply Now: click Easy Apply"}, "700": {"company": "Northrop Grumman", "description": "Are you interested in expanding your career through experience and exposure, all while supporting a mission that seeks to ensure the security of our nation and its allies? If so, then Northrop Grumman is the place for you. As a leading global security company, we provide innovative systems, products and solutions to our customers worldwide. We are comprised of diverse professionals that bring different perspectives and ideas, understanding that the more experiences we bring to our work the more innovative we can be. As we continue to build our workforce we look for people that exemplify our core values, leadership characteristics, and approach to innovation.\n\nNorthrop Grumman Corporation is seeking a Sr. Data Scientist to support the Office of the Deputy Undersecretary of the Army, Army Analytics Group's Research Facilitation Laboratory located in Monterey, CA.\n\nThe research team conducts advanced analytics and research support for U.S. Army and other DoD customers. The team works with administrative, personnel, survey, and medical data representing millions of individuals.\n\nProjects focus on health, resilience, and readiness among military service members, and include population-based studies, machine learning applications, measurement analysis, and pilot program evaluations.\n\nThe Data Scientist could support several projects.\n\nRole & Responsibilities:\n\nDevelop data mining and modeling plans; describe, explore, and verify data quality; select, clean, construct, integrate, and format data; select modeling techniques; generate training, testing, and validation designs; build and evaluate models; develop visualizations of model results.\n\nDevelop statistical models and methods to support predictive analytics to help senior leaders achieve and sustain individual readiness and optimize human performance.\n\nApply statistical, mathematical, and analytical techniques related to Health, Resilience, and Personal Readiness.\n\nProvide analysis and develop information papers, presentations, and other correspondence as required.\n\nPerform data consolidation, cleansing and analysis, and presents data from one or more source systems, cleansing and analysis, and presents data from one or more source systems.\n\n** This requisition may be filled at a higher grade based on qualifications listed below.\n\nBasic Qualifications:\n\nThis requisition may be filled at either a level 3 or a level 4.\n\nBasic Qualifications for a level 3 are:\nBachelors degree in a STEM related discipline, plus5 years applicable experience or a Master's with3 years experience applicable experience and/or a PhD with0 years experience; degree must be from an accredited college or university in Data Science, Statistics, Biostatistics, Applied Mathematics, Computer Science, Physics, Engineering, or other technical degree in a relevant field.\nBasic Qualifications for a level4 are:\nBachelors degree in a STEM related discipline, plus9 years applicable experience or a Master's with7 years experience applicable experience and/or a PhD with4 years experience; degree must be from an accredited college or university in Data Science, Statistics, Biostatistics, Applied Mathematics, Computer Science, Physics, Engineering, or other technical degree in a relevant field.\nThe Other Required Basic Qualifications Include:\nProficiency with data analysis\nExperience and proficiency with machine learning models, such as logistic regression, support vector machines, principal component analysis, clustering techniques (e.g., k-means, hierarchical), tree-based techniques, neural networks, and deep learning models.\nProficiency in Python\nSoftware Development Experience\nFamiliarity with databases and SQL.\nAbility to communicate results clearly and effectively.\nAbility to collaborate in a team environment.\nAbility to comprehend and analyze complex problems.\nU.S. Citizenship and the ability to obtain/maintain Department of Defense (DoD) Secret clearance is required.\nPreferred Qualifications:\n5+ years of experience and a Master's Degree in Data Science, Statistics, Biostatistics, Applied Mathematics, Computer Science, Physics, Engineering, or Psychology.\nDemonstrated experience in Deep Learning: DNN, CNN, RNNs (LSTM), GANs\nExperience in Natural Language Processing\nExperience working in anomaly or rare event detection.\nFamiliarity with developing data visualization products in tools such as Tableau.\nStrong data visualization skills.\nExperience working with DoD customers.\nExperience with operational machine learning pipelines\nExcellent written and oral communication.\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\nStart your job application: click Apply Now"}, "701": {"company": "Quartet Health", "description": "Company Description:\n\nQuartet is a healthcare technology company striving to improve the lives of people with mental health conditions and was ranked #29 of Modern Healthcare's 2019 Best Places to Work in Healthcare. We connect people to a personalized care team to get them the right care at the right time. Our collaborative technology platform and range of services brings together physicians, mental health providers, and insurance companies to effectively improve patient outcomes and drive down healthcare costs.\n\nBacked by $153MM in venture funding from top investors like Oak HC/FT, GV (formerly Google Ventures), F-Prime Capital Partners, Polaris Partners and Centene Corporation, Quartet is headquartered in NYC and is currently operating in several markets across the United States Pennsylvania, Washington, Northern California, New Jersey, North Carolina, Louisiana, and Illinois.\n\nRole Description:\n\nWe are looking for talented data scientists with a passion for addressing business needs through data modeling and analysis to join our team. As an individual contributor on this team, you will work side-by-side with senior members of the team and internal partners from across the organization. This position requires strong problem-solving, analytical and communication skills; experience with multitasking and prioritizing in a fast-paced environment; and the tenacity to execute against deliverables in a timely, high-quality fashion.\n\nAs a data scientist at Quartet, you will work on a range of projects -- developing statistical analyses to study impact of Quartet interventions; predicting mental health needs among populations; building machine learning models to suggest timely and appropriate behavioral health care interventions for patients. You'll develop a deep understanding of Quartet interventions and the predictive models and algorithms that enable effective integration of mental health into primary care to steer patients towards better health. You will learn and apply statistical methodologies to measure outcomes and impact of interventions.\n\nYou'll work with datasets that include millions of detailed medical, pharmacy, lab claims, EHR, and application data. You will help with development and validation of new algorithms that enhance our system in terms of scalability, reliability and accuracy.\n\nThe ideal candidate will be an entrepreneurial, motivated data scientist who is well-versed in data analysis and algorithm implementation and eager to learn new things and make an impact on the industry. Health data experience is a plus, but it's not necessary.\n\nResponsibilities:\nWork with an interdisciplinary technical team to develop statistical models in Quartet's platform.\nApply statistics, data mining, machine learning techniques to develop studies to evaluate patient outcomes and recommendations to meet patients' and doctors' needs.\nDesign and develop effective models, features, and algorithms involving multiple datasets - user activity, medical claims, pharmacy claims, lab test claims etc.\nDerive insights from descriptive analysis that drive a data-informed process for experimenting with new products to improve patient outcomes.\nLearn and contribute to team efforts to make our code scalable, our work output data-rich and actionable, and our research reproducible.\nQualifications:\n2-3 years experience as a data scientist.\nFormal training in statistics and computer science.\nKnowledge of mathematical fundamentals: probability theory, linear algebra and statistics.\nStrong data transformation and extraction skills with SQL databases.\nStrong statistical programming skills in both Python and R.\nComfort/self-sufficiency with Amazon Web Services infrastructure.\nComfort/self-sufficiency with Linux servers.\nComfort/self-sufficiency with git for version control.\nAbility to execute, starting from problem definition, to a working implementation.\nAbility to clearly communicate across disciplines and work collaboratively.\n\nEmployee Benefits for Quartet include: Unlimited vacation, volunteer opportunities, catered lunches, snacks, team events and outings, mental healthcare coverage of 15 free therapy sessions + unlimited copay reimbursements, medical, dental + vision coverage, generous parental leave, commuter benefits, 401K, stock option grants, gym benefits.\n\nWant to know what Quartet life is like? Click here to meet our team.\n\nQuartet is committed to building a diverse team and fostering an inclusive culture, and is proud to be an equal opportunity employer. We embrace and encourage our employees' differences in race, religion, color, national origin, gender, family status, sexual orientation, gender identity, gender expression, age, veteran status, disability, pregnancy, medical conditions, and other characteristics. Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Quartet does not accept unsolicited headhunter and agency resumes. Quartet will not pay fees to any third-party agency or company that does not have a signed agreement with Quartet.\n\nPlease note: Quartet interview requests and job offers only originate from quartethealth.com email addresses (e.g. jsmith@quartethealth.com). Quartet will also never ask for bank information (e.g. account and routing number), social security numbers, passwords, or other sensitive information to be delivered via email. If you receive a scam email or wish to report a security issue involving Quartet, please notify us at: security@quartethealth.com.\n\nHave someone to refer? Email talent@quartethealth.com to submit their details to us.\n\nStart your job application: click Easy Apply"}, "702": {"company": "DOCOMO Innovations", "description": "Responsibility\nThe ideal candidate will be responsible for real world Data Science problems, including but not limited to: Data planning/collections,\nannotation strategies and developing the state-of-the-art deep learning algorithms in the field of both computer vision/NLP to operate\non large data sets that provides robust situational assessment and predictive capabilities.\n\nPerform prototype implementation of the algorithms developed, solid engineering and classical CS knowledge is the key to success for this position.\nShare knowledge by clearly articulating ideas through papers and presentations to technical staff, management.\nQualifications\nBasic CS background (Algorithms/Data Structure) is absolutely essential, Engineering skill needs to be solid and will be tested.\nHeavy exposure computer vision/Open CV\nGood understanding of scikit-learn\nMust be professional level in Python and C++/C.\nFluency in Pytorch or Tensorflow/Keras, skills will be assessed\nMaster/Ph.D in the field of Computer Science, Computer Engineering, Electrical Engineering, Mathematics or related field"}, "703": {"company": "LendingHome", "description": "LendingHome is re-imagining the mortgage process from the ground up by combining innovative technology with an experienced team. Our goal is to create a seamless, transparent process that transforms the mortgage process from end to end.\n\nThe Team\n\nWith our built-from-scratch technology that covers every stage of the loan process, LendingHome has opened access and simplified a way for people to get financing and generate wealth through real estate. Since 2013, LendingHome has funded over $3.5 billion dollars worth of loans across 15,000+ projects, making it the largest fix and flip lender in the country. Combining the best technology and the most knowledgeable people, LendingHome has raised $167MM in venture capital, has grown to a team of over 300, and has been featured on the Forbes Fintech 50 list for two years running. LendingHome is uniquely positioned to become the next great financial services brand powered by the most advanced mortgage platform in the world.\n\nThe Role\n\nLendingHome is seeking a highly analytical and innovative Data Scientist to join our Data team. Data drives every area of LendingHome including marketing, sales, operations, and credit, and you will be collaborating closely with all of these groups to tackle the highest priority strategic questions and to enable excellent, robust data-driven decision making.\n\nResponsibilities\nDefine, create, and improve metrics and dashboards that precisely and accurately measure the pulse of the business\nProactively initiate in-depth, rigorous analysis to derive meaningful insights the business can clearly act upon\nDrive improvements in business outcomes by testing new and different strategies through systematic planning and execution of experiments\nContinually explore and iterate statistical models and features to advance our understanding of key underlying business drivers\nBuild production grade machine learning pipelines and data products that solve critical, complex problems and deliver business value\nIdentify, research, and analyze new data sources that complement and enrich the quality of the data platform\nSupport ad hoc analysis requests\nQualifications\nA graduate degree in Computer Science, Statistics, Math, or related quantitative discipline\nExcellent grasp of fundamentals in statistics and probability\nExpertise in SQL and proven comfort and an intellectual curiosity for working with large sets of data\nProficiency in coding and software engineering concepts. Fluency in Python/R preferred\nExperience with basic classes of machine learning techniques and algorithms (e.g. regression, classification, boosting, clustering, time series, NLP)\nAbility to partner, collaborate, and communicate well with a diverse set of colleagues, both technical and non-technical, at all levels\nA resourceful and pragmatic approach to problem solving and recognition that the best solutions are sometimes the simplest\nExperience in Hadoop/Spark or other distributed parallel computing paradigms is a plus\nAbility to transform technical analysis into easily digestible visualization is a plus\nLendingHome in the News\nWinner: Forbes Fintech 50\nLendingHome Passes $3 Billion in Mortgage News\nHow Wall Street, Silicon Valley Institutionalized Home Flipping\nA Tour of LendingHome's New San Francisco Headquarters\nRiding the House Flipping Boom, Mortgage Lender Adding More Jobs on North Side\nBenefits and Perks\nCareer Growth: We foster an environment that encourages opportunities to use your voice, make an impact, and move towards your long-term goals.\nLunch & Snacks: Hungry? We have you covered! Enjoy catered lunches and Bagel Wednesdays\u2014and don't forget to take your pick of healthy snacks and drinks daily from our fully stocked kitchen.\nWork-life Balance: With our flexible time off policy, you can enjoy a well-rounded lifestyle while easily balancing work, travel, loved ones, and passions.\nFamily Matters: We know your role here might not be the only one you have. Enjoy your job as a parent and welcoming your new bundle of joy with our competitive parental leave policy.\nCommuter Benefits: Travel from A to B without the stress. We help you save money on your commute to work with pre-tax deductions and a monthly stipend.\nProduct Ownership: We recognize your hand in making our business great. With offered equity, you can claim your stake in our growth.\nHealth Insurance: Your well-being is important to us. Our comprehensive medical, dental, and vision plans ensure that your mind and body are in good keeping.\nIf you'd like to see more about what LendingHome has to offer or explore additional opportunities, visit us at LendingHome.com/Careers.\n\n\nLendingHome is an Equal Opportunity Employer\nSan Francisco Fair Chance Ordinance Police Code, Article 49\nApply Now: click Easy Apply"}, "704": {"company": "Zynga", "description": "Position Overview\n\n\nAs a data scientist you will be working closely with Zynga\u2019s central analytics functions on a wide array of topics including (but definitely not limited to):\nAutomated ML platforms (e.g. propensity modeling and segmentation)\nEnd-to-end marketing optimization and automation\nReal-time in-app content personalization\nAI driven CRM solutions\nReal-time bidding optimization\nZynga\u2019s experienced central data team includes data scientists, analysts and product managers working closely with engineering and business stakeholders.\n\nThis role will focus on building automated data-driven workflows and predictive modeling across all of Zynga\u2019s business functions.\n\nMain Responsibilities:\nLead, define and develop creative and new business opportunities and products while communicating findings and results with leadership and product teams\nBuild production-grade systems for deploying predictive models and other ML solutions\nBuild algorithm-driven automated workflows for performance optimization\nWork closely with product management and engineers to design, deploy, and evaluate ML models and optimization algorithms\nDesign and evaluate innovative approaches for advancing data science at Zynga\nDesired Skills and Experience:\n\nBA in Computer Science, Math, or other quantitative field; Masters or PhD preferred\n5+ years of work experience in data science or analytics roles\nKnowledge of predictive modeling algorithms and frameworks\nKnowledge of machine learning trade-offs and model evaluation\nExperience building automated workflows (e.g. Python)\nDemonstrated experience with scalable compute technologies (e.g. PySpark)\nKnowledge of virtualization technologies (e.g. Docker)\nExperience working with large datasets in a cloud environment\nAbility to work independently and effectively in a fast-paced environment with changing priorities\nZynga is an equal opportunity employer. We are proud of our broad community; we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. We welcome job-seekers, players, employees, and partners from all backgrounds. Join us!\n\nWe will consider all qualified job-seekers with criminal histories in a manner consistent with applicable law.\n\nZynga is committed to providing reasonable accommodation to applicants with disabilities. If you need an accommodation during the interview process, please let us know.\nTo apply to this job, click Apply Now"}, "705": {"company": "Mathematica Policy Research", "description": "Position Description:\n\nMathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development.\n\nWe are looking for aData Scientist in our Washington DC office. Data scientists lead data processing and analysis tasks, such as monitoring data quality, developing documentation, applying statistical and data science methods, and creating data visualizations. Data scientists are expected to work on multi-disciplinary teams, overseeing and mentoring junior data scientists. The work of our data scientists supports our company's core offerings in program evaluation and data analytics, which yield crucial evidence and information for policy and decision makers.\n\nData scientists contribute throughout the course of a project on tasks such as the following:\nLeading multidisciplinary teams to answer research questions or build solutions that involve linking health or healthcare data (e.g., Medicare claims or HCUP) to other administrative data (e.g., Hospital Compare files)\nDesigning, planning, and overseeing the data science workflow on tasks and projects, involving descriptive statistics, machine learning or statistical analysis, data visualizations, and diagnostics using programming languages such as R or Python\nCommunicating results to collaborative project teams using data visualizations and presentations using tools such as Markdown (e.g., R Markdown), notebooks (e.g., Jupyter or Databricks), or interactive visualizations (e.g., R Shiny or Dash).\nDeveloping and implementing systems to ingest, process, and manage datasets\nDeveloping and maintaining documentation using Atlassian Confluence and Jira\nImplementing quality assurance practices such as version control and testing\nLeading or supporting proposal sections or applications\n\nPosition Requirements:\nDemonstrated enthusiasm for applying data science and statistics to social impact projects in academic, extra-curricular, and/or professional settings\nAn excellent academic record, including courses in subjects such as statistics, data science, math, computer science, and/or social science, and the following credentials:\nPhD, or 3+ years of experience in a social policy field post Masters or immersive bootcamp (e.g., Metis)\nMastery of R or Python to manipulate data, conduct analyses, and create data visualizations\nAbility and desire to work independently as part of remote, interdisciplinary teams\nAbility and desire to mentor junior data scientists and contribute to Mathematicas growing health data science community of 50+ staff\nAbility to version code using Git\nStrong oral and written communication skills.\nNice-to-have Skills:\n\nExperience with reproducible research principles, interactive visualizations, tidyverse, AWS, Google Cloud Platform, R Shiny, R Markdown, pandas, healthcare claims and administrative data (e.g., Medicare, Medicaid, electronic health records, all-payer claims databases, HCUP), and/or scikit-learn.\n\nPlease submit a cover letter, resume, and salary expectations. You will be asked to attach these materials during the online application process. Please click the \"Apply Now\" icon after the Position Description to attach your documents. Letter of recommendations not expected or required.\n\nMathematica offers our employees competitive salaries and a comprehensive benefits package, as well as the advantages of being 100 percent employee-owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the companys growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength.\n\nVarious federal agencies with whom we contract require that staff successfully undergo a background investigation or security clearance as a condition of working on the project. If you are assigned to such a project, you will be required to obtain the requisite security clearance.\n\nWe are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.\n\nStart your job application: click Apply Now"}, "706": {"company": "Seen by Indeed", "description": "Seen by Indeed is a free service that connects qualified job-seekers (that's you) with top companies hiring tech roles.\nWith one application you can be considered for thousands of tech roles from leading companies on Seen.\n\nHow Seen Works\nWe find out what's important to you and match you with your dream job\nGet started Complete a 5-minute application to be considered for roles at hundreds of leading companies\nGet matched Companies apply to you with opportunities that reflect your role, location and salary specifications\nGet career coaching Level up with free 1:1 coaching, our team will make sure you're ready to tackle any interview\nGet your dream job\nSkills and Requirements\nWe look for top tech talent to join the Seen platform. Each candidate is reviewed on the following to make sure you're a good fit for our network\n\nIn Demand Skills\nFrom strong communication skills to experience with the latest technologies, you have what employers are looking for\n\nStand Out Qualities\nYou bring unique qualities and traits that stand out and make an impact\n\nChange ready\nYou are ready for a career changes and will be responsive to employers who reach out with job opportunities\n\nGet matched with top tech companies on Seen!"}, "707": {"company": "Group O", "description": "Group O is seeking a strong candidate with the ability to design machine learning projects to address specific business problems determined by consultation with business partners to fill an exciting Data Scientist position, in the Chicago IL or Atlanta GA area for a Group O partner.\n\nResponsible for the development and implementation of machine learning algorithms and techniques to solve business problems and optimize member experiences. Primary duties may include are but not limited to: Design machine learning projects to address specific business problems determined by consultation with business partners. Work with data-sets of varying degrees of size and complexity including both structured and unstructured data. Piping and processing massive data-streams in distributed computing environments such as Hadoop to facilitate analysis. Implements batch and real-time model scoring to drive actions. Develops machine learning algorithms to build customized solutions that go beyond standard industry tools and lead to innovative solutions. Develop sophisticated visualization of analysis output for business users.\n\nBS/MA/MS/PhD in Statistics, Computer Science, Mathematics, Machine Learning, Econometrics, Physics, Biostatistics or related Quantitative disciplines. 5 years experience in predictive analytics and advanced expertise with software such as Python, or any combination of education and experience which would provide an equivalent background. Experience leading end-to-end data science project implementation. Experience in the health-care sector. Experience in Deep Learning strongly preferred.\nApply Now: click Apply Now"}, "708": {"company": "Raybeam", "description": "*If you are interested in the position please click on the link to begin the application process.*\nhttp://careerseval.raybeam.com\nWho are we? Raybeam Inc. is a consulting company focused building engineering and data solutions spanning business intelligence, brand and direct marketing, customer engagement for over twenty years in Silicon Valley and beyond. We have offices near Boston and San Francisco and support a strong list of clients including Google, Facebook, Microsoft, eBay, Disney and Hilton Worldwide.\nWhat do we do? We provide technology solutions by architecting and developing enterprise systems using a variety of programming languages, tools and platforms. This can range from building data warehouses, to web applications to implementing reporting platforms. We work in small teams, own the projects that we work on, and have direct input into the business decisions of our clients.\nWhat we\u2019d like to see in you:\nExperience in, design and build innovative data solutions, from discovery to delivery for clients and external stakeholders\nTranslate business problems to an analytics problem, recommending and applying the most appropriate methods to yield insights and results\nLeading sessions and meetings to drive analytics roadmap, long-term strategy with quarterly milestones and outlook\nProvide mentorship and guidance to teams of analyst; inspire innovative thinking in the analytics space\nRequirements:\n5-8 years of industry experience leading analytics projects\nExperience with customer and user tracking on web and mobile app\nExperience in applied analytics in space of sales, finance, marketing, or product engineering; track record of success\nFamiliarity with cloud platforms such as Google Cloud Platform, Microsoft Azure, AWS, IBM Cloud to use/deploy analytics resources\nStrong working knowledge of SQL and architecting relational databases. NoSQL is a plus\nProficient in at least one or other language for applied to statistics, data analysis, or machine learning - Python, R, Matlab, SPSS\nWhat do you get from working for Raybeam?\nThe opportunity to work for a variety of Fortune 500 companies.\nExcellent resume builder due to the exposure to a variety of technologies and experiences.\nThe chance to have input into business decisions of our clients.\nA fun, supportive work environment that promotes camaraderie and growth.\nThe chance to travel and network with important figures in the industry.\nThe opportunity to learn technologies that you\u2019ve always wanted but never had the chance.\nWe have fantastic benefits including competitive pay, fully paid health insurance (including vision), free daily lunch, 401k contribution, long term disability insurance, flexible schedule, annual company outing, generous vacation/sick time, holidays and more!\n\nTo apply please follow the link below to take a short 10 minute phase one data analyst quiz and then send a follow up cover letter to raybeam-hr@raybeam.com explaining why you would be a good fit for the role. Thank you!\nApply Now: click Easy Apply"}, "709": {"company": "Esurance", "description": "Esurance combines the spunk of a startup with the backing of Allstate (the largest publicly held personal lines insurer in the U.S.) to create a unique, energized, and exciting place to work. We're a digital company powered by smart, innovative, caring people. And our success depends on our associates, who bring diverse perspectives and a sense of community to work with them every day. When we ask them what they love about working at Esurance, the answers are always the same. It's about team, culture, and community. That's life at Esurance!\nEsurance has created a centralized data science & analytics (DSA) group that is responsible for helping business units make objective decisions using data. And we\u2019re hiring a Lead Data Scientist in San Francisco, CA to join today! Our Data Science team supports the company\u2019s overall business operations by delivering critical analytical insights and in-depth consultative analyses to senior management teams and our business partners.\n\nWhat you\u2019ll do:\nAs a Lead Data Scientist you will lead a small team while taking a hands on approach within the Data Science Group. You will work within project teams to provide technical and analytical leadership, leading all aspects of the development of project deliverables including cross-functional program management, data gathering and manipulation, analysis and modelling, and communication of insights and recommendations. In this role, you will interact often with our Senior Leadership team through presentations of various project findings.\nTo be successful as a Lead Data Scientist at Esurance you will bring the following skills:\nGraduate degree in technical field (CS, Physics, Mathematics, Data Science, etc)\n5+ years post-graduate work experience\n5+ years of experience coding in a major programming language such as R or Python\n4+ years of experience applying machine learning techniques to solve business problems\nExperience with Hadoop ecosystem a strong plus\n\nEsurance offers an exciting total rewards package to include:\nBonus potential for all positions\nBenefits eligibility on day 1\n401k + company matching\nTuition reimbursement & student loan repayment program\nPet insurance discount\nGive time, get time volunteer program\nAnd much more!\nTo perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.\nApply Now: click Apply Now"}, "710": {"company": "Numerator", "description": "This data scientist position is a highly-autonomous, product-focused role designed to create value and drive impact across the Product organization, while also influencing the evolution and strategic direction of our company as a whole. The role is cross-functional by nature and is responsible for developing data products and analytics, defining methodologies, conducting research and analysis on a variety of subject areas, and driving bottom-line growth through building operational efficiencies and leading special projects for our clients. The ideal candidate is a seasoned data scientist (e.g. quantitative analyst) with diversified experiences across several industries, who's held various positions within analytics or engineering functions. Since a major requirement for this role is to understand, author, and deploy production code, the ideal candidate should also be experienced with processing large quantities of data, building algorithms alongside software engineers, and foundationally rooted in applied statistics.\n\nResponsibilities- What you get to do!\nIdentify new opportunities to build and/or improve new product features and data products\nPartner with Product, Data, and Engineering teams to identify, investigate and deliver solutions related to product and back-end data issues\nDeliver complex projects involving heavy data and statistical modeling (e.g. sampling, segmentation, classification, predictive modeling, etc.)\nLead the discovery and development of new and existing methodologies and algorithms\nRegularly communicate outcomes, new initiatives and improvements, etc. to stakeholders\nProvide data science consulting and support to both internal and external clients\nWhat we are looking for\nBS in Mathematics, Statistics, Computer Science, Economics, Physics, or other behavioral and/or equivalent quantitative science\n3+ years of industry experience as a data scientist (or equivalent role). For data science boot camp graduates, 2+ years of experience as a data scientist post-graduation\nExperience with defining key product metrics, setting team goals, and building internal tools to monitor progress against KPI's\nProficiency in Python and/or R, SQL, Spreadsheets\nExperience with applied statistics across various data types and sizes\nExperience with communicating complex analyses and methodologies effectively to non-technical stakeholders\nOutstanding written and verbal data storytelling, demonstrated consulting skill and ability to tailor communication style and depth to a variety of audiences\nHighly autonomous, versatile, intellectually curious and resilient within a dynamic and fast-paced organization\nExtra, Nice to haves\nExperience with developing, deploying and maintaining back-end production code, including (but not limited to) applied ML frameworks and applications (e.g. SciKit Learn, TensorFlow, etc.)\nProven track record of delivering solutions to a production environment\nSolid understanding of SQL and transactional databases (e.g. MySQL, Postgres, etc.), and experience with building data models and/or improving warehouse architecture\nExperience with understanding, analyzing and modeling user data and behavioral trends\nEnthusiasm for identifying and pursuing new business and product opportunities\nExperience working with marketing insights, shopping data or in the retail industry\nDemonstrated ability to systematically break down large, vague feature requests into deliverable work product\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.\n\n.\nApply Now: click Apply Now"}, "711": {"company": "Dell", "description": "Data Science Consultant\n\nRound Rock, TX\n\nDell provides the technology that transforms the way we all work and live. But we are more than a technology company \u2014 we are a people company. We inspire, challenge and respect every one of our over 100,000 employees. We also provide them with unparalleled growth and development opportunities. We can\u2019t wait for you to discover this for yourself as a Sr. Data Scientist on our Performance Analytics Group team in Round Rock, TX\n\nData Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What\u2019s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.\n\nKey Responsibilities\nInteracts with business leaders to understand business strategy, conditions and problem areas and contributes to business strategy and influences decision making based on information gained from deep dive analysis\nPartners with both internal & external sources to gather and examine data from disparate sources with the goal of discovering previously hidden insights\nDesigns, develops and programs methods, processes and systems to consolidate and analyze unstructured data to generate actionable insights and solutions\nEvangelize the need and recommend strategies to position advanced analytics in areas such as Predictive/Prescriptive Analytics\nWork with key partners and software vendors contributing to recommendations on predictive / analytical modeling products, services, protocols, and standards in support of procurement and development efforts\nPlay an advisory role, provide thought leadership & propose advanced analytic solutions to customers\nContributing to predictive / analytical modeling standards, reporting, and data analysis methodologies, model management\nEssential Requirements\n8 + years of work experience in Data Science, Analytics, Modeling, Reporting or Business Intelligence\n5+ years of experience in large and medium projects as a leader in self-directed role\nExperience in solving client's analytics problems and effectively communicating results and methodologies\nStrong understanding and implementation of predictive / analytical modeling techniques, theories, principles, and practices. Specific experience in more than one of: forecast and statistical modeling, machine learning and text mining and sentiment analysis\nStrong background in Statistical modeling: Analysis of Variance, Data Transformation, Machine Learning Tools and models (e.g. pre-processing, model selection, data scaling, dimensionality reduction), Natural Language Processing Tools\nBenefits\n\nWe offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities \u2014 all to create a compelling and rewarding work environment. If you share our passion for data and you\u2019re keen to play a key role in driving progress, this is your opportunity to develop with Dell. Apply now!\n\nDellis committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Learn more about Diversity and Inclusion at Dell here.\n\n#DCAM-Gordon\nTo apply to this job, click Apply Now"}, "712": {"company": "Wolverine Trading", "description": "Data Science Intern (Summer 2020)\nLocation\n\n\nChicago\n\nJob Department\n\n\nTrading\n\nApply Now\n\nData Science Intern (Summer 2020) at Wolverine Trading\n\nIf you want to understand the data of modern markets at the deepest level and dive into quantitative trading, the data science research internship is right for you. Wolverine is offering the opportunity to work in a highly collaborative and dynamic environment where you\u2019ll get exposure to our algorithmic trading and execution systems. Data Scientists work with traders and engineers to develop, test, and implement statistical models and algorithmic trading systems that drive every aspect of Wolverine\u2019s business. Wolverine seeks intelligent and creative individuals who will apply their mathematical and programming skills to complex big data and time series problems.\n\nWhat You\u2019ll Do\n\nAs a summer intern, you will work on multiple ML, statistics, and data engineering projects using our cutting-edge cluster computing technology and A/B testing environments. You will perform huge data analysis on our algorithms, and have the opportunity to propose actionable changes to fully automated trading systems. You will gain experience with options pricing and equities trading strategies while learning how we approach significance testing, parameter tuning, outlier analysis, and algorithmic optimizations. Our team oversees thousands of data sources and the algorithms that convert these data into actionable insights for our trading strategies. Wolverine provides classroom education, hands-on training, and mock trading. Wolverine also provides fully furnished apartments that are located close to the office, making your morning commute quick and easy. Additionally, Wolverine will host several social activities throughout the summer to ensure an optimal work-life balance.\n\nWhat We Look For\nWorking toward a degree in statistics, computer science, mathematics, or another highly quantitative field and have an expected graduation date between December 2020 and June 2021.\nHistory of academic excellence.\nDemonstrated interest in trading, financial markets, and technology, but experience or knowledge of finance not required.\nExcellent quantitative and problem-solving skills.\nEntrepreneurial and self-motivated.\nStrong communication skills.\nDesire to work in a team environment.\n3-month commitment.\nExperience in Python.\nStrong background in classical statistics and machine learning preferred.\nAbout Wolverine\n\nFounded in 1994, the Wolverine companies comprise a number of diversified financial institutions specializing in proprietary trading, asset management, order execution services, and technology solutions. We are recognized as a market leader in derivatives valuation, trading, and value-added order execution across global equity, options, and futures markets. With a focus on innovation, achievement, and integrity, we take pride in serving the interests of both our clients and colleagues. The Wolverine companies are headquartered in Chicago with offices in New York and San Francisco and a proprietary trading affiliate office located in London.\n\nSponsorship is not available for this position.\n\nStart your job application: click Apply Now"}, "713": {"company": "United Airlines", "description": "We have a variety of career opportunities around the world - come find yours!\n\nOverview\n\nEngages in value added activities that generate practical solutions to complex business problems leveraging big data, explores and defines new business alternatives, and drives improvement in business decisions through innovations, research & development, and product knowledge. In addition, must have in-depth subject matter and professional expertise as well as thorough knowledge of the business tools and systems which render judgment and professional opinion an essential component of the job.\n\nMeet the CIEO team:\n\nhttps://www.youtube.com/watch?v=PfMzLZsHPfk\n\nResponsibilities\nInvestigates and identifies patterns in big data to generate business insights\nResponsible for sourcing data leveraging their expertise for product enhancements, and/or research & development activities as part of a team, with an orientation to generating practical business s insights, solutions and delivering value\nLeverages in-depth knowledge of business data/systems and understanding of the business process to identify and implement solutions and influences business processes that will result in significant bottom-line contributions and/or efficiency improvements\nStays abreast of changing business trends, data sources, and tools and enables the company in staying ahead of its competition\nSets short-term direction for research efforts and/or analyses\nDesigns and/or implements analysis to drive critical financial, operational, and/or strategic decisions\nDrives management decisions through descriptive and inquisitive data analytics using tools such as SAS, machine learning, BI tools, and/or other data extraction tools\nDesigns and develops predictive and prescriptive models for several efforts, and interfaces with client organizations and IT\nSome communication and presentation to organization leaders are required, with emphasis on data visualization skill, quality, and timeliness\nShare accountability for training other staff professionals within the organization. Mentor individuals for acquiring and/or maintaining the technical skills for which scientist can serve as the subject matter expert\nDevelops and delivers presentations aligned with CIEO standards\nRequired\nBS in a quantitative field such as Engineering, Operations Research, Statistics, or a related quantitative field\n6+ years (or 4.5+ years if MS in a quantitative field or 3+ years if PhD in a quantitative field) of airline or related business experience at successive levels in analytical fields solving complex business problems\n3+ years of in-depth experience in data modeling through use of statistical/machine learning toolkits such as SAS, R, Python, JMP, and Minitab, and/or BI tools like Spotfire and Tableau\n2+ years of demonstrated ability in innovation to create business value through data mining, data analytics, predictive modeling, information retrieval, machine learning and/or artificial intelligence techniques\nAdvanced quantitative skills, subject matter knowledge and data source expertise in at least one business area, good business technical communication, verbal/written communication, and presentation and sales skills\nAdaptability to changing business environment\nGood interpersonal skills and ability to interact with clients at all levels and influence business strategy\nStays abreast of changing industry trends and enable the company in staying ahead of its competition\nSuccessful completion of interview required to meet job qualifications\nReliable, punctual attendance is an essential function of the position\nPreferred\nAdvanced degree (MS, PhD, or equivalent) in quantitative field\n1+ years of airline business experience\nKnowledge of United/industry data sources\nExisting productive connections with academia to keep abreast of new developments\n\n\nEqual Opportunity Employer \u2013 Minorities/Women/Veterans/Disabled/LGBT\nTo apply to this job, click Apply Now"}, "714": {"company": "Kraken Digital Asset Exchange", "description": "About Kraken\n\nOur mission is to accelerate the adoption of cryptocurrency so that you and the rest of the world can achieve financial freedom and inclusion. Founded in 2011 and with over 4 million clients, Kraken is one of the world's largest, most successful bitcoin exchanges and we're growing faster than ever. Our range of successful products are playing an important role in the mainstream adoption of crypto assets. We attract people who constantly push themselves to think differently and chart exciting new paths in a rapidly growing industry. Kraken is a diverse group of dreamers and doers who see value in being radically transparent. Let's change the way the world thinks about money! Join the revolution!\n\nAbout the role:\n\nThis role is San Francisco based but can also be remote.\n\nWe are looking for a data scientist who is innovative, highly-motivated, and proactive.\nFor this role, you will be part of a team that builds cutting-edge trading products in the cryptocurrency industry. You will be responsible for transforming data and generating actionable insights into our customer behavior and measuring the performance of our trading engine. You will collaborate and lead projects with product management, engineering, marketing, and growth teams. You will transform data from complex systems, generate performance metrics, and share the results with stakeholders at all levels of the company.\nGreat benefits, amazing perks, remote work and travel opportunities, stock incentives, beautiful HQ office, and a flexible PTO policy make Kraken a great place to work. If you value having a seat at the table and want to make a big impact on guiding the direction of marketing and growth at one of the top crypto exchanges in the world, this role is for you.\nRequirements\nA degree in Statistics, Computer Science, Physical Sciences, Economics, Math or a related technical field.\n5+ years industry experience in data science or analytics\nA consistent track record of performing data analysis using Python, R, and/or SQL\nExperience using statistics and predictive analytics to solve complex business problems.\nThe versatility and willingness to learn new technologies on the job.\nThe ability to clearly communicate complex results to technical and non-technical audiences.\nFamiliarity with other data tools such as Hive, Vertica, Tableau & Ruby is a plus\nResponsibilities\nPartner with Kraken\u2019s engineering, marketing, product, and finance teams to identify, prioritize, and answer the most important questions where analytics and modeling will have a material impact.\nDrive cross functional analytic projects from beginning to end: build relationships with partner teams, frame and structure questions, collect and analyze data, summarize and present key insights in support of decision making.\nWork with engineers to evangelize data best practices and implement analytics solutions.\nCollaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models.\nCommunicate key results with self-serve tools (dashboards, analytics tools) for leadership and product management.\nDevelop anomaly detection, and data modelling tools to monitor key performance indicators to improve the efficiency of the products.\nDesign experiments for product teams to test hypothesis and help with idea generation and refinement.\nBuild key datasets and data pipelines using Python/ETL frameworks.\nWe\u2019re powered by people from around the world with their own unique backgrounds and experiences. We value all Krakenites and their talents, contributions, and perspectives.\n\nCheck out all our open roles at https://jobs.lever.co/kraken. We\u2019re excited to see what you\u2019re made of.\n\nLearn more about us:\n\nWatch \"Working at Kraken\"\nFollow us on Twitter\nCatch up on our blog\nTo apply to this job, click Apply Now"}, "715": {"company": "American Axle & Manufacturing", "description": "We are AAM. We have the POWER to move the world.\n\nAt AAM, we're looking for associates who push boundaries and drive solutions for the future. Innovators. Thinkers. Dreamers. Doers. No matter the role or function, every associate is a piece of what makes AAM great. Were growing and building #TeamAAM to be the best. Join us!\n\nJob Posting Title\n\nSenior Data Scientist\n\nJob Description Summary\n\nWe are looking for a Senior Data Scientist that will help us discover the information hidden in vast amounts of data and help us support our business. Your primary focus will be in applying data mining/statistical techniques, creating patterns and predictions. Ensuring validity of data using statistical languages to develop and launch descriptive, Predictive and prescriptive analysis. Work closely with the business to understand business needs.\n\nJob Description\nPerform Operational Support.\nWork on Major Projects and Responsible for Deliverables.\nData mining using state-of-the-art methods\nStrong skill in critical thinking\nExpert in AWS service and components (S3, EMR, EC2, Lambda, Kafka, green grass)\nProcessing, cleansing, and verifying the integrity of data used for analysis\nDoing ad-hoc analysis and presenting results in a clear manner\nExperience in IoT solutions\nEnhancing data collection procedures to include information that is relevant for building analytic systems\nMaster of Python, R, and SQL languages\nExtensive experience writing algorithms, statistical models, and predictions.\nModel creation using Python\nData visualization using MS Power BI, R Shiny\nExpert in classification, regression, clustering, anomaly detection, decision tree, Na\u00efve Bayes, Support Vector Machines\nWork with business users to conduct user acceptance testing.\nAll other duties as assigned.\nRequired Skills and Education\nBachelors Degree (Computer Science, Statistics, and Mathematics)\n5 years relevant experience\nPython, R Programming, R Shiny\nExpert in creating/modifying statistical data models\nExpert in Data Science - Experience creating Statistical Algorithms like Random Forest, Logistic regression, Na\u00efve Bayes, SVM etc.\nBig data ecosystem. (Impala, Spark, Hive, SQOOP etc)\nExpert in Microsoft Power BI Dashboards and reports\nExpert in creating statistical models to do real time machine learning.\nSQL expert\nGood understanding of ETL systems\nExpert in Data Science - Experience creating Statistical Algorithms like Random Forest, Logistic regression, Na\u00efve Bayes, SVM etc.\nBig data ecosystem. (Impala, Spark, Hive, SQOOP etc)\nExpert in Microsoft Power BI Dashboards and reports\nExpert in creating statistical models to do real time machine learning.\nSQL expert\nAbout American Axle & Manufacturing\n\nFor over 20 years, customers around the world have entrusted AAM to design, engineer, validate and manufacture driveline, metal forming, powertrain, and casting technologies for automotive, commercial and industrial markets. Today, we are a premier global Tier 1 automotive supplier with broad capabilities across multiple product lines to deliver efficient, powerful and innovative solutions for our customers. Weve earned the trust of our suppliers and our customers through our steadfast commitments to quality, operational excellence and technology leadership.\n\nAAM delivers power. We deliver power literally through vehicle components, systems and innovation, but we also deliver power in ways unseen. We power our associates, their families, and the communities in which we operate. Our global team of over 25,000 associates has a clear vision of where AAM is going and how we are going to get there. After all, they are the reason we are a leader in the automotive industry. We are powering the future. We are AAM. Move with us, and join #TeamAAM.\n\nAAM will not discriminate against any Associate or applicant for employment because of age, race, color, gender, religion, weight, height, marital status, sexual orientation, genetic history or information, gender identity or expression, disability, protected veteran status, national origin, or other characteristic protected by law. AAM will take affirmative action to ensure that applicants are employed, and that Associates are treated equally during employment, without regard to their age, race, color, gender, religion, weight, height, marital status, sexual orientation, genetic history or information, gender identity or expression, disability, protected veteran status, national origin, or other characteristic protected by law. For the Disabled Job Seeker: We offer reasonable accommodations for qualified disabled individuals who are applicants for employment. To request assistance or accommodations, please e-mail aamhr@aam.com . AAM is an equal opportunity/affirmative action employer.\nApply Now: click Apply Now"}, "716": {"company": "Ancestry", "description": "About Ancestry:\nWhen you join Ancestry, you join our family tree. Backed by history, science, and technology, were creating a new world of connection, innovation, and understanding. Whether its reuniting long-lost relatives through DNA or unearthing new family stories from historical records, Ancestry empowers life-changing experiences. With over 20 billion digitized historical records, 100 million family trees, and 15+ million DNA kits sold, Ancestry is bringing the power of personal discovery to people around the world.\n\nAncestry is looking for a highly motivated Data Scientists to join our Data Science Discovery team in San Francisco.\n\nYou will be a member of the global Data Science & Machine Learning Team, tackling our toughest and most exciting data science challenges. Ancestry's Data Science team has a wide reach across the company, working with Product, Science, and Marketing teams. We find ways to provide new and meaningful discoveries to our customers. We build machine learning models to improve our content or create new content that unlock stories for Ancestry customers.\nAs a Data Scientist on the Data Science Discovery team, you will be involved in the end to end process of data acquisition, data cleaning, model building, and model testing. You will help our users to find their ancestors and discover interesting family history events. You will utilize cutting edge machine learning algorithms and statistical analysis techniques to provide personalized discovery experience to our users.\nWhat You Will Do\nMachine learning for recommender systems and personalization\nDeep learning for natural language processing\nRanking algorithms for search and recommendation\nFeature engineering for people, family, records, photos and more\nNLP for query and document analysis, processing and understanding at a large scale\nRanking result evaluation and analysis\nWho You Are\nYou have either a PhD in a relevant field, such as recommendation systems, machine learning, deep learning, NLP or search OR a Masters plus one year of full-time industry experience\nYou have strong modeling skills in Python or R and a solid understanding of core CS algorithms and coding skills in Python, Java or C/C++\nBig Bonus Points For\nExperience with Big data, such as Hadoop/Hbase/Pig/Hive is a plus\nExperience with Solr/Elasticsearch is a plus\nExperience with Spark is a plus\nAdditional Information:\nAncestry is an Equal Opportunity Employer that makes employment decisions without regard to race, color, religious creed, national origin, ancestry, sex, pregnancy, sexual orientation, gender, gender identity, gender expression, age, mental or physical disability, medical condition, military or veteran status, citizenship, marital status, genetic information, or any other characteristic protected by applicable law. In addition, Ancestry will provide reasonable accommodations for qualified individuals with disabilities.\n\nAll job offers are contingent on a background check screen that complies with applicable law. For San Francisco office candidates, pursuant to the San Francisco Fair Chance Ordinance, Ancestry will consider for employment qualified applicants with arrest and conviction records.\n\nAncestry is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Ancestry via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Ancestry. No fee will be paid in the event the candidate is hired by Ancestry as a result of the referral or through other means\n\nApply Now: click Apply Now"}, "717": {"company": "Stripe", "description": "Generate insights and impact from data.\n\nWe're looking for data scientists to join the Analytics team who are excited about applying their analytical skills to understand our users and influence decision making. If you are naturally data curious, excited about deriving insights from data, and motivated by having impact on the business, we want to hear from you.\n\nYou will:\nWork closely with product and business teams to identify important questions and answer them with data.\n\nApply statistical and econometric models on large datasets to: i) measure results and outcomes, ii) identify causal impact and attribution, iii) predict future performance of users or products.\n\nDesign, analyze, and interpret the results of experiments.\n\nDrive the collection of new data and the refinement of existing data sources.\n\nCreate analyses that tell a \"story\" focused on insights, not just data.\n\nWe're looking for someone with:\n3+ years experience working with and analyzing large data sets to solve problems.\n\nA PhD or MS in a quantitative field (e.g., Economics, Statistics, Eng, Natural Sciences, CS).\n\nExpert knowledge of a scientific computing language (such as R or Python) and SQL.\n\nStrong knowledge of statistics and experimental design.\n\nAbility to communicate results clearly and a focus on driving impact.\n\nNice to haves:\nPrior experience with data-distributed tools (Scalding, Hadoop, Pig, etc).\n\nYou should include these in your application:\nResume and LinkedIn profile.\n\nDescription of the most interesting data analysis you've done, key findings, and its impact.\n\nLink to or attachment of code you've written related to data analysis.\n\nStart your job application: click Apply Now"}, "718": {"company": "Wells Fargo", "description": "Job Description\n\nImportant Note: During the application process, ensure your contact information (email and phone number) is up to date and upload your current resume prior to submitting your application for consideration. To participate in some selection activities you will need to respond to an invitation. The invitation can be sent by both email and text message. In order to receive text message invitations, your profile must include a mobile phone number designated as Personal Cell or Cellular in the contact information of your application.\n\nAt Wells Fargo, we want to satisfy our customers financial needs and help them succeed financially. Were looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where youll feel valued and inspired to contribute your unique skills and experience.\n\nHelp us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.\n\nConsumer Banking is an industry leader in supporting homeowners and consumers, in addition to operating one of the most extensive banking franchises in the country. We serve mass market, affluent, and small business customers; as well as provide home and personal lending. Our focus is on delivering an exceptional experience for our customers through financial advice and guidance coupled with providing the products and services that will help them realize their financial hopes and dreams. Weve built our team of top professionals by rewarding their accomplishments and ensuring they have what's needed to succeed.\n\nThe Role\n\nConsumer Control Monitoring & Surveillance Analytics is responsible for developing and implementing data driven self-assurance monitoring, reporting and metrics to increase and evidence control effectiveness. The incumbent will create risk detection and monitoring strategies across Home Lending Servicing systems, business processes, and interactions, using traditional risk analytics as well as advanced analytic techniques. This foundation will in turn provide Home Lending Servicing leadership key metrics and insights to manage operational and conduct risk.\n\nResponsibilities include:\nIdentify and implement data-driven, consistent processes of surveillance and supervision for servicing activities with a particular emphasis on operational risk and conduct\nCollaborate with senior leaders and/or peers to develop robust actionable analytics to monitor operational and conduct risk\nLeverage advanced data analytics to identify risk patterns and trends and provide insights on the effectiveness of risk detection and monitoring programs and processes\nResponsible for supporting the roll-out of detection strategies and assessing them for optimization and efficiency opportunities\nLeverage both structured and unstructured data and Big Data analytic tools and platforms to provide insight into risk trends and help improve risk and monitoring processes\nPartner closely with leaders across Home Lending Servicing to identify and optimize the ongoing risk analysis and reporting necessary to support first line accountability for operational risk, conduct risk, and other key risk issues\nLead efforts in collaboration with First Line and Second Line of Defense groups to research, identify and implement workflow and real-time alerts capabilities\nLeverage data and analytics to inform and influence line of business strategic planning team in long term plan development around sales supervision\nPartner closely with other Home Lending Servicing Risk Management teams to support site reviews, compliance reviews and other activities providing data analytics as required\nThe Team\n\nThe individual will join the Home Lending Servicing Core Analytics team within the Consumer Control Monitoring & Surveillance Analytics organization and report directly to Eric Throener, Home Lending Servicing Core Analytics Leader.\n\nThe Candidate\n\nSuccessful candidates will have proven track records of developing actionable data analytics and data strategies to inform, influence, and drive business outcomes. Leadership, relationship management, and credibility will be determining factors in selection. Successful candidates will be articulate and possess strong data analytic experience and have strong interpersonal effectiveness with the ability to translate complex analytics in to easily understood insights. He/She must have strong understanding of business drivers and processes and be an effective influencer that has credibility with business leaders and able to offer credible challenge as needed.\n\nPreferred locations include: 7001 Westown Pkwy, West Des Moines, IA; however, all locations will be considered including, but not limited to: 600 S 4th St, Minneapolis, MN; 11601 N Black Canyon Hwy, Phoenix, AZ; 301 S Tryon St, Charlotte, NC, or 4101 Wiseman Blvd, San Antonio, TX.\n\nRequired Qualifications\n6+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 4+ years of experience in one or a combination of the following: reporting, analytics, or modeling\nDesired Qualifications\nExtensive knowledge and understanding of research and analysis\nStrong analytical skills with high attention to detail and accuracy\nExcellent verbal, written, and interpersonal communication skills\nOther Desired Qualifications\n4+ years Business or Risk/Compliance Analytics role\nKnowledge of Home Lending Servicing processes, data and systems\nPrior experience working with analytic capabilities\nEffective leadership ability to drive successful execution of strategic plans; ability to plan, prioritize and set goals. Must possess strong collaborative skills\nExcellent analytical, critical thinking and problem-solving skills with attention to detail and accuracy\nAbility to communicate powerfully and prolifically to senior and executive leaders and simplify the complex\nAbility to influence without direct authority, create and manage (while achieving results) large-scale change and influence people at all levels of the organization\nDemonstrated ability to execute effectively in a matrixed organization, develop partnerships with many business and functional areas\nDemonstrated ability to build and maintain strong credible relationships with key stakeholder groups including executive management, regulatory examiners and internal auditors\nAbility to lead through adversity and adjust to changing priorities\nDemonstrated SQL skills to include the ability to write complex queries and database knowledge in order to analyze data sources across a variety of sources\nDemonstrated experience with SAS, TOAD or Teradata\nDemonstrated experience with SAS Visual Analytics and SAS Visual Investigator\nDemonstrated data visualization experience using a BI Tool e.g., Tableau, Microsoft BI, etc.\nJob Expectations\nThis position requires compliance with all mortgage regulatory requirements and Wells Fargo's compliance policies related to these requirements including acceptable background check investigation results. Successful candidates must also meet ongoing regulatory requirements including additional screening and required reporting of certain incidents.\nAbility to travel up to 10% of the time\nSalary Information\n\nThe salary range displayed below is based on a Full-time 40 hour a week schedule.\n\nIA-West Des Moines: Min: $78,100 Mid: $110,000\nMN-Minneapolis: Min: $78,100 Mid: $110,000\nAZ-PHX-Northwest Phoenix: Min: $78,100 Mid: $110,000\nNC-Charlotte: Min: $78,100 Mid: $110,000\nTX-San Antonio: Min: $78,100 Mid: $110,000\n\nStreet Address\n\nIA-West Des Moines: 7001 Westown Pkwy - West Des Moines, IA\nMN-Minneapolis: 600 S 4th St - Minneapolis, MN\nAZ-PHX-Northwest Phoenix: 11601 N Black Canyon Hwy - Phoenix, AZ\nNC-Charlotte: 301 S Tryon St - Charlotte, NC\nTX-San Antonio: 4101 Wiseman Blvd - San Antonio, TX\n\nDisclaimer\nAll offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.\n\nRelevant military experience is considered for veterans and transitioning service men and women.\nWells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.\nCONSUMER BNKG\nStart your job application: click Apply Now"}, "719": {"company": "Smartsheet", "description": "Smartsheet is looking for an experienced Data Scientist to help drive analyses, generate insights, and influence decision making. With thousands of subscribing organizations and millions of users there is lots of opportunity to make meaningful impact and drive growth through analytics within Smartsheet. The ideal candidate is intellectually curious, has strong analytical skills and has the ability to communicate key insights effectively. This individual will work closely with departments across the company and will be a part of a highly efficient and results oriented Business Intelligence team. This full time position reports to the Data Science Manager and is based in Smartsheet's corporate offices in Bellevue, WA.\n\nResponsibilities:\nMine large datasets and draw actionable insights\nPresent discoveries and insights to line of business teams and give recommendations to encourage data-driven decision making\nPartner with cross functional teams across Marketing, Sales, Product Management, Engineering in operationalizing the initiatives\nIdentify areas for further investigation\nRequirements:\nBA/BS in Computer Science, Mathematics, Operations Research, Physics, or other technical field. Advanced degree preferred but not required\n3+ years of experience in quantitative analysis, combined with strong business judgment and an ability to present analysis in a clear and compelling manner\nProficient in implementing various statistical models and data mining tools (predictive modeling, clustering, logistic regression, multivariate regression, decision trees, neural networks)\nHands on experience in executing analysis using tools such as SQL, R, Python, Excel, Tableau and Google Analytics.\nAbility to research and learn new technologies, tools, and platforms\nAbility to draw conclusions from data and recommend actions\nAbility to thrive in an unstructured environment, working autonomously on a strong team to find opportunity and deliver business impact\nA self-starters who can, with minimal guidance, drive projects from concept through completion\nFocus to make quick strikes, iterate, and produce in high volume\nSmarts to pick up new concepts at light speed\nAgility to quickly adjust priorities and shift direction\nFlexibility to contribute to other projects as required\nAbout Smartsheet\n\nIn 2005, Smartsheet was founded on the idea that teams and millions of people worldwide deserve a better way to deliver their very best work. Today, the company delivers a leading cloud-based platform for work execution, empowering organizations to plan, capture, track, automate, and report on work at scale, resulting in more efficient processes and better business outcomes. Smartsheet went public on the New York Stock Exchange in April 2018 and currently enables collaboration, better decision making, and accelerated innovation for over 76,000 domain-based customers in 190 countries, including 96 of the Fortune 100.\n\nSmartsheet is an Equal Opportunity Employer. Individuals seeking employment at Smartsheet are considered without regard to race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, citizenship status, or any other legally protected category.\nApply Now: click Apply Now"}, "720": {"company": "Underwriters Laboratories", "description": "Overview\n\n</h2>\nUL is seeking a NLP Research Scientist (Senior Data Scientist) to join the iON Compliance team in Chicago, IL.\n\niON Compliance is a big data platform combining data ingest, analytics, machine learning and elements of artificial intelligence within a data lake. iON is now looking to add a NLP Research Scientist to our team to accelerate the growth of the most innovative UL digital technology investment in its history. Our goal is to enable the UL client base to effectively apply the recent developments in the digital revolution, by giving them the ability to truly leverage their own corpus of data with internal core competences and win in a rapidly evolving digital eco-system.\n\n\n\nResponsibilities\n\nThe Natural Language Processing research scientist will be of the subject matter expert in innovative projects where natural language processing analytics will lead to increased efficiencies in businesses.\nApply machine, deep learning and probabilistic techniques to design and prototype intelligent, real-world applications that intelligently extract understanding from text and/or audio sources.\nKeep abreast of the latest developments in the field by participating in conferences and other venues and can champion promising, new methods to explore.\nProactively identify new areas of research and in partnership with business groups develop value-based proposals for investment.\nApply skills to work at the leading edge of automation in industries such as customer care, healthcare, retail and compliance solutions.\nAutomating the understanding of the intent, the topics, and the sentiment of the conversation for customer experience. In our education services we seek to understand the training needs of our clients and evaluate their effective delivery through free text analysis.\nIdentify use cases, create demonstrations of capabilities, and identify new opportunities in these and other Conduent businesses.\nContribute to the external community through conference participation and journal articles.\n\n\n\nQualifications\n\nSkills\nMust be a self-driven problem solver, capable of implementing innovative solutions to problems, performing experiments to show feasibility of their solutions and working to refine the solutions into a real-world context and demonstrated experience of working with teams to solve problems.\nPractical expertise with NLP, text mining, speech processing, dialog, or multimodal processing systems, experience with machine learning toolkits (e.g., Azure ML and Cognitive services, Weka, scikit-learn), and fluency in major programming language (e.g. Python, R) is required.\nPractical experience with deep learning paradigms and toolkits (e.g., TensorFlow, Keras) is required.\nFamiliarity with knowledge graph inference and interfacing with semantic engine preferred\nExperience in active learning, web scraping, and/or developing and executing a research agenda are ideal\nStrong communication skills (written and verbal)\nExperience & Education Requirements:\n\nMS with 2+ years of experience or Ph.D. in Computer Science, Computation Linguistics or a related field.\nExperience with the various aspects of Natural Language Processing including named entity recognition, sentiment analysis, semantic computing, content summarization, intent recognition, and experience with an understanding of the algorithms by which these are implemented\nExperience working in the retail/health care/finance industry is a plus\n\n<h2>\nApply Now: click Apply Now"}, "721": {"company": "Blink Health", "description": "Blink Health is a well-funded healthcare technology company on a mission to make prescription drugs more accessible and affordable for everyone. We're scaling up in a highly complex vertical to change the way Americans access the prescription drugs they need.\n\nOur proprietary platform and supply chain allows us to offer everyone whether they have insurance or not amazingly inexpensive prices on over 15,000 medications. With the addition of telemedicine and home delivery for prescriptions, Blink is providing a life-changing experience for people all over the country and fixing how opaque, unfair and overpriced healthcare has become. We are a highly collaborative team of builders and operators who invent new ways of working in an industry that historically has resisted innovation. Join us!\n\nSuccess:\n\nThe Data and Analytics team is a small team building the Big Data infrastructure at Blink; responsible for architecting and building infrastructure, frameworks and tooling to enable data driven decisions in addition to developing reports, dashboards, and metrics to provide accurate and timely information. The team also supports various product and business groups with recommendation and in-depth analyses. Our data platforms are built using tools available on AWS including Redshift, Data Pipeline, Spark, Looker.\n\nAs a data scientist, you will be a thought leader within the analytics team designing and building our metrics framework, and evolving it as we grow. You will work closely with engineers and business stakeholders across the company, developing and maintaining key performance and insight reports that help product teams and leadership make decisions on products and services. You will set a high bar for owning performance metrics ideation, creation, and enhancements.\n\nHow to achieve success/acumen:\n\nAll Blinkers are expected to operate with our value of \"Good Giving\" in mind. Our culture is infused with the dedication and enthusiasm of employees who continuously strive to make a difference. Here's how you will do that in this role.\n\nGood Execution - Do your best work\n\nDo your best work by investigating, designing, and building high quality analytics metrics and frameworks. Maintain and optimize analytics as needs evolve, and work with multiple internal customers to define models, then train and support your customers to self-service on analytics tools.\n\nGood Owner - Be the CEO of your role\n\nBe the CEO of your role through helping teams ship new products and features successfully with the right information to understand how to serve our customers; taking responsibility for the long term success of products, projects, and people.\n\nGood Learning - Learn something new every day\n\nLearn something new every day through leading by example to put new ideas into action, being willing to fail fast and learn. Demonstrate interest in learning new techniques and developing best practices.\n\nGood Feedback - Consider the perspective of others\n\nConsider the perspective of others by listening actively and responding effectively through a variety of channels. Give and receive candid and constructive feedback. Promote trust and encourage teamwork allow the teams to do their best work with you.\n\nRequired Experience:\n5+ years experience having worked in an analytics role. Experience in scripting with SQL, extracting large sets of data, and designing KPIs.\n3+ years experience working with analytics platforms such as Looker, QuickSight, Tableau to create new analytics capabilities.\nDemonstrated versatility in working with different types of data and data models: financial, digital marketing, transactional e-commerce, event-level product data, etc.\nDemonstrated expertise in SQL with a track record of designing and building product analytics.\nDemonstrated expertise at communicating effectively with other engineers, designers, product managers, and leaders, with collaborative examples on creating top-tier analytics solutions.\nBA/BS or Master's degree in a quantitative field such as; Statistics, Computer Science, Engineering, Mathematics, Data Sciences.\nExcellent written and verbal communication skills.\nDesired Experience:\nHealthcare-relevant company experience as part of the required experience above, with demonstrated industry knowledge of handling sensitive information.\nWhy Join Us:\n\n\nAt Blink, we put humans first. We want everyone at Blink to be able to do the best work of their lives. We are a relentlessly learning, constantly curious and aggressively collaborative cross-functional team dedicated to inventing new ways to improve the lives of our customers.\n\nLearn more:\nBlink Website\nBlink Pharmacy App for Android\nBlink Pharmacy App for iOS\n\nWe are an equal opportunity employer and value diversity of all kinds. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nApply Now: click Easy Apply"}, "722": {"company": "Northwestern Mutual Life Insurance Company", "description": "At Northwestern Mutual, we are strong, innovative and growing. We invest in our people. We care and make a positive difference.\n\nAre you interested in leveraging your data science skills to help derive data driven insights that are used to inform our company strategy? Are you looking for a role that combines data science skills with an opportunity to gain big picture knowledge of NM\u2019s business?\n\nCorporate Strategy is looking for a Data Scientist to deliver insights and provide data driven decision support for key initiatives of company strategy and measurement related to client and sales analyses to understand both growth and economic impact.\n\nThe Team:\n\nThe Strategic Intelligence Team in Corporate Strategy is an advanced analytics team that works with senior leaders to inform company strategies and decision-making through an objective viewpoint by leveraging the team\u2019s expertise in Client-Product-Field data, deep NM business knowledge, and utilizing statistical and advanced analytical techniques as appropriate.\n\nThe Role:\nUse advanced statistical and analytical techniques to inform highly complex and sophisticated business questions\nCombine deep business expertise with advanced statistical modeling and analysis skills to discover and identify new insights, predict and prescribe outcomes, turn new insights into actionable opportunities, and provide the tracking and measurement of results.\nPerform data driven research, utilizing quantitative techniques, through a variety of analytical tools.\nTell a story with data \u2013 Share insights, findings, and implications with stakeholders via interactive presentations, visualizations, and written communications.\nExamples of the types of Analytical Research projects you may work on:\nDrivers of Permanent Life Insurance Sales growth and incremental sales measurement impact across Permanent Life Insurance growth initiatives.\nAnalysis of Financial Advisor productivity to measure/assess the cumulative impact on Financial Advisor productivity across several initiatives designed to drive productivity growth\nAnalyze the impact of planning across both client behaviors (product, policy size, and purchase behaviors) as well as impact to Financial Advisor practices (activity, lives, etc.)\nThe Work:\nBe at the forefront of Analytical Research and Development at NM, leveraging data-based insights & decision support, to guide senior business partners in the activation of data driven insights and opportunities\nProvides data driven decision support for key initiatives of company strategy and measurement related to client and sales analyses to understand both growth and economic impact.\nTests new insights and hypothesis through tracking & measurement of a specific opportunity\nDetermines requisite data elements and partners with data engineers to design integrated datasets for analytical research purposes.\nDevelop solutions, mathematical models, algorithms, machine learning techniques, and robust analytics to support analytic insights and visualization\nIdentifies opportunities to enhance the team\u2019s analytical capabilities by evaluating current processes, working with business partners, and taking initiative to apply new and improved approaches.\nPerforms diagnostic and prescriptive analysis, derives new findings and insights, and highlights business implications in presentations to stakeholders.\nThe Desired Skills:\nBachelor\u2019s degree in data science, statistics, math, computer science, economics, or related field.\nPreferred: Advanced graduate level degree in a quantitative discipline (statistics, applied mathematics, computer science, econometrics, or related field)\n5+ years relevant experience to include research and data analysis, experiment design and measurement, or application of statistical research techniques.\nExpertise in one or more development or statistical analysis tool such as R, SAS, SQL, SPSS, or other tools. Tableau experience is a plus.\nProven excellence in research, quantitative analysis, problem solving, and analytical working techniques.\nStatistical knowledge and intuition\nStrong aptitude and desire for learning new analytical and visualization tools, modeling, and quantitative techniques.\nInitiative to independently design and develop own deliverables while still being a team player. Demonstrated ability to deliver results and recommendations in written, verbal and presentation form at an appropriate level for a business audience.\nDesirable qualifications: Experience in financial service industry\nGrow your career with a best-in-class company that puts our client\u2019s interests at the center of all we do. Get started now!\n\nWe are an equal opportunity/affirmative action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity or expression, sexual orientation, national origin, disability, age or status as a protected veteran, or any other characteristic protected by law.\n\nReq ID: 27195\nPosition Type: Regular Full Time\nEducation Experience: Bachelor's Desired\nEmployment Experience: 6-8 years\nLicenses/Certifications:\nFLSA Status: Exempt\nPosting Date: 11/25/2019\nApply Now: click Apply Now"}, "723": {"company": "Amyris", "description": "Amyris has developed a high-throughput genetic engineering platform for designing and building custom microbes to serve as living factories. Using an industrial scale fermentation process, our microbes convert cheap sugars into a wide variety of high-value target molecules. Our end products directly impact millions of lives. We are pragmatic idealists seeking a profitable way to make the world a better place. We are convinced synthetic biology is here to stay and will have a major positive impact on our planet and everyday life.\n\nWithin Amyris R&D, we are searching for a highly energetic, curious, and self-motivated scientist with a strong background in statistics, computing and biology to join our Computational Biology team. Research at Amyris is a highly multidisciplinary effort that needs brilliant contributions from life sciences and engineering disciplines in order to take projects from concept to market. From hacking directly on DNA in the lab to full scale factory production, every aspect of our work is facilitated and accelerated by quantitative science and software & hardware automation. The Computational Biology team works hand-in-hand with bench scientists and builds tools that enable genome engineering, protein engineering, metabolic modeling, omics experiment analysis, and statistical design of experiments in pursuit of making better microbial strains. In short, we help accelerate the design-build-test-analyze cycle in synthetic biology.\nResponsibilities\nIteratively develop computational algorithms, analysis and visualization tools to meet evolving scientific needs and to aid rapid data-driven decision making. Data types include: genotype (NGS), phenotype (metabolomics, proteomics, GC/MS, spectroscopy, fermentation), material flow\nBuild version-controlled, computable workflows to analyze rich, high-throughput phenotype data\nInteract closely with biology, analytical chemistry, and fermentation scientists\nCollaborate with automation engineers and software developers of in-house enterprise systems to mine experimental data and metadata\nRequired Qualifications\nDegree in quantitative discipline such as computer science, mathematics, computational biology, electrical engineering, bioengineering. For the Data Scientist role: Ph.D. plus 1-3 years experience, or M.S. plus 6 years experience. Experience managing a team required for the Senior Data Scientist role.\nAt least three years experience in analyzing & visualizing large scientific datasets representing biological & chemical phenotypes\nUndergraduate-level understanding of biology: genetics, cell physiology, biochemistry, evolution\nIndustrial programming experience, i.e. having written or maintained large codebase using software best practices (e.g. unit tests) and distributed version control\nExpert coder in Python\nKnowledge of machine learning frameworks\nOutstanding communication and interpersonal skills\nAbility to thrive in a fast-paced yet intellectually rigorous environment\nCreativity, independent thinking, and passion\nExperience with the following a plus\nBackground in mass spectrometry informatics, HTS, spectrophotometry, or industrial fermentation\nExperience in a microbiology or synthetic biology setting\n#LI-RJ1\n\nAmyris, a leader in industrial synthetic biology, uses its innovative bioscience solutions to achieve renewable products by converting plant sugars into hydrocarbon molecules. Amyris\u2019 molecules are used in wide range of specialty & performance chemicals, flavors & fragrances and in applications ranging from cosmetics to biofuels. Learn more at www.amyris.com.\n\nAs a VEVRAA Federal Contractor, Amyris is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. Amyris complies with applicable state and local laws governing nondiscrimination in employment.\n\nIf you are a recruiter or placement agency, please do not submit resumes to any person or email address at Amyris, Inc. prior to having a signed agreement. Amyris is not liable for and will not pay placement fees for candidates submitted by any agency other than its approved recruitment partners. Furthermore, any resumes sent to us without an agreement in place will be considered your company\u2019s gift to Amyris and may be forwarded to our recruiters for their attention.\n\nFor a full list of our current openings, please visit our website at www.amyris.com.\nStart your job application: click Apply Now"}, "724": {"company": "ShopKeep", "description": "About Us\n\nBorn out of frustration with the traditional cash register business, ShopKeep was designed by a retailer with a noble aim: to rescue independent business owners from the nightmare of archaic point of sale systems, and replace them with something beautiful, simple, and affordable. It turned out that by doing this, we were giving our fellow merchants a fighting chance against the big guys.\n\nToday, our mission is simple: empower independent business owners to dream big and to fight smart. We're doing this through our cloud-based architecture, amazing customer care, and intuitive software that delivers the data small business owners need to run smarter businesses.\n\nAt ShopKeep, we've been successful because of our awesome team that believes small businesses make up the heart of our communities.\n\nAbout This Role\n\nThe Data team at ShopKeep is a results-focussed team using data to provide solutions across the company. We are a B2B SaaS company, with terabytes of data - from our digital marketing channels and our sales pipelines, all the way through our merchant life cycle, including billing, onboarding, product/feature usage, transactions and customer care.\n\nWe are looking for an experienced data scientist to help us use this data to drive measurable improvements across ShopKeep. We are convinced our data holds the keys to figure out ways to optimize our business and find valuable insights. We are looking for a data scientist who believes the same and has some relevant experience.\n\nWhat You Will Do\nUse your data science expertise to build and productionize statistical learning models in areas of customer acquisition, LTV, retention and product engagement.\nWork with the marketing team to understand and help find actionable insights from the data to drive measurable improvements.\nWork with the product team to build solutions that empower our merchants.\nBuild pipelines to pull in new sources of data for your models in a way that is scalable and robust. Manage / debug previously written pipelines.\nBe a data story teller - communicate data insights and findings to stakeholders, both technical and non-technical.\nStrive to understand the nuances of the business and processes and become a trusted partner to your stakeholders.\nWhat We'd Like to See\n2 years+ experience building and productionizing predictive models with Python\nBackground in data mining and statistical analysis\nGood pattern recognition and predictive modeling skills\nComfort with a git-based workflow\nFluency with Python / Pandas and a deep desire to improve\nUnderstanding of probability, simulation, and statistical inference\nExperience writing SQL\nBonus Points For\nTime series modeling\nData visualization tools (especially Looker)\nColumnar databases (especially Redshift)\nDocument databases (especially ElasticSearch)\nPostgres\nApache Spark\nExperience with the AWS ecosystem\nBenefits\n\nWe provide the essentials...\nHealth, Life and Disability Benefits\nEmployee Assistance Program (EAP)\nGenerous Referral Bonus Program for Technology Roles\nFlexible Paid Time Off (PTO)\n401(k) Match\n...and the fun-damentals:\nLively and enriching Engineering culture\nRegularly scheduled hackathons, meetups and Tech Talks\nOpportunity to attend Engineering Conferences, thanks to our generous company conference budget\nNewsletters produced by Engineering teams\nCross-office collaboration between our NYC and Belfast teams with the opportunity to travel to our different offices\nRegular team events, including Happy Hours and Game Nights\nCatered lunches\nBreak area to play and relax\nStanding desks\nShopKeep is an Equal Opportunity Employer\n\nWe are an Equal Opportunities Employer. We don't discriminate based on gender, gender identity, sexual orientation, race, nationality, or any other individual characteristics. We practice equality of opportunity in employment and select the best person for the job.\n\nApplying\n\nWe like CVs, but links to your Github profile, your personal projects, your Twitter, your blog, your open source contributions, and so forth will give us a better idea of who you are.\nStart your job application: click Apply Now"}, "725": {"company": "Alarm.com", "description": "Position Overview:\n\nAre you passionate about solving complex puzzles and problems? Do you get excited by extreme data sets and analyzing data from the Internet of Things? Alarm.com is a rapidly expanding, entrepreneurial technology company that is seeking an ambitious, hardworking, expereince Data Scientist to help build and maintain large-scale statistical models that turn billions of data points into insights and actions. Few companies innovate across as broad of a range of technologies as Alarm.com. This position is ideal for the candidate who seeks a team-oriented, friendly company culture where one can work closely with smart and productive people.\n\nResponsibilities:\nProposes and evaluates innovative solutions for analyzing, clustering, associating, and classifying data.\nDevelops and validates algorithms via analysis, computer simulation, and prototyping\nExtends analytics platform for connected devices and sensors.\nWrites and debugs production code that spans the vertical from database to computational layer to web service\nWorks with QA team to identify and cover every edge case imaginable.\nHelps maintain large-scale analytics infrastructure, including distributed storage and computation clusters\nRequirements:\nBachelor's Degree; Mathematics, Statistics, Data Science, or other related fields, Master's is a plus\n4+ years of experience required\nExpertise in machine learning, statistics, control theory, computational modeling, or finance\nExperience in SQL and familiarity with other programming languages. Some development experience in at least one scripting language (PHP, Python, Perl, etc.)\nExperience with business intelligence tools (MicroStrategy, Tableau, Qlik, BOBJ, Cognos) and statistical packages in R, Python, etc.\nUnderstanding of Data Management and the data lifecycle\nExcellent written/oral communication and interpersonal skills\nStrong problem solving skills\nAn interest in technology\nCOMPANY INFO\n\nAlarm.com is the leading cloud-based platform for smart security and the Internet of Things. More than 6 million home and business owners depend on our solutions every day to make their properties safer, smarter, and more efficient. And every day, we're innovating new technologies in rapidly evolving spaces including AI, video analytics, facial recognition, machine learning, energy analytics, and more. Alarm.com earned the Top Workplace award for our employee culture and the meaningful work we do to give property owners peace of mind, help them conserve energy and water, and stay connected to loved ones. We're seeking those who are passionate about creating change through technology and who want to make a lasting impact on the world around them.\n\nCOMPANY BENEFITS\nAlarm.com offers competitive pay and benefits including a wide choice of healthcare options with generous company subsidy, a health savings account option with company contribution, 401(k) with employer match, paid holidays and paid time off increasing with tenure, paid maternity and paternity leave, company paid STD/LTD and life insurance, flexible spending accounts, and a casual dress work environment.\n\nAlarm.com is an Equal Opportunity Employer\nApply Now: click Easy Apply"}, "726": {"company": "Alaant Workforce Solutions", "description": "Alaant Workforce solutions is seeking a Senior Data Engineer to work as part of the technical data management team supporting the needs of data scientists and analytic developers for our client, a top insurance company in the Albany, NY area. This opportunity offers top-notch benefits, a great culture, and continued career growth!\n\nJob duties include:\nBuilding interactive information systems, run queries and algorithms against distributed data assets for predictive analytics\nMachine learning and data mining\nWorking with business units and development departments to deliver data aggregations to executives, business analysts and other consumers of more traditional types of data to aid in ongoing operations\nDownstream data entities and building with an eye towards transfer of support training/documentation\nSuccessful candidates will possess the following skills, education, and experience:\nBachelor\u2019s degree required. 7 years relevant experience may be substituted for degree. Degree in Computer Science or a business discipline is preferred.\n3-5 years AWS Cloud based experience (Salesforce/ServiceNow may be possible)\n3-5 years\u2019 experience with Python Development\n3 -5 years\u2019 experience with Integrations\n3-5 years EMR experience\n3-5 years\u2019 experience with databases\nExperience developing in Java or .net\nAWS certifications a plus\nStrong customer service skills\nFor more details on this role contact:\nJaime Toolan, Senior Talent Resource Manager @ 518-689-3155, Jaime.toolan@alaant.com\n\nAlaant Workforce Solutions wants all interested applicants to know they are seeking a diverse workforce and are actively recruiting candidates in accordance with diversity, inclusion and equal opportunity policies.\n\nConnect with us on LinkedIn, Facebook, Twitter, Instagram & Glassdoor\n\nAt Alaant we believe in People First! We Care. We Listen & We Support.\n\nwww.alaant.com\n\nINDNYH\nApply Now: click Easy Apply"}, "727": {"company": "Discord", "description": "Discord Secret Sauce recipe:\n\n\n-3/4th of a cup of recommendation systems that allow our users to discover content they might enjoy\n\n-2/3rds a cup of characterizing a healthy Discord server and learning how can we help more server owners build healthy communities\n\n-1/2 a cup of developing applied machine learning models to tag voice sessions with poor voice quality in real time\n\n-Pinch of sugar (it helps balance the acidity)\n\nIf you're a master Data Scientist chef who wants to take a crack at this recipe and look through our expansive cookbook for more, we'd like to invite you into our massive, data-driven kitchen.\n\nWe're looking for a foundational Lead Data Scientist to help build out the core data science function at Discord, provide mentorship, and set the direction for the team. You will work closely with teams like Analytics, Data Platform, Product, and Engineering to explore our data and unlock insights that will be used to power analyses and drive decision-making at all levels of the company. Join us in creating a best-in-class communications platform that millions of users and communities love!\n\nWhat you'll be doing\nHelp define and grow our nascent Data Science team as the foundational first hire\nPartner with internal stakeholders across product, engineering, and business teams to identify opportunities, prioritize projects, and produce models and findings that drive data-informed decisions\nExplore our data and apply advanced statistical techniques to provide a deeper understanding of our product, users, communities, and business\nImprove our existing capabilities in product experimentation, business forecasting, and anomaly detection for KPIs\nDesign experiments to tease out causal impact and draw actionable conclusions\n\nWhat you should have\nCollaborative attitude and a healthy dose of natural curiosity\nAbility to communicate complex analyses in easy-to-understand ways\nPhD or MS in Statistics, Math, Computer Science, or other quantitative field\n5+ years of work experience in an applied research or data science role\nProven track record of team mentorship and technical leadership\nFluency in SQL and a language such as Python, Java, R, or Scala to work efficiently with large data sets in a production environment\nDeep technical expertise in statistical modeling, modern machine learning techniques, and experiment design\nA vision for what Data Science can and should be, as well as the ability to work with internal stakeholders to execute on that vision\n\nBonus Points\nPassion for Discord, games, or online communities\nExperience at a consumer tech company\nDirect experience with hiring / growing data science teams\nExperience with large data sets and distributed computing (Hive/Hadoop)\nFamiliarity with technologies such as Airflow, AWS Redshift, and/or BigQuery to build and optimize production data pipelines\n\nApply Now: click Easy Apply"}, "728": {"company": "Niantic", "description": "Do you want to help connect people all over the world, and work on a team building the next generation of planet scale, real world AR games? We're looking for hardworking people to help our company become more data focused. Folks with the ability to be dedicated, thorough, and independent but also to work effectively in a collaborative, fast-paced environment.\n\nResponsibilities\nTranslate quantitative findings in concise and clear messages to leadership and external partners.\nEmbedded within a product you are the data guru responsible for setting and monitoring the targets, diagnosing problems, quantifying the impact, and coming up with solutions.\nResponsible for defining analytics requirements for new & evolving products.\nHave a product-first mindset that aligns with our mission, values and strategy.\nDrive consensus; independently deliver data insights to drive decisions to cross functional teams.\nBe a hands-on, self-starter and help the company make evidence based decisions.\nQualifications\nExpert level SQL experience; deep experience with statistical packages such as Python or R.\nDeep understanding of statistics and data analytics concepts, especially with regression and time series data.\nExperience with data visualization to help communicate the significance of data to others in the organization.\nKnowledge and experience with A/B testing or randomized control trials.\nBA/BS in statistics, applied mathematics, economics, computer science, machine learning or related field.\nGraduate degree in relevant fields preferred but not required.\n3-5+ years of work experience in data science or analytics role.\nExperience working on one or more launched products.\nJoin the Niantic team!\n\n\nNiantic is the world's leading AR technology company, sparking creative and engaging journeys in the real world. Our products inspire outdoor exploration, exercise, and meaningful social interaction.\n\nOriginally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok\u00e9mon Company, and Alsop Louie Partners. Our current titles include pioneering global-control game Ingress, record-breaking AR game Pok\u00e9mon GO, and recently released third title, Harry Potter: Wizards Unite.\n\nNiantic is an Equal Opportunity and Affirmative Action employer. We believe that cultivating a workplace where our people are supported and included is essential to creating great products our community will love. Our mission emphasizes seeking and hiring diverse voices, including those who are traditionally underrepresented in the technology industry, and we consider this to be one of the most important values we hold close.\n\nWe're a hard-working, fun, and exciting group who value intellectual curiosity and a passion for problem-solving! We have growing offices located in San Francisco, Sunnyvale, Bellevue, Los Angeles, London, Tokyo, Hamburg, and Zurich.\nApply Now: click Easy Apply"}, "729": {"company": "Two Sigma", "description": "Two Sigma is a different kind of investment manager. Since 2001, we have used data science and technology to derive insights to forecast the future and discover value in markets worldwide. Our team of scientists, technologists and academics looks beyond traditional finance to understand the bigger picture and to develop creative solutions to some of the world\u2019s most difficult economic problems. Our work spans markets and industries, from insurance and securities to private investments and new ventures.\n\nThe Strategic Data Science team\u2019s mission is to unlock new high-potential revenue streams by harnessing Two Sigma\u2019s data, technology and modeling capability into a scalable and portable prediction engine and monetizing this engine into new investment products or non-investment business lines.\n\nIn particular, the Strategic Data Science team is working on building a systematic and data-driven private investment focused modeling environment, with application to investment products across the Two Sigma businesses. The team\u2019s ambition is to leverage Two Sigma\u2019s accumulated know-how, proprietary data-science platform and scientific investment approach in highly fragmented, illiquid and unstructured markets. By leveraging these tools, we can develop a meaningfully differentiating investment process in an industry dominated by institutions relying on local knowledge, personal networks and incomplete information.\n\nThe Strategic Data Science team is seeking a data scientist to join our growing team and contribute to building the initial data and modeling platform used to guide our team\u2019s investment process and asset selection. With statistics, economics, and computation at the heart of all our work, we will be most successful when data science is used to empower our team to make data-driven, evidence-based investment decisions that scale quickly. Our mission is to give our team a significant competitive edge in this alpha-phase of the initiative, while also building a platform that scales and provides an enduring advantage: the world\u2019s first data-driven private asset prediction engine.\n\nYou will take on the following responsibilities:\nIndependently generate and articulate hypotheses on what may affect private markets, asset valuations, and private deal processes\nLeverage existing data sets, as well as identify and trial new data sets, in order to interrogate yours \u2014 and the team\u2019s \u2014 hypotheses\nPresent your work internally to the working teams, other modeling teams, members of Two Sigma\u2019s leadership team and various Two Sigma businesses\nSpend time with private market partners to better understand how it works, how software is used, and what data is critical to industry practitioners daily workflows\nDevelop a deep understanding of private markets\nYou should possess the following qualifications:\nStrong independent development of predictive models in common open-source statistical programming languages\nExperience working with high-dimensional and sparse datasets, as well as recognition of when and how to combine such datasets to enhance their value\nFamiliarity with time-series and spatial analysis methods and software, particularly mapping tools\nDesire to work in a dynamic and evolving research and development environment, where you may be working on several parallel research tracks and will be expected to switch context frequently\nStrong communication skills, with an emphasis on the ability to understand your audience and flexibility to communicate complex topics to non-experts\nTwo Sigma employees enjoy the following benefits:\nCore Benefits: Fully paid medical and dental insurance premiums for employees and dependents, competitive 401k match, employer-paid life & disability insurance\nPerks: Onsite gyms with laundry service, wellness activities, casual dress, snacks, game rooms\nLearning: Tuition reimbursement, conference and training sponsorship\nTime Off: Generous vacation and unlimited sick days, competitive paid caregiver leaves\nWe are proud to be an equal opportunity workplace. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity/expression, age, status as a protected veteran, status as an individual with a disability, or any other applicable legally protected characteristics\n\nStart your job application: click Apply Now"}, "730": {"company": "Intuit - Data", "description": "Overview\n\n\nIntuit is seeking a Sr Customer Analyst to cover Intuits Consumer Group (TurboTax, Mint, Turbo). We have an exciting opportunity to help shape how we use data to generate hypotheses, surface insights, and build models in order to personalize customer experiences and provide awesome outcomes for the business and our customers. This role will partner closely with data engineering, data analytics, data science, marketing managers, and product management.\n\nResponsibilities\nPartner with cross-functional stakeholders to better understand our users and create a single, accurate view of a customer across businesses to make decisions about how best to acquire/retain them, segment, identify high potential value, and proactively interact with them.\nOwn projects from the teams backlog, and partner directly with business partners to effectively execute on a co-owned and evolving product strategy.\nCollect, analyze, and model available data to advance the customer analytics space and build a broad understanding of the Consumer Groups customers and relevant customer segments.\nPursue data quality, troubleshoot data validation, and see issues to resolution.\nQualifications\n5-7 years of experience working in web, product, customer, care, or other related analytics fields. Ability to tell stories with data, educate effectively, and instill confidence, motivating stakeholders to act on recommendations.\n3+ years applied data science/data modeling experience. Ability to Analyze large amounts of structured and unstructured data and determine suitability for modeling. Broad understanding and demonstrated history of applying various algorithms to business use cases to drive business and customer value.\nStrong modeling foundation hands-on expertise with data mining and statistical modeling techniques such as clustering, classification, regression, tree-based methods, neural nets, support vector machines, anomaly detection, and natural language processing. Expertise with NLP is a plus.\nExpertise in modern advanced analytical tools and programming languages such as Python (highly preferred will be used in this role), Scala, or R. Efficient in SQL, Hive, SparkSQL, etc.\nAbility to manage projects end-to-end to meet objectives and deadlines.\nOutstanding communications skills with both technical and non-technical colleagues.\nMS in Statistics, Mathematics, Computer Science, Economics, Operations Research, or equivalent is preferred.\nApply Now: click Apply Now"}, "731": {"company": "Telaria", "description": "What We're About\n\nTelaria (NYSE: TLRA), (formerly Tremor Video), is the leading independent data-driven software platform built to monetize and manage premium video inventory with the greatest speed, control, and transparency, wherever and however audiences are watching.\n\nWe are looking to leverage our vast amounts of advertising data to make informed decisions around business optimizations and efficiencies. We are a small and efficient team building out a solution in an exciting space with lots of green field ahead of it. Believing we're just scratching the surface of the power of our data, we're actively searching for passionate and analytical data scientists to help us extract actionable insights in order to improve our product offerings.\n\nWhy You'll Be Excited\nHaving a large stake and impact on the product and business direction and bottom-line\nCollaborating with innovative and goal-focused engineering and business teams\nApplying statistics, modeling and ML to improve the efficiency of systems relating to bid traffic shaping and infrastructure costs\nDiving into a wide range of advertising business topics, such as forecasting, revenue yield, auction dynamics, and exchange optimization\nInfluencing and steering the improvement and development of our data platforms, data pipelines, and data science processes\nPerforming deep dive analyses to understand and optimize the key levers of our growth\nWhy We'll Be Excited About You\nYou have strong verbal and written communication skills that help you express your work in meaningful ways to cross functional teams\nYou are passionate about digging into data sets\nYou are able to write efficient and well-structured SQL queries on large data sets\nYou have a solid background and understanding of statistical analysis, experimental design, and machine learning aspects (regression, classification, clustering, supervised/unsupervised, etc.)\nYou have experience with data extraction, exploration, and analysis using programming languages (Java, Python, R, or similar) and data technologies (Spark, etc.)\nYou have a degree in Mathematics, Statistics, Computer Science, or another applicable quantitative field\nYou have familiarity with concepts relating to feature extraction and selection\nBonus: You have previous advertising domain knowledge/expertise\nWhy We (and You'll) Love It Here\nWe are a technology and data-driven business\nWe embrace analytical thinking, kind, and results driven people\nWe have a plethora of challenging and interesting problems to solve\nWe help and support each other in creating a productive work/life balance\nCompensation & Benefits:\n\nAt Telaria we place an emphasis and importance on ensuring our total rewards are competitive, aligned with industry and to help you create a productive work/life balance. Benefits are highly subsidized and include medical, company paid dental, vision, employer contributed Health Savings Account, 401k matching, corporate gym discounts, pre-tax health and commuter savings, life insurance, 5 and 10-year Sabbatical programs, Discretionary Time Off (a.k.a. open vacation policy!), Paid Parental Leave, an Employee Referral Program, Employee Stock Purchase Plan (ESPP), and much more! All this is within a collaborative work environment you can personalize and topped with engaging programs like Micro-Mentorship, and Team Sports.\n\nTelaria values diversity and is proud to be an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nTo apply to this job, click Easy Apply"}, "732": {"company": "Two Sigma", "description": "Two Sigma is a different kind of investment manager. Since 2001, we have used data science and technology to derive insights that forecast the future and discover value in markets worldwide. Our team of scientists, technologists and academics looks beyond traditional finance to understand the bigger picture and develop creative solutions to some of the world\u2019s most challenging economic problems. Our work spans across markets and industries, from insurance and securities to private investments and new ventures.\n\nThe Alpha Insights team at Two Sigma is looking for an entrepreneurial data scientist to contribute to its data-driven investment initiatives. Alpha Insights crowdsources the world\u2019s investment insights and through such data creation we are an integral part of Two Sigma investment management process. We interact with people external to the firm to collect and analyze their investment insights through our web and mobile products.\n\nData science in Alpha Insights has 3 missions: (1) make relevant data and metrics accessible to the team (2) perform analyses to guide business and product decisions and (3) build data-driven features that power our products.\n\nYou will take on the following responsibilities:\nDeliver metrics and analyses to all functions within Alpha Insights including product, design, and business units\nWrite ETLs to convert structure/unstructured data into stable data assets\nBuild visualizations to enable team members to extract relevant insights\nApply statistical analysis and exploratory techniques to enable data-driven decision making\nOwn data-driven product components (e.g. ranking and recommendation algorithms)\n\nYou should possess the following qualifications:\n3-5 years of experience in data analysis or similar role\nMS or PhD in Computer Science, Statistics, Economics or related, quantitative field\nExperience applying statistical methods (distribution analysis, classification, regression, clustering, etc.). Application of these methods to user behavior a plus\nDemonstrated experience highlighting innovation, creativity, and intuition, e.g. the ability to laterally identify other sources of useful information and think 'outside the box'\nStrong data transformation skills (e.g. using Pandas, R,)\nSoftware engineering skills in at least one imperative programming language\nCommunication skills to explain metrics/analyses to members of management, engineering, product and business teams.\nPrior experience in finance is not required\n\nYou will enjoy the following benefits:\nCore Benefits: Fully paid medical and dental insurance premiums for employees and dependents, 401k match, employer-paid life & disability insurance\nPerks: Onsite gyms with laundry service, wellness activities, casual dress, snacks, game rooms\nLearning: Tuition reimbursement, conference and training sponsorship\nTime Off: Generous vacation, sick days, and paid caregiver leaves\n\nWe are proud to be an equal opportunity workplace. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity/expression, age, status as a protected veteran, status as an individual with a disability, or any other applicable legally protected characteristics.\n\nTo apply to this job, click Apply Now"}, "733": {"company": "BlackLine", "description": "Responsibilities:\nBring Creativity to Data products.\nApply machine learning methods to a variety of finance and accounting problems.\nResponsible for building and maintaining the machine learning systems, data, platform and processes.\nBuild, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.\nPerform qualitative and quantitative data analysis.\nCleanse and transform raw data used in machine models.\nPerform data munging, data mining, clustering & classification methods, pattern recognition.\nComfortable with statistics, calculus and multivariate analysis.\nParticipate in ML POCs, validate the results and develop production implementations.\nBuild and optimize scalable machine learning solutions in the public cloud.\nFamiliar with SQL, Python, R, SparkML, TensorFlow, GCP, AWS, SQL Server.\nDevelop production systems in Python.\nWork independently to research and solve business and technical problems.\nPlan their work individually and as part of a team.\nMentor and train other Data Scientists on the team.\nQualifications:\nStrong practical experience with machine learning techniques in the industry, accounting and financial industries is a plus.\nExtensive experience solving analytical problems using quantitative approaches.\nExperience with machine learning algorithms for building ML models, their accuracy, cleanliness, reliability.\nExperience with predictive and prescriptive analyses, modeling, and segmentation.\nHave strong passion for empirical data research for practical applications.\nAbility to communicate complex quantitative analysis in clear, precise, and actionable\nComfortable with complex, high-volume, high-dimensionality data from varying sources.\nVery comfortable with data engineering methods and pipelines.\nExpert knowledge of analysis tools such as R, Matlab, or SAS\nExperience with data warehousing, relational databases, ETL, BI, data mining.\nExperience in SQL, R, Python languages.\nStrong familiarity with GCP and AWS, SQL Server.\nPractical experience with GIT version control.\nComfortable working with open source tools in a Unix/Linux environment.\nExperience with and ownership of data-informed decision-making.\nExperience translating business requirements into functional, and non-functional requirements.\nStrong sense of product and data ownership.\nWorks independently without the need for supervision.\nStrong written and verbal skills \u2013 able to explain the work in plain language.\nMS/PhD in Computer Science or other quantitative disciplines\nStart your job application: click Apply Now"}, "734": {"company": "Billy Casper Golf", "description": "Billy Casper Golf is one of the largest privately owned golf course management companies in the U.S. that prides itself on being an industry leader in advancing the marketing science of the industry. This position will be a key member of the analytics team developing capabilities leveraging the CRM and a suite of marketing technologies to drive conversion and grow revenue for clients. The ideal candidate will have strong ability across the full data lifecycle: from data extraction via queries and API integration through model development, implementation, and measurement. This role will require close collaboration with both marketing and IT team members.\n\nQualifications:\nA degree in Computer Science, Physics, Mathematics, Electrical Engineering, or related discipline.\n3+ years of experience as a Data Scientist.\nExpertise in Python and R with proficiency using PyCharm, Jupyter Notebook, and RStudio environments.\nAdvanced SQL knowledge.\nExperience with cloud storage and computing, preferably Amazon Web Services.\nDemonstrated ability to use predictive modeling and machine learning algorithms to solve business problems.\nCapability with business intelligence and data visualization tools such as Shiny, Tableau, or Domo.\nFamiliarity with Java and/or C++ a plus.\nAbility to convey analysis and results in a clear manner.\nResponsibilities:\nWrite software that extracts and transforms data across disparate sources into unified and centralized systems.\nBuild and deploy algorithmic solutions across various marketing technologies and applications that improve the customer experience and result in increased engagement.\nDevelop and implement models for pricing optimization by channel.\nGenerate methods to evaluate and measure the true business value of marketing tactics.\nPropose reporting formats to effectively communicate meaningful data trends and relationships.\nPresent complex analysis across various organizational levels and external clients.\nTo apply to this job, click Apply Now"}, "735": {"company": "DOCOMO Innovations", "description": "Responsibility\nThe ideal candidate will be responsible for real world Data Science problems, including but not limited to: Data planning/collections,\nannotation strategies and developing the state-of-the-art deep learning algorithms in the field of both computer vision/NLP to operate\non large data sets that provides robust situational assessment and predictive capabilities.\n\nPerform prototype implementation of the algorithms developed, solid engineering and classical CS knowledge is the key to success for this position.\nShare knowledge by clearly articulating ideas through papers and presentations to technical staff, management.\nQualifications\nBasic CS background (Algorithms/Data Structure) is absolutely essential, Engineering skill needs to be solid and will be tested.\nHeavy exposure computer vision/Open CV\nGood understanding of scikit-learn\nMust be professional level in Python and C++/C.\nFluency in Pytorch or Tensorflow/Keras, skills will be assessed\nMaster/Ph.D in the field of Computer Science, Computer Engineering, Electrical Engineering, Mathematics or related field"}, "736": {"company": "Telaria", "description": "What We're About\n\nTelaria (NYSE: TLRA), (formerly Tremor Video), is the leading independent data-driven software platform built to monetize and manage premium video inventory with the greatest speed, control, and transparency, wherever and however audiences are watching.\n\nWe are looking to leverage our vast amounts of advertising data to make informed decisions around business optimizations and efficiencies. We are a small and efficient team building out a solution in an exciting space with lots of green field ahead of it. Believing we're just scratching the surface of the power of our data, we're actively searching for passionate and analytical data scientists to help us extract actionable insights in order to improve our product offerings.\n\nWhy You'll Be Excited\nHaving a large stake and impact on the product and business direction and bottom-line\nCollaborating with innovative and goal-focused engineering and business teams\nApplying statistics, modeling and ML to improve the efficiency of systems relating to bid traffic shaping and infrastructure costs\nDiving into a wide range of advertising business topics, such as forecasting, revenue yield, auction dynamics, and exchange optimization\nInfluencing and steering the improvement and development of our data platforms, data pipelines, and data science processes\nPerforming deep dive analyses to understand and optimize the key levers of our growth\nWhy We'll Be Excited About You\nYou have strong verbal and written communication skills that help you express your work in meaningful ways to cross functional teams\nYou are passionate about digging into data sets\nYou are able to write efficient and well-structured SQL queries on large data sets\nYou have a solid background and understanding of statistical analysis, experimental design, and machine learning aspects (regression, classification, clustering, supervised/unsupervised, etc.)\nYou have experience with data extraction, exploration, and analysis using programming languages (Java, Python, R, or similar) and data technologies (Spark, etc.)\nYou have a degree in Mathematics, Statistics, Computer Science, or another applicable quantitative field\nYou have familiarity with concepts relating to feature extraction and selection\nBonus: You have previous advertising domain knowledge/expertise\nWhy We (and You'll) Love It Here\nWe are a technology and data-driven business\nWe embrace analytical thinking, kind, and results driven people\nWe have a plethora of challenging and interesting problems to solve\nWe help and support each other in creating a productive work/life balance\nCompensation & Benefits:\n\nAt Telaria we place an emphasis and importance on ensuring our total rewards are competitive, aligned with industry and to help you create a productive work/life balance. Benefits are highly subsidized and include medical, company paid dental, vision, employer contributed Health Savings Account, 401k matching, corporate gym discounts, pre-tax health and commuter savings, life insurance, 5 and 10-year Sabbatical programs, Discretionary Time Off (a.k.a. open vacation policy!), Paid Parental Leave, an Employee Referral Program, Employee Stock Purchase Plan (ESPP), and much more! All this is within a collaborative work environment you can personalize and topped with engaging programs like Micro-Mentorship, and Team Sports.\n\nTelaria values diversity and is proud to be an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nStart your job application: click Easy Apply"}, "737": {"company": "Two Sigma", "description": "Two Sigma is a different kind of investment manager. Since 2001, we have used data science and technology to derive insights that forecast the future and discover value in markets worldwide. Our team of scientists, technologists and academics looks beyond traditional finance to understand the bigger picture and develop creative solutions to some of the world\u2019s most challenging economic problems. Our work spans across markets and industries, from insurance and securities to private investments and new ventures.\n\nThe Alpha Insights team at Two Sigma is looking for an entrepreneurial data scientist to contribute to its data-driven investment initiatives. Alpha Insights crowdsources the world\u2019s investment insights and through such data creation we are an integral part of Two Sigma investment management process. We interact with people external to the firm to collect and analyze their investment insights through our web and mobile products.\n\nData science in Alpha Insights has 3 missions: (1) make relevant data and metrics accessible to the team (2) perform analyses to guide business and product decisions and (3) build data-driven features that power our products.\n\nYou will take on the following responsibilities:\nDeliver metrics and analyses to all functions within Alpha Insights including product, design, and business units\nWrite ETLs to convert structure/unstructured data into stable data assets\nBuild visualizations to enable team members to extract relevant insights\nApply statistical analysis and exploratory techniques to enable data-driven decision making\nOwn data-driven product components (e.g. ranking and recommendation algorithms)\n\nYou should possess the following qualifications:\n3-5 years of experience in data analysis or similar role\nMS or PhD in Computer Science, Statistics, Economics or related, quantitative field\nExperience applying statistical methods (distribution analysis, classification, regression, clustering, etc.). Application of these methods to user behavior a plus\nDemonstrated experience highlighting innovation, creativity, and intuition, e.g. the ability to laterally identify other sources of useful information and think 'outside the box'\nStrong data transformation skills (e.g. using Pandas, R,)\nSoftware engineering skills in at least one imperative programming language\nCommunication skills to explain metrics/analyses to members of management, engineering, product and business teams.\nPrior experience in finance is not required\n\nYou will enjoy the following benefits:\nCore Benefits: Fully paid medical and dental insurance premiums for employees and dependents, 401k match, employer-paid life & disability insurance\nPerks: Onsite gyms with laundry service, wellness activities, casual dress, snacks, game rooms\nLearning: Tuition reimbursement, conference and training sponsorship\nTime Off: Generous vacation, sick days, and paid caregiver leaves\n\nWe are proud to be an equal opportunity workplace. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity/expression, age, status as a protected veteran, status as an individual with a disability, or any other applicable legally protected characteristics.\n\nTo apply to this job, click Apply Now"}, "738": {"company": "Pfizer", "description": "THIS ROLE MUST BE BASED IN SAN DIEGO\n\nAs part of the Data Monitoring and Management group, an integral delivery unit within the Global Product Development (GPD) organization, the Clinical Data Scientist is responsible for timely and high quality data management deliverables supporting the Pfizer portfolio. The Clinical Data Scientist designs, develops, and maintains key data management deliverables used to collect, review, monitor, and ensure the integrity of clinical data, oversees application of standards, data review and query management, and is accountable for quality study data set release and consistency in asset/submission data.\n\nROLE RESPONSIBILITIES\nServe as Clinical Data Scientist for one or more clinical trials assuming responsibility for all DM&M activities including selection and application of data acquisition standards, Data Management Plan, selection of quality risk indicators, third party study data due diligence\nParticipates and ensures quality database design including documentation, testing and implementation of clinical data collection tools, both CRF and non-CRF, using an electronic data capture (EDC) system and/or other data collection systems.\nServe as a technical resource to the study teams for DM and RBM standards, tools, data provisioning, and reporting\nPartners with Research/Business Units and any external DM service provider to deliver high quality data management for all studies as assigned.\nProactively drives quality and efficiency to meet timeline and milestones for data management, ensuring scientific and operational excellence in support of strategic imperatives and in collaboration with the cross functional study team (s).\nEnsure work carried out by DM providers is in accordance with applicable SOPs and working practices.\nEnsure the required study-specific DM&M documents in the Trial Master File (TMF) are of high quality and are filed contemporaneously.\nEnsure operational excellence in collaboration with partners for application of standards, data acquisition, proactive data review and data integrity monitoring, data cleaning, e-data processing, data access and visualization, and database release.\nQUALIFICATIONS\nProficient experience using Oracle Inform EDC software\nExperience with Oracle DMW preferred\nWorking experience applying CDISC CDASH standards\nDemonstrated successful experience in all relevant clinical data management activities in a BioPharmaceutical or CRO setting\nWorking knowledge of all phases of clinical trials and ability to assess and determine study requirement from protocol review\nStrong Project and Risk Management\nCRO and vendor oversight experience preferred\nStrong verbal and written communication skills\nConsistent, detail oriented, communicative, dedicated to do a job well done\nMinimum 5 years Data Management experience required\nWorking knowledge of clinical research, FDA & ICH, GCP, GCDMP, and related regulatory requirements\nExperience using data visualization tools (e.g. Spotfire, jReview)\nFamiliarity with MedDRA/WHO-Drug\nProficiency in the use of Microsoft Office Suite of tools (Outlook, Word, Excel, etc.)\nBachelor\u2019s degree required.\nROLE MUST BE BASED IN SAN DIEGO\n\nRELOCATION ASSISTANCE NOT OFFERED WITH THIS ROLE\nSunshine Act\n\nPfizer reports payments and other transfers of value to health care providers as required by federal and state transparency laws and implementing regulations. These laws and regulations require Pfizer to provide government agencies with information such as a health care provider\u2019s name, address and the type of payments or other value received, generally for public disclosure. Subject to further legal review and statutory or regulatory clarification, which Pfizer intends to pursue, reimbursement of recruiting expenses for licensed physicians may constitute a reportable transfer of value under the federal transparency law commonly known as the Sunshine Act. Therefore, if you are a licensed physician who incurs recruiting expenses as a result of interviewing with Pfizer that we pay or reimburse, your name, address and the amount of payments made currently will be reported to the government. If you have questions regarding this matter, please do not hesitate to contact your Talent Acquisition representative.\n\nEEO & Employment Eligibility\n\nPfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status. Pfizer also complies with all applicable national, state and local laws governing nondiscrimination in employment as well as work authorization and employment eligibility verification requirements of the Immigration and Nationality Act and IRCA. Pfizer is an E-Verify employer.\n\n#LI-PFE\n\nPfizer is an equal opportunity employer and complies with all applicable equal employment opportunity legislation in each jurisdiction in which it operates.\nStart your job application: click Apply Now"}, "739": {"company": "BlackLine", "description": "Responsibilities:\nBring Creativity to Data products.\nApply machine learning methods to a variety of finance and accounting problems.\nResponsible for building and maintaining the machine learning systems, data, platform and processes.\nBuild, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.\nPerform qualitative and quantitative data analysis.\nCleanse and transform raw data used in machine models.\nPerform data munging, data mining, clustering & classification methods, pattern recognition.\nComfortable with statistics, calculus and multivariate analysis.\nParticipate in ML POCs, validate the results and develop production implementations.\nBuild and optimize scalable machine learning solutions in the public cloud.\nFamiliar with SQL, Python, R, SparkML, TensorFlow, GCP, AWS, SQL Server.\nDevelop production systems in Python.\nWork independently to research and solve business and technical problems.\nPlan their work individually and as part of a team.\nMentor and train other Data Scientists on the team.\nQualifications:\nStrong practical experience with machine learning techniques in the industry, accounting and financial industries is a plus.\nExtensive experience solving analytical problems using quantitative approaches.\nExperience with machine learning algorithms for building ML models, their accuracy, cleanliness, reliability.\nExperience with predictive and prescriptive analyses, modeling, and segmentation.\nHave strong passion for empirical data research for practical applications.\nAbility to communicate complex quantitative analysis in clear, precise, and actionable\nComfortable with complex, high-volume, high-dimensionality data from varying sources.\nVery comfortable with data engineering methods and pipelines.\nExpert knowledge of analysis tools such as R, Matlab, or SAS\nExperience with data warehousing, relational databases, ETL, BI, data mining.\nExperience in SQL, R, Python languages.\nStrong familiarity with GCP and AWS, SQL Server.\nPractical experience with GIT version control.\nComfortable working with open source tools in a Unix/Linux environment.\nExperience with and ownership of data-informed decision-making.\nExperience translating business requirements into functional, and non-functional requirements.\nStrong sense of product and data ownership.\nWorks independently without the need for supervision.\nStrong written and verbal skills \u2013 able to explain the work in plain language.\nMS/PhD in Computer Science or other quantitative disciplines\nTo apply to this job, click Apply Now"}, "740": {"company": "Wish", "description": "Want to join our NEW centralized data science team working on company level data projects?\n\nData driven decision-making is an integral part of life at Wish. It drives our success with customers and merchants. We\u2019re looking for talented Data Scientists to continue to improve our user experiences and grow the business through data and quantitative techniques. You should have a proven track record of using data to drive the understanding, growth, and the success of a product. You should be impact-driven, self motivated, and resourceful.\nWe are looking for Data Scientists focusing on analytics to:\nDefine and evaluate key metrics and understand their trade-offs.\nDiscover new leverage points to grow the business.\nDrive deep understanding of our user and product to develop actionable insights and recommendations.\nUnderstand and discover the root cause of metrics movement.\n\nDesired Skills & Experience\nA minimum of two years of data analytics related experience.\nBachelor degree in a quantitative field.\nProficient in SQL.\nPreferred Skills\nDemonstrated track record of successful projects in applying quantitative techniques to improve a product or business.\n3+ years analytics related experience in the technology industry.\nProficient in R or Python for data analytics\nWish is transforming the way the world shops by offering a convenient and personalized mobile shopping experience. Our mission is to offer an unlimited selection of affordable quality goods to be accessible for everyone on a global scale. We bring together world-class technical talent with a passion for connecting relevant products to relevant people.\n\nLearn more about us:\nIntro to Wish\nOur CEO discusses Wish\nCrunchbase\nRecruiting Video\n\nWish values diversity and is committed to creating an inclusive work environment. We provide equal employment opportunity for all applicants and employees. We do not discriminate based on any legally-protected class or characteristic. Employment decisions are made based on qualifications, merit, and business needs. If you need assistance or accommodation due to a disability, please let your recruiter know. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.\nTo apply to this job, click Apply Now"}, "741": {"company": "DTE Energy", "description": "The future is bright at DTE Energy! We are one of the largest Fortune 500 diversified utilities in the United States with an aspiration to be the best-operated energy company in North America and a force for good in the communities we live and serve. We have businesses in 26 different states and are comprised of regulated utility and non-utility businesses. Our utility business provides electric and gas service to approximately 3 million customers. Our non-utility businesses include a diversified portfolio of energy related companies, ranging from gas storage and pipelines to renewable power development.\n\nDTE Energy\u2019s utility and non-utility businesses are poised for significant growth. We look forward to working with highly motivated and team-oriented individuals to energize our efforts of growing economically and environmentally.\n\nRecently, DTE Energy has been recognized as an outstanding place to work and has received the following accolades:\n\n* Gallup Great Workplace Award for consecutive years\nCivic 50 Award for corporate citizenship excellence\nIndeed\u2019s annual \u201c50 Best Places to Work\u201d award for two years running\nMetropolitan Detroit\u2019s 101 Best and Brightest Companies to work For\nJ.D. Power Customer Satisfaction Award\nProfessional Women\u2019s Magazine/Black EOE Journal \u201cBest of the Best\u201d\nComputerworld\u2019s 100 Best Places to Work in IT\nBest Employers for a Healthy Lifestyle Gold Award\nDetroit Free Press Green Leaders Award\n\nDTE Energy is an equal opportunity employer and considers all qualified applicants without regard to race, color, sex, sexual orientation, gender identity, age, religion, disability, national origin, citizenship, height, weight, genetic information, marital status, pregnancy, protected veteran status or any other status protected by law.\n\nExternal Pre-Hire Assessment Required: Professional Pre-Hire Assessment\nTesting Required: Not Applicable\nJob Summary\nResponsible for translating business requirements into analytical constructs and using data to propose solutions for effective decision making. Collects, validates, transforms, and cleanses data, as well as performs quantitative analysis to derive insights. Runs analytical experiments in a methodical manner and regularly evaluates alternative models and techniques. Develops predictive models to forecast business performance metrics and provides recommendations for strategic decisions. Responsible for teaching others the tools, techniques and best practices in self-service reporting, data analysis and predictive analytics.\nKey Accountabilities\nPerforms in-depth analyses (e.g., cost-benefit, invest-divest, forecasting, predictive, what-if, impact analysis, etc.) to help the company focus on key decisions to improve safety, employee engagement, operational efficiency, product quality, and customer satisfaction\nDevelops, modifies, and automates reports, builds and prototypes dashboards to provide insights, and provides analytical solutions\nResponsible for discovering insights from Big Data to help shape or meet specific business needs and goals.\nDevelops and maintains analytical models through understanding data, evaluating technologies, optimizing algorithms, experimenting and validating models\nDelivers effective presentations that tell compelling stories about analytical insights\nPerforms data cleansing and blending processes to produce analytic data sets for use by a variety of downstream purposes\nImplements new statistical, mathematical, machine learning or other methodologies for modeling or analysis\nUtilizes business knowledge to translate goals into data-based deliverables, such as predictive models, pattern detection analysis or optimization algorithms\nTrains and enables self-service reporting capability and use of Business Intelligence tools for supported business unit(s)\nConducts research to identify relevant data for developing prototypes and proof-of-concepts\nCollaborates with cross-functional stakeholders to understand business needs, formulate complete end-to-end analyses that includes business requirements, data gathering, analysis, scaleable solutions, and presentations\nMinimum Education & Experience Requirements\nThis is a dual-track base requirement job; education and experience requirements can be satisfied through one of the following two options:\nBachelor\u2019s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 3 years of experience working in a data analytical or computer programming function; or\nMaster\u2019s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 1 year of experience working in a data analytical or computer programming function\nOther Qualifications\nPreferred:\nMaster\u2019s or PhD degree in Data Science\nExperience in quantitative analytics (e.g. data mining, regression analysis, hypothesis testing, predictive modeling techniques, and model optimization)\nKnowledge and intermediate-level skills in data modeling, data structure, and the application of complex SQL queries with data from multiple sources, including Big Data platform (e.g., Hadoop, AWS, Azure)\nFamiliarity with Cloud environments\nExperience with SAP Business Intelligence tools and SAP CRM, ISU, and BW data\nFamiliarity with Continuous Improvement concepts and applications (e.g., six sigma, lan)\nStrong written and verbal communication skills\nUtility/energy or customer-oriented industry experience\nOther Requirements:\nIntermediate-level experience with data mining and statistical analysis using analytical packages/tools (e.g., R, SAS, SPSS, Stata, MATLAB, Minitab, etc.)\nIntermediate-level experience in articulating business questions, pulling data from relational databases (e.g., SAP BW, ORACLE, SQL SERVER) and using advanced excel and statistical tools (e.g., Minitab, Alteryx, Advanced Excel with VBA, R, Python, SAS, SPSS, Stata, MATLAB, etc.) to conduct in-depth analysis to support decision making\nIntermediate-level proficiency in business intelligence tools (e.g., Microsoft PowerBI, Tableau, SAP, Business Objects (BOBJ), etc.)\nIntermediate-level programming skills in SQL, C/C++/C#, PHP, Java, Python, R, ASP, or SAS\nUnderstanding of applied research design and machine learning (e.g. multivariate statistical analysis, unsupervised and supervised learning, predictive modeling)\nSelf-starter and quick learner; advances self and others' knowledge and skill sets in business processes, data science, new analytical frameworks, technologies, and applications\nInterpersonal, analytical and problem-solving skills, including ability to communicate technical information and complex data analytics to a non-technical audience\nAdditional Information\nIncumbents may engage in all or some combination of the activities and accountabilities, and utilize a variety of the competencies cited in this description depending upon the organization and role to which they are assigned. This description is intended to describe the general nature and level of work performed by incumbents in this job. It is not intended as an all-inclusive list of accountabilities or responsibilities, nor is it intended to limit the rights of supervisors or management representatives to assign, direct and control the work of employees under their supervision.\nApply Now: click Apply Now"}, "742": {"company": "Nolij Consulting", "description": "Nolij Consulting, LLC is an Economically Disadvantaged Women-Owned Small Business (EDWOSB) providing consulting services for IT Operations, Software Development, Program Management, Training, Human Capital/HR Operations, and Acquisition Management. Our mission is to understand the challenges and goals of our clients, address them with innovative solutions, and work together to achieve project success. Were eager to hear from candidates like you that can join and contribute to our team.\n\nNolij Consulting has an opening for a Lead Data Scientist to join our team based in Vienna, VA.\n\nResponsibilities:\nMust be able to think abstractly in developing scalable models representing human language descriptions of real world items.\nMust be able to implement various statistical and mathematical models to compare different items using various AI patterns.\nMust be familiar with standard concepts, practices, and procedures within the AI domain.\nMust have experience in advanced analytics across a number of dimensions to find insights in unstructured data from a number of sources.\nMust have experience in supervised and unsupervised learning, development of primary models via AI, Markov decision processes, semantic networks, neural networks, cluster analysis and deductive dynamic classification.\nMust be familiar or willing to learn operating in a Block-chain Hyperledger Fabric framework.\nMust be able to rely on limited experience and judgment to plan and accomplish goals.\nMust be able to show a large degree of creativity and latitude in a high tempo work hard/play hard team.\nMust be able to work side by side with a wide range of stakeholders in a 'full contact development' approach.\nRequirements:\nRequired a bachelor's degree in area of specialty.\nRequired at least 8-10 years of experience in the field or in a related area.\nNote: Since this position is for a Federal Project, a candidate must possess US Citizenship to obtain Clearance.\nDo you like the idea of being a driver on a team of distinction? If so, we want to hear from you. To apply, go to https://www.nolijconsulting.com/careers/\n\nNolij is an EEO/Affirmative Action employer and encourages all qualified applicants to apply.\nApply Now: click Apply Now"}, "746": {"company": "FanDuel", "description": "FanDuel Group is an innovative sports-tech entertainment company that is changing the way consumers engage with their favorite sports, teams, and leagues. The premier gaming destination in the United States, FanDuel Group consists of a portfolio of leading brands across gaming, sports betting, daily fantasy sports, advance-deposit wagering, and TV/media, including FanDuel, Betfair US, DRAFT, and TVG. FanDuel Group has a presence across 45 states and 8 million customers. The company is based in New York with offices in California, New Jersey, Florida, Oregon, and Scotland.\n\nAbout the role\n\nThe sportsbook analyst will be responsible for providing a data driven approach to key long-term investment decisions as well as providing insight to sustain and accelerate the growth of the business. The role will leverage internal data sources, market data and industry knowledge & expertise to support strategic decision making.\n\nPre-requisites for the role include a technical/analytical skill set, a strong business acumen and a curious mind-set capable of thinking outside the box and questioning the status quo. The role requires a high degree of flexibility and the ability to proactively provide insight and recommendations throughout the organization.\n\nEssential Functions\n\nIn depth analysis\nUnderstand the business drivers, spot new growth opportunities and make recommendations to drive the business to a higher level of profitability.\nBusiness cases\nWork on new investment ideas, building a business case to support the decision. Assess costs and forecast the revenue streams.\nMarketing spend analys\nUnderstand the impact of retention and acquisition marketing on the business. Calculate the Return of Investment, provide actionable insights and work with the commercial and marketing team to set the right strategy.\nAutomating processes\nUse a scalable approach when facing problems and build tools to automate and improve manual processes.\nWho we're looking for\nExperience in working with large complex datasets to derive insight and\nExcellent knowledge of MS Excel and Power Point.\nExcellent knowledge of SQL.\nComfortable using graphs and other illustrative tools to present large volume of data.\nPro-active problem solver attitude with flexibility to work across different units.\nStrong work ethic complemented by a positive, can-do attitude.\nUnderstanding of the online business, e-commerce.\nInclined to learn data analysis tools and languages such as Knime, R, SAS etc.\nProfessional interest in sports and wagering.\nCollege Degree in an analytical discipline (i.e. Engineering, Statistical Science, Mathematics, Actuarial Studies, Economics, Computer Science, etc.)\nA minimum of 2 years analytics/data engineering experience, working in an analytically focused role.\nWhat you get in return\n\nBeyond working with such a great team!\nAn exciting environment with real growth\nContribute to exciting products used by a highly passionate user base\nPersonal learning and development opportunities\n401K with company contribution match\nGenerous healthcare & value creation share plan\nThere's more, but we don't want to go on and on!\n\nFanDuel is an equal opportunities employer. Diversity and inclusion in FanDuel means that we respect and value everyone as individuals. We don't tolerate bias, judgment or harassment. Our focus is on developing employees so that they reach their full potential.\nStart your job application: click Easy Apply"}, "747": {"company": "SeatGeek", "description": "We are looking for a talented data scientist to join SeatGeek's Marketing Science & Analytics team in New York City. As a member of the team, your insights will shape strategy across important marketing functions such as user acquisition, retention, brand, and sponsorship.\n\nYou will dive into a sea of data to understand the effectiveness of marketing campaigns, the optimal marketing resource allocation, the unique dynamics of supply and demand in the ticketing marketplace, and differences in customer behavior across segments. This is your chance to help improve the world's fastest-growing company in the live event ticketing space. As an essential part of data science team, you will not only learn from a team of exceptional analysts, product managers and machine learning experts, but also develop your financial literacy through substantial executive exposure.\n\nWhat You'll Do:\nLead strategic marketing experiments; design test plans, obtain cross-functional alignment, perform analysis, and provide insights\nApply marketing experimentation insights to daily campaign measurement and reporting; forecast impact and provide ongoing recommendations for optimization and efficiency\nAssess and develop new measurement solutions by applying your modeling skills, with a focus on channel interactions (i.e. Media Mix Modeling)\nDevelop a deep understanding of customers and customer value using first-party and third-party data touchpoints/channel, promo usage, and purchase behavior.\nEstablish key metrics for marketing channels and understand drivers of changes. Help set realistic performance targets\nUse your excellent communication skills to develop fantastic partnerships with performance channel managers, product and offline marketing on experimentation roadmap and design.\nWho You Are:\n\n\n3 or more years years of relevant applied experience with a degree or higher in economics, psychology, computer science, statistics, or mathematics or another quantitative discipline\nTechnical competence to perform advanced analytics and predictive modeling\nCoding skills (such as R or Python) and familiarity with the standard data science modeling toolkit\nUnderstand probability theory, causal inference, and experimental design, along with having used them in the real-world\nExperience with data extraction & visualization tools (SQL, Looker, ggplot/matplotlib or equivalent)\nA strong statistical understanding of online testing methodologies and metric development\nBonus: Work experience with marketing, marketing analytics, customer analytics\nSeatGeek is committed to providing equal employment opportunities to all employees and applicants for employment regardless of race, color, religion, creed, age, national origin or ancestry, ethnicity, sex, sexual orientation, gender identity or expression, disability, military or veteran status, or any other category protected by federal, state, or local law. As an equal opportunities employer, we recognize that diversity is a positive attribute and we welcome the differences and benefits that a diverse culture brings. Come join us!\nTo apply to this job, click Apply Now"}, "748": {"company": "Eversight", "description": "The Opportunity\n\nEversight is the recognized leader in AI-powered price and promotions. Eversight's proprietary cloud-based SaaS solution brings AI and continuous experimentation to consumer brands and retailers. Our software acts as a coach, enabling market leaders to transform pricing and promotion strategy for the $3.4 trillion spent in consumer goods retail using intelligent, real-time data and insights.\n\nReporting directly to the Head of Data Science, you will be at the center of what determines Eversight's success as a company. You will develop production code using the newest data science techniques to determine the optimal prices and promotions for Consumer Packaged Goods companies such as Coca-Cola, Mars, and General Mills, and the retailers that sell these products. This is an opportunity to work at the tip of the spear in applying cutting edge data science to transform an industry, working cross-functionally with a collaborative team in a dynamic startup.\n\nResponsibilities\nWork with Product Management to help generate ideas and quickly turn them into efficient, well-tested, functioning code (including but not limited to Python)\nResearch and implement modern data science techniques to solve problems in a robust manner\nMine customer and retailer digital assets to generate insights about optimal promotional test design and variable selection\nPartner with the engineering team to create highly scalable solutions\nServe as data science expert for Eversight's users\nTranslate analytic insights into concrete, actionable recommendations for business or product improvement\nLead custom analyses and communicate findings\nContribute to experimental design and validation\nTechnical resource for science-related questions about the product, test design, and insights\nBehavioral Profile\nAnalytical, framework thinker with a strong empirical orientation\nComfortable in a fast-paced environment\nElite ability in math and statistics\nHighly collaborative\nStrong at translating data science concepts to non-technical audiences\nBusiness focused; measures work in its contributions to business outcomes and prioritizes effort against deliverables accordingly\nExperience\n2+ years of relevant experience in analytics, machine learning, data mining and experimentation with direct impact on business value\nExperience with large data sets\nB.S. in Statistics, Mathematics, Engineering, Operations Research, Economics, Computer Science or relevant quantitative field\nExperience in A/B testing and design of experiments (DOE) preferred\nExperience in machine learning methods with emphasis on regression techniques (GLM, GLMM, decision trees, logistic regression, boosting, SVM)\nExperience with SQL strongly preferred\nAgile experience strongly preferred\nExperience with econometric modeling nice to have\nKnowledge of common data structures and ability to write efficient code in Python\nLocation\n\nPalo Alto, CA\n\nAbout the Company\n\nEversight is the recognized leader in AI-powered pricing and promotions. Global brands and retailers rely on the Eversight platform to optimize pricing in response to market conditions and to deliver higher ROI on promotional spend. Eversight's Pricing Suite and Offer Innovation Suite solutions are driving strong margin and sales volume improvements for leading companies such as Coca-Cola, General Mills, Raley's, and Rite Aid. Founded in 2013, Eversight is headquartered in Palo Alto, California, with offices in Chicago and New York.\nTo apply to this job, click Easy Apply"}, "749": {"company": "Perspecta", "description": "Business Group Highlights\nCivilian, State and Local\n\nPerspectas Civilian, State and Local segment partners with the U.S. Federal Civilian State and Local governments to provide infrastructure services, business solutions, and digital transformation services that help them achieve policy objectives and integrate citizen-centric services.\n\nResponsibilities\n\nCandidate will use SQL, power pivot, excel, pyramid analytics and/or other similar software to analyze data to support business decisions.\nEffectively collaborates with others to identify/clarify data needs, operationalize data elements, and format/display the data in order for it to become useful.\nQualified candidates will be able to develop computer code to support data modeling and simulation/resampling techniques and to store, manipulate, transform or present information/data.\nDevelop, analyze and present data model and modeling results to the customer.\n\nQualifications\n\nDegree from an accredited college or university in Computer Science, Information Systems, a Physical Science, Engineering or a Mathematics-Intensive discipline.\nBachelor's degree and 6 years of experience, or Master's and 4 years of experience, or PhD and 2 years of general IT experience (including formal training and 1 years experience in Business Process Reengineering (BPR) methods, plus 1 year training and experience in enterprise applications).\nApplicable training certificate from an accredited training institution.\nQualified candidates will possess substantial knowledge useful in managing large, complex AIS projects, closely related to the work to be automated.\n5 years of increasingly complex and progressive experience in performing systems analysis, development, and implementation of business, mathematical, or scientific settings using a variety of information technology resources. Has experience with current technologies and, where required for the task, emerging technologies.\n\nAbout Perspecta\n\nWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sectorfrom investigative services and IT strategy to systems work and next-generation engineering.\n\nOur promise is simple: never stop solving our nations most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to just that, as a partner of choice across the entire sector.\n\nPerspecta is an AA/EEO Employer - Minorities/Women/Veterans/Disabled and other protected categories.\n\nOptions\n\nApply for this job onlineApply\n\nShare\n\nEmail this job to a friendRefer\nSorry the Share function is not working properly at this moment. Please refresh the page and try again later.\n\nShare on your newsfeed\n\nAs a government contractor, Perspecta abides by the following provision\nPAY TRANSPARENCY NONDISCRIMINATION PROVISION\nThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)"}, "750": {"company": "Mercedes-Benz Research & Development North America, Inc.", "description": "Embedded in a worldwide network Mercedes-Benz Research &\nDevelopment North America, Inc. continuously strives to remain at the forefront\nof successful automotive research and development. MBRDNA is headquartered in\nSilicon Valley, California, with key areas of Autonomous Driving, Advanced\nInteraction Design, Digital User Experience, Machine Learning, Customer\nResearch, and Open Innovation. In Redford, Michigan, the focus is on Powertrain\nand eDrive technology as well as in Long Beach, where the teams test durability\nof the latest driver assistance and telematics systems. The Digital Hub in\nSeattle focuses on developing a cloud architecture and building out the cloud\nplatform for the next generation of connected car services. The Testing and\nRegulatory Affairs team in Ann Arbor and the Advanced Vehicle Design in\nCarlsbad complete the competence center.\nJob Introduction: (Primary purpose of this position)\n\nCollaborate\ndirectly with stakeholders and subject-matter experts to define use-cases and\nidentify relevant data sources\n\nKey Tasks & Responsibilities\n\u2022Analyze available data and create reports and dashboards to generate internal\nbusiness intelligence and enable data-driven decision making\n\u2022Where applicable, use data visualizations to help demo and explain insights\nto key stakeholders and management\n\u2022Develop predictive models and new algorithms that can be used in\nnext-generation vehicle features and services\n\nEducation & Experience\nRequired\nQualifications Minimum level of education required and required field of\nstudy:\n\nBA/BS in Computer Science, Math, Physics,\nEngineering, Statistics or other relevant technical field. Advanced degrees\npreferred.\nMinimum skills\nrequired :\n\n\u2022Demonstrable programming experience with at\nleast two of the following languages: Python, Java, Scala, R, Ruby, MATLAB,\nSQL\n\u2022Solid knowledge and experience with a scientific computing platform (e.g.\nscikit learn, Weka, MATLAB)\n\u2022Hands-on experience working with common DBMS (SQL, NoSQL), as well as\ndistributed application platforms (Hadoop)\n\u2022Strong knowledge of statistical data analysis and machine learning techniques\n(e.g. SVM, regression, classification, clustering, time series, deep learning)\n\u2022Hands-on experience with visualization tools (e.g. D3.js, Tableau) and an\nacute ability to prepare and present data in a visually appealing and easy to\nunderstand manner\n\u2022A strong voice for data integrity and reporting quality utilizing\nbest-practices and industry standards\n\u2022Excellent critical thinking, problem solving and analytical skills\n\u2022Excellent communication skills, and the ability to work effectively with\nothers\nCombination of\nDegree and Years of experience acceptable (minimum) :\n\nBachelors 2 yrs / Masters 0 yrs\nWill accept\nequivalent work experience in lieu of formal education\n\nYes\nCombination of\nDegree and Years of experience acceptable (minimum) : Bachelors 3 yrs / Masters 1 yrs\nWhy should you apply?\n\nHere at MBRDNA, you create digital ecosystems around cars, you design\na language between humans and machines, you make a car even more intelligent -\nyou make the new reality for cars. Our benefits include medical, dental and\nvision insurance, 401k savings plan, tuition and fitness reimbursement programs\nand much more. We have an open and flexible environment to allow you to push\nboundaries, join MBRDNA and design your future.\n\nCheck out our open jobs here. Learn more about MBRDNA and\nconnect with us on LinkedIn, Twitter, Instagram\nand Facebook.\n\nMBRNDNA is an equal opportunity employer (EOE) and strongly supports diversity\nin the workforce.\n\nMBRNDNA only accepts resumes from approved agencies who have a valid Agency\nAgreement on file. Please do not forward resumes to our applicant tracking\nsystem, MBRNDNA employees, or send to any MBRNDNA location. MBRNDNA is not\nresponsible for any fees or claims related to receipt of unsolicited resumes.\nStart your job application: click Apply Now"}, "751": {"company": "GameChanger", "description": "About GameChanger:\n\nSports matter because they inspire leadership, teamwork, commitment, and confidence\u2014critical life lessons that have the power to propel young athletes toward meaningful futures. GameChanger recognizes that without coaches, parents, and volunteers, organized youth sports could not exist. We celebrate those tireless heroes and make it our mission to help them do what they do best.\n\nGameChanger is a SportsTech company providing team management, scorekeeping, and live fan experiences that build connections across the team community. With GameChanger, coaches and parents can organize and follow their athlete's journey in a simple and powerful way.\n\nWe're headquartered in downtown Manhattan and are proud to be part of the DICK'S Sporting Goods family.\n\nThe position:\n\nWe are looking for a data scientist that can use data to help us make smarter decisions and deliver even better products. In this role you will work closely with other data scientists, product managers, designers, marketers, and engineers to create measurements and appropriate metrics, design randomized controlled experiments, and tackle open-ended questions that help us understand our users and business. Making use of GameChanger's rich data warehouse and other data sources, you'll get to work creatively to answer hard questions and expand the impact of the current Data & Analytics Team.\n\nYou will:\nFrame out major data initiatives to answer open-ended questions around product and user needs\nAsk thoughtful questions in order to understand partners' goals, and discover the best solutions to data-centric problems\nWork with product teams to integrate data-driven features into our products\nSelect appropriate statistical methods, and implement the solutions with clean code\nTransform our raw data into useful product metrics\nWork closely with data engineers to define the requirements of our data pipeline and warehouse\nWhat we're looking for:\n3+ years experience doing stakeholder-focused quantitative work\nAbility to write efficient SQL queries, and clean Python or R analytic code\nExperience applying statistical and machine learning methods to business problems\nAbility to listen to, write for, and present to audiences with a range of quantitative experience\nOptional Experience:\nMasters degree (or equivalent) in computer science, mathematics, statistics, economics, or a related field\nLooker or equivalent business intelligence tool\nNoSQL databases, particularly MongoDB\nCommand line & git\nThe Perks:\nBe part of a diverse team of genuinely kind and interesting individuals dedicated to improving the lives of our customers.\nBenefits include medical, vision, prescription, dental, FSA/HRA, and coverage for family/dependents.\nGenerous maternity / paternity leave policy\nWell-furnished, modern office\nCommuter Benefits\nEndless supply of snacks and drinks\nLearning tools including Safari Books Online, opportunities to join clubs, hack days, and conferences\nOrganized lunches, happy hours, and team outings\nThe Culture:\n\nAt GameChanger we are\u2026\n\nCustomer-Obsessed\nWe put our customers first, always asking, \"Will this enhance their youth sports experience?\"\nWe deeply understand our customers and work hard to anticipate their needs.\nWe celebrate and support our customers' contributions to their communities.\nTeam Players\nWe listen actively, seeking to understand others before making ourselves heard.\nWe challenge each other directly while caring about each other personally.\nWe do unglamorous work in service of the team.\nAmbitious\nWe set aggressive goals designed to drive meaningful change.\nWe are eager teachers and curious students who invest in learning.\nWe are resilient, thriving in change and adversity.\nEmpowered\nWe value creative ideas and productivity over seniority and hours worked.\nWe entrust decisions to those best positioned to make them.\nTo apply to this job, click Apply Now"}, "752": {"company": "Perspecta", "description": "Business Group Highlights\nCivilian, State and Local\n\nPerspectas Civilian, State and Local segment partners with the U.S. Federal Civilian State and Local governments to provide infrastructure services, business solutions, and digital transformation services that help them achieve policy objectives and integrate citizen-centric services.\n\nResponsibilities\n\nThe candidate will provide coordination and leadership to project members involved in the detailed identification and collection of necessary data; interpret and analyze data; develop and evaluate alternatives; and prepare appropriate documentation to support knowledge transfer.\nPerform various duties concerned with the application of, or research into, computer science methods, data modeling and simulation/resampling techniques to store, manipulate, transform or present information/data.\nPossess specialized knowledge of design characteristics, limitations, and potential applications of information systems, modeling and of broad areas of applications of computing which have common structures, processes, frameworks and techniques useful to analyze and support business processes.\n\nQualifications\n\nThis position requires a minimum of 10 years experience, of which at least 7 years must be specialized.\nA Master's degree in computer science, information systems, engineering, business, education, management sciences, psychology, human resources development/management, or other related scientific or technical discipline.\nWith a Bachelor s degree in computer science, information systems, engineering, or other related scientific or technical discipline and 12 years general experience of which at least 9 must be specialized experience, a Masters degree is preferred.\nWith a Ph.D. (in the fields described above): 8 years general experience of which at least 6 years must be specialized experience is required.\nSpecialized experience may include: facilitation, training, methodology development and evaluation, process reengineering across all phases, identifying best practices, change management, business management techniques, organizational development, activity and data modeling, or information system development methods and practices and supervision of Business Process Reengineering Specialist.\n\nAbout Perspecta\n\nWhat matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sectorfrom investigative services and IT strategy to systems work and next-generation engineering.\n\nOur promise is simple: never stop solving our nations most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to just that, as a partner of choice across the entire sector.\n\nPerspecta is an AA/EEO Employer - Minorities/Women/Veterans/Disabled and other protected categories.\n\nOptions\n\nApply for this job onlineApply\n\nShare\n\nEmail this job to a friendRefer\nSorry the Share function is not working properly at this moment. Please refresh the page and try again later.\n\nShare on your newsfeed\n\nAs a government contractor, Perspecta abides by the following provision\nPAY TRANSPARENCY NONDISCRIMINATION PROVISION\nThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)"}, "753": {"company": "Kelly Services", "description": "Kelly Services has an outstanding opportunity as a Data Scientist in Houston.\n\nReporting to the Manager of Information Management (IM), the Data Scientist will be engaged in the performance monitoring as well as the development and delivery of business improvement initiatives for Information Management, to enhance the delivery of services offered by TC Energy\u2019s Technical Center. The work within this role may span the department and may be sensitive in nature.\n\nResponsibilities:\nGather, analyze, evaluate and report data\nPrepare and deliver presentations to internal and external clients at all levels of staff and management\nProvide team with strategy, insights, analytics, and reports to support data migration activities\nMigration of operational, regulatory, and engineering content across ECM systems\nDeliver valuable insights via data analytics and advanced data-driven methods\nProvide data-driven, action-oriented solutions to challenging data migration initiatives\nAnalyzing and processing complex data sets using advanced querying, visualization and analytics tools\nDemonstrated ability to perform under tight deadlines with multiple priorities\nResearch, analyze and synthesize multi-source data and produce clear and precise outputs, reports and recommendations\nDeal with ambiguity and is sensitive to confidential material\nDeveloping/implementing algorithms based on deep-dive analysis and data modeling to support data migration and cleanup efforts\nRelied on as a key advisor in data migration activities\nOther tasks as required\nQualifications:\nUndergraduate Degree\n5+ years of relevant work experience\nStrong analytical and critical thinking skills;\nOpenText or other ECM platforms\nStatistics; Data Analytics; Data Science; Computer Science; Data and Quantitative Analysis; Decision Analytics; Predictive Modeling; Data-Driven Personalization; KPI Dashboards and BPI Plans\nFamiliarity with records management\nBig Data Queries and Interpretation\nData Mining and Visualization Tools\nMachine Learning Algorithms\nBusiness Intelligence (BI)\nResearch, Reports and Forecasts\nFamiliarity with engineering content\nCertifications: MCSE: Data Management and Analytics (optional)\nData and Analytics Tools/Languages: Spark, SparkR, R, Python, Scala, Hive, SQL, VBA, SAS, Tableau/Power BI, SPSS or Stata\nImportant information: This position is recruited for by a remote Kelly office, not your local Kelly branch. To be considered for this position, you must apply now to submit your resume. If you have questions about the position, you may contact the recruiter recruiting for this position (Matt Baldwin: matb122@kellyservices.com).\n\nWhy Kelly\u00ae?\n\n\nWith Kelly, youll have direct connections to leading IT organizations in the best companies around the globeoffering you the chance to work on some of todays most intriguing, innovative and high-visibility projects. In a field where change is the only constant, our connections and opportunities will help you take your career exactly where you want to go. We work with 90 of the Fortune 100 companies companies and found opportunities for more than 8,600 IT professionals last year. Let us help advance your career today.\n\nAbout Kelly\u00ae\n\n\nAt Kelly, were always thinking about whats next and advising job seekers on new ways of working to reach their full potential. In fact, were a leading advocate for temporary/nontraditional workstyles, because we believe they allow flexibility and tremendous growth opportunities that enable a better way to work and live. Connecting great people with great companies is what we do best, and our employment opportunities span a wide variety of workstyles, skill levels, and industries around the world.\n\nKelly is an equal opportunity employer committed to employing a diverse workforce, including, but not limited to, minorities, females, individuals with disabilities, protected veterans, sexual orientation, gender identity. Equal Employment Opportunity is The Law.\nApply Now: click Apply Now"}, "754": {"company": "Swiss Re", "description": "About Swiss Re</strong></p>\n\nThe Swiss Re Group is one of the world\u2019s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. It anticipates and manages risk \u2013 from natural catastrophes to climate change, from ageing populations to cybercrime. The aim of the Swiss Re Group is to enable society to thrive and progress, creating new opportunities and solutions for its clients. Headquartered in Zurich, Switzerland, where it was founded in 1863, the Swiss Re Group operates through a network of around 80 offices globally. It is organised into three Business Units, each with a distinct strategy and set of objectives contributing to the Group\u2019s overall mission.\n\nABOUT SWISS RE\n\nSwiss Re is one of the world\u2019s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We apply fresh perspectives, knowledge and capital to anticipate and manage risk. (For more company information, go to www.swissre.com).\n\nINTERN PROGRAM DETAILS\n\nEvery year, Swiss Re offers internships to a number of bright and highly motivated students, enabling them to benefit from the company's global perspective and to discover the world. A Swiss Re internship can be much more than a temporary job - it can be your first step to a rewarding career. The program is expected to last 10 - 12 weeks, offers competitive salaries, and is offered in various Swiss Re locations.\n\nABOUT YOU\n\nWe are looking for students who have a passion for tech and innovation. You have a desire to work with technical experts and business leaders to drive ideas forward. You are resilient, passionate, creative, and dependable. You are curious with a focus in execution, taking great pride in attention to details. You hold yourself and your colleagues to a high bar, and inspire us to aim higher.\n\nABOUT THE TEAM\n\nYou will join an entrepreneurial global team comprised of technologists and innovation specialists, with diverse technical and business backgrounds, who are passionate about solving the problems of tomorrow. As a part of this global team, you will have the opportunity to collaborate with colleagues in Canada, Latin America, Europe, and Asia.\n\nABOUT THE DATA SCIENTIST INTERN POSITION\nAs a Data Science Intern you will join a team of data scientists, analytics consultants, and business experts to work on a global strategic initiative to make better use of our data and enhance our ability to make data driven decisions. You will work closely with business stakeholders to identify opportunities for leveraging data to drive business solutions, understand the business problem and extract relevant trends and patterns from data.\nYou will help the team shape, develop, and execute complex analytic solutions that will transform the insurance industry. You will gain exposure to a project that is leveraging cutting edge technology that applies Big Data and Machine Learning to solve new and emerging problems for Swiss Re. You will also support the Analytics Consulting team in sharing periodic updates with stakeholders to highlight key projects and milestones.\n\nOpportunities:\n\n\u2022 Work with a business team to analyze data sets and design analytical solutions\n\n\u2022 Build industry knowledge\n\n\u2022 Communicate findings that help support solving business problems, insight generation and decision making\n\n\u2022 Develop custom data models and algorithms to apply to datasets\n\n\u2022 Build end to end big data pipelines from data ingestion to insight generation\n\n\u2022 Check to ensure consistency, integrity and robustness of data pipelines\n\n\u2022 Manage code base and git repository in the development platform\n\nPosition Requirements:\n\n\u2022 Pursuing a Master's Degree in data science/analytics, computer science, computational linguistics or related field.\n\n\u2022 Analytical & conceptual skills to understand key business needs and design tailored solutions to solve specific business problems.\n\n\u2022 Proficient in Python and or R, SQL; Familiarity with PySpark is a plus \u2022 Experience with large data sets and distributed computing (Hive/Hadoop) is a plus.\n\n\u2022 Exposure to cognitive technology\n\n\u2022 Exposure or experience in areas such as information retrieval, natural language processing, data analytics and information visualization.\n\n\u2022 Basic understanding of statistical analysis\n\n\u2022 Ability to adapt to a flexible work environment.\n\n\u2022 Team leader/player with a \"can do\" attitude.\n\n\u2022 Ability to read, speak and write in Spanish proficiently to communicate with clients is a plus.\n\n\u2022 Exceptional academic performance (minimum 3.25 GPA).\n<strong>\n</br>Swiss Re\nStart your job application: click Apply Now"}, "755": {"company": "The Knot Worldwide", "description": "WHAT WE DO MATTERS:\n\nHere at The Knot Worldwide, we believe in doing work that matters. In 15 countries around the world, our leading family of brands (The Knot, WeddingWire, Bodas, GigMasters, The Bump, How They Asked, Lasting, and more) inspire, inform, and celebrate our communities as they move through life's milestones. From the proposal to creating a home, and starting a family together, we're there for every step of the journey. Our couples and business partners depend on us. They're all in. So are we.\n\nABOUT THE ROLE AND OUR TEAM:\n\nThe Knot Worldwide is in search of a full-time Data Scientist. Our Data Scientists work with stakeholders across all departments within the company. They answer strategic questions and provide insight to internal decision makers ranging from executives and senior management to product managers and team leads. They also work with our product team to develop data driven algorithms that improve features on the website.\n\nRESPONSIBILITIES:\nCreate smarter product solutions for our couples and vendors\nAnswer strategic questions by analyzing behavioral data\nCommunicate, collaborate and present results to clients within The Knot Worldwide\nExplore novel ways to look at our data\nSUCCESSFUL DATA SCIENTIST CANDIDATES HAVE:\nMaster's Degree or Ph.D. preferred\nProficiency in key statistical and machine learning techniques (predictive modeling, classification, clustering, text analytics, recommender systems , data mining methods, forecasting, and other advanced techniques)\nProficiency with R or Python\nFamiliarity with common Linux command line tasks and version control software like git or svn preferable\nAbility to communicate effectively and influence others\nAbility to work in a fast paced environment and shift gears quickly\nAt The Knot Worldwide, we believe you are more than a resume and invite you to go for it, take the leap of faith, and apply for this job if it sparks your passion to join TKWW and make a difference!\n\nWHAT WE LOVE ABOUT YOU:\nYou deeply understand our users and put them at the center of everything you do. You aim to serve and delight them every day.\nYou are respectful and act with the highest integrity.\nYou ask questions to understand a perspective and are comfortable respectfully challenging assumptions.\nYou set clear ambitious goals. You anticipate obstacles, persevere, and are accountable for your commitments.\nYou aren't afraid to challenge the status quo and know that there's no such thing as failure if you learn from it.\nYou seek out feedback and never settle in your quest to grow and develop. By being here, you make our company stronger.\nWHAT YOU LOVE ABOUT US:\n\nThe Knot Worldwide offers a unique employee experience and we are deeply proud of our award-winning culture. From flexible vacation and generous parental leave benefits to promoting wellness and giving back to our community, we believe in happiness above all else\u2014in and out of the office.\n\n----\n\nThe Knot Worldwide provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, or disability. In addition to federal law requirements, The Knot Worldwide complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. The Knot Worldwide expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status.\n\n--\n\nThis position is not eligible for sponsorship.\nTo apply to this job, click Easy Apply"}, "756": {"company": "Colgate-Palmolive", "description": "No Relocation Assistance Offered\n# 73484 - Piscataway, New Jersey, United States\n\nWe are looking for a Data Scientist who will support our cross-functional teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\nResponsibilities for Data Scientist\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nDevelop company A/B testing framework and test model quality.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications for Data Scientist\nWe\u2019re looking for someone with 0-5 years of experience manipulating data sets and building statistical models,\nBachelor's degree required; Certificate, Master\u2019s or PHD in Statistics, Mathematics, Computer Science or another quantitative field a plus\nStrong problem solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nA drive to learn and master new technologies and techniques.\nFamiliarity with the following software/tools:\nCoding knowledge and experience with several languages: Java, R, Python, SLQ\nExperience with cloud services: GCP, AWS, etc\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Facebook Insights, etc.\nExperience with big data tools: Hadoop, Spark, Kafka, etc.\nExperience visualizing/presenting data for stakeholders using: Data Studio, Datalab, Redshift, etc\nEqual Opportunity Employer\nColgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.\n\nAre you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.\n\nColgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom\u2019s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill\u2019s Science Diet and Hill\u2019s Prescription Diet.\n\nFor more information about Colgate\u2019s global business, visit the Company\u2019s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures\u00ae oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill\u2019s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom\u2019s of Maine please visit http://www.tomsofmaine.com.\n\nReasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject \"Accommodation Request\" should you require accommodation.\nApply Now: click Apply Now"}, "757": {"company": "Grammarly", "description": "The opportunity\n\n\nGrammarly empowers people to thrive and connect, whenever and wherever they communicate. More than 20 million people around the world use our AI-powered writing assistant every day. All of this begins with our team collaborating in a values-driven and learning-oriented environment.\n\nWe're looking for a Data Scientist to help us drive decision-making, find bigger opportunities, and improve our product. As a consumer internet company, we produce huge amounts of data, and in this role, you will have outsize opportunities to develop the insights to make it actionable. You will have broad impact and exposure across Grammarly, working with team members from our Product, Research, Marketing, Engineering, and Finance teams.\n\nGrammarly's engineers and researchers have the freedom to innovate and uncover breakthroughs\u2014and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.\n\nYour impact\n\n\nAs a Data Scientist at Grammarly, you will help our team make better decisions by advocating for data-driven approaches across the organization. Your analysis will contribute to our strategy across the business in areas such as user acquisition, engagement, retention, and more.\nWithin your first month, you will start developing a good understanding of the overall data-processing pipeline, understand a subset of Grammarly's key metrics, and complete at least two small data reports to present to relevant business owners.\nBy month three, you will become an expert user of our analytical tools, start contributing to the Data Science team's projects, understand all of Grammarly's key metrics, and independently work on small-to-medium-complexity data projects (including A/B tests, channel analysis, and user engagement).\nBy month six, you will start working independently on complex data projects, such as user segmentation, short- and long-term user-engagement analysis, and lifetime value projections.\nBy year one, you will become the go-to person and subject-matter expert for a few of Grammarly's key metrics, own and drive projects independently with minimal supervision, and along with our other Data Scientists, ensure \"data science excellence\" at Grammarly (dashboards, high-quality reports, empowered teams, etc.).\nWe're looking for someone who\nEmbodies our EAGER values\u2014is ethical, adaptable, gritty, empathetic, and remarkable.\nHolds a PhD in a quantitative field or a masters in a quantitative field and has at least 3 years of experience working as a data scientist.\nHas experience in data analysis, A/B testing, retention tracking, etc. (consumer product experience is preferred).\nIs proficient in data mining and statistics.\nHas experience with SQL as well as experience programming in Python, R, Scala, or an equivalent language.\nHas strong analytical and critical thinking skills as well as a strong bias toward actionable insights; loves finding insights and getting others to act on them.\nIs a self-starter with superior organizational and prioritization skills.\nSupport for you, professionally and personally\nProfessional growth: We hire people we trust, and we give team members autonomy to do their best work. We also support professional development with training, coaching, and regular feedback.\nA connected team: Grammarly builds products that help people connect, and we apply this mindset to our own team. We have a highly collaborative culture supported by our EAGER values. We also take time to celebrate our colleagues and accomplishments with global, local, and team-specific events and programs.\nComprehensive benefits: Grammarly offers all team members competitive pay along with a benefits package that includes superior health care. We also offer ample and defined time off, catered lunches, gym and recreation stipends, admission discounts, and more.\nWe encourage you to apply\n\n\nAt Grammarly, we value our differences, and we encourage all\u2014especially those whose identities are traditionally underrepresented in tech organizations\u2014to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, national origin, citizenship, age, marital status, veteran status, disability status, or any other characteristic protected by law. Grammarly will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. Grammarly is an equal opportunity employer and participant in the U.S. Federal E-Verify program.\nTo apply to this job, click Apply Now"}, "758": {"company": "Airtable", "description": "Airtable's unique approach to enabling end-user software creation has struck a chord with users across many industries and use cases. Our accelerating growth, coupled with our ambitious product surface area, brings many challenges. As one of the founding members of the Data Science team, you will play a crucial role in shaping the future of Airtable by deepening our understanding of how people use the open-ended toolkit that Airtable offers. You'll work cross-functionally to identify and answer our most important questions, transforming raw data into understandable and actionable insights.\n\nWhat you'll do\nPartner with product, marketing, and sales teams to help drive insights, identify opportunities, and understand behavior and long-term trends.\nTake a leading role in producing new datasets that unlock business opportunities.\nManage the design and analysis of experiments; develop and socialize a rigorous culture of experimentation throughout the entire company.\nPlay a foundational role in building a data culture at Airtable through reproducible work, improved processes, and better tooling.\nDevelop hypotheses and test them with data, rather than solely or primarily attempt to glean patterns from the data already in front of us\nDefine and monitor key metrics through consistent tracking, KPI's, and dashboards.\nWho you are\nYou have 2+ years previous experience as a data scientist, data analyst, or data engineer.\nYou have strong knowledge of statistics and experimental design.\nYou possess a natural curiosity and strive to uncover the deeper relationships that are not always immediately discoverable.\nYou have experience writing and optimizing complex SQL queries for large data sets and are familiar with a scientific programming language, such as R or Python.\nYou are an excellent storyteller and able to communicate your findings with clarity and precision, whether through writing or visualizations.\nWhat we offer\nHealth care: we have you 100% covered (and your dependents 50% covered) with competitive medical, dental, and vision insurance. You'll also be eligible for a complimentary membership to One Medical Group\nLearning & Development: we offer a $2,000 per year stipend for your personal career development\nGym Membership: we're proud to provide employees in our San Francisco and New York offices with complimentary gym memberships to Equinox, or up to $100/month reimbursement towards any other gym\nCatered lunches: we have high-quality catered lunches every day and well-stocked kitchens. We'll also reimburse you for any reasonable food expenses incurred while working\nGenerous PTO, sick leave, and parental leave\nAbout Airtable\n\n\nAirtable's mission is to democratize software creation, similar to the way the Macintosh democratized personal computing. Software is arguably the most important creative medium of the last century, yet most people cannot build their own software. Airtable gives people and companies a \"lego kit\" they can use to create custom applications on their own, regardless of technical experience.\n\nWe've raised $170M in venture funding, including most recently a 100M Series C from Benchmark, Thrive, and Coatue.\nApply Now: click Easy Apply"}, "759": {"company": "Southern New Hampshire University", "description": "This position will be responsible for enabling our students facing/supporting staff and leadership in their goals and initiatives aimed at setting up our students for better success and also, enable our business development teams in expanding the reach for University - both on-campus and online - courses. The data scientist will be responsible for delivering forecasting and data science needs to our business partners by actively identifying opportunities, providing actionable, insightful analysis and designing scalable programs.\n\nEssential duties and responsibilities of this position include the following:\nWork on all aspects of creating predictive intelligence including collecting requirements, establish analytics work plan, data exploration, cleansing, and preparation, identifying features, selecting algorithms, building and testing models, iteratively improving solutions\nDevelop data driven, insightful analyses to answer questions, with a focus on cause and effect relationships, address business challenges or identify opportunities, and provide actionable recommendations\nLook for opportunities to enrich company\u2019s data quality with external third party sources\nBuild and leverage machine learning models like gradient boosting trees, random forest, etc. or high quality prediction systems like recommender engines, to advance the current suite of analytical capabilities and drive better targeting strategies\nSynthesize these qualitative and quantitative solutions into actionable recommendations and communicate those findings to business teams\nLeverage story-telling skills to deliver insights that are clear, concise and actionable\nContribute to and maintain the state-of-the-art data science ecosystem that enables the larger team to leverage these data science products/packages for their needs\nCollaborate with other analytics team members and business units to drive common goal achievement and organizational objectives. The cross-team interaction is very important - you'll be required to enforce a culture of data analytics driven approach across organization\nMinimum Qualifications:\n3+ year of experience with Bachelor\u2019s degree in Applied Math, Economics, Statistics, Engineering, Computer Science or other quantitative field, preferably working in a strategic consulting or data centric role; or\n0-3 year of experience with Masters in above mentioned quantitative fields\nStrong knowledge of applied statistics skills, such as statistical testing, propensity matching, statistical modeling, classification, etc.\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Trees \u2013 GBM, XGBoost, etc.\nExperience with common data science toolkits, such as R, Python, Caret, PySpark, NumPy, etc. Excellence in more of these is highly desirable\nProficiency in using query languages such as SQL, or Hive\nData-oriented personality, combined with superior communication skills\nPreferred Qualifications:\nFamiliarity with advanced visualization tools and techniques\nExperience with text mining \u2013 NLP, Sentiment Analysis, etc.\nPhD degree in above mentioned quantitative fields\nWork Hours:\n\nTypically Monday through Friday, 8:00 am to 4:30 pm with flexibility to meet business demands as needed.\n\nA background check is required for employment. Please submit a cover letter, in addition to your resume, with your application.\n\nWhy Join SNHU?\n\nSouthern New Hampshire University (SNHU), founded in 1932, is a private, nonprofit, accredited institution located in Manchester, New Hampshire. We value teamwork, openness and diversity, and believe every employee has a voice in driving our success. At SNHU, we put our mission to work \u2014 and it makes for much more than your typical 9 to 5. In fact, it\u2019s one of many reasons we\u2019ve been voted one of The Chronicle of Higher Education\u2019s \u201cBest Colleges to Work For\u201d every year since its inception! Our competitive benefits package includes tuition reimbursement, employer contribution to Retirement Plan, affordable Medical, Dental, and Vision coverage, and generous paid-time off. We\u2019re constantly seeking creative, collaborative, and hard-working talent to join our team! Come be a part of innovation and education!\nApply Now: click Apply Now"}, "760": {"company": "Genworth", "description": "POSITION TITLE\n\nData Scientist\n\nLOCATION\n\nRaleigh, NC\n\nYOUR ROLE\n\nGenworth Mortgage Insurance is looking for motivated and talented individuals with a background in data and analytics to work on insurance focused analytics problems. This is a dynamic and challenging opportunity to apply the latest tools and methods in Big Data and Data Science to a variety of problems.\n\nThe Data Scientist is part of a highly analytical team that provides business critical intelligence and advice for decision support. In this role, you will collaborate with partners in operations (underwriting and claims), marketing, products and customer experience, pricing, risk, and other functions to define problems, identify data, build reports and dashboards, establish predictive and prescriptive models, and deliver optimal solutions across the entire range of Genworths line of business and customers.\n\nThe Data Scientist will report to the Senior Manager of Data Science and provides analytical cross-functional support through effective use of predictive analytics and forecasting methods to improve operational visibility and efficiencies. This Raleigh-based position will support cross-functional as well as cross-platform (including international) advanced modeling and promote best practices sharing at Genworth.\n\nYOUR RESPONSIBILITIES\nResearch current processes and proactively identify emerging needs for analytic models\nDevelop supervised (regression and classification) and unsupervised (e.g. clustering and segmentation) models and dashboards (Tableau)\nEvolve and advance a customer behavioral segmentation model, building marketing, sales and product predicative models, analyzing results and movements of segments/clusters and providing business insights to grow the companys market share and revenue\nDesign, create, and implement advanced analytics and forecasting models to optimize business processes. Provide insights for decision making through the use of ML, traditional statistical modeling and BI.\nPerform monthly reporting of some key metrics as a part of advanced business intelligence support to functional areas (e.g. through Tableau dashboards or providing automated reports and decks)\nPartner with IT and Enterprise Data Management Organization (EDMO) teams on the evaluation of data assets and their proper use\nProvide mentorship and share knowledge with functional and cross-functional peers\nBecome a trusted analytical partner to the functional areas of support (Marketing, customer solutions, Underwriting, Loss Mitigation, Pricing) and collaborate on the development and planning of analytic projects in response to business needs\nDevelop and perform preliminary exploratory analysis on datasets associated with building advanced ML models. Ability to work with structured and unstructured data.\nDetermine requirements, evaluate analytical approaches and take ownership of the processes of creating predictive models to optimize decision making for functional areas of support\nCommunicate and document statistical analyses and methods in a logical and understandable manner for non-analytical business users and executive decision makers.\nEnsure accuracy of results and analytic methods. Perform regular validation and collaborations of the analytical models\nDemonstrate strong business acumen and understanding of mortgage insurance concepts\nFacilitate fulfilling ad-hoc requests timely and efficiently\nYOUR QUALIFICATIONS\nBachelors degree\n4+ years business analytics and business support functions\nBusiness acumen along with a strong understanding of statistical modeling / machine learning (ML) and forecasting techniques\nExperience in advance analytics. Hands-on experience with logistic regression, time series, forecasting, optimization, and other predictive modeling techniques. ML experience and knowledge of ML platforms, libraries and programming\n1+ year of experience in one or more of the following statistical / analytic languages such as Python, Apache Spark (or PySpark), Hive, Scala, preferably in a cloud computing environment e.g. AWS, Databricks, Azure, Cloudera, Hortonworks, Google Cloud, Anaconda etc.\n2+ years of experience in one or more of the following: database query and management tools (SQL, Spark, Hive / HQL etc.)\nKnowledge of or willingness to learn AWS environment where the above tools and enterprise data are being migrated to\nHands-on experience working with advanced BI tools, Dashboard experience with visualization and automation tools, Tableau experience preferred\nADDITIONAL QUALIFICATIONS (PREFERRED)\nMasters Degree\nSome experience with legacy analytics software such SAS or willingness to learn the basics\nAbility to perform complex day-to-day ETL tasks such as data gathering, data cleaning, wrangling, coding or programming, business and analytics requirements gathering, and data analysis\nExperience with large analysis datasets and enterprise scale database systems (e.g. Large Hadoop, Redshift, Hive, SQL tables etc.)\nCOMPANY\n\nGenworth Financial, Inc. is a leading insurance holding company committed to helping families achieve the dream of home ownership and address the financial challenges of aging through its leadership positions in mortgage insurance and long-term care insurance. Headquartered in Richmond, Virginia, Genworth traces its roots back to 1871.\n\nGenworth Mortgage Insurance, headquartered in Raleigh, North Carolina, is a global mortgage insurer with a major presence in the United States, Canada, and Australia. With origins dating back to 1980, Genworth Mortgage Insurance provides primary mortgage guaranty insurance coverage on residential mortgage loans, as well as mortgage pool insurance policies that enhance insurance coverage for various types of mortgage-related securities. Our mortgage insurance can help individuals secure low-down payment loans and realize the dream of home ownership faster even for the first time.\n\nWe know we cant deliver on our mission unless we deliver for our employees. Thats why were committed to creating a work environment that fosters inclusion, excellence, improvement and connection. We know each employee contributes in their own unique way and were dedicated to supporting every one of them to help them reach their full potential.\nApply Now: click Apply Now"}, "761": {"company": "Spectrum", "description": "JOB SUMMARY\n\nResponsible for defining or assessing work requirements, problem discovery with stakeholders, architecting solutions to solve problems big and small. Work products include predictive analytics, statistical modeling, machine learning, automation, and data engineering. This role is within a fast-growing startup department serving a significant portion of this Fortune 100 company.\nMAJOR DUTIES AND RESPONSIBILITIES\n\nActively and consistently support all efforts to simplify and enhance the customer experience\nUnderstand customer business use cases and be able to translate them to technical specifications and vision on how to implement a solution\nClearly communicate the benefits of the analytic solutions to both a business as well as a technical audience\nLeverage knowledge in analytic and statistical algorithms to help customers explore methods to improve their business\nLead large-scale analytical research projects through all stages including concept formulation, determination of appropriate statistical methodology, data manipulation, research evaluation, and final research report\nDesign, build, and extract large and complex data sets while thinking strategically about uses of data and how data use interacts with data design\nLead large-scale data studies and data discovery for new data sources or new uses for existing data sources\nLead design and implementation of statistical data quality procedures for existing and new data sources\nVisualize and report data findings creatively in a variety of visual formats that appropriately provide insight to the stakeholders\nEstablish links across existing data sources and find new, interesting data correlations\nWork closely with the operations team to define the implementation of these solutions\nAchieve defined project goals within customer deadlines; proactively communicate status and escalate issues as needed\nREQUIRED QUALIFICATIONS\nSkills/Abilities and Knowledge\nAbility to read, write, speak and understand English\nMust be self-motivated, results-driven, team player able to work with minimum supervision\nOutstanding interpersonal, communication, and customer relationship skills able to work effectively with customers from developers and Ops personnel through senior management\nIntellectually curious and passionate about data maintenance, data quality control and all other important data analysis techniques\nExcellent analytical and problem solving skills with attention to detail and data accuracy\nAbility to work cross-functionally to solve complex problems and improve quality and service\nUnderstanding of machine learning algorithms, such as k-NN, GBM, Neural Networks, Naive Bayes, SVM, Decision Forests\nProven ability in data wrangling, modeling, visualization, machine learning, and project leadership\nProven ability to clearly communicate insights in PowerPoint and Excel\nAdvanced level with Programing Languages: Python and R required, Java additionally preferred\nAdvanced level with data visualization: Tableau or MicroStrategy\nIntermediate level with database languages: SQL Server and Hive QL\nDesirable experience with: NLP and text based extraction techniques\nDesirable experience with version control systems: Git, BitBucket\nDesirable experience with: Hadoop, Spark, Kafka, Hive, etc.\nDesirable experience with: TensorFlow, PyTorch, Theano, Keras etc.\nRelated Work Experience Number of Years\n3+ Years Data manipulation and statistical modeling as an Analyst, Scientist, Consultant, Architect, DBA, or Engineer experience\n2+ years of Programming experience\nEducation\nBachelors degree or Masters degree in Computer Science, Physics, Math, Statistics, Economics or other quantitative discipline (additional relevant experience may be a substitute)\nPREFERRED QUALIFICATIONS\nSkills/Abilities and Knowledge\nSpanish Language Ability\nCall Center Operations or Support Experience\nTelecommunications Industry Experience\nFamiliarity with software development life-cycle and project management methods (Agile, CRISP-DM)\nWORKING CONDITIONS\nOffice Environment\nTravel as required\nTo apply to this job, click Apply Now"}, "762": {"company": "Acorns", "description": "Data Scientist | Acorns\n\nAt Acorns, we're building a financial wellness system that enables everyday Americans to save and invest every day. We are transforming the category and recruiting a team that is relentless at fulfilling our mission. The Acorns team comes together every day to deliver a revolutionary product to its customers, the up-and-coming. If you thrive in an environment where you can push yourself beyond all previous thresholds of possibility, come join us at Acorns.\n\nAcorns is actively seeking a highly self-motivated, detail-oriented, and solution-focused Data Scientist. This position will reside in the Data Science group, which serves as the central data science team for the company. The team is responsible for developing and using state-of-the-art mathematical modeling, data mining, and machine learning techniques to be agents for good by helping look after the financial best interests of the up-and-coming.\n\nThe Acorns Data Science group is obsessed with solving hard problems that directly affect customers, including recommendation engines, fraud prevention, and customer intention inference. But these aren't Kaggle-type problems; we operate fast and often with imperfect data. We focus on impact - we innovate and put the models into production quickly. We know that solving problems with data is an art and a science. Data Scientists at Acorns are as good at communicating and collaborating as they are at building models and writing code.\n\nAt Acorns, Data Scientists have broad latitude around data and you will work across functional teams including Analytics, Engineering, Product Management, Marketing, Operations, and Business Development, and will play a key role in shaping the technology and product directions of the company.\n\nWithin 1 month, you will:\nUnderstand the Acorns products, data warehouse, and how data fits into the products.\nDiscover new opportunities to apply data science concepts to the portfolio of products.\nPresent findings to the Data Science team members.\nInteract with multiple teams.\nWithin 3 months, you will:\nHave established architecture and implementation for an intelligence-driven product feature in a data-rich environment.\nHave complete ownership of a data science product and made production quality code commits into the team's repository.\nContribute to the broader team's success by offering ideas and constructive feedback to other team member's projects.\nPropose novel ML research directions that will eventually power new products.\nWithin 6 months, you will:\nWork independently and closely with the Product Management team to plan projects and recommend areas for the next generation of Acorns products.\nWork independently and closely with Engineering teams to deliver data science solutions into the product with proper API design.\nBuild an identity within the company and can independently represent the Data Science team with other departments.\nWhat you will bring to Acorns:\nA team player that is enthusiastic, self-motivated, detail-oriented, and solution-focused.\nEmpathy with our customers' financial situations and the desire to help our customers in need of personalized products and services.\nUphold the values of transparency, honesty, and unconditional support for the team.\nDefine problems, collect data, establish facts, draw valid conclusions, and make recommendations for continuous improvement.\nAn ability to explain complex problems in a simple way.\nCapability to build algorithms that touch the cutting edge of statistics and machine learning.\nApply state of the art machine learning, statistics or data mining in a variety of areas, including user analysis and data product design.\nDevelop scalable and efficient methods for large scale data analysis and model development.\nDerive pride from technical excellence, and pursue excellence in all areas of work.\nRequirements:\nHunger for impact, drive to learn fast, be creative, and win as a team.\nBS in Computer Science, Statistics, Mathematics, Physics, Engineering or a related field, or equivalent experience.\n2-3+ years experience in working with noisy real world structured and semi-structured data.\nExpert in Python or Scala, with related statistical and machine learning packages.\nBackground in NLP, data mining, machine learning, statistical analysis, and modeling, with experience deploying models in a production environment.\nExperience with A/B testing methodologies and experiments.\nStrong SQL abilities and experience with massive relational database systems.\nAble to take a complex, ambiguous topic and turn it into a rigorously defined and well-formulated problem that answers the business question we are trying to solve.\nExcellent communication skills to explain your results and solution to the stakeholders in a clear and compelling way.\nBonus\nMS or PhD in Statistics, Mathematics, Computer Science, Physics, Engineering or a related field.\nPatent, publication, or conference presentation in an AI or ML related field.\nHas written production quality, version controlled code.\nExperience considering user psychology and user experience.\nExperience with Databricks, Spark, AWS, Airflow, Kafka or Kinesis.\nKnowledge of basic macroeconomic concepts.\nThirst for delivering game-changing products.\nExceptional drive and precision in delivery.\nA belief that your work is tied to your life's mission.\nOptimistic about the potential of societal change.\nWhat we offer:\nCompetitive salary and stock options.\nA comprehensive benefits package to meet the needs of you and your family.\nFlexible paid time off.\nCorporate gym access.\nDaily breakfast, weekly team lunches, and an endless supply of snacks.\nNumerous career possibilities that allow you to grow with Acorns.\nTalented and motivated team members who care deeply about one another, our mission and our customers.\nThe rare opportunity to create a new world. We inspire one another every day to do meaningful work that solves big societal challenges.\nAbout Acorns:\n\nAcorns is the leading micro-investing app in the U.S. It allows users to round up their daily purchases and automatically Invest the Change\u00ae into a low-cost, diversified portfolio of exchange-traded funds offered by some of the world's top asset managers (including Vanguard and BlackRock). Founded in Newport Beach, Calif., by father and son team Walter and Jeff Cruttenden, Acorns provides a simple entry-point using the Acorns app on iPhone or Android. Customers accumulate fractional shares in one of five portfolios constructed by world-renowned Nobel Laureate economist Dr. Harry Markowitz. Acorns' smart portfolio algorithms automatically work in the background of life, helping users build wealth naturally, pennies at a time. From Acorns mighty oaks do grow.\n\nMission:\n\nWith benevolence and courage, we look after the financial best interests of the up-and-coming; beginning with the empowering step of micro-investing.\n\nValues:\nLead with heart\nMake bold decisions\nAlways build trust\nNever stop growing\nFind a way\nStart your job application: click Easy Apply"}, "763": {"company": "Formation", "description": "Formation provides personalization for the largest enterprise businesses in the world. We work with high volume data streams to deliver tailored experiences and orchestrate physical and digital exchanges into a seamless journey. Our Data Science Team is transforming the way people engage across multiple industries.\n\nYou'll collaborate closely with engineers and share responsibility throughout the product life-cycle. You'll work in small, self-sufficient teams with a common goal: deliver excellent data science solutions anchored in a culture of quality, delivery, and innovation.\n\nAs a Data Scientist at Formation you're capable of working in an agile data science environment to generate and test hypotheses quickly. You're also passionate about improving, optimizing, and developing new reinforcement learning (RL) strategies to enhance the value of our platform.\n\nKey Responsibilities:\nApply RL and statistical analysis to complex, real-world problems through massive data sets\nIndependently design, test, and productionize RL-based experimentation to refine customer strategies\nCollaborate with colleagues in product and customer success roles, sharing responsibility throughout the product life-cycle\nAbility to explore an unfamiliar and large data sets with big data tools such as Hive or Spark\nPresent methodology and results to external stakeholders and Fortune 500 clients\nSkills and Experience:\nMinimum 2 years experience as a Data Scientist, prior software development experience is a plus\nMaster's or Ph.D. in a relevant technical field (e.g. Computer Science, Mathematics, Statistics, Physics)\nPrior experience with RL frameworks such as TensorFlow or Vowpal Wabbit, and Spark is a plus\nMachine learning knowledge with a focus on contextual bandits, reinforcement learning, recommender systems, knowledge of common Data Science concepts related to e-commerce (e.g. lifetime value, net incremental revenue, churn) is a plus\nDemonstrated ability to communicate and collaborate with peers\nDemonstrated skills in result-driven problem solving\nABOUT FORMATION\n\nFormation distills complex customer data into uniquely tailored experiences; we orchestrate physical and digital exchanges into one seamless journey. Our business is building lasting, trusted relationships between people and brands\u2014and making it look easy.\n\nWe're already reaching millions of people a day, and we're just getting started. Our founding leadership is equal parts business, design, and engineering\u2014because we believe differing perspectives + passionate discourse achieve the greatest outcomes. We are collectively talented, but also humble. We give our whole selves. We love learning new things.\n\nFormation is committed to inclusion and diversity and is an equal opportunity employer. All applicants will receive consideration without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, disability, or veteran status.\n\nAlso, we are thrilled to be named one of the Top 50 startups by LinkedIn! Every member of our team makes Formation a special place to work and grow. Come join us and see for yourself!\nApply Now: click Apply Now"}, "764": {"company": "eBay", "description": "We are looking to hire an analytics & insights Data Scientist to partner with the eBay core product team. As a critical member of the Product Insights team, this role will have the unique opportunity to influence decision making of the Seller experience roadmap with their insights and thought leadership.\n\nWith a vision to identify opportunities to drive transformative change in the customer experience and result in significant business growth, we mine the largest datasets in the world of e-Commerce and use best in class analytic and big data techniques to extract impactful insights. We achieve this by partnering closely with the product and engineering teams, and identify opportunities that are accretive to the product roadmaps.\n\nTo be successful in this role:\nRequire the minimum of a bachelors degree in Statistics, Mathematics, Computer Science, Data Science, Business Administration or Business Analytics.\nYou would have to strike a balance between strategic thinking and actual hands-on analyses using tools & packages such as SQL, R, Python, Tableau etc.\nYou possess super strong technical skills to turn big data in Teradata and Hadoop into actionable insights. At the same time, you also have the ability to think about the big picture and connect the dots to evaluate how the insights impact eBays ecosystem.\nIn addition to delivering insights on existing Product & Tech initiatives, you will come up with innovative product growth opportunities based on insights, and create momentum through influence.\nProactive collaboration and effective communication are critical\nAdditionally, the following background and experience is preferred:\nProven track record of turning insights into product growth opportunities in prior roles with increasing scope and responsibilities\nAbility to present complex analyses and insights effectively in simple terms\nGood experience with both descriptive and inferential statistics ability to build basic prototype models\nExperience in a leading technology company\nBackground in ecommerce product experience\nMasters degree is a plus.\nExperience with site experimentation (A/B testing) is a plus\nThis website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies\n\nView our privacy policy\n\nView our accessibility info\n\neBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible.\n\nFor more information see:\n\nEEO is the Law Poster\n\nEEO is the Law Poster Supplement\nApply Now: click Apply Now"}, "765": {"company": "Grid Dynamics", "description": "As part of the Enterprise Data team, the Data Scientist supports the development of next-generation data platforms by employing data analytics and various data science capabilities (i.e. machine learning). Incumbents will be part of an innovative and energetic team that develops capabilities which will influence our business model and help our customer build the next generation data platform. The Data Scientist will have access to the vast amount of data stored in heterogeneous formats. This person is supposed to handle complex problems independently and demonstrate analytical thinking. Data Scientist should be able to make judgments and recommendations based on the analysis and interpretation of data.\n\nResponsibilities:\nInvestigate and analyze business and technical problems (application architecture), requirements for a new solution\nDrive the collection, cleaning, processing and analysis of new and existing data sources\nDesign a new solution architecture for manufacturing, sales\nCollaborate with development, testing, release engineering teams\nPlan phases of R&D towards the final architecture state\nSupport decision making on process layout through the data analyzing\nRequirements:\nStrong practical knowledge of analytical techniques and methodologies such as machine learning(supervised and unsupervised techniques), segmentation, time series modeling, response modeling, lift modeling\nExperience in manufacturing, marketing & sales, pricing, demand forecasting\nTechnologies: Python, Pytorch/Tensorflow, Keras, Spark\nEnglish level Intermediate and higher\nWe offer:\nOpportunity to work on bleeding-edge projects\nWork with a highly motivated and dedicated team\nCompetitive salary\nFlexible schedule\nMedical insurance\nBenefits program\nCorporate social events\nProfessional development opportunities\nNB:\nPlacement and Staffing Agencies need not apply. We do not work with C2C at this time.\nAt this moment, we are not able to process H1B transfers. Applicants with CPT and OPT visas are welcome to apply.\n\nAbout us:\nGrid Dynamics is the engineering services company known for transformative, mission-critical cloud solutions for retail, finance and technology sectors. We architected some of the busiest e-commerce services on the Internet and have never had an outage during the peak season. Founded in 2006 and headquartered in San Ramon, California with offices throughout the US and Eastern Europe, we focus on big data analytics, scalable omnichannel services, DevOps, and cloud enablement.\nApply Now: click Apply Now"}, "766": {"company": "UFG Insurance", "description": "UFG offers you an award-winning workplace and a trustworthy, financially stable company. While we\u2019ve always known our commitment to employees and financial stewardship, it is good to have others recognize our dedicated efforts. We've been named an Iowa Top Workplace by the Des Moines Register for four consecutive years, and included on Forbes\u2019 \u201cAmerica\u2019s Most Trustworthy Financial Companies\u201d every year since 2014. Additionally, UFG is a super-regional property and casualty insurer rated \u201cA\u201d (Excellent) by A.M. Best Company.\nThe UFG Enterprise Analytics Department is focused on delivering strategically-impactful results by building analytically based solutions that integrate a wide range of internal and external data assets. The ultimate objective of the Enterprise Analytics organization is to help UFG gain and maintain a competitive advantage in how it prices risk and identifies potential loss.\nWe are seeking an Associate Data Scientist to facilitate the development of Analytics solutions in support of UFG\u2019s strategic plan. This individual will work closely with business units throughout the organization to develop and implement strategies that leverage data to enable enhanced decision making. The ideal candidate will possess strong technical and communication skills, as well as proven experience in predictive modeling, change management, and the insurance industry in general.\n\nWork with management to prioritize modeling needs\nSupport research and development efforts in a diverse set of challenges as we rapidly prototype and build new models\nExtensive experience analyzing data and a broad understanding of core statistical and ML techniques\nDesign, build, and deploy Machine Learning (ML) systems aligning to business objectives\nTranslate and champion ML capabilities for non-technical audiences\nStay current with modeling techniques/technologies\nMaintain positive, professional business acumen and relationships with cross-functional teams and external customers\nTrain end users on new models\nResearch opportunities for data acquisition and new uses for existing data\nCollaborate with data architects, analysts and IT team members on project goals\n\nEducation:\nCompetencies typically acquired through a Ph.D. (in Statistics, Computer Science, Mathematics, or other scientific field of study)\nExperience:\n1-3 years of relevant commercial P&C modeling experience\nExtensive experience analyzing data and a broad understanding of core statistical and ML techniques\nPast experience implementing complex data-driven solutions is preferred.\nDeep experience with GLMs as well as modern machine learning methods.\nDemonstrated experience in handling large datasets, structured and semi-structured data formats\nKnowledge, skills & abilities:\nThis role will require the candidate to be extremely hands on with building models and data driven tools.\nAdvanced Python skills. Should be familiar with Python\u2019s scientific computing ecosystem.\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.\nAbility to translate technical concepts into non-technical, lay terms.\nUnderstanding of star/snowflake schemas as general data warehousing methodologies (i.e. Kimball).\nStrong written and verbal communication skills.\nAbility to deliver incremental value via an Agile Development Methodology.\nAbility to thrive in a fast-paced environment with significant uncertainty\nApply Now: click Apply Now"}, "767": {"company": "CyberCoders", "description": "Data Scientist\nIf you are a Data Scientist with experience, please read on! Join our Data Science team in San Francisco. The Data Science team builds mathematical and behavioral economics models underpinning core solutions for actionable analytics and behavioral intelligence. The set of problems that we tackle is incredibly diverse and complex. They cut across optimization, prediction, modeling, inference, and behavioral science. We research and develop the algorithms and models that make our solution intelligent, as well as implementing, scaling and maintaining the code that powers our production systems.\n\nThe ideal candidate is a critical thinker with experience and background in commercial life science domain, passionate about solving mathematical and behavioral problems with data, and is excited about working in a fast-paced, innovative and collaborative environment.\n\nLocal candidates only and available to start in 2 weeks from offer or sooner.\nWhat You Will Be Doing\nWork with Data Scientists, Product Managers, Customer Success and Services teams to frame a problem, both mathematically and within the business context\nWrite production-level code; collaborate with Engineering team to implement algorithms in production and productize common solutions\nPerform exploratory data analysis to gain a deeper understanding of the problem\nConstruct and fit statistical, machine learning and optimization models\nUtilize commonly used computing and database environments to get the data that you need and implement a working prototype of the formulated model.\nLearn and apply new methodologies in the intersection of applied math/ probability/statistics/machine learning/computer science.\nMake intelligent approximations to the model if required to make it scalable.\nAnalyze experimental and observational data; communicate findings; facilitate launch decisions\nIdentify data sources that could be used to test assumptions\nWhat You Need for this Position\nMore Than 5 Years of experience and knowledge of:\n\nProven track record of developing algorithms for production-ready recommendation or prediction systems using languages and big data platforms such as Scala, Python, R, Java, Spark, Cassandra, and Hadoop\nExperience in commercial life science domain or Pharma\nExperience working in an agile software development environment\nPassion for solving unstructured and non-standard mathematical and behavioral problems\nEnd-to-end experience with data, including querying, aggregation, analysis, and visualization\nExperience implementing machine learning algorithms\nExperience with analytics for commercial life science and pharma-specific analyses a big plus\nExcellent communication and presentation skills, being able to explain complex problems and the solutions applied, feeling comfortable in being part of the sales process, supporting the sales team, engaging with customers and presenting technical solutions to a nontechnical audience\nExperience in data science and data analytics for life science industry especially in GTM strategy and execution a big plus\nHigh-energy self-starter with a passion for your work, attention to detail, and a positive attitude\nGreat team player, willingness to collaborate and communicate with others to solve a problem.\nEDUCATION\nM.S. or Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, or other quantitative disciplines with at least 5 years of experience\nSo, if you are a Data Scientist with experience, please apply today!\n-\nApplicants must be authorized to work in the U.S.\n\n\nCyberCoders, Inc is proud to be an Equal Opportunity Employer\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n\nYour Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nApply Now: click Apply Now"}, "768": {"company": "Affinity", "description": "Affinity is on a mission to help everyone in the world succeed by cultivating and harnessing the power of their network. We've got a lot left to build, and we're growing fast. As we grow, we're looking for a Data Scientist to analyze large amounts of raw information to find insights and patterns that will help improve our company. We will rely on you to lead the building of data products to extract valuable business insights, with support from engineering and other functions within the company. Your goal will be to help our company use data to make better decisions.\nWhat you'll be doing\nIdentify valuable data sources and automate collection processes\nUndertake preprocessing of structured and unstructured data\nAnalyze large amounts of information to discover trends and patterns\nIdentify KPIs and create company dashboards that help us track the health of our business\nPresent information using data visualization techniques\nPropose solutions and strategies to business challenges based on findings from data analysis\nCollaborate with engineering and product development teams\nWhere beneficial to the business, build predictive models and machine-learning algorithms\nWe'd love to hear from you if you have:\nProven experience as a Data Scientist or Data Analyst\nExceptional SQL skills\nExperience in data mining\nExperience using business intelligence tools (e.g. Tableau, Amplitude) and data frameworks (e.g. Hadoop)\nUnderstanding of machine-learning and operations research\nKnowledge of R, Python is an asset\nAnalytical mind and business acumen\nProblem-solving aptitude\nExcellent communication and presentation skills\nA BIT ABOUT US\nRelationships are the backbone of the world's most valuable industries\u2014from sales and business development to finance and philanthropy. But the tools used today to manage those relationships are broken. Actionable context remains locked away in the email and calendar streams of coworkers and colleagues, and no one has the time to analyze or organize this exponentially growing trail of data.\n\nAffinity ingests and analyzes this massive communications data stream and uses it to power our platform, which helps our customers understand, manage, and leverage their networks more effectively.\n\nWe've raised over $40M, and in the past two years, we launched the product and have since processed over 1 billion communication data points and generated 4+ million introductions and connections while capturing close to 40% of the global venture capital market. We are also actively breaking into new markets. We're growing fast and we\u2019ve got a lot left to build.\n\nTECH STACK\nSome of our core technologies are Ruby, PostgreSQL, TypeScript, React, React Native, and Redux. On the infrastructure side, we make extensive use of AWS, Kubernetes, and Terraform.\n\nWe love learning and teaching, and we\u2019re happy to bring on strong engineering leaders whether or not they have experience with these particular tools.\n\nALL ARE WELCOME\nThe more diverse our team is, the more we\u2019ll be able to learn from each other, and the better our company and our product will be. Whatever your gender, race, sexual orientation, religion, age, veteran status, favorite Spotify playlist, or social, cultural, and economic background, we can\u2019t wait to welcome you to Affinity!\n\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\nApply Now: click Apply Now"}, "769": {"company": "Redox", "description": "At Redox our mission is to enable the frictionless adoption of technology in healthcare. To that end we have enabled a network of healthcare organizations and technology developers to connect through us to improve patient healthcare. Our customers have asked us to help minimize data duplication for various scenarios. An ideal candidate is a data science enthusiast and will solve complex data-related problems, using advanced statistical and machine learning tools, in a real-world setting with product managers and engineers. Candidates should demonstrate strong statistical, mathematical and technical skills, with proven capabilities to transition ideas into fully working projects. In addition, the candidate needs to have a creative and first principles mindset to examine our current processes and help us grow our Data Science muscle at Redox.\nWHAT YOU'LL DO:\nApply advanced statistical and predictive modeling techniques to build, maintain, and improve multiple real-time decision-making systems \u2013 from research to production and deployment\nCollaborate on highly technical projects - from redesigning working infrastructures to maintaining and improving our current models and underlying systems to integrating new technologies to the data science workflow\nEnhance data collection procedures to include information that is relevant for building our analytical systems\nWHAT WE LOOK FOR:\nMinimum 3-5 years of experience working in data science at a company.\nExperience working with machine learning libraries, for example, Fastai, Numpy, xgboost, sklearn, scipy among others; natural language processing experience is a plus\nExperience with deep learning frameworks (Tensorflow, PyTorch, etc) a plus\nExperience in implementing statistical/machine learning algorithms (parametric and non-parametric models, classification and regression trees, Bayesian models, clustering and dimensionality reduction techniques)\nBackground in at least one high level programming language (e.g.,Python, R, Java, Javascript)\nAbout Redox:\n\nWhat We Do\nHealthcare organizations and technology vendors connect to Redox once, then authorize what data they send to and receive from partners through a centralized hub. Redox's cloud-based platform is vendor and standards agnostic and enables the secure and efficient exchange of healthcare data.\n\nThis approach eradicates the need for point-to-point integrations and accelerates the discovery, adoption, and distribution of patient and provider-facing technology solutions. With hundreds of healthcare organizations and technology vendors exchanging data today, Redox represents the largest interoperable network in healthcare. Learn how you can leverage the Redox platform at www.redoxengine.com.\n\nOther Stuff About Us\nRedox is an EEO company. We fully support the diversity of our team! Here's a recent blog post about our stance on diversity and belonging: Diversity at Redox\n\nWe believe in holding ourselves to a high standard of conduct. Here's how we think about this: Redox Code of Conduct\n\nSuccessful candidates must be eligible to be employed in the US, and must reside in the US.\n\nThank you for your interest in Redox!\n\nApply Now: click Apply Now"}, "770": {"company": "1904labs", "description": "About Us\n\n\nInterested in working for a human-centered technology company that prides itself on using modern tools and technologies? Want to be surrounded by intensely curious and innovative thinkers?\n\nSeeking to solve complex technical challenges by building products that work for people, meet and exceed the needs of businesses, and work elegantly and efficiently?\n\nModeling ourselves after the 1904 World's Fair, which brought innovation to the region, 1904labs is seeking top technical talent in St. Louis to bring innovation and creativity to our clients.\n\nOur clients consist of Fortune 500 and Global 2000 companies headquartered here in St. Louis. We partner with them on complex projects that range from reimagining and refactoring their existing applications, to helping to envision and build new applications or data streams to operationalize their existing data. Working in a team-based labs model, using our own flavor of #HCDAgile, we strive to work at the cutting edge of technology's capabilities while solving problems for our clients and their users.\n\nThe Role\n\n\nAs a Data Scientist with 1904labs, you will be working with other data scientists, data engineers, and developers to provide analytical services to clients. You will leverage the clients' data assets to answer business questions using best practices and innovative approaches. This will mean employing various data science tools (Python, apache spark, TensorFlow) and techniques (dimensionality reduction, unsupervised learning, supervised learning) to create and test machine learning algorithms. Once tested and verified you will work with development teams to implement the algorithm as a scalable, hosted service.\n\nWe're looking for an experienced and creative data scientist who can conceptualize a project from start to finish, identifying the appropriate data and methodologies to use. Our Data Scientists work with open-source machine learning packages and libraries, so this position involves building custom ML/AI utilities from open-source resources in languages such as Python (preferred) and R. In this role, you will own and share technical solutions with both technical and non-technical stakeholders across multiple teams both internally and with external clients.\n\nResponsibilities\nPerform data analysis to understand the right combinations of data to meet outlined objectives\nTranslate client queries into actionable data pulls and help translate outputs into client strategies\nBuild and evaluate predictive modeling & machine learning utilities to produce meaningful outcomes that enable data-led decisions\nTranslate analysis results into actionable insights\nPresent insights to both technical and non-technical audiences\nPartner with internal data scientists, developers, and tech teams to develop new methodologies and utilities\nWork with development teams to implement data science algorithms as scalable, hosted services\nYour Skills\nRequirements\nBackground in math including linear algebra, statistics, probability, and numerical analysis.\nMachine Learning Analysis: Must be able to execute, evaluate, and apply various models such as logistic regression, random forests/decision tree, nearest neighbor, neural net, support vector machine, an ensemble of multiple models, etc\nProgramming: Proficient coding in a language suited for machine learning systems such as Python or R (not reliant on GUI-based systems to execute analysis) for the purpose of cleaning, manipulating, visualizing, and analyzing data\nDesired Skills\nExperience with software engineering and developing deployable API services\nMust be adaptable and have the drive to learn new technologies and frameworks to support developing client solutions\nUsing browser based interactive computational environments (like Jupyter Notebook) to perform analysis activities and test / evaluate data models and algorithms.\nTools: Spark, Pandas, SciKit-Learn, TensorFlow, Keras, SQL\nCommunication: Must be able to explain analysis process and translate results into actionable insights for both technical and non-technical audiences\nTeamwork: Must be accountable for individual responsibilities while working collaboratively with development and engineering teams to achieve project deliverables\nComfort in an agile development environment (eg. writing stories, participating in workshops, sprint planning and retros)\nPerks\nBenefits Program (medical, dental, life insurance, 401(k), professional and personal development, PTO)\nInnovation Time - we allow 10% of your time to be devoted to innovation hours. This time can be used to foster individual ideas, personal projects, start up ideas, improve an open source tool or for career advancement and self-education. All during traditional working hours.\nDress Code - we don't have one\nThese roles are located in St. Louis, MO. While we would prefer local candidates your location is not the most important factor; please help us understand why you would like to call St. Louis home if you would be relocating.\n\n]]>\nStart your job application: click Apply Now"}, "771": {"company": "Henkel", "description": "HENKEL IS FOR THOSE WHO STEP UP. DO YOU?\n\nAt Henkel, you can make a difference and craft your career. That\u2019s why you own your projects and take full responsibility from an early stage. Our unique brands in markets around the world open up countless opportunities to follow your convictions and explore new paths. If you have an entrepreneurial mindset that allows you to always think out of the box - take the chance and shape the digital future together with us.\n\nYOUR ROLE\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.\nDeveloping reports, visualizations, or statistical analysis as required and develop processes and tools to monitor and analyze model performance and data accuracy.\n\nYOUR SKILLS\nFour\nyear degree in Computer Sciences/Information Systems or related with at\nleast 2-3 years of experience in the area of Data Warehousing and Business\nIntelligence.\nKnowledge\nof modern data warehousing concepts, data modelling and data management.\nExperience\nin relational databases (MS SQL, Teradata, Oracle, DB2) and good\nknowledge of SQL\nExperience\nin Azure Cloud technology and Big Data \u2013 Hadoop, Java, Python, Spark,\nDremio, Tableau, Power Bi \u2013 extremely beneficial\nKnowledge\nof BI tools e.g. Analysis Server, Cognos, Oracle BI, SAP BW beneficial\nStrong\nbackground in data architecture, data mining, and data cleansing\nExperience\nin Azure Data Factory, Data Bricks, Data Lake\nStrong\nanalytical skills and Agile and\nDevOps Team Experience a plus\n\nHenkel is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.\n\nHenkel does not accept unsolicited resumes from search firms or employment agencies. Unsolicited referrals and resumes are considered Henkel property and therefore, Henkel will not pay a fee for any placement resulting from the receipt of an unsolicited referral. At Henkel\u2019s request only, preferred vendors may be invited to refer talent for specific open positions. In these cases, a fully-executed agreement with Henkel must be in place and current.\nStart your job application: click Apply Now"}, "772": {"company": "Edison Energy", "description": "Company Overview:\n\nEdison Energy is the expert independent advisor for commercial, industrial, and institutional energy users, delivering comprehensive, data driven and integrated global energy solutions. We provide a full-suite of sustainability-driven& energy management solutions including specialized delivery of renewables, supply, demand, engineering, portfolio advisory and analytics services, serving market leaders facing an increasingly complex energy environment.\n\nAs a wholly owned subsidiary of Edison International (NYSE: EIX), Edison Energy combines sophisticated, cloud-based analytics and focused energy advisory services with Edison International\u2019s scale and stability to deliver high-quality services to our clients. Our goal is to leverage our years of experience in traditional power and gas markets, renewable energy and sustainability advisory, and engineering and implementation services to design solutions that empower our clients to build economically sustainable energy portfolios.\n\nPosition Overview:\n\nEdison Energy\u2019s Technology Development team is responsible for implementation of Edison Energy\u2019s client focused internal software systems and tools.\n\nEdison Energy\u2019s data science team is responsible for discovering actionable insight. The team will create data-driven solutions and develop client-focused software systems and tools. Edison Energy\u2019s digital assets provide business analyst with insight to be used on behalf of our clients. The cloud-based systems and software include, but not limited to: energy portfolio management, energy asset virtualization, big data analytics, and big data visualizations.\n\nEssential Functions:\nWork closely with management, business analysts, and product managers to define features\nLeverage subject matter expertise to create new feature ideas\nDevelop technical specifications from feature requests\nCollect, combine, and clean structured and unstructured data\nResearch, implement& apply statistical modeling techniques from paper into prototype\nDevelop scalable methodologies for big-data& real-time analytics\nJob Requirements:\n3-5+ years in Data Science, Business Intelligence, Data Analytics\n2+ years using Python or R\nExperience with Machine Learning\nAbility to efficiently analyze and visualize large quantities of data\nFamiliar with Energy (power or gas) a plus\nEducation Requirements:\nBachelors in computer science, engineering, mathematics, or other technical or business field (required)\nPreferences:\nEnergy or Finance experience or coursework\nDistributed machine learning& data-mining experience\nExperience with Amazon Web Services or Microsoft Azure\nNOTE: Edison Energy is not the same company as Southern California Edison, the utility, and Edison Energy is not regulated by the California Public Utilities Commission.\nTo apply to this job, click Apply Now"}, "773": {"company": "Cotiviti, Inc.", "description": "Job Description\nData Scientist works directly with a team of analytics and healthcare professionals including analysts, clinicians, coding specialists, auditors and innovators to set aggressive goals and execute on them with the team.\n\nPrincipal Responsibilities and Essential Duties:\nDefine and develop analytical, statistical and machine learning algorithms for advanced analysis and prediction.\nArchitect, design, build and integrate solutions using Hadoop and open source solutions: Scala/Spark, R, Python, Ruby, Whatever, the Mahout machine learning library.\nEstablish credibility and strong working relationship with development teams to review design and code for adherence to established standards and best practices.\nDeliver using an Agile development process.\nMaintain our repository and other relevant documentation. Architect and hands-on development of Analytics solutions.\nDefine and develop analytical, statistical and machine learning algorithms for advanced analysis and prediction.\nArchitect, design, build and integrate solutions using Hadoop and open source solutions: Scala/Spark, R, Python, Ruby, Whatever, the Mahout machine learning library\nCompletes all responsibilities as outlined on annual Performance Plan.\nCompletes all special projects and other duties as assigned.\nMust be able to perform duties with or without reasonable accommodation\nRequirements:\nBachelor\u2019s Degree in Mathematics, Statistics, Computer Science; Masters or advanced certifications preferred\nMinimum 2 years\u2019 experience in advanced analytics\nMinimum 2 years\u2019 experience in a data architecture role with deep understanding of architecture principles & best practices\nExperience delivering solutions in an Agile environment\nAbility to work independently as well as a member of a collaborative team\nStrong knowledge of the Hadoop ecosystem, including creating and debugging\nMust have flexibility and willingness to participate in the work processes of an international organization, including conference calls scheduled to accommodate global time zones\nUnderstanding of Node.js and SQL; Expert proficiency in one or more programming languages such as Scala/Spark, Python, et al;\nExpert proficiency in at least one statistical modeling program like R, MATLAB, or SAS.\nUnderstanding of machine learning, artificial intelligence and/or artificial neural networks. Strong proficiency in applying various mathematical and statistical models to include, but not limited to: Discrete Event Simulation, Factor Analysis, Genetic Algorithms, Bayesian Probability Models, Hidden Markov Models and Sensitivity Analysis.\nEqual Opportunity Employer/Protected Veterans/Individuals with Disabilities\nCompany Description\nCotiviti is a leading solutions and analytics company that leverages unparalleled clinical and financial datasets to deliver deep insight into the performance of the healthcare system. These insights uncover new opportunities for healthcare organizations to collaborate to improve their financial performance, reduce inefficiency, and improve healthcare quality.\n\nWe focus on improving the financial and quality performance of our clients. In healthcare, this means taking in billions of clinical and financial data points, analyzing them, and then helping our clients discover ways they can improve efficiency and quality. In addition, we support retail and life/legal industries with data management and recovery audit services.\n\nCotiviti applies deep data science and market expertise to help healthcare organizations in three critical areas:\n\n\u2022 Payment Accuracy: analyzing data flowing between payers and providers to ensure that claims are paid appropriately\n\u2022 Risk Adjustment: ensuring that health plans accurately capture and report how sick their members are so that plans are appropriately reimbursed for the healthcare services their members receive\n\u2022 Quality and Performance: evaluating healthcare cost, quality, and utilization at individual, provider, and population levels to identify the best opportunities for financial and clinical performance improvement"}, "774": {"company": "Deerwalk Inc.", "description": "Job Description\nJob Summary\n\nJoin a small team dedicated to development and research initiatives leveraging machine learning and artificial intelligence methods to mine Deerwalk\u2019s seven-million member data set of post-adjudicated medical and pharmacy claims for actionable insights.\n\nJob Responsibilities\nConstruct and curate a knowledge base of machine learning techniques and algorithms to help the team scale and grow\nDevelop models and algorithms that further Deerwalk\u2019s product development and operational goals\nCoordinate with product development teams to identify business problems with AI solutions\nInterface with offshore machine learning engineers\n\nCompany Description\nDeerwalk Inc. (\u201cDeerwalk\u201d or the \u201cCompany\u201d) is the leading provider of emerging Big Data analytics solutions to the healthcare industry. Deerwalk was established in 2010 by founders of D2Hawkeye, a pioneer in healthcare analytics, which was acquired by Verisk as its platform in the healthcare analytics space. Deerwalk\u2019s cutting-edge software products are based upon the next-generation Big Data technologies such as Hadoop. The Company\u2019s customizable suite of integrated care management and innovative data analytic applications; enable advanced capabilities and streamlined workflows for Providers and Healthcare IT organizations of all sizes."}, "775": {"company": "DCS Corp", "description": "Job Description\nInfoscitex, a DCS company, is an employee owned organization with a reputation for agile and efficient development of technology solutions for U.S. Defense, Aerospace, Human Factors, and Security markets. We continue to provide innovative solutions with our multidisciplinary teams formed with exceptional employees. Infoscitex is seeking a Data Scientist to join our team. As this Data Scientist, you will use established programmatic and quantitative methods to find patterns and relationships in large data sets. In this role, you could expect to conduct mathematical, statistical or other data-driven problem solving analysis to identify operations or intelligence questions by internal and external customers.\n\nPlease note this is a very math intensive opportunity; if you are extremely comfortable discussing and applying mathematical principles learned in undergraduate Calculus 1-3; including Differential Equations, Linear Algebra, and Statistics; then you may thrive in this role.\n\nRequirements:\n\nDue to the sensitivity of customer related requirements, U.S. Citizenship is required.\n\nMS degree in Electrical Engineering, Computer Engineering, Computer Science, Mathematics, or a related discipline; and at least 5 years of related experience researching and providing data science solutions to the Department of Defense or the Intel Community in the areas of data understanding and insight, big data including using cloud computing, or artificial intelligence and machine learning. (We have multiple levels associated with this opportunity. Candidates with more advanced degrees or varying experience may be considered for alternative classification.)\n\nApplicants selected will be subject to a U.S. Government background investigation and must meet eligibility requirements for access to classified information: Active TS/SCI.\n\nProficiency in a compiled programming language: C/C++, Fortran, etc.\n\nExperience using Python, R, Java, or other computer languages in a Linux environment to perform data science, develop automated solutions to process, and transform data.\n\nExperience applying machine-learning techniques on a variety of different data types (e.g. images, text, time series, etc.).\n\nStrong skills in MS Office suite.\n\nAbility to work in a highly collaborative team environment.\n\nExcellent verbal and written English communication skills with ability to prepare and deliver clear presentations on research and development plans, project status, technical issues, and results.\n\nDemonstrated ability and react effectively to time critical situations to achieve project success.\n\nAbility to travel (8-10 short travel trips per year are anticipated)\n\nDCS Corp is an Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities.\nCompany Description\nDCS Corp is an employee owned Aerospace Engineering Company that supports all branches of the military and government sectors. We have been in business since 1977 and are now more than 1,300+ employee/owners strong.\n\nIn addition, as an employee of DCS you will also be an owner and stock holder.\n\nOur Core Values are People, Quality and Integrity and Profitable Growth."}, "776": {"company": "Paylocity", "description": "As a Data Scientist, you will help Paylocity discover the information hidden in vast amounts of data, to help our customers make smarter human capital decisions that drive organizational success. Your primary focus will be to apply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement.\n\nAre you the teammate we are looking for?\n\nWho you are:\nEnthusiastic about advanced analytics and how predictive insights lead to a superior customer experience\nInvested in staying current in data science by applying new technologies and practices\nAble to work in a collaborative environment with a desire to share your ideas\nAble to work independently on modules and complete tasks with high quality, but unafraid to seek out suggestions from other team members\nExcited to work on cutting-edge technology!\nDuring the first three months at Paylocity, you will:\nSelect features, build and optimize classifiers using machine learning techniques such as random forests, xgboost, TensorFlow, linear regression, time series methods\nCollaborate with Product Owners, Sales Leaders, Enterprise Architects and other executives to translate complex human capital management challenges into data science projects\nExtend company\u2019s data with third party sources of information when needed\nEnhance data collection procedures to include information that is relevant for building analytic systems\nLeverage cutting edge big data technologies on AWS and Microsoft Azure\nConduct ad-hoc analysis and present results in a clear manner\nCreate automated anomaly detection systems and tracking of its performance\nWork closely with full stack .net engineers in an agile product development environment\nWhat you bring:\n\nDemonstrated ability to leverage data science to drive business results. Some ways previous successful candidates have demonstrated this are:\n3-6 years of data science success at other software companies\nRecognized success for data science skills via academic awards, scholarships or corporate recognition programs (Employee of the Year, etc.)\nExperience in writing production grade machine learning models in Python. Some ways previous successful candidates have demonstrated this are:\nA portfolio of publicly available data science projects that resulted in a fully functioning piece of software\nStrong academic publication or speaking record in organizations such as ICML, NeurIPS, JML, KDD, and INFORMS\nHistory of strong performance in Kaggle competitions\nExperience with cloud infrastructure on AWS or Azure\nSkilled at translating business problems into data science problems and communicating the results to non-technical audiences. Some ways previous successful candidates have demonstrated this are:\nA resume or cover letter outlining previous experience leveraging data science across many domains\nA professional or academic track record of teaching mathematical or data science concepts to non-traditional audiences\nExperience or interest for leveraging technology and data to empower employees. Some ways previous successful candidates have demonstrated this are:\nProfessional or academic experience in HR, social science or psychology\nAdvanced degree (Masters or Phd) preferred in computer science, industrial engineering, statistics, industrial organizational psychology, neurology, public policy, linguistics or other quantitative field preferred. Bachelor\u2019s degree required.\n\nTo apply to this job, click Apply Now"}, "777": {"company": "Waitr", "description": "Job Description\nWaitr seeks a Data Scientist.\n\nYou should:\nHave 2+ years of industry experience developing machine learning models with business impact \u2014 more experience preferred\nHave a B.S., M.S., or PhD. in Statistics, Computer Science, Math, Physics, Economics, or other quantitative field\nPossess Deep understanding of statistics / machine learning\nBe able to demonstrate the ability to write well written code (experience with Python preferred)\nBonus points if you:\nhave experience with real-time technology problems\nhave experience with Pandas / Python machine learning libraries\nhave experience with AWS SageMaker\nAs a data scientist, you will have the opportunity to leverage our data infrastructure to develop models that impact millions of users across our three audiences and tackle our most challenging business problems. You will work with data scientists, engineers, and product managers to develop and iterate on models to help us grow our business.\n\nHere's how you'll be spending your week:\nUse quantitative analysis and the presentation of data to see beyond the numbers and understand what drives our business\nProvide insights to help business and product leaders understand marketplace dynamics, user behaviors, and long-term trends\nIdentify and quantify levers to help move key metrics\nRecommend which features to build and why\nWork backwards from understanding and sizing problems to ideating solutions\nGenerate recommendations and use statistical techniques and hypothesis testing to validate your findings. This includes:\nPerforming analytical deep-dives to identify problems, opportunities and actions required;\nCollecting, processing, and cleaning data from disparate sources using SQL, Python, or other scripting and statistical tools; and\nManaging the design, execution, and analysis of experiments; driving rigor and testing culture through product and operations teams\nReport against company initiatives by identifying key metrics and building executive-facing dashboards to track progress\nMonitor key performance metrics, understanding root causes of changes\nBuild data sets and reporting tables to empower operational and exploratory analysis\nPartner with engineering to implement, document, validate, and iterate on building solutions at scale\nWe're looking for someone who:\nIs high-energy and confident \u2014 you\u2019ll do whatever it takes to win\nIs an owner \u2014 driven, focused, and quick to take ownership of your work\nIs humble \u2014 you\u2019re willing to jump in and you\u2019re open to feedback\nIs Adaptable, resilient, and able to thrive in ambiguity \u2014 things change quickly in our fast-paced startup and you\u2019ll need to be able to keep up!\nIs Growth-minded \u2014 you\u2019re eager to expand your skill set and excited to carve out your career path in a hyper-growth setting\nHas a strong desire for impact \u2014 ready to take on a lot of responsibility and work collaboratively with your team\nIs it worth it? Let us perk it.\nGround floor opportunity with the team; shape the strategic direction of the company.\nThe rare opportunity to change the world such that everyone around you is using the product you built. We\u2019re reinventing the dining experience.\nWe support and encourage continual learning through sponsoring conference attendance and ongoing learning subscriptions.\nSharp, motivated co-workers in a fun work environment.\nFull medical/dental/vision package to fit your needs.\nNine paid company holidays.\nUnlimited vacation policy; work hard and take time when you need it.\nStandard issue latest generation Macbook Pro (or an equivalent substitute of your choice.)\nBuilding a diverse and inclusive workplace where we learn from each other is an important part of the culture at Waitr. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a fun place to work. Get ready to do the best work of your life here at Waitr!\n\nCompany Description\nWAITR is an app based restaurant platform that connects restaurants and guests. Guests scroll restaurant menus, customize an order, modify any item, add people to a group order, split the check, choose delivery or carryout, and with the push of a button, have an order in their hands.\n\nWAITR has transformed the way restaurants reach people & the way people choose restaurants. The WAITR delivery team & on-demand delivery platform differentiates itself from the pack by being built by hospitality professionals for hospitality professionals. Over half a million orders have been handed to happy people by smiling WAITRs."}, "778": {"company": "HCSC", "description": "Description:\n\nWe're looking for a Data Scientist in our growing Enterprise Analytics area to develop new data science products using machine learning, natural language processing, data visualization techniques, and other forms of advanced analytics.\n\nThe Enterprise Analytics team is also a Center of Excellence for data science at Blue Cross and Blue Shield of Illinois, New Mexico, Montana, Oklahoma & Texas. This person will spend approximately a quarter of their time promoting best practices in data science across the enterprise and leading and organizing technical training for the broader community.\n\nAt the largest customer-owned and not-for-profit health insurer and fourth largest health insurer overall in the United States, you will have the opportunity to work with massive datasets to drive revenue growth, improve our operational and member-facing processes, and affect how healthcare is delivered to our members.\n\nAn ideal candidate would be someone who loves working with data, demonstrates a continuous learning and growth mindset, possesses an interest in the intersection of healthcare and technology, and has an ability to communicate complex technical concepts to non-technical audiences.\n\nJob Purpose:\nThis position is responsible for employing advanced analytical techniques to create and drive adoption of data-based products and processes to add business value for internal and external customers. They will use data analysis, machine learning, predictive modeling, statistics, visualization, and other data science techniques to derive actionable insights. They will leverage domain expertise and communication skills to identify data-based solutions to customer needs, and present and explain technical findings to non-technical audiences to promote data-driven decision making. They will create analytical processes for automated machine driven decision making where human decision making is not scalable or feasible.\n\nRequired Job Qualifications:\nBachelor's degree and 3 years of work experience in a mathematical, statistical, computer science, engineering, physics, economics or related quantitative field; OR Actuarial credential or Master\ns degree and 2 years of work experience in a mathematical, statistical, computer science, engineering, physics, economics or related quantitative field; OR Ph.D. in a mathematical, statistical, computer science, engineering, physics, economics or related quantitative field; OR 6 years\nexperience in an advanced mathematical, statistical, computer science, engineering, physics, economics or related quantitative field.\nStrong learning and growth mindset\nCustomer-focused\nStrong interpersonal, verbal and written communication skills.\nMust demonstrate proficiency in at least four of the following six areas: 1) data analysis and relational-style query languages; 2) machine learning and/or statistical modeling; 3) data visualization; 4) a high-level programming language; 5) distributed computing; 6) understanding of healthcare.\nProficiency with Microsoft applications including Access, Excel, Word and Power Point.\nPreferred Job Qualifications:\nMasters or Ph.D. in a quantitative field, or bachelors degree with significant healthcare experience.\nThis position is based in Chicago, IL.\nRelocation will not be provided for this position.\n\nLocation: IL - Chicago\nActivation Date: Tuesday, January 29, 2019\nExpiration Date: Wednesday, January 1, 2020\nTo apply to this job, click Apply Now"}, "779": {"company": "Itron, Inc.", "description": "The work we do every day matters. From modernizing the grid and ensuring safe, reliable water delivery to creating smarter cities, you can make an impact with Itron.\n\nAs a Data Scientist at Itron, you will work with business leaders to deliver business outcomes for utility customers using advanced data analytics. You will work closely with project teams and utility customers to identify and solve business problems by mining the value from large sets of structured, semi-structured, and unstructured data in a distributed processing environment. This role will focus on algorithm development and prototyping, as well as supporting developers who will implement such algorithms for production. Accordingly, this position captures combined skills of a scientist, statistician, data analyst, and programmer.\n\nSome remote work and flex time possible, although travel will be increased to work on-site with some of the teams.\n\nJob Duties & Responsibilities:\n*Management and manipulation of data sets as required from raw source to analytics platform.\n*Perform data cleansing & validation.\n*Responsible for completing predictive data analysis.\n*Develop software algorithms and models to achieve business results.\n*Perform data visualization.\n*Communicate both written and verbal activities with customers and Itron Product Management and R&D management.\n*Interpretation and presentation of statistical tests & results.\n*Commit to learning energy & utility domains.\n\nQualifications:\nExperience: This position requires a minimum of 1-2 years of related experience.\nExperience with the following programming languages would be beneficial: R, ML, Python, Matlab, SQL.\n\nOther desired skills:\n*Effective interpersonal communication\n*Familiarity with source control and issue tracking systems such as git, Microsoft ADS/VSTS or Jira.\n*Statistical skills such as regressions, clustering, time-series, Fourier Transforms\n*Analog circuits or basic power/electrical engineering concepts\n\nEducation: Bachelor's degree in related field (engineering, physics, mathematics, or actuary science, etc.) is required. Master's Degree in a related field (data science, mathematics, or statistics, etc.) is required; PhD in a related field is preferred.\n\nTravel: 10 - 20%\n\nLocation: Can be located in either San Jose or Oakland, CA, Raleigh, NC, or Liberty Lake, WA\n\nPhysical Demands: This is a typical office job, with no special physical requirements or unusual work environment.\n\nIf you require an accommodation in order to apply to this position, please contact your local recruiting representative at 1-800-635-5461 or email .\n\n#LI-JO1\n\n\n\nItron is an Equal Opportunity, Affirmative Action Employer. Qualified applicants are considered without regard to race, color, religion, sex, age, national origin, citizenship, sexual orientation, marital status, pregnancy, medical condition, veteran status, disability, genetic information, gender identity or other characteristics protected by law."}, "780": {"company": "L.A. Care Health Plan", "description": "Data Scientist\n\nJob Category:\n\nInformation Technology\n\nDepartment:\n\nEnterprise Data Strategy\n\nLocation:\n\nLos Angeles, CA, US, 90017\n\n#job-location.job-location-inline {\ndisplay: inline;\n}\n\nPosition Type:\n\nFull Time\n\nRequisition ID:\n\n4678\n\nEstablished in 1997, L.A. Care Health Plan is an independent public agency created by the state of California to provide health coverage to low-income Los Angeles County residents. We are the nation\u2019s largest publicly operated health plan. Serving more than 2 million members in five health plans, we make sure our members get the right care at the right place at the right time.\n\nMission: L.A. Care\u2019s mission is to provide access to quality health care for Los Angeles County's vulnerable and low-income communities and residents and to support the safety net required to achieve that purpose.\nJob Summary\nThe Data Scientist is responsible for supporting L.A. Care\u2019s strategic business initiatives through the application of predictive analytics as part of production workflows. This individual will lead projects through the iterative data science process (Stating the Question > Exploratory Data Analysis > Model Building > Interpretation > Communication > Operationalization), collaborating with business, I.T., and data subject matter experts from across the enterprise.\nDuties\nAbility to query, transform, and integrate data from multiple sources and structures. Research and develop predictive learning models using modeling software.\n\nEffective communication of reproducible analyses and results (including failures), both visually and orally, in peer review and customer settings.\n\nCollaborate and work closely with other departments to identify gaps and structure problems.\n\nPropose solutions and actionable strategies to business challenges.\n\nWork closely with domain experts (both business and data) to understand processes and solution inputs.\n\nMonitor the performance of operationalized predictive models.\n\nPerform other duties as assigned.\nEducation\nBachelor's Degree in Computer Science and/or Engineering or related field\nExperience\nRequired:\n\nWith Bachelor's Degree: 6-8 years of traditional data analysis, including querying, aggregation, basic\n\nstatistical analysis, and visualization with the intent to provide business insights (preferably in a health plan).\n\n2+ years of applied predictive modeling in a business setting (preferably in a health plan).\n\nPreferred:\n\nWith Master's Degree: 4 years of traditional data analysis, including querying, aggregation, basic statistical\n\nanalysis, and visualization with the intent to provide business insights (preferably in a health plan).\n\nEquivalent Experience:\n\nWith High School Diploma/GED: 12 years of traditional data analysis, including querying, aggregation, basic\n\nstatistical analysis, and visualization with the intent to provide business insights (preferably in a health plan).\n\nWith Associate's Degree: 9 years of traditional data analysis, including querying, aggregation, basic statistical analysis, and visualization with the intent to provide business insights (preferably in a health plan).\nSkills\nRequired:\n\nWorking knowledge of relational databases, database structures.\n\nProficiency in Apache Spark, R and SQL (Tableau, Python, and SAS a plus).\n\nExploratory data analysis capabilities to understand the data. e.g., estimates of location and variability, correlation matrices, feature comparison visualization, trend analysis.\n\nRegression and classification predictive model development and interpretation using: Heuristic/traditional techniques. e.g., linear regression, logistic regression, Na\u00efve Bayes; Supervised machine learning techniques. e.g., decision trees, bootstrap aggregation, boosting, deep learning; Unsupervised machine learning techniques. e.g., k-means clustering, principal component analysis, hierarchical clustering.\n\nWorking optimally as part of a cross-functional team.\n\nAbility to initiate and drive projects to completion with minimal guidance.\n\nAbility to problem solve and quickly find solutions on your own.\n\nStrong interpersonal skills, including the ability to influence management at various levels of the organizations.\nAdditional Information\n\nL.A. Care offers a wide range of benefits including\nPaid Time Off (PTO)\nTuition Reimbursement\nRetirement Plans\nMedical, Dental and Vision\nWellness Program\nVolunteer Time Off (VTO)\n\nNearest Major Market: Los Angeles\nJob Segment:\nMedical, Healthcare\nTo apply to this job, click Apply Now"}, "781": {"company": "Ford Motor Company", "description": "The Corporate Decision Sciences team within Global Data Insights and Analytics (GDI&A) supports analytical solutions and insights across the enterprise in areas like Finance, Office of General Counsel, General Auditors Office, Human Resources and others. The Data Scientist discovers and curates new and existing data sources to create insight for the business. This is an exciting opportunity to utilize the latest tools and methods in Statistics, Big Data, and Data Science to solve a variety of business problems.\n\nThe role spans the full project lifecycle from analytic problem definition, through data gathering, analysis, model development, reporting/visualization development, testing, and operational deployment.\n\\n\\n\\n\\n\n\nResponsibilities include:\n\nAcquire deep understanding of the business problems and translate them into appropriate business solutions\nDrive development and delivery of analytic and statistical models using skills such as data acquisition and management, algorithm design, and model development & refinement\nEnsure overall quality of the data & solutions throughout the analytic development process\nInterpret results and communicate insights to technical and non-technical audiences including executive leadership\n\nBasic Qualifications:\nBachelor's degree in Statistics, Economics, Data Science, Computer Science, Engineering or Mathematics\n1+ years of experience in mathematical programming, data mining, and/or statistical analysis\n1+ years of experience with one or more of the following tools: Data Gathering skills/tools (e.g. SQL, Hadoop, Teradata, SAS, Business Objects, Alteryx, etc.) and/or Visualization skills/tools (e.g. Qlikview, Tableau, WebFocus, etc.)\n1+ years of experience collaborating with business to develop strategies and innovations to solve complex business problems\n\nPreferred Qualifications:\nMaster's degree in Statistics, Economics, Data Science, Computer Science, Engineering or Mathematics\n3+ years of experience in statistical or mathematic modeling\n6+ months of experience in Accounting or Finance\nLarge scale data manipulation and mining/pattern recognition experience\nDeveloped and implemented Machine Learning models\nStrong oral and written communication skills\nStrong problem formulation and problem solving skills\nExperience communicating findings to make data analysis actionable and understandable by business partners\nAbility to take complex problems and break them down to create and implement an action plan\nStrong understanding of analysis and computational complexity and ability to programmatically solve problems\nStrong capabilities at designing visual interface for data interaction\n\nJoin our team as we create tomorrow! We believe in putting people first, working together, and facing challenges head-on, because we're Built Ford Tough. We're one team striving to make people's lives better while creating value, delivering excellence and ultimately going for thewin.\n\nCandidates for positions with Ford Motor Company must be legally authorized to work in the United States on a permanent basis. Verification of employment eligibility will be required at the time of hire. Visa sponsorship is not available for this position.\n\nFord Motor Company is an equal opportunity employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status"}, "782": {"company": "INFICON", "description": "COMPANY OVERVIEW:\n\nINFICON is a growing, global, leading provider of innovative technologies that enhances productivity and quality in sophisticated industrial processes. The products provided by INFICON are world-class instruments for gas analysis, measurement, and control and are vital to manufacturers and end-users in the complex fabrication of semiconductors and thin film coatings for optics, flat panel displays, solar cells, and industrial vacuum coating applications. INFICON is headquartered in Switzerland and has world-class manufacturing facilities in Europe, the United States and China with subsidiaries located throughout the world. This position will be located in East Syracuse, NY. For more detailed information about INFICON, please visit our website at www.inficon.com.\n\nINFICON's Data Science Research group in East Syracuse NY conducts research to analyze data from our products, and to automatically identify events of critical importance to our customers. Our group seeks to develop techniques that reliably identify extremely rare and unpredictable anomalies within the delicate processes that build the world's most advanced semiconductor products. We also invent algorithms to process faint signals buried in noisy mass spectral data so that we can protect people's lives from deadly chemicals.\n\nYou will apply your mastery of state-of-the-art machine learning technologies to difficult problems on noisy high-dimensional data. You will work in a multi-disciplinary team that includes experts in computer science, mathematics, chemistry, physics, electronics, and advanced semiconductor manufacturing processes. Your work will have high visibility in the company because of its potential to greatly increase the value of our products. INFICON is the top company in most of the markets we serve, so your research also has potential for great impact on the industry.\n\nIn this job, you will be given ample freedom and flexibility to explore a wide range of novel approaches, you will work closely with your colleagues, with large amounts of real data, and you will always remain focused on the goal: to create running code of high value to our customers.\n\nResponsibilities:\nPrimary: Research and develop anomaly detection algorithms for multivariate time-series data.\nSecondary: Enhance performance of algorithms for compound identification in mass-spectral and other sensor instruments.\n\nRequired background:\nPhD or equivalent in computer science or applied mathematics, with specialization in data science and machine learning.\nExperience with multivariate time series analysis and modeling techniques.\nAccomplished software developer, with experience training and testing ML models on large high-dimensional data sets.\nCandidates without a PhD are encouraged to apply if they have experience solving challenging data science problems, especially if in the area of multivariate time-series anomaly detection.\n\nPreferred background:\nPublished papers or and/or code for analyzing time series data or process control data.\nFluency with Python, Linux, C++, common scientific computing libraries, machine learning libraries.\nPrior work with unsupervised or semi-supervised ML for anomaly detection.\nKnowledge of Physics or Chemometrics or Process control.\n\nCompensation will be commensurate with experience including a competitive base salary, discretionary bonus opportunity, competitive benefits package, and relocation assistance.\n\nINFICON, is committed to ensuring that our online application process provides an equal opportunity to all job seekers that apply without regard to race, religion, ethnicity, national origin, citizenship, gender, age, protected veteran status, disability status, genetic information, sexual orientation, or any other protected characteristic. A notice describing Federal equal employment opportunity laws is available here and here to reaffirm this commitment.\n\nINFICON is also committed to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for an employment opportunity at INFICON and require special assistance or an accommodation during the application process, please contact Human Resources at 315-434-1100. Determination on requests for reasonable accommodations are made on a case-by-case basis.\n\nPAY TRANSPARENCY NONDISCRIMINATION PROVISION\n\nEmployee Polygraph Protection Act Poster\n\nPI115660703\n\nApply Here"}, "783": {"company": "MATRIX Resources", "description": "Position: Data Scientist Location Kennesaw, GA Duration: 12 Months POSITION SUMMARY: The Data Scientist provides merchandizing, sales, and marketing teams with the capabilities of delivering personalized ecommerce experience. Critical thinking and problem solving skills are essential for interpreting data. Responsibilities Collect/refine/cleansing source data include but not limit to: order transactions/obligations, marketing campaigns, customer profile, and product taxonomy.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcome.\nMine and analyze data to drive optimization and improvement of product development, marketing techniques and business initiatives.\nApply machine learning capabilities to define/develop recommendation framework.\nDevelop A/B testing framework and test model quality.\nDevelop processes and tools to monitor and measure model performance and data accuracy.\nEvaluating new technologies, data scientist tooling, learn and master new technologies and techniques.\nCollaborate with development team to standardize/collect key analytical matrix.\nMaintain big data ecosystems.\n\nRequired Experience: Knowledge of data mining\n2-5 years of experience as a Data Scientist\n2-5 years of R programming experience\n2-5 years of experience with SQL database\nKnowledge of big data stack.\nWorking experience with Hadoop\n\nDesired Experience: Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc, and their real world drawbacks and advantages.\nGood applied statistics knowledge, such as distributions, statistical testing, regression, etc.\nGood programming and scripting skills.\nExperience with data scientist toolkit include Scala, Spark, NumPy, Matlab.\nProficiency in using query languages such as SQL, Hive, Pig.\nExperience with streaming processing like Kafka\nExperience with BI tools like Tableau.\n\nProfessional Skills: Ability to work accurately in a fast-paced environment.\nAbility to work with a diverse group of people.\nAbility to work comfortably under pressure.\nAbility to prioritize and work multiple tasks and exceeds deadlines.\nAbility to work independently and with a group on various on-going projects simultaneously.\nEffectively communicate with internal and external customers (management, co-workers, vendors and customers.)\nAbility to operate an automobile or arranged transportation to meet demands of the position.\nAbility to concentrate for extended periods of time.\nExcellent oral and written communication skills.\nMust have the ability to carry out instructions furnished in both oral and written form\nAbility to plan and organize time and projects efficiently.\nAbility to exchange and furnish information requiring detailed explanations and maintain active discussions with customers and other work groups.\nAbility to act in an ethical, honest and professional manner at all times.\nDesire to work independently as well as in a team environment.\n\nEducation: Bachelors degree or equivalent in relevant work experience."}, "784": {"company": "Pinnacle Group", "description": "Job Description:\nData scientist that designs and develops methods that consolidate and analyze \"big data\" to generate insights to solve customer problems.\nDevelop a keen understanding of the data, write software programs, algorithms, and automated processes to transform large datasets into meaningful information for gathering insight.\nDraw conclusions from large, disparate sources of data, Worldpay can continue to build industry leading data products that help their customers grow.\nInteracts with product and service teams to understand the business objectives and translate those into data problems, experiments and eventually solutions.\nDesigns, develops and programs methods, processes, and systems to consolidate and analyze unstructured, diverse \"big data\" sources to generate actionable insights and solutions for client services and product enhancement.\nDevelops strong understanding of the Worldpay data sets and identifies ways to enhance its value by combining it with other data sets.\nIdentifies meaningful insights from large data, interprets, and communicates insights from analysis and experiments\nCreates workflows to pre-process data, build machine learning models, and evaluate the effectiveness of those models on large data sets.\nLeverages previous experience/knowledge and current data to provide insightful analytics.\nExercises judgment in selecting methods, techniques, and evaluation criteria for obtaining results.\nUses MS Excel/PowerPoint to summarize findings and communicate effectively to the product team.\nDevelops thorough business friendly documentation.\nWorks in cross-functional teams and work independently.\nAbility to challenges conventional thinking when necessary."}, "785": {"company": "Brooksource", "description": "Data Scientist\nDayton, OH\n\nRole and Responsibility:\n\nResponsible for developing, implementing, managing and presenting in-depth analyses that meet the health care information needs of the organization such as utilization cost analyses, care management return-on-investment analyses, performance comparisons, and state mandated measurement requirements\nIdentify trends and patterns using standard departmental reports and databases as well as leveraging other processes and data sources\nConduct outcome analyses to determine impact and effectiveness of corporate initiatives\nManage the development, production, and validation of reports generated from detailed claims, eligibility, pharmacy and clinical data\nConduct examination and explanation of complex data relationships to answer questions identified either within the department or by other departments\nUse statistical techniques to measure impact of various actions/studies, internal and external, develop sampling and hypothesis testing to help the organization determine outcomes, and forecast and predict future behaviors and events\n\nEducation and Experience:\n\nBachelor's Degree or equivalent years of relevant work experience is required\nMaster's Degree (e.g., public health, mathematics, statistics, experimental psychology, epidemiology, health economics, nursing) is preferred\nMinimum of five (5) years of experience in data analysis and/or analytic programming required\nHealth care delivery and/or payer experience preferred\n\nSkills:\n\nProven analytic skills in solving multi-dimensional problems\nWord, Excel, and/or Access skills; SQL and/or SAS experience preferred\nGraphic development/presentation skills\nApplied exploratory and inferential statistical skills\nKnowledge of managed care and health care data coding\nAbility to lead analytic efforts\n\nABOUT EIGHT ELEVEN:\n\nAt Eight Eleven, our business is people. Relationships are at the center of what we do. A successful partnership is only as strong as the relationship built. We're your trusted partner for IT hiring, recruiting and staffing needs.\n\nFor over 16 years, Eight Eleven has established and maintained relationships that are designed to meet your IT staffing needs. Whether it's contract, contract-to-hire, or permanent placement work, we customize our search based upon your company's unique initiatives, culture and technologies. With our national team of recruiters placed at 21 major hubs around the nation, Eight Eleven finds the people best-suited for your business. When you work with us, we work with you. That's the Eight Eleven promise.\n\nEight Eleven Group provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws.\n\nEight Eleven Group provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws."}, "786": {"company": "Grab Technology LLC", "description": "Data Scientist\n\nJob Description: Solve problems using a combination of Big data, Machine learning and Operations research techniques. Build, validate, test, and deploy machine learning/ deep learning models for behavior, recommendation or demand modelling. Develop and implement optimization algorithms to solve vehicle dispatch, routing and pooling problems. Drive product improvements and roll-out of new features. Communicate problem formulation, solution, analyses and insights to team members and stakeholders. Design and build machine learning and optimization algorithms and integrate, simulate and test impact of algorithms and features on the overall system.\n\nRequirements:\n\nMasters or foreign equivalent degree in Computer Science, or a related field.\nTwo years of experience including: developing and operating large-scale data structures for business intelligence analytics using ETL/ELT processes, OLAP Technologies, data modeling, and SQL; Optimizing algorithms; and Implementing predictive models in large-scale or developing large-scale data processing utilizing Python with Spark (PySpark)/Scala. One year of experience in: converting Hive scripts to PySpark scripts for better performance; R; C++; and Large-scale parallel programming.\n\nPosition at Grab Technology LLC in Bellevue, WA. To apply, please visit: https://tinyurl.com/w6ufptd"}, "787": {"company": "Tech Mahindra Limited", "description": "Job Title: Data Scientist\nLocation: Philadelphia, PA\nDuration: Longterm\n\nJob Description:\nRequirements:\n\u2022Four-year degree in a related Computer Science, Math or Statistical field of study.\n\u20227+ continuous years of professional experience as a Data Scientist.\n\u2022Strong problem-solving skills with an emphasis on product development.\n\u2022Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022Experience working with and creating data architectures.\n\u2022Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\n\u2022Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\n\u2022A drive to learn and master new technologies and techniques.\n\u2022Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.\n\u2022SUPERB communication skills with an emphasis on writing and interpreting abilities\n\u2022Excellent presentation skills. Must have the ability to confirm complex data into digestible formats for non-technical business teams.\nNice to have:\n\u2022Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.\n\u2022Experience using web services: Redshift, S3, Spark, etc.\n\u2022Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.\n\u2022Experience analyzing data from 3rd party providers.\n\u2022Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\n\u2022Experience visualizing/presenting data for stakeholders.\n\u2022Experience in Telecoms / CSPs / MNOs / Order Management Domain"}, "788": {"company": "Brains Workgroup, Inc.", "description": "Our client, a global provider of Information Technology and Services is looking for a talented Data Scientist in Plymouth Meeting, PA location\n\nConsulting position, initial term is 6 months with possible extensions.\n(Hourly rate will be identified DOE)\n\nPlease read the description below and to be considered immediately email your resume to deepaf@brainsworkgroup.com\n\nPython Data Scientist\nDescription:Postgraduate degree or higher involving machine learning or computer science\nExperience of statistical / machine learning projects in academia or commercial sector end to end with proven delivery capability including capturing requirements, designing analysis plans, interfacing with clients and report / manuscript writing.\nExperience developing scalable solutions and pipelines to handle large and complex data\nExcellent knowledge of supervised machine learning methods, such as regularized regressions, ensemble tree classifiers (e.g. xgboost), support vector machines, deep learning methods, etc. Good grasp of classical statistical methods, such as fitting regression models, inference testing and sampling.\nStrong programming skills in Python. Experience in pySpark is highly beneficial.\nSolid understanding of best coding practices and version control software such as Git, ability to write clean and efficient code and a good understanding of the data science package landscape.\nFamiliarity with agile software development practices such as Scrum.\nExcellent written and spoken communication skills, including ability to present technical concepts to lay audiences, write analysis plans for projects, contribute to proposals / grant applications, pitch ideas effectively and persuasively to clients / internal stakeholders, etc.\nA proactive, innovative and pragmatic approach to problem solving and an ability to think critically and independently, able to work as part of a cross-functional team.\nPeer-reviewed publications involving machine learning\nKnowledge of healthcare patient-level data\nKnowledge of epidemiology / biostatistics, particularly analytical issues relating to studies of treatment effectiveness, disease progression, adherence, healthcare utilization, etc.\nWork in bioinformatics.\nKnowledge of healthcare / life science issues involving Real-World Evidence.\nExperience with patient-level, longitudinal data.\n\nPlease email your resume or use this link to apply directly:\nhttps://brainsworkgroup.catsone.com/careers/index.php?m=portal&a=details&jobOrderID=12964315\nOr email: deepaf@brainsworkgroup.com\nCheck ALL our Jobs: http://brainsworkgroup.catsone.com/careers"}, "789": {"company": "3k Technologies, LLC", "description": "Data Scientist\n\nSan Francisco, California\n\n12+ motnhs\n\nTitle: Data Scientist\n\nMust skills : Chatbot experience\n\nPrimary Skills:-\n\n\u2022 Programming skills:- Python (with working experience in most of common libraries like Scikit , numpy, pandas, mathplotlib, keras, tensorflow, nltk, genism, spacy etc)\n\u2022 Good knowledge in statistics and deep understanding on ML algorithms and their usage\n\u2022 Working experience in end to end data science project life cycles from use case framing, data collection, data exploration, model building, deployment\n\u2022 Working experience in most of the common Machine Learning techniques related to Time series, Regression, Classification, Clustering, NLP, working with IoT data\n\u2022 Working Knowledge in Deep learning with different NN architectures like CNN, RNN, LSTM, GANs Auto encoders etc.\n\u2022 Knowledge of visualization tools like tableau, R Shiny with libraries to effectively communicate the results/inferences derived out of data science models\n\u2022 Good to have working exposure in common cloud environments and understanding of robust on premise data science infrastructure.\n\u2022 Nice to have understanding of big data related technologies and DevOps(Dockers, Singularity)\n\nThanks\n\nThanks\n\nKishore Reddy\n\n3K Technologies, LLC\n\nwww.3ktechnologies.com | mkr@3ktechnologies.com\nAnalytics | BI | Big Data | Cloud |Software Engg.\n\nt: +1 (408) 900-0076 | f: +1 (408) 884-2420"}, "790": {"company": "Amazon Corporate LLC", "description": "How can Amazon improve the advertising experience for customers around the world? How can we help advertisers and customers find each other in a meaningful way? Amazon Advertising creates and transforms the connection between retailers/service providers and customers. Join the Insights & Performance Team to contribute to product solutions that allow us to solve this through technology and automation. If you are passionate about developing analytical solutions to solve business problems, and are looking for a team that drives results to help influence Amazon business decisions, this is the right place for you.\n\nThe Insights & Performance Team seeks a Data Scientist to analyze big data to build models and algorithms that power our display advertising products. We strive to better understand the advertising and non-advertising features that best influence and predict display advertising campaign performance and ROI. This role will focus on mining existing campaign performance data, and evaluating the impact of experimentation initiatives and their outcomes. With this data, we will create A/B test recommendations for our customers to uncover previously untapped areas and drive overall advertising value. The ideal candidate must be willing to effectively project-manage and prioritize across multiple tasks, exhibit strong problem solving skills and be ready to jump into a fast-paced, dynamic & fun environment.\n\nResponsibilities:\nWork closely with product development, analytics and machine learning teams to increase advertising product efficiency.\nPartner with software development teams to implement algorithms in production systems.\nBuild consensus with business stakeholders on how your models and algorithms will drive the optimal results for Amazon customers.\nDeliver project milestones to add customer value throughout the build process.\nPartner with experimentation teams to generate A/B test recommendations.Basic Qualifications\nMS with 2+ years of industry experience or Bachelors with 5+ years of experience in Quantitative field (CS, ML, Mathematics, Statistics, Physics)\n3+ years of experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), or statistical/mathematical software (e.g. R, SAS, Matlab)\nExperience in creating data driven visualizations to describe an end-to-end system\nHighly skilled in data and statistical methods (i.e. modeling, algorithms)\nEvidence of using of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects\nAmazon is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age"}, "791": {"company": "Renown Health", "description": "Position Purpose:\n\nUnder the direction of leadership, the Population Health Data Scientist will model complex enterprise problems, and identify and implement performance improvement opportunities through the use of statistical, algorithmic, mining and visualization techniques.\n\nThe Data Scientist works closely with Renown organizational leadership, data stewards, project/program managers and other key stakeholders to turn data into critical information and knowledge that can be used to make sound organizational decisions. Other responsibilitiesinclude working with enterprise, community and regional stakeholders to (i) solve data aggregation and validation challenges, (ii) data mining and reporting activities, (iii) analysis of complex population health and risk management data sets, (iv) provide congruent and reliable conclusions and recommendations, and (v) working with said stakeholders to operationalize and achieve performance improvement objectives.\n\nMust be a creative thinker and propose innovative ways to look at problems by using data mining (the process of discovering new patterns from large datasets) approaches on the set of information available. Must validate findings using a scientific, experimental and iterative approach. Must be able to present findings to identified stakeholders by exposing assumptions and validation work in a way that can be easily understood by the intended audience.\n\nThe encumbent must be proficient at integrating and preparing large, varied datasets, architecting specialized database and computing environments, as well as communicating results. Must have a combination of business focus, strong analytical and problem solving skills and programming knowledge to be able to quickly cycle hypothesis through the discovery phase of the project. Excellent written and communication skills to report back the findings in a clear, structured manner are required.\n\nNature and Scope:\n\nThe Population Health Data Scientist will:\nAdvocate, evangelize and build data-fueled products that help the organization positively improve clinical, financial, and operational functions\nBecome an expert on Renown Health datasets.\nProvide insight into leading analytic practices, design and lead iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become part of our core deliverables.\nWork with cross-functional team members to identify and prioritize actionable, high-impact insights across a variety of core business areas.\nResearch, design, implement and validate cutting-edge algorithms to analyze diverse sources of data to achieve targeted outcomes.\nEnsure all applicable applications, including the EPIC EMR, that receive or transmit information to internal or external systems maintain adherence to organizational Data Governance policy and procedure.\nTurn data into critical information and knowledge that can be used to make sound organizational decisions.\nEnsure deliverables are completed according to priorities of Renown Leadership and the Renown Health strategic plan.\nAct as a liaison for Data Governance, Businesses Intelligence, and Information Technology teams.\nAdminister the report design, build and analysis for Key Performance Indicators and reporting.\nProvide leadership, training and mentorship for junior level analysts and report writers\nProvide expert services on complex coding, analysis, and validation problems.\nEstablish tracking and trending reports to be utilized by all levels of leadership.\nEvaluate new reporting and statistical analysis tools.\nThis position does not provide patient care.\n\nThe foregoing description is not intended and should not be construed to be an exhaustive list of all responsibilities, skills and efforts or work conditions associated with the job. It is intended to be an accurate reflection of the general nature and level of the job.\n\nMinimum Qualifications: Requirements - Required and/or Preferred\n\nEducation:\n\nMust have working-level knowledge of the English language, including reading, writing and speaking English. Masters in mathematics, statistics, public health, computer science or related field required. PhD degree preferred.\n\nExperience:\n\nThree (3) years analyst experience required, along with the following preferred work experience:\nInsurance and/or health care setting.\nFive (5) years of application design, development, coding and maintenance.\nAdvanced Standard Query Language for the purposes of report writing and data analytics.\nStatistical programming experience (SQL, SAL or R)\nEPIC Clarity and EPIC Reporting Workbench.\nBusiness Objects Crystal Reports.\nKnowledge of data security requirements.\nLicense(s):\n\nNone.\n\nCertification(s):\n\nMust be or become proficient in EPIC hyperspace/application reporting, including Cognitive Computing frameworks\n\nComputer / Typing:\n\nMust be proficient with Microsoft Office Suite, including Outlook, PowerPoint, Excel and Word and have the ability to use the computer to complete online learning requirements for job-specific competencies, access online forms and policies, complete online benefits enrollment, etc."}, "792": {"company": "Agilisium", "description": "Agilisium is looking for an experienced, Data Scientist. This is a client-facing role and the ideal candidate will play a critical role in understanding the business and solution needs of customers to create a superior customer experience. Visit us:www.agilisium.com\n\nLocation: New York, NY\n\nJob Type: Full Time\n\nJob Description :\nMinimum 2+ years of applied work experience in Data, Analytics and Data Science, in the digital division of a traditional TV & Film entertainment company\nWorking knowledge and a deep interest in relevant industry sectors: e.g. digital entertainment, digital advertising, consumer products, broadcasting, cable, film, television, sports, and news\nHands-on experience analyzing and mining large datasets in SQL.\nApplied experience creating time-series forecasts in R and/or Python (i.e. ARIMA, Exponential Smoothing, etc.).\nExperience with ML, predictive modeling, classification models, and clustering a plus. Experience with BI visualization tools such as Domo, Tableau, Lookr, or Microstrategy\nProven ownership abilities.\nIt can deliver results with a sense of accountability and proactivity.\nDemonstrated ability to thrive in a fast-paced, high throughput environment.\nPrevious experience in Digital Entertainment, High Tech, or Digital Marketing industries is preferred.\nAbility to effectively communicate and present findings to leadership and peers.\nStrong interpersonal skills.\nAbility to partner and earn the trust of constituents.\n\nRoles & Responsibilities\nProvide business analysis and insights on new growth opportunities in digital media with a focus on digital advertising, consumer products, and digital video streaming in broadcasting, cable, film, news and, sports.\nPartner closely with digital strategy, finance & business development team to gather requirements. Build models to analyze ROI on TV content licensing deals and guild /residual/participant cost models for various levels of content exploitation.\nCreate predictive models to support various digital TV entertainment forecasts and financial budgets including detailed forecasting of digital video metrics by series, season and episode, video starts, view-through, segment starts, minutes watched, ad impressions and average unique viewers\nAnalyze and create predictive models to support financial analysis of video performance on social platforms such as YouTube, Facebook Twitter, and Instagram.\nProvide predictive analysis, A/B testing and data science for stakeholder teams.\nContinue to raise the bar and improve existing prediction models for digital TV entertainment specific issues such as optimizing MVPD authentication rates.\nApply feature engineering and a deep understanding of the TV digital entertainment business to help optimize digital video recommendation engines and personalization algorithms on both ad-supported and subscription-supported video streaming platforms.\nLead the build-out of standardized reporting for multiple groups within the organization. Create requirements for new data sources and ETL for new reports.\nHelp QA and ensure business definitions are accurate.\nPartner closely with the Data Engineering team to provide technical support, define use cases and guidance for key architectural decisions including real-time processing, distributed computing, & containerized ML models.\nTrack the progress and/or ROI on business initiatives through deep-dive analysis. Leverage estimations, third party data, and other resources to provide performance updates. Participate in daily scrums and the AGILE process. Help maintain a backlog and document work in internal wiki.\nCommunicate the result effectively through presentations and syndicated reports.\nHelp regularly present findings in weekly and monthly meetings\n\nEducation\nMasters degree from a quantitative field from such as Mathematics, Statistics, Finance, Economics, Engineering.\n\nAgilisium is an equal opportunity employer. All applicants will be considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. To be considered for this role you must be authorized to work in the United States for any employer.\n\nWith Best Regards\nBalaji Govindarajan\nManager Talent Acquisition\nEmail:balaji.govindarajan@agilisium.com\nPhone No: 213-805-6747\nWeb: www.agilisium.com"}, "793": {"company": "AGCO", "description": "Job Summary:\n\nFuse is the leading global open platform for digital farming products and services operated by AGCO Corporation. Our digital Ag solutions empower farmers to make data-informed business decisions for their farms, leading to higher yields and profitability. This position will support our Fuse organization as we develop our enterprise data analytics strategy and competency through the development of data mining & machine learning techniques, statistical analysis, data exploration and visualization. Through close collaboration with business stakeholders, data engineers and IT partners, value will be generated for the customer, dealer and internal business partners by scaling advanced analytics. These analytics will deliver on the value of data to provide both cost reduction and increased revenues, enabling AGCO to better serve those feeding the world.\n\nJob Responsibilities:\nWork with business partners to understand opportunities in which analytics could be applied to generate business value, make processes more efficient and anticipate customer and business needs in order to increase revenue and reduce costs.\nAccountable for delivering world-class data science outcomes, solving complex analytical problems using quantitative approaches with a unique blend of analytical, mathematical and technical skills in programming languages that are used in big data environments, and supporting model and insight acceptance and understanding.\n\nEngage with functional/business leaders and team members, including data engineers to understand needs, formulate and document use-cases, turn these into data requirements, and structure data-based solutions.\nDesign, build and deploy high-performance prediction and optimization algorithms to solve business problems and facilitate new digital applications\nLeverage data to present compelling business cases to optimize decisions; communicate analysis and resulting recommendations to senior management using rich visualizations\nResearch, design, implement and validate cutting-edge algorithms to analyze diverse sources of data to achieve targeted outcomes\nProvide technical project and program oversight to ensure appropriate technical rigor is applied to project work\nGuide the efforts of and contribute to the work of technical teams in the development, deployment, and usage of applied, predictive and prescriptive analytics\nGenerate reports, annotated code, and other project artifacts to effectively document, archive, and communicate work and outcomes\n\nEvaluate model accuracy and report on performance of insights. Participate in peer review of models and code.\n\nEnhance understanding of data science and models in order to increase acceptance and demystify analytics output.\nQualifications/Experience\nMasters in statistics, applied mathematics, computer science, data science or a related field. Proficiency in two or more languages/programs: Python, R, Spark, SAS, etc (Master's preferred)\nDeep understanding of predictive modeling concepts, machine-learning approaches, clustering and classification techniques, recommendation and optimization algorithms\n\nExperience using cloud computing platforms such as AWS S3, EC2, Athena,Redshift, SageMaker, etc., for analysis of big data and model execution\n\nExperience developing advanced machine learning algorithms, statistical and analytical models, including but not limited to neural networks, decision trees, clustering, regression, scenario analysis, simulation\nExperience working with any of the predictive modeling libraries such as Scikit learn, Caret, MLLib etc.\nExperience working with database technologies like PostgreSQL, MySQL, Oracle etc.\n\nStrong communication and presentation skills, and the ability to make analytics accessible to multiple levels of the organization from fellow data scientists to those non data scientists. This includes data visualization skills and experience using tools such as Tableau, as well as strong story telling with data.\nAGCO/RSR"}, "794": {"company": "Huntington", "description": "Location: Columbus, OH\n\nDescription\n\nOur Enterprise Analytics department is growing, and we're looking for an outstanding data scientist to create predictive models to drive strategy, efficiency, and profitability across the bank.\n\nIn this role you will work within our Data Science and Predictive Modeling team and partner with data architecture, indirect lending, and consumer bank leadership to drive actionable and valuable insights to our customers and colleagues. This includes identifying opportunities and championing these capabilities around Huntington. You will lead the enhancement of our pricing optimization across multiple lines of lending, by building predictive models, automating insights, and operationalizing the delivery mechanism throughout the enterprise. At the project level, you will need to identify the appropriate technique, develop new data sets and models, define and monitor success, and communicate with technical and non-technical partners along the way.\n\nResponsibilities:\n\nCollaborate with pricing, product, marketing, and compliance teams to ensure business needs are understood and translated into project requirements.\n\nYou'll need to create a road map consisting of the technology, analytical approach, delivery mechanisms, and monitoring to ensure on-going success of pricing analytics. You'll also need to work with executive leadership to gain buy-in as well as technology experts to ensure execution success, across multiple lines of business.\n\nThis position requires both technology and project leadership while planning and executing multiple analytic projects at once in response to evolving business needs.\n\nBasic Qualifications:\nMaster's Degree\n5 or more years of work experience in Statistics, Computer Science, Engineering, or Library Science.\nA minimum of 3 years of experience with machine learning frameworks (i.e. scikit learn, keras, caret, TensorFlow, h2o) and machine learning technologies (e.g. supervised, unsupervised, reinforcement, deep)\nA minimum of 3 years of experience with at least one programming language (i.e. R, Python, SAS, or Julia).\nPreferred Qualifications:\nPhD preferred.\nExperience with mathematical optimization, specifically linear programming.\nCoursework in Generalized Linear Models, Statistical Inference, Statistical Computation, Statistical Theory, Design of Experiments, Data Mining, Bayesian Analysis, Multivariate Analysis, Probability Theory, Time Series, Nonparametric Statistics, or Spatial Statistics.\n3 years of experience with SQL queries of large databases such as Oracle, DB2, SQL Server, Teradata, and Hadoop.\nExperience developing and applying statistical or machine learning methods in a corporate environment through applications such as R, python, or SAS.\nFluent in programming languages such as Python, Java, or C++ in a data mining context, and experience building web-based applications or dashboards using R, python, HTML, CSS, Perl, and JavaScript.\nExcellent written and verbal communication skills with a proven ability to interact effectively across all organizational levels.\nProgressive thinker and problem solver, with a strong ability to manage ambiguity and complexity.\nWork effectively in teams as well as independently across multiple tasks while meeting aggressive timelines.\nExperience working in a consumer-centric company and with teams of technical professionals in a cross-functional environment.\nAbility to embrace change, constructively negotiate constraints, and effectively leverage resources to create exceptional outcomes. Consistently model and inspire high levels of professional demeanor and integrity.\nEEO/AA Employer/Minority/Female/Disability/Veteran/Sexual Orientation/Gender Identity\n\nTobacco-Free Hiring Practice: Visit Huntington's Career Web Site for more details.\n\nAgency Statement: Huntington does not accept solicitation from Third Party Recruiters for any position"}, "795": {"company": "Huntington", "description": "Job Description\nData Scientist\n\nPosition requires US citizenship and the candidate must have the ability to obtain a DoD Top Secret SCI Security Clearance.\n\nBigBear, Inc. is a leading provider of big data computing and analytic solutions. We help people make sense of their data using our cloud-based platform and big data processing algorithms. Each day, we crunch massive volumes of structured and unstructured data into usable and actionable information for our customers.\n\nWe are currently seeking a talented and passionate Data Scientist to help build high-performing, innovative, enterprise data analytic solutions. You will be responsible for deriving meaning from massive volumes of data to provide insights and analytics for trends, activities, and patterns of life with data. The successful candidate will be a self-starter that demonstrates excellent leadership, organization, and communication skills with a strong passion and curiosity for big data.\n\nREQUIRED EXPERIENCE:\n\n\u25cf Ability to interrogate extremely large sets of data to identify new intelligence and insights.\n\n\u25cf Work with vast geospatial datasets to facilitate complex analytics generating actionable location intelligence.\n\n\u25cf Strong experience with professional and applied use of Python to include Requests, SciKit Learn, Pandas, or Jupyter Notebooks\n\n\u25cf Advanced data flow and management skills.\n\n\u25cf Strong decision-making skills and ability to think outside of established policies to produce customer satisfaction.\n\n\u25cf Ability to work well independently, show self-motivation skills, set goals, be versatile and demonstrate initiative when needed.\n\n\u25cf Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, a related field, or equivalent work experience\n\nTECHNOLOGY WE USE:\n\n\u25cf ElasticSearch\n\n\u25cf PostgreSQL\n\n\u25cf Python\n\n\u25cf AWS\n\n\u25cf Git\n\nOur Company:\n\nBigBear, Inc. is an Information Technology enterprise with locations in Northern Virginia and Southern California. Our mission is to enable big data computing and analytics for our customers at a low cost. We leverage capabilities such as machine learning, crowdsourcing, geospatial image processing, and Extract-Transform-Load (ETL) data processing using our on-premise cloud computing technology stack. Our solutions provide a unique offering of products, custom built software and services focused within Big Data Analytics, Geospatial Information Systems (GIS), Visualization and Cloud Computing to our Department of Defense, and Commercial customers. We currently have exciting and challenging career opportunities for talented, motivated individuals who want to be part of a fast-growing company.\n\nOur Team:\n\nOperating as a unified team, with employees who are creative, dynamic, and visionary, drives our mission to success. Each team member provides a unique set of advanced technical skills and trade that contributes to our overall success. We pride our team on having a burning desire to push our technology and solutions to the next level of innovation. To accomplish these goals, we advocate hard work, dedication, leadership, and a passion for excellence.\n\nWhy Us?\n\nWe are seeking to expand our top-notch team of forward-thinking engineers, data scientists, and innovators, to help our customers make sense of their data. We are experiencing rapid growth, with a mission to help our customers find new ways to discover, understand, and visualize information. We will provide you a competitive salary based on experience, 100% employer paid for medical, dental, and vision, FSA, 401(k) with match, life/disability insurance, education assistance, gym reimbursement, flexible hours, unlimited coffee and snacks, and an ownership opportunity in the company as we grow.\n\nBigBear is an Equal Employment Opportunity Employer/Veterans/Disabled\nCompany Description\nBigBear, Inc. is an industry-leading provider of big data computing and analytics solutions. We help people make sense of their data using our cloud-based platform and big data processing algorithms. Each day, we crunch massive volumes of structured and unstructured data into usable and actionable information for our customers. We currently have offices in Reston, VA., Charlottesville, VA., and San Diego, CA."}, "796": {"company": "Jobot", "description": "This Jobot Job is hosted by: Bryan McQuilkin\nAre you a fit? Easy Apply now by clicking the \"Apply Now\" button and sending us your resume.\nSalary: $90,000 - $130,000\nA bit about us:\n\n\nBased in Austin (Lake Travis area), we are a marketing and information services company that provides digital advertising, technology, strategy, and media production services to the residential construction (Home building) industry.\nWe have an immediate need for a Data Scientist to produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets. This is the perfect opportunity to become a part of an innovative and energetic team that develops analysis tools which will elevate our products and delver tangible results to our teams.\n\nThis position will apply knowledge of statistics, machine learning, programming, data modeling, simulation and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement. In this role, you will design and develop predictive models and advanced algorithms that lead to optimal value extraction from the data. You will also generate and test hypotheses and interpret the results of product experiments. Additionally, you will work with different business units to translate prototypes into new products and services and provide guidelines for large-scale implementation.\n\nWhat you will be doing?\nResearch and develop statistical learning models for data analysis\nCollaborate with business unit teams to understand company needs and devise possible solutions\nCommunicate results and ideas to key decision makers\nImplement new statistical methodologies as needed for specific models or analysis\nOptimize joint development efforts through appropriate database use and project design\nSolve business problems developing and implementing machine learning algorithms and statistical models\n\nIs your background a fit? We are looking for\nDegree in Computer Science, Statistics, Applied Math or related field\n2+ years experience with SAS, ETL, data processing, database programming and data analytics\nBackground in data mining and statistical analysis\nExcellent pattern recognition and predictive modeling skills\nExperience with programming languages such as Java/Python, SAS, R, Spark, Scala, Mathematica, etc., and the understanding of their limitations\nStrong interpersonal skills and the ability to build and maintain relationships with co-workers, customers, and colleagues\n\nWhy join us?\n\nRecognized as one of Austin's best companies to work for we are an extremely employee-centric company. We provide comprehensive benefits package including medical, dental, vision, and a 401k matching plan. We have an onsite gym featuring a fitness instructors, yoga classes, and an indoor basketball court and we even have a vacation home at the beach and in the mountains for employee use.\n\nInterested in hearing more? Easy Apply now by clicking the \"Apply Now\" button.\nTo apply to this job, click Apply Now"}}